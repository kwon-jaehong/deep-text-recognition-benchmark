{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21895a42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use multi-GPU setting ------\n",
      "if you stuck too long time with multi-GPU setting, try to set --workers 0\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
      "epoch : 0 [0/23] Train loss: 7.82387,Valid loss: 7.82160, time : 27.48381519317627 lr : 1\n",
      "epoch : 0 [1/23] Train loss: 7.68975,Valid loss: 7.77373, time : 7.67116117477417 lr : 1\n",
      "epoch : 0 [2/23] Train loss: 7.53181,Valid loss: 7.67954, time : 7.454776763916016 lr : 1\n",
      "epoch : 0 [3/23] Train loss: 7.32899,Valid loss: 7.53975, time : 7.568933486938477 lr : 1\n",
      "epoch : 0 [4/23] Train loss: 7.08693,Valid loss: 7.26721, time : 7.549732446670532 lr : 1\n",
      "epoch : 0 [5/23] Train loss: 6.80533,Valid loss: 6.87814, time : 7.360023260116577 lr : 1\n",
      "epoch : 0 [6/23] Train loss: 6.52310,Valid loss: 6.60615, time : 7.6156158447265625 lr : 1\n",
      "epoch : 0 [7/23] Train loss: 6.34041,Valid loss: 6.40934, time : 7.676161766052246 lr : 1\n",
      "epoch : 0 [8/23] Train loss: 6.19131,Valid loss: 6.29193, time : 7.684175968170166 lr : 1\n",
      "epoch : 0 [9/23] Train loss: 6.08383,Valid loss: 6.11145, time : 7.659600019454956 lr : 1\n",
      "epoch : 0 [10/23] Train loss: 5.97403,Valid loss: 6.09932, time : 7.886864423751831 lr : 1\n",
      "epoch : 0 [11/23] Train loss: 5.86949,Valid loss: 5.93356, time : 8.233905553817749 lr : 1\n",
      "epoch : 0 [12/23] Train loss: 5.77907,Valid loss: 5.96108, time : 7.872765064239502 lr : 1\n",
      "epoch : 0 [13/23] Train loss: 5.66613,Valid loss: 5.74218, time : 8.18614673614502 lr : 1\n",
      "epoch : 0 [14/23] Train loss: 5.58045,Valid loss: 5.79743, time : 8.064604997634888 lr : 1\n",
      "epoch : 0 [15/23] Train loss: 5.49276,Valid loss: 5.64819, time : 7.86172890663147 lr : 1\n",
      "epoch : 0 [16/23] Train loss: 5.41918,Valid loss: 5.69080, time : 7.996068477630615 lr : 1\n",
      "epoch : 0 [17/23] Train loss: 5.34705,Valid loss: 5.57005, time : 8.229593515396118 lr : 1\n",
      "epoch : 0 [18/23] Train loss: 5.29865,Valid loss: 5.65865, time : 8.324965000152588 lr : 1\n",
      "epoch : 0 [19/23] Train loss: 5.27332,Valid loss: 5.47214, time : 8.29816722869873 lr : 1\n",
      "epoch : 0 [20/23] Train loss: 5.22815,Valid loss: 5.54031, time : 8.126383781433105 lr : 1\n",
      "epoch : 0 [21/23] Train loss: 5.16561,Valid loss: 5.45495, time : 8.346001148223877 lr : 1\n",
      "epoch : 0 [22/23] Train loss: 5.16475,Valid loss: 5.48227, time : 19.54509162902832 lr : 1\n",
      "epoch : 1 [0/23] Train loss: 5.11285,Valid loss: 5.40370, time : 9.321238040924072 lr : 0.99\n",
      "epoch : 1 [1/23] Train loss: 5.10631,Valid loss: 5.42518, time : 9.028465986251831 lr : 0.99\n",
      "epoch : 1 [2/23] Train loss: 5.06346,Valid loss: 5.40835, time : 8.425673484802246 lr : 0.99\n",
      "epoch : 1 [3/23] Train loss: 5.05120,Valid loss: 5.35738, time : 8.95152997970581 lr : 0.99\n",
      "epoch : 1 [4/23] Train loss: 5.02689,Valid loss: 5.39957, time : 8.58414912223816 lr : 0.99\n",
      "epoch : 1 [5/23] Train loss: 5.02124,Valid loss: 5.30058, time : 8.440105438232422 lr : 0.99\n",
      "epoch : 1 [6/23] Train loss: 5.01295,Valid loss: 5.38554, time : 8.731401443481445 lr : 0.99\n",
      "epoch : 1 [7/23] Train loss: 4.97421,Valid loss: 5.26153, time : 8.951784133911133 lr : 0.99\n",
      "epoch : 1 [8/23] Train loss: 4.97827,Valid loss: 5.35945, time : 8.71807312965393 lr : 0.99\n",
      "epoch : 1 [9/23] Train loss: 4.97604,Valid loss: 5.24823, time : 8.989634037017822 lr : 0.99\n",
      "epoch : 1 [10/23] Train loss: 4.96764,Valid loss: 5.34387, time : 8.622787952423096 lr : 0.99\n",
      "epoch : 1 [11/23] Train loss: 4.94400,Valid loss: 5.21443, time : 8.975782632827759 lr : 0.99\n",
      "epoch : 1 [12/23] Train loss: 4.93726,Valid loss: 5.34556, time : 8.762062549591064 lr : 0.99\n",
      "epoch : 1 [13/23] Train loss: 4.93434,Valid loss: 5.20908, time : 9.17604398727417 lr : 0.99\n",
      "epoch : 1 [14/23] Train loss: 4.93563,Valid loss: 5.35410, time : 8.988539695739746 lr : 0.99\n",
      "epoch : 1 [15/23] Train loss: 4.91315,Valid loss: 5.17173, time : 8.922892332077026 lr : 0.99\n",
      "epoch : 1 [16/23] Train loss: 4.93011,Valid loss: 5.29653, time : 9.016356468200684 lr : 0.99\n",
      "epoch : 1 [17/23] Train loss: 4.89954,Valid loss: 5.19029, time : 9.147818565368652 lr : 0.99\n",
      "epoch : 1 [18/23] Train loss: 4.89887,Valid loss: 5.29973, time : 8.67345643043518 lr : 0.99\n",
      "epoch : 1 [19/23] Train loss: 4.88481,Valid loss: 5.17824, time : 9.409127950668335 lr : 0.99\n",
      "epoch : 1 [20/23] Train loss: 4.88595,Valid loss: 5.31919, time : 9.015357494354248 lr : 0.99\n",
      "epoch : 1 [21/23] Train loss: 4.89472,Valid loss: 5.12760, time : 9.187502145767212 lr : 0.99\n",
      "epoch : 1 [22/23] Train loss: 4.89335,Valid loss: 5.29345, time : 8.407511472702026 lr : 0.99\n",
      "epoch : 2 [0/23] Train loss: 4.85993,Valid loss: 5.16307, time : 9.310733079910278 lr : 0.9801\n",
      "epoch : 2 [1/23] Train loss: 4.86970,Valid loss: 5.26132, time : 8.99932599067688 lr : 0.9801\n",
      "epoch : 2 [2/23] Train loss: 4.85152,Valid loss: 5.15729, time : 9.0694580078125 lr : 0.9801\n",
      "epoch : 2 [3/23] Train loss: 4.84540,Valid loss: 5.28461, time : 8.922358751296997 lr : 0.9801\n",
      "epoch : 2 [4/23] Train loss: 4.85392,Valid loss: 5.12610, time : 8.83776044845581 lr : 0.9801\n",
      "epoch : 2 [5/23] Train loss: 4.86746,Valid loss: 5.29362, time : 9.317954540252686 lr : 0.9801\n",
      "epoch : 2 [6/23] Train loss: 4.85798,Valid loss: 5.13469, time : 8.839941263198853 lr : 0.9801\n",
      "epoch : 2 [7/23] Train loss: 4.85521,Valid loss: 5.27798, time : 9.159214496612549 lr : 0.9801\n",
      "epoch : 2 [8/23] Train loss: 4.84480,Valid loss: 5.14209, time : 8.951016902923584 lr : 0.9801\n",
      "epoch : 2 [9/23] Train loss: 4.84640,Valid loss: 5.28771, time : 9.120766162872314 lr : 0.9801\n",
      "epoch : 2 [10/23] Train loss: 4.84317,Valid loss: 5.10731, time : 8.919919729232788 lr : 0.9801\n",
      "epoch : 2 [11/23] Train loss: 4.84797,Valid loss: 5.31917, time : 9.553324222564697 lr : 0.9801\n",
      "epoch : 2 [12/23] Train loss: 4.82884,Valid loss: 5.08551, time : 8.886186838150024 lr : 0.9801\n",
      "epoch : 2 [13/23] Train loss: 4.84001,Valid loss: 5.26325, time : 8.957523107528687 lr : 0.9801\n",
      "epoch : 2 [14/23] Train loss: 4.83268,Valid loss: 5.12722, time : 8.91132140159607 lr : 0.9801\n",
      "epoch : 2 [15/23] Train loss: 4.81709,Valid loss: 5.27945, time : 8.994528532028198 lr : 0.9801\n",
      "epoch : 2 [16/23] Train loss: 4.82565,Valid loss: 5.10033, time : 9.71265959739685 lr : 0.9801\n",
      "epoch : 2 [17/23] Train loss: 4.83363,Valid loss: 5.28349, time : 9.050398826599121 lr : 0.9801\n",
      "epoch : 2 [18/23] Train loss: 4.82838,Valid loss: 5.10562, time : 9.428607940673828 lr : 0.9801\n",
      "epoch : 2 [19/23] Train loss: 4.81804,Valid loss: 5.31346, time : 9.210912227630615 lr : 0.9801\n",
      "epoch : 2 [20/23] Train loss: 4.81333,Valid loss: 5.06534, time : 9.086527109146118 lr : 0.9801\n",
      "epoch : 2 [21/23] Train loss: 4.82609,Valid loss: 5.27579, time : 9.352175951004028 lr : 0.9801\n",
      "epoch : 2 [22/23] Train loss: 4.80130,Valid loss: 5.09860, time : 8.761726140975952 lr : 0.9801\n",
      "epoch : 3 [0/23] Train loss: 4.81289,Valid loss: 5.28834, time : 9.352946281433105 lr : 0.9702989999999999\n",
      "epoch : 3 [1/23] Train loss: 4.80483,Valid loss: 5.07749, time : 9.433722734451294 lr : 0.9702989999999999\n",
      "epoch : 3 [2/23] Train loss: 4.80801,Valid loss: 5.27301, time : 9.02340316772461 lr : 0.9702989999999999\n",
      "epoch : 3 [3/23] Train loss: 4.80553,Valid loss: 5.08125, time : 9.22389268875122 lr : 0.9702989999999999\n",
      "epoch : 3 [4/23] Train loss: 4.81314,Valid loss: 5.26700, time : 9.528515100479126 lr : 0.9702989999999999\n",
      "epoch : 3 [5/23] Train loss: 4.79044,Valid loss: 5.09713, time : 9.575742244720459 lr : 0.9702989999999999\n",
      "epoch : 3 [6/23] Train loss: 4.79593,Valid loss: 5.28249, time : 9.161189079284668 lr : 0.9702989999999999\n",
      "epoch : 3 [7/23] Train loss: 4.81459,Valid loss: 5.07595, time : 9.782050132751465 lr : 0.9702989999999999\n",
      "epoch : 3 [8/23] Train loss: 4.79997,Valid loss: 5.30721, time : 9.155803680419922 lr : 0.9702989999999999\n",
      "epoch : 3 [9/23] Train loss: 4.80156,Valid loss: 5.04435, time : 9.463011026382446 lr : 0.9702989999999999\n",
      "epoch : 3 [10/23] Train loss: 4.80773,Valid loss: 5.28653, time : 9.531157493591309 lr : 0.9702989999999999\n",
      "epoch : 3 [11/23] Train loss: 4.79487,Valid loss: 5.08490, time : 9.145158290863037 lr : 0.9702989999999999\n",
      "epoch : 3 [12/23] Train loss: 4.79634,Valid loss: 5.29126, time : 9.416457414627075 lr : 0.9702989999999999\n",
      "epoch : 3 [13/23] Train loss: 4.77737,Valid loss: 5.05034, time : 9.115483283996582 lr : 0.9702989999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3 [14/23] Train loss: 4.78862,Valid loss: 5.27709, time : 9.585374116897583 lr : 0.9702989999999999\n",
      "epoch : 3 [15/23] Train loss: 4.79550,Valid loss: 5.09032, time : 9.365378856658936 lr : 0.9702989999999999\n",
      "epoch : 3 [16/23] Train loss: 4.80214,Valid loss: 5.28174, time : 9.28157114982605 lr : 0.9702989999999999\n",
      "epoch : 3 [17/23] Train loss: 4.78857,Valid loss: 5.05898, time : 9.439975500106812 lr : 0.9702989999999999\n",
      "epoch : 3 [18/23] Train loss: 4.80499,Valid loss: 5.29412, time : 9.047627210617065 lr : 0.9702989999999999\n",
      "epoch : 3 [19/23] Train loss: 4.79327,Valid loss: 5.05423, time : 9.649041414260864 lr : 0.9702989999999999\n",
      "epoch : 3 [20/23] Train loss: 4.77644,Valid loss: 5.29620, time : 9.158173561096191 lr : 0.9702989999999999\n",
      "epoch : 3 [21/23] Train loss: 4.78347,Valid loss: 5.04830, time : 9.195147275924683 lr : 0.9702989999999999\n",
      "epoch : 3 [22/23] Train loss: 4.78916,Valid loss: 5.27585, time : 8.774902820587158 lr : 0.9702989999999999\n",
      "epoch : 4 [0/23] Train loss: 4.78750,Valid loss: 5.06407, time : 9.653303384780884 lr : 0.96059601\n",
      "epoch : 4 [1/23] Train loss: 4.78987,Valid loss: 5.28413, time : 9.597412586212158 lr : 0.96059601\n",
      "epoch : 4 [2/23] Train loss: 4.77389,Valid loss: 5.05717, time : 9.251754760742188 lr : 0.96059601\n",
      "epoch : 4 [3/23] Train loss: 4.78517,Valid loss: 5.29216, time : 9.195535659790039 lr : 0.96059601\n",
      "epoch : 4 [4/23] Train loss: 4.76858,Valid loss: 5.05127, time : 9.35458755493164 lr : 0.96059601\n",
      "epoch : 4 [5/23] Train loss: 4.77700,Valid loss: 5.30379, time : 9.274919271469116 lr : 0.96059601\n",
      "epoch : 4 [6/23] Train loss: 4.77839,Valid loss: 5.02400, time : 9.504740715026855 lr : 0.96059601\n",
      "epoch : 4 [7/23] Train loss: 4.78698,Valid loss: 5.27337, time : 9.464422464370728 lr : 0.96059601\n",
      "epoch : 4 [8/23] Train loss: 4.76556,Valid loss: 5.05818, time : 9.334809303283691 lr : 0.96059601\n",
      "epoch : 4 [9/23] Train loss: 4.78453,Valid loss: 5.26046, time : 9.113919734954834 lr : 0.96059601\n",
      "epoch : 4 [10/23] Train loss: 4.76170,Valid loss: 5.04284, time : 9.439532995223999 lr : 0.96059601\n",
      "epoch : 4 [11/23] Train loss: 4.76456,Valid loss: 5.29036, time : 9.464885234832764 lr : 0.96059601\n",
      "epoch : 4 [12/23] Train loss: 4.76403,Valid loss: 5.05629, time : 9.277111053466797 lr : 0.96059601\n",
      "epoch : 4 [13/23] Train loss: 4.76904,Valid loss: 5.29519, time : 9.546474933624268 lr : 0.96059601\n",
      "epoch : 4 [14/23] Train loss: 4.77138,Valid loss: 5.04226, time : 9.565043449401855 lr : 0.96059601\n",
      "epoch : 4 [15/23] Train loss: 4.76752,Valid loss: 5.28666, time : 9.789935827255249 lr : 0.96059601\n",
      "epoch : 4 [16/23] Train loss: 4.78411,Valid loss: 5.06466, time : 9.798554420471191 lr : 0.96059601\n",
      "epoch : 4 [17/23] Train loss: 4.77078,Valid loss: 5.27243, time : 9.344448804855347 lr : 0.96059601\n",
      "epoch : 4 [18/23] Train loss: 4.76299,Valid loss: 5.06600, time : 9.306709289550781 lr : 0.96059601\n",
      "epoch : 4 [19/23] Train loss: 4.76241,Valid loss: 5.26696, time : 9.780702114105225 lr : 0.96059601\n",
      "epoch : 4 [20/23] Train loss: 4.75751,Valid loss: 5.08956, time : 9.508845090866089 lr : 0.96059601\n",
      "epoch : 4 [21/23] Train loss: 4.77856,Valid loss: 5.28332, time : 9.676408290863037 lr : 0.96059601\n",
      "epoch : 4 [22/23] Train loss: 4.76743,Valid loss: 5.01588, time : 8.93384861946106 lr : 0.96059601\n",
      "epoch : 5 [0/23] Train loss: 4.78042,Valid loss: 5.30990, time : 9.563223600387573 lr : 0.9509900498999999\n",
      "epoch : 5 [1/23] Train loss: 4.76454,Valid loss: 5.02742, time : 9.314034700393677 lr : 0.9509900498999999\n",
      "epoch : 5 [2/23] Train loss: 4.78767,Valid loss: 5.26087, time : 9.481079339981079 lr : 0.9509900498999999\n",
      "epoch : 5 [3/23] Train loss: 4.75462,Valid loss: 5.10661, time : 9.417628049850464 lr : 0.9509900498999999\n",
      "epoch : 5 [4/23] Train loss: 4.74956,Valid loss: 5.24013, time : 9.596174240112305 lr : 0.9509900498999999\n",
      "epoch : 5 [5/23] Train loss: 4.75472,Valid loss: 5.09366, time : 9.280527353286743 lr : 0.9509900498999999\n",
      "epoch : 5 [6/23] Train loss: 4.76405,Valid loss: 5.30291, time : 9.334944725036621 lr : 0.9509900498999999\n",
      "epoch : 5 [7/23] Train loss: 4.76104,Valid loss: 4.96269, time : 9.529037714004517 lr : 0.9509900498999999\n",
      "epoch : 5 [8/23] Train loss: 4.77888,Valid loss: 5.25834, time : 9.50680685043335 lr : 0.9509900498999999\n",
      "epoch : 5 [9/23] Train loss: 4.75311,Valid loss: 5.06097, time : 9.432065725326538 lr : 0.9509900498999999\n",
      "epoch : 5 [10/23] Train loss: 4.73871,Valid loss: 5.24880, time : 9.856337308883667 lr : 0.9509900498999999\n",
      "epoch : 5 [11/23] Train loss: 4.74814,Valid loss: 5.05823, time : 9.388924360275269 lr : 0.9509900498999999\n",
      "epoch : 5 [12/23] Train loss: 4.75112,Valid loss: 5.28998, time : 9.544898271560669 lr : 0.9509900498999999\n",
      "epoch : 5 [13/23] Train loss: 4.75590,Valid loss: 4.99871, time : 9.396570920944214 lr : 0.9509900498999999\n",
      "epoch : 5 [14/23] Train loss: 4.77647,Valid loss: 5.28637, time : 9.503938913345337 lr : 0.9509900498999999\n",
      "epoch : 5 [15/23] Train loss: 4.75913,Valid loss: 5.04175, time : 9.422169923782349 lr : 0.9509900498999999\n",
      "epoch : 5 [16/23] Train loss: 4.75627,Valid loss: 5.25196, time : 9.765883445739746 lr : 0.9509900498999999\n",
      "epoch : 5 [17/23] Train loss: 4.74457,Valid loss: 5.05752, time : 9.381523132324219 lr : 0.9509900498999999\n",
      "epoch : 5 [18/23] Train loss: 4.76699,Valid loss: 5.31066, time : 9.3332998752594 lr : 0.9509900498999999\n",
      "epoch : 5 [19/23] Train loss: 4.74604,Valid loss: 4.96121, time : 9.79827332496643 lr : 0.9509900498999999\n",
      "epoch : 5 [20/23] Train loss: 4.77226,Valid loss: 5.23918, time : 9.154041290283203 lr : 0.9509900498999999\n",
      "epoch : 5 [21/23] Train loss: 4.76155,Valid loss: 5.07638, time : 9.770111083984375 lr : 0.9509900498999999\n",
      "epoch : 5 [22/23] Train loss: 4.72632,Valid loss: 5.25353, time : 9.010584115982056 lr : 0.9509900498999999\n",
      "epoch : 6 [0/23] Train loss: 4.73739,Valid loss: 5.01647, time : 9.563097476959229 lr : 0.9414801494009999\n",
      "epoch : 6 [1/23] Train loss: 4.75525,Valid loss: 5.30740, time : 9.539551734924316 lr : 0.9414801494009999\n",
      "epoch : 6 [2/23] Train loss: 4.75680,Valid loss: 4.96915, time : 9.109318971633911 lr : 0.9414801494009999\n",
      "epoch : 6 [3/23] Train loss: 4.76008,Valid loss: 5.27460, time : 9.311460256576538 lr : 0.9414801494009999\n",
      "epoch : 6 [4/23] Train loss: 4.75193,Valid loss: 5.03944, time : 9.158313989639282 lr : 0.9414801494009999\n",
      "epoch : 6 [5/23] Train loss: 4.72970,Valid loss: 5.24027, time : 9.712271213531494 lr : 0.9414801494009999\n",
      "epoch : 6 [6/23] Train loss: 4.73238,Valid loss: 4.99143, time : 9.265703678131104 lr : 0.9414801494009999\n",
      "epoch : 6 [7/23] Train loss: 4.75261,Valid loss: 5.30124, time : 9.578488826751709 lr : 0.9414801494009999\n",
      "epoch : 6 [8/23] Train loss: 4.74810,Valid loss: 4.95348, time : 9.855072498321533 lr : 0.9414801494009999\n",
      "epoch : 6 [9/23] Train loss: 4.75855,Valid loss: 5.19553, time : 9.471513509750366 lr : 0.9414801494009999\n",
      "epoch : 6 [10/23] Train loss: 4.73451,Valid loss: 5.05031, time : 9.801399230957031 lr : 0.9414801494009999\n",
      "epoch : 6 [11/23] Train loss: 4.73857,Valid loss: 5.19750, time : 10.000813722610474 lr : 0.9414801494009999\n",
      "epoch : 6 [12/23] Train loss: 4.73322,Valid loss: 4.95166, time : 9.451076030731201 lr : 0.9414801494009999\n",
      "epoch : 6 [13/23] Train loss: 4.77194,Valid loss: 5.15322, time : 10.000603675842285 lr : 0.9414801494009999\n",
      "epoch : 6 [14/23] Train loss: 4.73904,Valid loss: 5.02127, time : 9.546009063720703 lr : 0.9414801494009999\n",
      "epoch : 6 [15/23] Train loss: 4.73054,Valid loss: 5.21432, time : 9.608937501907349 lr : 0.9414801494009999\n",
      "epoch : 6 [16/23] Train loss: 4.72788,Valid loss: 4.92986, time : 9.401267051696777 lr : 0.9414801494009999\n",
      "epoch : 6 [17/23] Train loss: 4.77515,Valid loss: 5.24501, time : 9.278995037078857 lr : 0.9414801494009999\n",
      "epoch : 6 [18/23] Train loss: 4.73550,Valid loss: 4.96668, time : 9.454029083251953 lr : 0.9414801494009999\n",
      "epoch : 6 [19/23] Train loss: 4.74773,Valid loss: 5.18267, time : 9.666904926300049 lr : 0.9414801494009999\n",
      "epoch : 6 [20/23] Train loss: 4.72947,Valid loss: 4.96213, time : 9.170790910720825 lr : 0.9414801494009999\n",
      "epoch : 6 [21/23] Train loss: 4.72777,Valid loss: 5.22772, time : 9.437434196472168 lr : 0.9414801494009999\n",
      "epoch : 6 [22/23] Train loss: 4.70869,Valid loss: 4.93225, time : 8.957553625106812 lr : 0.9414801494009999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 7 [0/23] Train loss: 4.73935,Valid loss: 5.16746, time : 9.60843801498413 lr : 0.9320653479069899\n",
      "epoch : 7 [1/23] Train loss: 4.72964,Valid loss: 4.96637, time : 9.53887677192688 lr : 0.9320653479069899\n",
      "epoch : 7 [2/23] Train loss: 4.75169,Valid loss: 5.16153, time : 9.503590106964111 lr : 0.9320653479069899\n",
      "epoch : 7 [3/23] Train loss: 4.72844,Valid loss: 4.98539, time : 9.889378547668457 lr : 0.9320653479069899\n",
      "epoch : 7 [4/23] Train loss: 4.72236,Valid loss: 5.23827, time : 9.450141429901123 lr : 0.9320653479069899\n",
      "epoch : 7 [5/23] Train loss: 4.72143,Valid loss: 4.92456, time : 9.707441091537476 lr : 0.9320653479069899\n",
      "epoch : 7 [6/23] Train loss: 4.73809,Valid loss: 5.13846, time : 9.494905710220337 lr : 0.9320653479069899\n",
      "epoch : 7 [7/23] Train loss: 4.71569,Valid loss: 4.96715, time : 9.607858896255493 lr : 0.9320653479069899\n",
      "epoch : 7 [8/23] Train loss: 4.72471,Valid loss: 5.11072, time : 9.507297992706299 lr : 0.9320653479069899\n",
      "epoch : 7 [9/23] Train loss: 4.71596,Valid loss: 4.92910, time : 9.86860179901123 lr : 0.9320653479069899\n",
      "epoch : 7 [10/23] Train loss: 4.73447,Valid loss: 5.19795, time : 9.66463851928711 lr : 0.9320653479069899\n",
      "epoch : 7 [11/23] Train loss: 4.73802,Valid loss: 4.89133, time : 9.878092288970947 lr : 0.9320653479069899\n",
      "epoch : 7 [12/23] Train loss: 4.77211,Valid loss: 5.12151, time : 9.232942819595337 lr : 0.9320653479069899\n",
      "epoch : 7 [13/23] Train loss: 4.73143,Valid loss: 4.99809, time : 9.792726993560791 lr : 0.9320653479069899\n",
      "epoch : 7 [14/23] Train loss: 4.69985,Valid loss: 5.05736, time : 9.756750583648682 lr : 0.9320653479069899\n",
      "epoch : 7 [15/23] Train loss: 4.69581,Valid loss: 4.90108, time : 9.97713017463684 lr : 0.9320653479069899\n",
      "epoch : 7 [16/23] Train loss: 4.73230,Valid loss: 5.16172, time : 9.731860160827637 lr : 0.9320653479069899\n",
      "epoch : 7 [17/23] Train loss: 4.73619,Valid loss: 4.89859, time : 9.942134380340576 lr : 0.9320653479069899\n",
      "epoch : 7 [18/23] Train loss: 4.74673,Valid loss: 5.19256, time : 9.901402950286865 lr : 0.9320653479069899\n",
      "epoch : 7 [19/23] Train loss: 4.72967,Valid loss: 4.98233, time : 9.707897186279297 lr : 0.9320653479069899\n",
      "epoch : 7 [20/23] Train loss: 4.70061,Valid loss: 5.03794, time : 9.364607810974121 lr : 0.9320653479069899\n",
      "epoch : 7 [21/23] Train loss: 4.70618,Valid loss: 4.92610, time : 9.202492475509644 lr : 0.9320653479069899\n",
      "epoch : 7 [22/23] Train loss: 4.70807,Valid loss: 5.13055, time : 9.02918267250061 lr : 0.9320653479069899\n",
      "epoch : 8 [0/23] Train loss: 4.72223,Valid loss: 4.87268, time : 9.672849416732788 lr : 0.92274469442792\n",
      "epoch : 8 [1/23] Train loss: 4.75263,Valid loss: 5.06784, time : 9.294899463653564 lr : 0.92274469442792\n",
      "epoch : 8 [2/23] Train loss: 4.71805,Valid loss: 4.89654, time : 9.652007579803467 lr : 0.92274469442792\n",
      "epoch : 8 [3/23] Train loss: 4.72870,Valid loss: 5.10982, time : 9.488313436508179 lr : 0.92274469442792\n",
      "epoch : 8 [4/23] Train loss: 4.72076,Valid loss: 4.89983, time : 9.846110343933105 lr : 0.92274469442792\n",
      "epoch : 8 [5/23] Train loss: 4.74210,Valid loss: 5.13196, time : 9.216825485229492 lr : 0.92274469442792\n",
      "epoch : 8 [6/23] Train loss: 4.69589,Valid loss: 4.91879, time : 10.092661380767822 lr : 0.92274469442792\n",
      "epoch : 8 [7/23] Train loss: 4.69501,Valid loss: 5.15491, time : 9.980667352676392 lr : 0.92274469442792\n",
      "epoch : 8 [8/23] Train loss: 4.70753,Valid loss: 4.84827, time : 10.138606786727905 lr : 0.92274469442792\n",
      "epoch : 8 [9/23] Train loss: 4.81410,Valid loss: 5.10394, time : 9.421799182891846 lr : 0.92274469442792\n",
      "epoch : 8 [10/23] Train loss: 4.73414,Valid loss: 4.94845, time : 9.51789903640747 lr : 0.92274469442792\n",
      "epoch : 8 [11/23] Train loss: 4.69569,Valid loss: 4.99444, time : 9.765290975570679 lr : 0.92274469442792\n",
      "epoch : 8 [12/23] Train loss: 4.69757,Valid loss: 4.98873, time : 9.745864391326904 lr : 0.92274469442792\n",
      "epoch : 8 [13/23] Train loss: 4.68169,Valid loss: 4.95147, time : 9.377325773239136 lr : 0.92274469442792\n",
      "epoch : 8 [14/23] Train loss: 4.68424,Valid loss: 5.01644, time : 9.886109590530396 lr : 0.92274469442792\n",
      "epoch : 8 [15/23] Train loss: 4.70849,Valid loss: 4.94314, time : 9.926169872283936 lr : 0.92274469442792\n",
      "epoch : 8 [16/23] Train loss: 4.73870,Valid loss: 5.05646, time : 9.973954439163208 lr : 0.92274469442792\n",
      "epoch : 8 [17/23] Train loss: 4.71432,Valid loss: 4.85599, time : 9.377272605895996 lr : 0.92274469442792\n",
      "epoch : 8 [18/23] Train loss: 4.73877,Valid loss: 5.16907, time : 9.925123691558838 lr : 0.92274469442792\n",
      "epoch : 8 [19/23] Train loss: 4.70828,Valid loss: 4.87997, time : 9.934324502944946 lr : 0.92274469442792\n",
      "epoch : 8 [20/23] Train loss: 4.72649,Valid loss: 5.03105, time : 9.921040058135986 lr : 0.92274469442792\n",
      "epoch : 8 [21/23] Train loss: 4.68212,Valid loss: 4.88214, time : 9.838146448135376 lr : 0.92274469442792\n",
      "epoch : 8 [22/23] Train loss: 4.68815,Valid loss: 5.21487, time : 9.146124839782715 lr : 0.92274469442792\n",
      "epoch : 9 [0/23] Train loss: 4.74670,Valid loss: 4.84063, time : 9.594537019729614 lr : 0.9135172474836407\n",
      "epoch : 9 [1/23] Train loss: 4.75004,Valid loss: 5.03803, time : 10.104928731918335 lr : 0.9135172474836407\n",
      "epoch : 9 [2/23] Train loss: 4.70612,Valid loss: 4.93927, time : 9.794002532958984 lr : 0.9135172474836407\n",
      "epoch : 9 [3/23] Train loss: 4.70094,Valid loss: 5.03825, time : 9.904322862625122 lr : 0.9135172474836407\n",
      "epoch : 9 [4/23] Train loss: 4.68550,Valid loss: 4.88140, time : 9.635948181152344 lr : 0.9135172474836407\n",
      "epoch : 9 [5/23] Train loss: 4.68508,Valid loss: 5.14145, time : 9.396724462509155 lr : 0.9135172474836407\n",
      "epoch : 9 [6/23] Train loss: 4.71056,Valid loss: 4.82814, time : 9.747992515563965 lr : 0.9135172474836407\n",
      "epoch : 9 [7/23] Train loss: 4.74924,Valid loss: 5.03312, time : 9.704647302627563 lr : 0.9135172474836407\n",
      "epoch : 9 [8/23] Train loss: 4.68563,Valid loss: 4.93184, time : 9.765035629272461 lr : 0.9135172474836407\n",
      "epoch : 9 [9/23] Train loss: 4.69566,Valid loss: 5.00524, time : 10.038053750991821 lr : 0.9135172474836407\n",
      "epoch : 9 [10/23] Train loss: 4.67079,Valid loss: 4.86370, time : 10.020608901977539 lr : 0.9135172474836407\n",
      "epoch : 9 [11/23] Train loss: 4.69553,Valid loss: 5.09490, time : 9.893207550048828 lr : 0.9135172474836407\n",
      "epoch : 9 [12/23] Train loss: 4.70379,Valid loss: 4.81125, time : 9.50569486618042 lr : 0.9135172474836407\n",
      "epoch : 9 [13/23] Train loss: 4.76040,Valid loss: 4.99923, time : 9.506589889526367 lr : 0.9135172474836407\n",
      "epoch : 9 [14/23] Train loss: 4.70945,Valid loss: 4.92633, time : 9.644989728927612 lr : 0.9135172474836407\n",
      "epoch : 9 [15/23] Train loss: 4.68076,Valid loss: 4.94239, time : 9.48569369316101 lr : 0.9135172474836407\n",
      "epoch : 9 [16/23] Train loss: 4.67129,Valid loss: 4.92307, time : 9.481268167495728 lr : 0.9135172474836407\n",
      "epoch : 9 [17/23] Train loss: 4.67605,Valid loss: 4.96258, time : 10.176028728485107 lr : 0.9135172474836407\n",
      "epoch : 9 [18/23] Train loss: 4.67990,Valid loss: 4.87115, time : 9.898625612258911 lr : 0.9135172474836407\n",
      "epoch : 9 [19/23] Train loss: 4.73587,Valid loss: 5.10882, time : 9.485265493392944 lr : 0.9135172474836407\n",
      "epoch : 9 [20/23] Train loss: 4.70203,Valid loss: 4.89762, time : 9.526688814163208 lr : 0.9135172474836407\n",
      "epoch : 9 [21/23] Train loss: 4.74833,Valid loss: 5.05956, time : 9.86427092552185 lr : 0.9135172474836407\n",
      "epoch : 9 [22/23] Train loss: 4.70110,Valid loss: 4.87861, time : 9.19804835319519 lr : 0.9135172474836407\n",
      "epoch : 10 [0/23] Train loss: 4.69138,Valid loss: 5.00755, time : 10.177014112472534 lr : 0.9043820750088043\n",
      "epoch : 10 [1/23] Train loss: 4.67865,Valid loss: 4.84491, time : 9.668961524963379 lr : 0.9043820750088043\n",
      "epoch : 10 [2/23] Train loss: 4.69922,Valid loss: 5.06535, time : 9.506515264511108 lr : 0.9043820750088043\n",
      "epoch : 10 [3/23] Train loss: 4.69028,Valid loss: 4.82312, time : 9.823498249053955 lr : 0.9043820750088043\n",
      "epoch : 10 [4/23] Train loss: 4.76673,Valid loss: 5.02941, time : 9.618549585342407 lr : 0.9043820750088043\n",
      "epoch : 10 [5/23] Train loss: 4.69436,Valid loss: 4.89356, time : 9.740762948989868 lr : 0.9043820750088043\n",
      "epoch : 10 [6/23] Train loss: 4.65550,Valid loss: 4.97711, time : 9.931938886642456 lr : 0.9043820750088043\n",
      "epoch : 10 [7/23] Train loss: 4.64975,Valid loss: 4.83794, time : 9.826702117919922 lr : 0.9043820750088043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10 [8/23] Train loss: 4.68523,Valid loss: 5.07034, time : 9.398581743240356 lr : 0.9043820750088043\n",
      "epoch : 10 [9/23] Train loss: 4.68524,Valid loss: 4.82094, time : 9.485077142715454 lr : 0.9043820750088043\n",
      "epoch : 10 [10/23] Train loss: 4.75196,Valid loss: 4.97478, time : 9.490891456604004 lr : 0.9043820750088043\n",
      "epoch : 10 [11/23] Train loss: 4.68787,Valid loss: 4.93966, time : 9.904149293899536 lr : 0.9043820750088043\n",
      "epoch : 10 [12/23] Train loss: 4.67595,Valid loss: 4.94579, time : 9.342158794403076 lr : 0.9043820750088043\n",
      "epoch : 10 [13/23] Train loss: 4.66441,Valid loss: 4.87004, time : 9.922587156295776 lr : 0.9043820750088043\n",
      "epoch : 10 [14/23] Train loss: 4.68922,Valid loss: 5.00240, time : 9.340147495269775 lr : 0.9043820750088043\n",
      "epoch : 10 [15/23] Train loss: 4.69784,Valid loss: 4.82125, time : 9.913043975830078 lr : 0.9043820750088043\n",
      "epoch : 10 [16/23] Train loss: 4.72493,Valid loss: 5.07546, time : 9.58562707901001 lr : 0.9043820750088043\n",
      "epoch : 10 [17/23] Train loss: 4.66668,Valid loss: 4.85715, time : 9.901336193084717 lr : 0.9043820750088043\n",
      "epoch : 10 [18/23] Train loss: 4.66441,Valid loss: 5.12504, time : 9.763518571853638 lr : 0.9043820750088043\n",
      "epoch : 10 [19/23] Train loss: 4.68450,Valid loss: 4.87211, time : 9.80690622329712 lr : 0.9043820750088043\n",
      "epoch : 10 [20/23] Train loss: 4.71077,Valid loss: 4.97281, time : 9.634365797042847 lr : 0.9043820750088043\n",
      "epoch : 10 [21/23] Train loss: 4.66969,Valid loss: 4.87158, time : 9.573091745376587 lr : 0.9043820750088043\n",
      "epoch : 10 [22/23] Train loss: 4.66860,Valid loss: 5.05076, time : 9.505495071411133 lr : 0.9043820750088043\n",
      "epoch : 11 [0/23] Train loss: 4.65966,Valid loss: 4.84913, time : 10.166971683502197 lr : 0.8953382542587163\n",
      "epoch : 11 [1/23] Train loss: 4.67561,Valid loss: 4.94340, time : 9.88186240196228 lr : 0.8953382542587163\n",
      "epoch : 11 [2/23] Train loss: 4.66780,Valid loss: 4.80445, time : 9.588752269744873 lr : 0.8953382542587163\n",
      "epoch : 11 [3/23] Train loss: 4.68772,Valid loss: 4.96500, time : 9.665918588638306 lr : 0.8953382542587163\n",
      "epoch : 11 [4/23] Train loss: 4.69112,Valid loss: 4.89606, time : 9.739903450012207 lr : 0.8953382542587163\n",
      "epoch : 11 [5/23] Train loss: 4.69425,Valid loss: 4.98072, time : 9.631833791732788 lr : 0.8953382542587163\n",
      "epoch : 11 [6/23] Train loss: 4.67000,Valid loss: 4.85685, time : 9.880368709564209 lr : 0.8953382542587163\n",
      "epoch : 11 [7/23] Train loss: 4.67200,Valid loss: 5.03347, time : 9.869601011276245 lr : 0.8953382542587163\n",
      "epoch : 11 [8/23] Train loss: 4.70005,Valid loss: 4.79696, time : 9.82222843170166 lr : 0.8953382542587163\n",
      "epoch : 11 [9/23] Train loss: 4.71285,Valid loss: 5.00788, time : 9.807426452636719 lr : 0.8953382542587163\n",
      "epoch : 11 [10/23] Train loss: 4.66636,Valid loss: 4.84248, time : 9.720526933670044 lr : 0.8953382542587163\n",
      "epoch : 11 [11/23] Train loss: 4.64619,Valid loss: 4.94623, time : 9.612667322158813 lr : 0.8953382542587163\n",
      "epoch : 11 [12/23] Train loss: 4.67249,Valid loss: 4.78043, time : 10.006385564804077 lr : 0.8953382542587163\n",
      "epoch : 11 [13/23] Train loss: 4.72371,Valid loss: 4.96025, time : 9.67411470413208 lr : 0.8953382542587163\n",
      "epoch : 11 [14/23] Train loss: 4.67076,Valid loss: 4.98942, time : 9.814691066741943 lr : 0.8953382542587163\n",
      "epoch : 11 [15/23] Train loss: 4.66753,Valid loss: 4.94107, time : 10.268525838851929 lr : 0.8953382542587163\n",
      "epoch : 11 [16/23] Train loss: 4.66868,Valid loss: 4.89681, time : 9.649394273757935 lr : 0.8953382542587163\n",
      "epoch : 11 [17/23] Train loss: 4.70970,Valid loss: 4.95174, time : 9.566762208938599 lr : 0.8953382542587163\n",
      "epoch : 11 [18/23] Train loss: 4.66794,Valid loss: 4.82580, time : 9.91911005973816 lr : 0.8953382542587163\n",
      "epoch : 11 [19/23] Train loss: 4.63726,Valid loss: 5.08772, time : 9.675178527832031 lr : 0.8953382542587163\n",
      "epoch : 11 [20/23] Train loss: 4.64253,Valid loss: 4.81027, time : 9.887351274490356 lr : 0.8953382542587163\n",
      "epoch : 11 [21/23] Train loss: 4.67853,Valid loss: 5.29028, time : 9.667476415634155 lr : 0.8953382542587163\n",
      "epoch : 11 [22/23] Train loss: 4.65621,Valid loss: 4.85393, time : 9.395508766174316 lr : 0.8953382542587163\n",
      "epoch : 12 [0/23] Train loss: 4.65681,Valid loss: 4.98793, time : 9.83740782737732 lr : 0.8863848717161291\n",
      "epoch : 12 [1/23] Train loss: 4.65188,Valid loss: 4.79789, time : 10.032556056976318 lr : 0.8863848717161291\n",
      "epoch : 12 [2/23] Train loss: 4.71502,Valid loss: 4.88126, time : 10.077171325683594 lr : 0.8863848717161291\n",
      "epoch : 12 [3/23] Train loss: 4.62862,Valid loss: 4.89035, time : 9.46687650680542 lr : 0.8863848717161291\n",
      "epoch : 12 [4/23] Train loss: 4.63380,Valid loss: 4.84923, time : 9.356229066848755 lr : 0.8863848717161291\n",
      "epoch : 12 [5/23] Train loss: 4.63114,Valid loss: 4.98428, time : 9.715606927871704 lr : 0.8863848717161291\n",
      "epoch : 12 [6/23] Train loss: 4.66880,Valid loss: 4.92522, time : 9.78412914276123 lr : 0.8863848717161291\n",
      "epoch : 12 [7/23] Train loss: 4.67463,Valid loss: 4.90852, time : 10.233474493026733 lr : 0.8863848717161291\n",
      "epoch : 12 [8/23] Train loss: 4.71983,Valid loss: 4.98407, time : 9.80491304397583 lr : 0.8863848717161291\n",
      "epoch : 12 [9/23] Train loss: 4.65613,Valid loss: 4.83318, time : 10.165283918380737 lr : 0.8863848717161291\n",
      "epoch : 12 [10/23] Train loss: 4.63398,Valid loss: 4.89055, time : 10.471911430358887 lr : 0.8863848717161291\n",
      "epoch : 12 [11/23] Train loss: 4.64225,Valid loss: 4.77383, time : 10.666688919067383 lr : 0.8863848717161291\n",
      "epoch : 12 [12/23] Train loss: 4.68735,Valid loss: 5.03657, time : 9.983476877212524 lr : 0.8863848717161291\n",
      "epoch : 12 [13/23] Train loss: 4.66577,Valid loss: 4.81528, time : 10.45866870880127 lr : 0.8863848717161291\n",
      "epoch : 12 [14/23] Train loss: 4.66646,Valid loss: 4.96848, time : 10.753082275390625 lr : 0.8863848717161291\n",
      "epoch : 12 [15/23] Train loss: 4.65033,Valid loss: 4.78030, time : 10.048287391662598 lr : 0.8863848717161291\n",
      "epoch : 12 [16/23] Train loss: 4.65936,Valid loss: 4.88246, time : 10.024799346923828 lr : 0.8863848717161291\n",
      "epoch : 12 [17/23] Train loss: 4.63213,Valid loss: 4.77430, time : 10.785699605941772 lr : 0.8863848717161291\n",
      "epoch : 12 [18/23] Train loss: 4.69218,Valid loss: 4.86644, time : 9.929331064224243 lr : 0.8863848717161291\n",
      "epoch : 12 [19/23] Train loss: 4.63681,Valid loss: 4.79218, time : 10.60552167892456 lr : 0.8863848717161291\n",
      "epoch : 12 [20/23] Train loss: 4.61975,Valid loss: 4.94909, time : 9.986017227172852 lr : 0.8863848717161291\n",
      "epoch : 12 [21/23] Train loss: 4.63994,Valid loss: 4.80670, time : 10.124615907669067 lr : 0.8863848717161291\n",
      "epoch : 12 [22/23] Train loss: 4.69316,Valid loss: 4.98454, time : 9.423980712890625 lr : 0.8863848717161291\n",
      "epoch : 13 [0/23] Train loss: 4.64774,Valid loss: 4.75958, time : 10.461661100387573 lr : 0.8775210229989678\n",
      "epoch : 13 [1/23] Train loss: 4.65161,Valid loss: 4.92849, time : 9.962734937667847 lr : 0.8775210229989678\n",
      "epoch : 13 [2/23] Train loss: 4.65867,Valid loss: 4.77477, time : 10.237328052520752 lr : 0.8775210229989678\n",
      "epoch : 13 [3/23] Train loss: 4.66931,Valid loss: 4.91099, time : 10.413822412490845 lr : 0.8775210229989678\n",
      "epoch : 13 [4/23] Train loss: 4.63005,Valid loss: 4.87791, time : 9.816195011138916 lr : 0.8775210229989678\n",
      "epoch : 13 [5/23] Train loss: 4.63351,Valid loss: 4.85761, time : 10.012065172195435 lr : 0.8775210229989678\n",
      "epoch : 13 [6/23] Train loss: 4.62808,Valid loss: 4.79941, time : 9.758377075195312 lr : 0.8775210229989678\n",
      "epoch : 13 [7/23] Train loss: 4.65326,Valid loss: 4.93732, time : 9.533705472946167 lr : 0.8775210229989678\n",
      "epoch : 13 [8/23] Train loss: 4.64243,Valid loss: 4.78371, time : 9.802064180374146 lr : 0.8775210229989678\n",
      "epoch : 13 [9/23] Train loss: 4.61404,Valid loss: 4.88842, time : 9.728365898132324 lr : 0.8775210229989678\n",
      "epoch : 13 [10/23] Train loss: 4.62144,Valid loss: 4.76150, time : 9.55356478691101 lr : 0.8775210229989678\n",
      "epoch : 13 [11/23] Train loss: 4.66715,Valid loss: 4.96281, time : 9.560356616973877 lr : 0.8775210229989678\n",
      "epoch : 13 [12/23] Train loss: 4.63769,Valid loss: 4.75990, time : 9.918469905853271 lr : 0.8775210229989678\n",
      "epoch : 13 [13/23] Train loss: 4.66299,Valid loss: 5.02588, time : 9.459544897079468 lr : 0.8775210229989678\n",
      "epoch : 13 [14/23] Train loss: 4.63496,Valid loss: 4.78888, time : 9.638311386108398 lr : 0.8775210229989678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 13 [15/23] Train loss: 4.61675,Valid loss: 4.93284, time : 9.543246746063232 lr : 0.8775210229989678\n",
      "epoch : 13 [16/23] Train loss: 4.65134,Valid loss: 4.81176, time : 9.723329067230225 lr : 0.8775210229989678\n",
      "epoch : 13 [17/23] Train loss: 4.68124,Valid loss: 4.88591, time : 9.961178541183472 lr : 0.8775210229989678\n",
      "epoch : 13 [18/23] Train loss: 4.62272,Valid loss: 4.87030, time : 9.901655912399292 lr : 0.8775210229989678\n",
      "epoch : 13 [19/23] Train loss: 4.63609,Valid loss: 4.82992, time : 9.430723905563354 lr : 0.8775210229989678\n",
      "epoch : 13 [20/23] Train loss: 4.62249,Valid loss: 4.75798, time : 9.776795625686646 lr : 0.8775210229989678\n",
      "epoch : 13 [21/23] Train loss: 4.68888,Valid loss: 4.85344, time : 9.636003494262695 lr : 0.8775210229989678\n",
      "epoch : 13 [22/23] Train loss: 4.61771,Valid loss: 4.75323, time : 9.226398944854736 lr : 0.8775210229989678\n",
      "epoch : 14 [0/23] Train loss: 4.60679,Valid loss: 4.94306, time : 9.9016592502594 lr : 0.8687458127689781\n",
      "epoch : 14 [1/23] Train loss: 4.62430,Valid loss: 4.73467, time : 10.096808195114136 lr : 0.8687458127689781\n",
      "epoch : 14 [2/23] Train loss: 4.68834,Valid loss: 4.86610, time : 10.151250123977661 lr : 0.8687458127689781\n",
      "epoch : 14 [3/23] Train loss: 4.62404,Valid loss: 5.05110, time : 9.936363697052002 lr : 0.8687458127689781\n",
      "epoch : 14 [4/23] Train loss: 4.61153,Valid loss: 4.85252, time : 9.699862003326416 lr : 0.8687458127689781\n",
      "epoch : 14 [5/23] Train loss: 4.58976,Valid loss: 5.34197, time : 9.58258318901062 lr : 0.8687458127689781\n",
      "epoch : 14 [6/23] Train loss: 4.62454,Valid loss: 4.98652, time : 9.954446077346802 lr : 0.8687458127689781\n",
      "epoch : 14 [7/23] Train loss: 4.62422,Valid loss: 4.74349, time : 9.90463900566101 lr : 0.8687458127689781\n",
      "epoch : 14 [8/23] Train loss: 4.63569,Valid loss: 4.91212, time : 10.113186359405518 lr : 0.8687458127689781\n",
      "epoch : 14 [9/23] Train loss: 4.61108,Valid loss: 4.76725, time : 9.574493885040283 lr : 0.8687458127689781\n",
      "epoch : 14 [10/23] Train loss: 4.63660,Valid loss: 4.90915, time : 9.48626971244812 lr : 0.8687458127689781\n",
      "epoch : 14 [11/23] Train loss: 4.63224,Valid loss: 4.76497, time : 9.888686418533325 lr : 0.8687458127689781\n",
      "epoch : 14 [12/23] Train loss: 4.65851,Valid loss: 4.82154, time : 9.654722690582275 lr : 0.8687458127689781\n",
      "epoch : 14 [13/23] Train loss: 4.60636,Valid loss: 4.74876, time : 9.948434114456177 lr : 0.8687458127689781\n",
      "epoch : 14 [14/23] Train loss: 4.60041,Valid loss: 4.85217, time : 9.803681373596191 lr : 0.8687458127689781\n",
      "epoch : 14 [15/23] Train loss: 4.61743,Valid loss: 4.71659, time : 10.017517566680908 lr : 0.8687458127689781\n",
      "epoch : 14 [16/23] Train loss: 4.67885,Valid loss: 4.80819, time : 9.899861097335815 lr : 0.8687458127689781\n",
      "epoch : 14 [17/23] Train loss: 4.61181,Valid loss: 4.76348, time : 10.052888870239258 lr : 0.8687458127689781\n",
      "epoch : 14 [18/23] Train loss: 4.59062,Valid loss: 4.84055, time : 10.093711853027344 lr : 0.8687458127689781\n",
      "epoch : 14 [19/23] Train loss: 4.59920,Valid loss: 4.70319, time : 10.290647983551025 lr : 0.8687458127689781\n",
      "epoch : 14 [20/23] Train loss: 4.65519,Valid loss: 4.82642, time : 10.414279222488403 lr : 0.8687458127689781\n",
      "epoch : 14 [21/23] Train loss: 4.59222,Valid loss: 4.74125, time : 10.169951677322388 lr : 0.8687458127689781\n",
      "epoch : 14 [22/23] Train loss: 4.61005,Valid loss: 4.95004, time : 9.374271154403687 lr : 0.8687458127689781\n",
      "epoch : 15 [0/23] Train loss: 4.61777,Valid loss: 4.75343, time : 10.13351845741272 lr : 0.8600583546412883\n",
      "epoch : 15 [1/23] Train loss: 4.66650,Valid loss: 4.90156, time : 9.971531629562378 lr : 0.8600583546412883\n",
      "epoch : 15 [2/23] Train loss: 4.60207,Valid loss: 4.75824, time : 9.742228984832764 lr : 0.8600583546412883\n",
      "epoch : 15 [3/23] Train loss: 4.57747,Valid loss: 4.88894, time : 10.233756065368652 lr : 0.8600583546412883\n",
      "epoch : 15 [4/23] Train loss: 4.58646,Valid loss: 4.83245, time : 10.047605037689209 lr : 0.8600583546412883\n",
      "epoch : 15 [5/23] Train loss: 4.62169,Valid loss: 4.93425, time : 9.870129585266113 lr : 0.8600583546412883\n",
      "epoch : 15 [6/23] Train loss: 4.60954,Valid loss: 4.73451, time : 10.188970804214478 lr : 0.8600583546412883\n",
      "epoch : 15 [7/23] Train loss: 4.63482,Valid loss: 4.86135, time : 10.005231142044067 lr : 0.8600583546412883\n",
      "epoch : 15 [8/23] Train loss: 4.59857,Valid loss: 4.72932, time : 9.72158932685852 lr : 0.8600583546412883\n",
      "epoch : 15 [9/23] Train loss: 4.58959,Valid loss: 4.97247, time : 9.628318071365356 lr : 0.8600583546412883\n",
      "epoch : 15 [10/23] Train loss: 4.59375,Valid loss: 4.69962, time : 10.223193168640137 lr : 0.8600583546412883\n",
      "epoch : 15 [11/23] Train loss: 4.66258,Valid loss: 4.77359, time : 10.261552810668945 lr : 0.8600583546412883\n",
      "epoch : 15 [12/23] Train loss: 4.58305,Valid loss: 4.82745, time : 10.1255943775177 lr : 0.8600583546412883\n",
      "epoch : 15 [13/23] Train loss: 4.55749,Valid loss: 4.75759, time : 9.985398054122925 lr : 0.8600583546412883\n",
      "epoch : 15 [14/23] Train loss: 4.55255,Valid loss: 4.96664, time : 9.708388090133667 lr : 0.8600583546412883\n",
      "epoch : 15 [15/23] Train loss: 4.61095,Valid loss: 4.81098, time : 9.870763301849365 lr : 0.8600583546412883\n",
      "epoch : 15 [16/23] Train loss: 4.60525,Valid loss: 4.69360, time : 9.95010232925415 lr : 0.8600583546412883\n",
      "epoch : 15 [17/23] Train loss: 4.68979,Valid loss: 4.95768, time : 9.700910091400146 lr : 0.8600583546412883\n",
      "epoch : 15 [18/23] Train loss: 4.58506,Valid loss: 4.72763, time : 10.018148422241211 lr : 0.8600583546412883\n",
      "epoch : 15 [19/23] Train loss: 4.58160,Valid loss: 4.74938, time : 10.170428991317749 lr : 0.8600583546412883\n",
      "epoch : 15 [20/23] Train loss: 4.55650,Valid loss: 4.70847, time : 10.212272882461548 lr : 0.8600583546412883\n",
      "epoch : 15 [21/23] Train loss: 4.56068,Valid loss: 4.95429, time : 9.740535974502563 lr : 0.8600583546412883\n",
      "epoch : 15 [22/23] Train loss: 4.57812,Valid loss: 4.81470, time : 9.218809604644775 lr : 0.8600583546412883\n",
      "epoch : 16 [0/23] Train loss: 4.65684,Valid loss: 4.84731, time : 10.383036375045776 lr : 0.8514577710948754\n",
      "epoch : 16 [1/23] Train loss: 4.58023,Valid loss: 4.73706, time : 9.89722228050232 lr : 0.8514577710948754\n",
      "epoch : 16 [2/23] Train loss: 4.59552,Valid loss: 4.96796, time : 10.198126554489136 lr : 0.8514577710948754\n",
      "epoch : 16 [3/23] Train loss: 4.56855,Valid loss: 4.71796, time : 9.825209379196167 lr : 0.8514577710948754\n",
      "epoch : 16 [4/23] Train loss: 4.60117,Valid loss: 4.90760, time : 10.294755220413208 lr : 0.8514577710948754\n",
      "epoch : 16 [5/23] Train loss: 4.57187,Valid loss: 4.68763, time : 9.832063913345337 lr : 0.8514577710948754\n",
      "epoch : 16 [6/23] Train loss: 4.61413,Valid loss: 4.83317, time : 10.336962699890137 lr : 0.8514577710948754\n",
      "epoch : 16 [7/23] Train loss: 4.55976,Valid loss: 4.92440, time : 9.561150550842285 lr : 0.8514577710948754\n",
      "epoch : 16 [8/23] Train loss: 4.57052,Valid loss: 4.81698, time : 10.142264604568481 lr : 0.8514577710948754\n",
      "epoch : 16 [9/23] Train loss: 4.58792,Valid loss: 4.72419, time : 9.646770477294922 lr : 0.8514577710948754\n",
      "epoch : 16 [10/23] Train loss: 4.61170,Valid loss: 4.74541, time : 9.845072269439697 lr : 0.8514577710948754\n",
      "epoch : 16 [11/23] Train loss: 4.55803,Valid loss: 4.73237, time : 9.783898115158081 lr : 0.8514577710948754\n",
      "epoch : 16 [12/23] Train loss: 4.55820,Valid loss: 4.99871, time : 10.101322412490845 lr : 0.8514577710948754\n",
      "epoch : 16 [13/23] Train loss: 4.57391,Valid loss: 4.77257, time : 9.667739868164062 lr : 0.8514577710948754\n",
      "epoch : 16 [14/23] Train loss: 4.64867,Valid loss: 4.81661, time : 10.264127731323242 lr : 0.8514577710948754\n",
      "epoch : 16 [15/23] Train loss: 4.55299,Valid loss: 4.71367, time : 9.63143277168274 lr : 0.8514577710948754\n",
      "epoch : 16 [16/23] Train loss: 4.54083,Valid loss: 4.86317, time : 9.821638822555542 lr : 0.8514577710948754\n",
      "epoch : 16 [17/23] Train loss: 4.57270,Valid loss: 4.73049, time : 9.67992901802063 lr : 0.8514577710948754\n",
      "epoch : 16 [18/23] Train loss: 4.63998,Valid loss: 4.78999, time : 10.234583139419556 lr : 0.8514577710948754\n",
      "epoch : 16 [19/23] Train loss: 4.55525,Valid loss: 4.71271, time : 9.637009143829346 lr : 0.8514577710948754\n",
      "epoch : 16 [20/23] Train loss: 4.53336,Valid loss: 4.74914, time : 9.732148170471191 lr : 0.8514577710948754\n",
      "epoch : 16 [21/23] Train loss: 4.52895,Valid loss: 4.70001, time : 9.62195611000061 lr : 0.8514577710948754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 16 [22/23] Train loss: 4.53063,Valid loss: 4.80548, time : 9.365411043167114 lr : 0.8514577710948754\n",
      "epoch : 17 [0/23] Train loss: 4.54733,Valid loss: 4.77241, time : 10.19424057006836 lr : 0.8429431933839266\n",
      "epoch : 17 [1/23] Train loss: 4.61547,Valid loss: 4.77041, time : 9.858460426330566 lr : 0.8429431933839266\n",
      "epoch : 17 [2/23] Train loss: 4.56458,Valid loss: 4.87141, time : 10.161729097366333 lr : 0.8429431933839266\n",
      "epoch : 17 [3/23] Train loss: 4.59944,Valid loss: 4.75615, time : 9.71408724784851 lr : 0.8429431933839266\n",
      "epoch : 17 [4/23] Train loss: 4.52323,Valid loss: 4.71438, time : 9.916013479232788 lr : 0.8429431933839266\n",
      "epoch : 17 [5/23] Train loss: 4.53791,Valid loss: 4.73626, time : 9.584467649459839 lr : 0.8429431933839266\n",
      "epoch : 17 [6/23] Train loss: 4.56444,Valid loss: 4.66975, time : 9.830415487289429 lr : 0.8429431933839266\n",
      "epoch : 17 [7/23] Train loss: 4.63826,Valid loss: 4.72009, time : 9.725564002990723 lr : 0.8429431933839266\n",
      "epoch : 17 [8/23] Train loss: 4.52002,Valid loss: 4.71798, time : 9.925668716430664 lr : 0.8429431933839266\n",
      "epoch : 17 [9/23] Train loss: 4.51091,Valid loss: 4.74278, time : 9.74435830116272 lr : 0.8429431933839266\n",
      "epoch : 17 [10/23] Train loss: 4.52509,Valid loss: 4.74957, time : 9.780592918395996 lr : 0.8429431933839266\n",
      "epoch : 17 [11/23] Train loss: 4.52526,Valid loss: 4.80949, time : 9.59732699394226 lr : 0.8429431933839266\n",
      "epoch : 17 [12/23] Train loss: 4.52782,Valid loss: 4.76035, time : 10.03562331199646 lr : 0.8429431933839266\n",
      "epoch : 17 [13/23] Train loss: 4.59697,Valid loss: 5.01915, time : 9.563840627670288 lr : 0.8429431933839266\n",
      "epoch : 17 [14/23] Train loss: 4.52956,Valid loss: 4.77053, time : 9.983341217041016 lr : 0.8429431933839266\n",
      "epoch : 17 [15/23] Train loss: 4.57737,Valid loss: 5.12776, time : 9.82970929145813 lr : 0.8429431933839266\n",
      "epoch : 17 [16/23] Train loss: 4.51087,Valid loss: 4.80420, time : 10.184048414230347 lr : 0.8429431933839266\n",
      "epoch : 17 [17/23] Train loss: 4.54324,Valid loss: 5.04354, time : 9.910320043563843 lr : 0.8429431933839266\n",
      "epoch : 17 [18/23] Train loss: 4.54623,Valid loss: 4.69621, time : 10.010165214538574 lr : 0.8429431933839266\n",
      "epoch : 17 [19/23] Train loss: 4.60623,Valid loss: 4.77176, time : 9.82830286026001 lr : 0.8429431933839266\n",
      "epoch : 17 [20/23] Train loss: 4.53752,Valid loss: 4.69044, time : 9.73162055015564 lr : 0.8429431933839266\n",
      "epoch : 17 [21/23] Train loss: 4.50023,Valid loss: 4.71916, time : 9.993113040924072 lr : 0.8429431933839266\n",
      "epoch : 17 [22/23] Train loss: 4.50619,Valid loss: 5.03042, time : 9.352566957473755 lr : 0.8429431933839266\n",
      "epoch : 18 [0/23] Train loss: 4.53717,Valid loss: 4.75056, time : 9.939973831176758 lr : 0.8345137614500874\n",
      "epoch : 18 [1/23] Train loss: 4.54735,Valid loss: 4.71771, time : 10.088008880615234 lr : 0.8345137614500874\n",
      "epoch : 18 [2/23] Train loss: 4.54201,Valid loss: 4.88376, time : 9.715508699417114 lr : 0.8345137614500874\n",
      "epoch : 18 [3/23] Train loss: 4.61063,Valid loss: 4.81639, time : 9.878665208816528 lr : 0.8345137614500874\n",
      "epoch : 18 [4/23] Train loss: 4.50451,Valid loss: 4.78076, time : 10.103580236434937 lr : 0.8345137614500874\n",
      "epoch : 18 [5/23] Train loss: 4.49345,Valid loss: 4.75328, time : 9.840838193893433 lr : 0.8345137614500874\n",
      "epoch : 18 [6/23] Train loss: 4.51353,Valid loss: 4.93429, time : 9.792827606201172 lr : 0.8345137614500874\n",
      "epoch : 18 [7/23] Train loss: 4.55567,Valid loss: 4.77326, time : 9.621363639831543 lr : 0.8345137614500874\n",
      "epoch : 18 [8/23] Train loss: 4.53995,Valid loss: 4.71912, time : 9.477848052978516 lr : 0.8345137614500874\n",
      "epoch : 18 [9/23] Train loss: 4.55944,Valid loss: 4.72493, time : 9.833072185516357 lr : 0.8345137614500874\n",
      "epoch : 18 [10/23] Train loss: 4.50517,Valid loss: 4.70292, time : 9.66350793838501 lr : 0.8345137614500874\n",
      "epoch : 18 [11/23] Train loss: 4.49254,Valid loss: 4.79579, time : 10.025916576385498 lr : 0.8345137614500874\n",
      "epoch : 18 [12/23] Train loss: 4.53420,Valid loss: 4.73040, time : 9.931804418563843 lr : 0.8345137614500874\n",
      "epoch : 18 [13/23] Train loss: 4.60861,Valid loss: 4.69873, time : 9.586112022399902 lr : 0.8345137614500874\n",
      "epoch : 18 [14/23] Train loss: 4.49171,Valid loss: 4.71552, time : 9.687201499938965 lr : 0.8345137614500874\n",
      "epoch : 18 [15/23] Train loss: 4.47702,Valid loss: 4.98385, time : 10.041765451431274 lr : 0.8345137614500874\n",
      "epoch : 18 [16/23] Train loss: 4.46977,Valid loss: 4.77660, time : 10.008806943893433 lr : 0.8345137614500874\n",
      "epoch : 18 [17/23] Train loss: 4.47144,Valid loss: 5.43563, time : 9.65341854095459 lr : 0.8345137614500874\n",
      "epoch : 18 [18/23] Train loss: 4.49845,Valid loss: 4.86025, time : 9.63706660270691 lr : 0.8345137614500874\n",
      "epoch : 18 [19/23] Train loss: 4.57494,Valid loss: 4.76377, time : 9.824749946594238 lr : 0.8345137614500874\n",
      "epoch : 18 [20/23] Train loss: 4.51035,Valid loss: 4.66092, time : 9.693298816680908 lr : 0.8345137614500874\n",
      "epoch : 18 [21/23] Train loss: 4.51251,Valid loss: 4.73597, time : 9.565351963043213 lr : 0.8345137614500874\n",
      "epoch : 18 [22/23] Train loss: 4.48581,Valid loss: 4.67410, time : 9.465148687362671 lr : 0.8345137614500874\n",
      "epoch : 19 [0/23] Train loss: 4.50536,Valid loss: 4.76284, time : 10.315554857254028 lr : 0.8261686238355865\n",
      "epoch : 19 [1/23] Train loss: 4.49027,Valid loss: 4.65155, time : 9.88589882850647 lr : 0.8261686238355865\n",
      "epoch : 19 [2/23] Train loss: 4.52688,Valid loss: 4.72813, time : 10.160758018493652 lr : 0.8261686238355865\n",
      "epoch : 19 [3/23] Train loss: 4.46317,Valid loss: 4.68615, time : 9.88333010673523 lr : 0.8261686238355865\n",
      "epoch : 19 [4/23] Train loss: 4.44551,Valid loss: 4.70219, time : 10.258254766464233 lr : 0.8261686238355865\n",
      "epoch : 19 [5/23] Train loss: 4.47662,Valid loss: 4.84842, time : 9.995541095733643 lr : 0.8261686238355865\n",
      "epoch : 19 [6/23] Train loss: 4.55977,Valid loss: 4.70746, time : 10.028681993484497 lr : 0.8261686238355865\n",
      "epoch : 19 [7/23] Train loss: 4.45462,Valid loss: 4.65969, time : 9.879920244216919 lr : 0.8261686238355865\n",
      "epoch : 19 [8/23] Train loss: 4.45256,Valid loss: 4.75820, time : 10.240410566329956 lr : 0.8261686238355865\n",
      "epoch : 19 [9/23] Train loss: 4.48197,Valid loss: 4.64699, time : 10.251460552215576 lr : 0.8261686238355865\n",
      "epoch : 19 [10/23] Train loss: 4.54479,Valid loss: 4.81618, time : 10.200992822647095 lr : 0.8261686238355865\n",
      "epoch : 19 [11/23] Train loss: 4.46736,Valid loss: 4.69648, time : 9.892300367355347 lr : 0.8261686238355865\n",
      "epoch : 19 [12/23] Train loss: 4.56182,Valid loss: 4.79366, time : 10.303231716156006 lr : 0.8261686238355865\n",
      "epoch : 19 [13/23] Train loss: 4.47928,Valid loss: 4.68370, time : 9.799484729766846 lr : 0.8261686238355865\n",
      "epoch : 19 [14/23] Train loss: 4.47012,Valid loss: 5.02642, time : 9.65717077255249 lr : 0.8261686238355865\n",
      "epoch : 19 [15/23] Train loss: 4.51033,Valid loss: 4.62615, time : 10.096535444259644 lr : 0.8261686238355865\n",
      "epoch : 19 [16/23] Train loss: 4.59404,Valid loss: 4.72868, time : 10.380358695983887 lr : 0.8261686238355865\n",
      "epoch : 19 [17/23] Train loss: 4.48415,Valid loss: 4.66070, time : 10.076126098632812 lr : 0.8261686238355865\n",
      "epoch : 19 [18/23] Train loss: 4.43901,Valid loss: 4.72815, time : 9.935657024383545 lr : 0.8261686238355865\n",
      "epoch : 19 [19/23] Train loss: 4.43093,Valid loss: 4.64357, time : 9.84032940864563 lr : 0.8261686238355865\n",
      "epoch : 19 [20/23] Train loss: 4.42802,Valid loss: 5.19800, time : 9.95879054069519 lr : 0.8261686238355865\n",
      "epoch : 19 [21/23] Train loss: 4.47044,Valid loss: 4.85913, time : 9.983970403671265 lr : 0.8261686238355865\n",
      "epoch : 19 [22/23] Train loss: 4.54344,Valid loss: 4.77818, time : 9.88461184501648 lr : 0.8261686238355865\n",
      "epoch : 20 [0/23] Train loss: 4.46087,Valid loss: 4.65207, time : 10.407971858978271 lr : 0.8179069375972307\n",
      "epoch : 20 [1/23] Train loss: 4.49522,Valid loss: 4.69388, time : 10.581321477890015 lr : 0.8179069375972307\n",
      "epoch : 20 [2/23] Train loss: 4.43448,Valid loss: 4.70423, time : 10.019845962524414 lr : 0.8179069375972307\n",
      "epoch : 20 [3/23] Train loss: 4.45288,Valid loss: 4.74832, time : 10.096627473831177 lr : 0.8179069375972307\n",
      "epoch : 20 [4/23] Train loss: 4.48503,Valid loss: 4.73095, time : 9.701369524002075 lr : 0.8179069375972307\n",
      "epoch : 20 [5/23] Train loss: 4.53231,Valid loss: 4.68193, time : 9.999664306640625 lr : 0.8179069375972307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 20 [6/23] Train loss: 4.42280,Valid loss: 4.68617, time : 9.704082012176514 lr : 0.8179069375972307\n",
      "epoch : 20 [7/23] Train loss: 4.41322,Valid loss: 4.80679, time : 9.884323835372925 lr : 0.8179069375972307\n",
      "epoch : 20 [8/23] Train loss: 4.40233,Valid loss: 4.67968, time : 9.939080238342285 lr : 0.8179069375972307\n",
      "epoch : 20 [9/23] Train loss: 4.42086,Valid loss: 5.34613, time : 9.81077265739441 lr : 0.8179069375972307\n",
      "epoch : 20 [10/23] Train loss: 4.44990,Valid loss: 4.78227, time : 10.082409143447876 lr : 0.8179069375972307\n",
      "epoch : 20 [11/23] Train loss: 4.49321,Valid loss: 5.12420, time : 9.886804580688477 lr : 0.8179069375972307\n",
      "epoch : 20 [12/23] Train loss: 4.51188,Valid loss: 4.69509, time : 10.107235431671143 lr : 0.8179069375972307\n",
      "epoch : 20 [13/23] Train loss: 4.44114,Valid loss: 4.65674, time : 9.78658151626587 lr : 0.8179069375972307\n",
      "epoch : 20 [14/23] Train loss: 4.43112,Valid loss: 4.78943, time : 10.057554721832275 lr : 0.8179069375972307\n",
      "epoch : 20 [15/23] Train loss: 4.44537,Valid loss: 4.66659, time : 9.856470823287964 lr : 0.8179069375972307\n",
      "epoch : 20 [16/23] Train loss: 4.47424,Valid loss: 4.67285, time : 9.876451015472412 lr : 0.8179069375972307\n",
      "epoch : 20 [17/23] Train loss: 4.43916,Valid loss: 4.62379, time : 10.025408029556274 lr : 0.8179069375972307\n",
      "epoch : 20 [18/23] Train loss: 4.47814,Valid loss: 4.67139, time : 9.82157015800476 lr : 0.8179069375972307\n",
      "epoch : 20 [19/23] Train loss: 4.43191,Valid loss: 4.63275, time : 9.72043752670288 lr : 0.8179069375972307\n",
      "epoch : 20 [20/23] Train loss: 4.42906,Valid loss: 4.64002, time : 9.853799819946289 lr : 0.8179069375972307\n",
      "epoch : 20 [21/23] Train loss: 4.44564,Valid loss: 4.68046, time : 9.873410940170288 lr : 0.8179069375972307\n",
      "epoch : 20 [22/23] Train loss: 4.53552,Valid loss: 4.69122, time : 9.758629560470581 lr : 0.8179069375972307\n",
      "epoch : 21 [0/23] Train loss: 4.38805,Valid loss: 4.63568, time : 10.479357719421387 lr : 0.8097278682212583\n",
      "epoch : 21 [1/23] Train loss: 4.39855,Valid loss: 4.60520, time : 9.909310817718506 lr : 0.8097278682212583\n",
      "epoch : 21 [2/23] Train loss: 4.38618,Valid loss: 4.63623, time : 10.318367719650269 lr : 0.8097278682212583\n",
      "epoch : 21 [3/23] Train loss: 4.38420,Valid loss: 4.61535, time : 9.708324193954468 lr : 0.8097278682212583\n",
      "epoch : 21 [4/23] Train loss: 4.40450,Valid loss: 5.59659, time : 10.11837363243103 lr : 0.8097278682212583\n",
      "epoch : 21 [5/23] Train loss: 4.42460,Valid loss: 4.89037, time : 9.817474365234375 lr : 0.8097278682212583\n",
      "epoch : 21 [6/23] Train loss: 4.42851,Valid loss: 5.31859, time : 9.885560989379883 lr : 0.8097278682212583\n",
      "epoch : 21 [7/23] Train loss: 4.46227,Valid loss: 4.76344, time : 9.948957443237305 lr : 0.8097278682212583\n",
      "epoch : 21 [8/23] Train loss: 4.43657,Valid loss: 4.70218, time : 10.062173843383789 lr : 0.8097278682212583\n",
      "epoch : 21 [9/23] Train loss: 4.54345,Valid loss: 4.67188, time : 10.01053786277771 lr : 0.8097278682212583\n",
      "epoch : 21 [10/23] Train loss: 4.41968,Valid loss: 4.64555, time : 9.893064260482788 lr : 0.8097278682212583\n",
      "epoch : 21 [11/23] Train loss: 4.39249,Valid loss: 4.64490, time : 9.84175419807434 lr : 0.8097278682212583\n",
      "epoch : 21 [12/23] Train loss: 4.38208,Valid loss: 4.60275, time : 10.316325664520264 lr : 0.8097278682212583\n",
      "epoch : 21 [13/23] Train loss: 4.37408,Valid loss: 4.83128, time : 10.114288330078125 lr : 0.8097278682212583\n",
      "epoch : 21 [14/23] Train loss: 4.40223,Valid loss: 4.65784, time : 10.096076488494873 lr : 0.8097278682212583\n",
      "epoch : 21 [15/23] Train loss: 4.50945,Valid loss: 4.64302, time : 10.607355833053589 lr : 0.8097278682212583\n",
      "epoch : 21 [16/23] Train loss: 4.40630,Valid loss: 4.60474, time : 10.115809917449951 lr : 0.8097278682212583\n",
      "epoch : 21 [17/23] Train loss: 4.37575,Valid loss: 4.79049, time : 10.26036787033081 lr : 0.8097278682212583\n",
      "epoch : 21 [18/23] Train loss: 4.37729,Valid loss: 4.61312, time : 9.80456805229187 lr : 0.8097278682212583\n",
      "epoch : 21 [19/23] Train loss: 4.45227,Valid loss: 4.71497, time : 9.99823546409607 lr : 0.8097278682212583\n",
      "epoch : 21 [20/23] Train loss: 4.36844,Valid loss: 4.61380, time : 10.088667869567871 lr : 0.8097278682212583\n",
      "epoch : 21 [21/23] Train loss: 4.37231,Valid loss: 4.86013, time : 9.847180366516113 lr : 0.8097278682212583\n",
      "epoch : 21 [22/23] Train loss: 4.38916,Valid loss: 4.57146, time : 9.4779953956604 lr : 0.8097278682212583\n",
      "epoch : 22 [0/23] Train loss: 4.46624,Valid loss: 4.62385, time : 10.227022409439087 lr : 0.8016305895390458\n",
      "epoch : 22 [1/23] Train loss: 4.38073,Valid loss: 4.59807, time : 9.876712322235107 lr : 0.8016305895390458\n",
      "epoch : 22 [2/23] Train loss: 4.33302,Valid loss: 4.64147, time : 9.944332599639893 lr : 0.8016305895390458\n",
      "epoch : 22 [3/23] Train loss: 4.32491,Valid loss: 4.65244, time : 9.91755723953247 lr : 0.8016305895390458\n",
      "epoch : 22 [4/23] Train loss: 4.33622,Valid loss: 4.73951, time : 9.628643989562988 lr : 0.8016305895390458\n",
      "epoch : 22 [5/23] Train loss: 4.33454,Valid loss: 4.65532, time : 10.230556011199951 lr : 0.8016305895390458\n",
      "epoch : 22 [6/23] Train loss: 4.44414,Valid loss: 4.61619, time : 9.935827016830444 lr : 0.8016305895390458\n",
      "epoch : 22 [7/23] Train loss: 4.53001,Valid loss: 4.61470, time : 10.151912450790405 lr : 0.8016305895390458\n",
      "epoch : 22 [8/23] Train loss: 4.36051,Valid loss: 4.58612, time : 9.912984609603882 lr : 0.8016305895390458\n",
      "epoch : 22 [9/23] Train loss: 4.36009,Valid loss: 4.66541, time : 10.241830348968506 lr : 0.8016305895390458\n",
      "epoch : 22 [10/23] Train loss: 4.37506,Valid loss: 4.70350, time : 10.215959310531616 lr : 0.8016305895390458\n",
      "epoch : 22 [11/23] Train loss: 4.40911,Valid loss: 4.64094, time : 9.999784708023071 lr : 0.8016305895390458\n",
      "epoch : 22 [12/23] Train loss: 4.35880,Valid loss: 4.57231, time : 9.755099296569824 lr : 0.8016305895390458\n",
      "epoch : 22 [13/23] Train loss: 4.39281,Valid loss: 4.57781, time : 10.245611429214478 lr : 0.8016305895390458\n",
      "epoch : 22 [14/23] Train loss: 4.35712,Valid loss: 4.67125, time : 9.873056888580322 lr : 0.8016305895390458\n",
      "epoch : 22 [15/23] Train loss: 4.40877,Valid loss: 4.86788, time : 10.164422035217285 lr : 0.8016305895390458\n",
      "epoch : 22 [16/23] Train loss: 4.33431,Valid loss: 4.78122, time : 10.15593671798706 lr : 0.8016305895390458\n",
      "epoch : 22 [17/23] Train loss: 4.35944,Valid loss: 5.12932, time : 10.205241918563843 lr : 0.8016305895390458\n",
      "epoch : 22 [18/23] Train loss: 4.36212,Valid loss: 4.60689, time : 9.955149412155151 lr : 0.8016305895390458\n",
      "epoch : 22 [19/23] Train loss: 4.44332,Valid loss: 4.65509, time : 10.030230522155762 lr : 0.8016305895390458\n",
      "epoch : 22 [20/23] Train loss: 4.34814,Valid loss: 4.85696, time : 9.838063716888428 lr : 0.8016305895390458\n",
      "epoch : 22 [21/23] Train loss: 4.32177,Valid loss: 4.64056, time : 10.249943017959595 lr : 0.8016305895390458\n",
      "epoch : 22 [22/23] Train loss: 4.31545,Valid loss: 5.32241, time : 9.559752941131592 lr : 0.8016305895390458\n",
      "epoch : 23 [0/23] Train loss: 4.35770,Valid loss: 4.67521, time : 10.327637910842896 lr : 0.7936142836436553\n",
      "epoch : 23 [1/23] Train loss: 4.35652,Valid loss: 4.74161, time : 10.428089618682861 lr : 0.7936142836436553\n",
      "epoch : 23 [2/23] Train loss: 4.38115,Valid loss: 4.59157, time : 9.73531198501587 lr : 0.7936142836436553\n",
      "epoch : 23 [3/23] Train loss: 4.31651,Valid loss: 4.59297, time : 9.740560054779053 lr : 0.7936142836436553\n",
      "epoch : 23 [4/23] Train loss: 4.32769,Valid loss: 4.74356, time : 9.923681020736694 lr : 0.7936142836436553\n",
      "epoch : 23 [5/23] Train loss: 4.32631,Valid loss: 4.58634, time : 9.689120531082153 lr : 0.7936142836436553\n",
      "epoch : 23 [6/23] Train loss: 4.39346,Valid loss: 4.61059, time : 10.10867691040039 lr : 0.7936142836436553\n",
      "epoch : 23 [7/23] Train loss: 4.29312,Valid loss: 4.57558, time : 9.770638704299927 lr : 0.7936142836436553\n",
      "epoch : 23 [8/23] Train loss: 4.29074,Valid loss: 4.61483, time : 10.275908470153809 lr : 0.7936142836436553\n",
      "epoch : 23 [9/23] Train loss: 4.31728,Valid loss: 4.59954, time : 9.728693962097168 lr : 0.7936142836436553\n",
      "epoch : 23 [10/23] Train loss: 4.38422,Valid loss: 5.04186, time : 10.18545413017273 lr : 0.7936142836436553\n",
      "epoch : 23 [11/23] Train loss: 4.32477,Valid loss: 4.73329, time : 9.653573989868164 lr : 0.7936142836436553\n",
      "epoch : 23 [12/23] Train loss: 4.36854,Valid loss: 5.07838, time : 9.749590158462524 lr : 0.7936142836436553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 23 [13/23] Train loss: 4.28160,Valid loss: 4.57842, time : 9.664170742034912 lr : 0.7936142836436553\n",
      "epoch : 23 [14/23] Train loss: 4.30368,Valid loss: 4.80207, time : 9.952964067459106 lr : 0.7936142836436553\n",
      "epoch : 23 [15/23] Train loss: 4.31713,Valid loss: 4.56997, time : 9.775465488433838 lr : 0.7936142836436553\n",
      "epoch : 23 [16/23] Train loss: 4.40526,Valid loss: 4.62012, time : 9.740365028381348 lr : 0.7936142836436553\n",
      "epoch : 23 [17/23] Train loss: 4.29592,Valid loss: 4.61872, time : 10.261738777160645 lr : 0.7936142836436553\n",
      "epoch : 23 [18/23] Train loss: 4.28891,Valid loss: 4.58205, time : 9.888136386871338 lr : 0.7936142836436553\n",
      "epoch : 23 [19/23] Train loss: 4.27288,Valid loss: 4.65093, time : 9.778077125549316 lr : 0.7936142836436553\n",
      "epoch : 23 [20/23] Train loss: 4.29355,Valid loss: 4.85666, time : 10.419614315032959 lr : 0.7936142836436553\n",
      "epoch : 23 [21/23] Train loss: 4.31620,Valid loss: 4.69186, time : 9.761819124221802 lr : 0.7936142836436553\n",
      "epoch : 23 [22/23] Train loss: 4.41343,Valid loss: 4.67169, time : 9.486127138137817 lr : 0.7936142836436553\n",
      "epoch : 24 [0/23] Train loss: 4.27378,Valid loss: 4.60613, time : 10.520512104034424 lr : 0.7856781408072188\n",
      "epoch : 24 [1/23] Train loss: 4.26007,Valid loss: 4.73206, time : 10.27029037475586 lr : 0.7856781408072188\n",
      "epoch : 24 [2/23] Train loss: 4.26748,Valid loss: 4.68588, time : 10.615962266921997 lr : 0.7856781408072188\n",
      "epoch : 24 [3/23] Train loss: 4.36841,Valid loss: 5.23879, time : 10.539829730987549 lr : 0.7856781408072188\n",
      "epoch : 24 [4/23] Train loss: 4.31554,Valid loss: 4.69018, time : 10.91445255279541 lr : 0.7856781408072188\n",
      "epoch : 24 [5/23] Train loss: 4.31615,Valid loss: 4.76496, time : 10.117817640304565 lr : 0.7856781408072188\n",
      "epoch : 24 [6/23] Train loss: 4.29098,Valid loss: 4.55121, time : 10.102625370025635 lr : 0.7856781408072188\n",
      "epoch : 24 [7/23] Train loss: 4.35566,Valid loss: 4.58531, time : 10.298009872436523 lr : 0.7856781408072188\n",
      "epoch : 24 [8/23] Train loss: 4.27879,Valid loss: 4.53821, time : 10.197996616363525 lr : 0.7856781408072188\n",
      "epoch : 24 [9/23] Train loss: 4.27921,Valid loss: 4.65177, time : 10.022404193878174 lr : 0.7856781408072188\n",
      "epoch : 24 [10/23] Train loss: 4.29077,Valid loss: 4.83551, time : 10.32427716255188 lr : 0.7856781408072188\n",
      "epoch : 24 [11/23] Train loss: 4.31248,Valid loss: 4.62474, time : 10.333513498306274 lr : 0.7856781408072188\n",
      "epoch : 24 [12/23] Train loss: 4.25482,Valid loss: 4.69474, time : 9.997671365737915 lr : 0.7856781408072188\n",
      "epoch : 24 [13/23] Train loss: 4.24888,Valid loss: 4.73915, time : 9.933502435684204 lr : 0.7856781408072188\n",
      "epoch : 24 [14/23] Train loss: 4.29041,Valid loss: 5.18786, time : 10.29761266708374 lr : 0.7856781408072188\n",
      "epoch : 24 [15/23] Train loss: 4.32595,Valid loss: 4.64713, time : 9.983709812164307 lr : 0.7856781408072188\n",
      "epoch : 24 [16/23] Train loss: 4.23300,Valid loss: 4.62834, time : 9.93464994430542 lr : 0.7856781408072188\n",
      "epoch : 24 [17/23] Train loss: 4.26389,Valid loss: 4.83266, time : 10.119448900222778 lr : 0.7856781408072188\n",
      "epoch : 24 [18/23] Train loss: 4.27117,Valid loss: 4.64092, time : 10.393048524856567 lr : 0.7856781408072188\n",
      "epoch : 24 [19/23] Train loss: 4.31839,Valid loss: 5.01403, time : 10.324992179870605 lr : 0.7856781408072188\n",
      "epoch : 24 [20/23] Train loss: 4.21542,Valid loss: 4.61602, time : 10.278097867965698 lr : 0.7856781408072188\n",
      "epoch : 24 [21/23] Train loss: 4.21797,Valid loss: 4.83600, time : 10.226219654083252 lr : 0.7856781408072188\n",
      "epoch : 24 [22/23] Train loss: 4.25806,Valid loss: 4.55305, time : 9.568236112594604 lr : 0.7856781408072188\n",
      "epoch : 25 [0/23] Train loss: 4.39718,Valid loss: 4.55824, time : 10.028485536575317 lr : 0.7778213593991465\n",
      "epoch : 25 [1/23] Train loss: 4.23998,Valid loss: 4.55646, time : 10.241437673568726 lr : 0.7778213593991465\n",
      "epoch : 25 [2/23] Train loss: 4.19893,Valid loss: 4.52210, time : 10.330837965011597 lr : 0.7778213593991465\n",
      "epoch : 25 [3/23] Train loss: 4.20344,Valid loss: 4.94949, time : 10.21081256866455 lr : 0.7778213593991465\n",
      "epoch : 25 [4/23] Train loss: 4.20703,Valid loss: 4.58170, time : 10.315200328826904 lr : 0.7778213593991465\n",
      "epoch : 25 [5/23] Train loss: 4.25545,Valid loss: 5.25521, time : 10.205094337463379 lr : 0.7778213593991465\n",
      "epoch : 25 [6/23] Train loss: 4.25179,Valid loss: 4.76869, time : 10.412168264389038 lr : 0.7778213593991465\n",
      "epoch : 25 [7/23] Train loss: 4.23877,Valid loss: 4.57100, time : 10.260955095291138 lr : 0.7778213593991465\n",
      "epoch : 25 [8/23] Train loss: 4.31340,Valid loss: 4.65023, time : 9.837444067001343 lr : 0.7778213593991465\n",
      "epoch : 25 [9/23] Train loss: 4.25890,Valid loss: 4.77436, time : 9.81939172744751 lr : 0.7778213593991465\n",
      "epoch : 25 [10/23] Train loss: 4.23672,Valid loss: 5.47099, time : 9.730196475982666 lr : 0.7778213593991465\n",
      "epoch : 25 [11/23] Train loss: 4.26010,Valid loss: 4.64861, time : 10.407634019851685 lr : 0.7778213593991465\n",
      "epoch : 25 [12/23] Train loss: 4.26714,Valid loss: 4.62766, time : 10.323745250701904 lr : 0.7778213593991465\n",
      "epoch : 25 [13/23] Train loss: 4.21374,Valid loss: 4.50531, time : 10.105286121368408 lr : 0.7778213593991465\n",
      "epoch : 25 [14/23] Train loss: 4.25773,Valid loss: 4.57839, time : 10.05237340927124 lr : 0.7778213593991465\n",
      "epoch : 25 [15/23] Train loss: 4.18060,Valid loss: 4.56009, time : 10.288150072097778 lr : 0.7778213593991465\n",
      "epoch : 25 [16/23] Train loss: 4.21491,Valid loss: 4.79209, time : 10.066799640655518 lr : 0.7778213593991465\n",
      "epoch : 25 [17/23] Train loss: 4.22736,Valid loss: 4.59389, time : 9.744261741638184 lr : 0.7778213593991465\n",
      "epoch : 25 [18/23] Train loss: 4.29781,Valid loss: 4.93651, time : 9.953044176101685 lr : 0.7778213593991465\n",
      "epoch : 25 [19/23] Train loss: 4.19210,Valid loss: 4.58311, time : 10.222282648086548 lr : 0.7778213593991465\n",
      "epoch : 25 [20/23] Train loss: 4.17621,Valid loss: 4.66368, time : 10.337632417678833 lr : 0.7778213593991465\n",
      "epoch : 25 [21/23] Train loss: 4.19457,Valid loss: 4.56472, time : 10.561800718307495 lr : 0.7778213593991465\n",
      "epoch : 25 [22/23] Train loss: 4.31807,Valid loss: 4.53884, time : 9.508681297302246 lr : 0.7778213593991465\n",
      "epoch : 26 [0/23] Train loss: 4.18710,Valid loss: 4.62325, time : 10.094629049301147 lr : 0.7700431458051551\n",
      "epoch : 26 [1/23] Train loss: 4.20095,Valid loss: 4.54972, time : 10.077324151992798 lr : 0.7700431458051551\n",
      "epoch : 26 [2/23] Train loss: 4.18665,Valid loss: 4.73038, time : 9.646552324295044 lr : 0.7700431458051551\n",
      "epoch : 26 [3/23] Train loss: 4.22488,Valid loss: 4.56300, time : 10.144274711608887 lr : 0.7700431458051551\n",
      "epoch : 26 [4/23] Train loss: 4.19998,Valid loss: 4.61538, time : 9.97175931930542 lr : 0.7700431458051551\n",
      "epoch : 26 [5/23] Train loss: 4.25422,Valid loss: 4.66424, time : 10.02204155921936 lr : 0.7700431458051551\n",
      "epoch : 26 [6/23] Train loss: 4.16001,Valid loss: 4.61067, time : 9.849432945251465 lr : 0.7700431458051551\n",
      "epoch : 26 [7/23] Train loss: 4.17869,Valid loss: 4.64771, time : 9.867647886276245 lr : 0.7700431458051551\n",
      "epoch : 26 [8/23] Train loss: 4.20158,Valid loss: 4.54592, time : 9.605581045150757 lr : 0.7700431458051551\n",
      "epoch : 26 [9/23] Train loss: 4.26505,Valid loss: 5.08365, time : 9.890796899795532 lr : 0.7700431458051551\n",
      "epoch : 26 [10/23] Train loss: 4.17797,Valid loss: 4.62528, time : 9.865995168685913 lr : 0.7700431458051551\n",
      "epoch : 26 [11/23] Train loss: 4.14365,Valid loss: 5.04745, time : 9.89878535270691 lr : 0.7700431458051551\n",
      "epoch : 26 [12/23] Train loss: 4.13330,Valid loss: 4.81891, time : 9.55997371673584 lr : 0.7700431458051551\n",
      "epoch : 26 [13/23] Train loss: 4.17971,Valid loss: 5.48245, time : 9.449517726898193 lr : 0.7700431458051551\n",
      "epoch : 26 [14/23] Train loss: 4.22469,Valid loss: 4.70925, time : 9.474669456481934 lr : 0.7700431458051551\n",
      "epoch : 26 [15/23] Train loss: 4.28743,Valid loss: 4.57317, time : 9.575881242752075 lr : 0.7700431458051551\n",
      "epoch : 26 [16/23] Train loss: 4.16709,Valid loss: 4.57794, time : 9.517518281936646 lr : 0.7700431458051551\n",
      "epoch : 26 [17/23] Train loss: 4.13608,Valid loss: 4.57988, time : 9.510558366775513 lr : 0.7700431458051551\n",
      "epoch : 26 [18/23] Train loss: 4.13250,Valid loss: 4.55139, time : 9.799162149429321 lr : 0.7700431458051551\n",
      "epoch : 26 [19/23] Train loss: 4.12895,Valid loss: 4.55899, time : 10.004701614379883 lr : 0.7700431458051551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 26 [20/23] Train loss: 4.13268,Valid loss: 4.46915, time : 9.978087425231934 lr : 0.7700431458051551\n",
      "epoch : 26 [21/23] Train loss: 4.22961,Valid loss: 4.86957, time : 10.096867084503174 lr : 0.7700431458051551\n",
      "epoch : 26 [22/23] Train loss: 4.13933,Valid loss: 4.57288, time : 9.350224018096924 lr : 0.7700431458051551\n",
      "epoch : 27 [0/23] Train loss: 4.17658,Valid loss: 4.73330, time : 10.646595001220703 lr : 0.7623427143471035\n",
      "epoch : 27 [1/23] Train loss: 4.18071,Valid loss: 4.52385, time : 9.627841711044312 lr : 0.7623427143471035\n",
      "epoch : 27 [2/23] Train loss: 4.24787,Valid loss: 4.63242, time : 9.7998948097229 lr : 0.7623427143471035\n",
      "epoch : 27 [3/23] Train loss: 4.15738,Valid loss: 4.60000, time : 9.820688486099243 lr : 0.7623427143471035\n",
      "epoch : 27 [4/23] Train loss: 4.14392,Valid loss: 4.69352, time : 10.477915287017822 lr : 0.7623427143471035\n",
      "epoch : 27 [5/23] Train loss: 4.15800,Valid loss: 4.74826, time : 9.997159242630005 lr : 0.7623427143471035\n",
      "epoch : 27 [6/23] Train loss: 4.17142,Valid loss: 4.59486, time : 10.258065223693848 lr : 0.7623427143471035\n",
      "epoch : 27 [7/23] Train loss: 4.11779,Valid loss: 4.57204, time : 10.3251371383667 lr : 0.7623427143471035\n",
      "epoch : 27 [8/23] Train loss: 4.13052,Valid loss: 4.73567, time : 10.415494918823242 lr : 0.7623427143471035\n",
      "epoch : 27 [9/23] Train loss: 4.12560,Valid loss: 4.87633, time : 10.034295558929443 lr : 0.7623427143471035\n",
      "epoch : 27 [10/23] Train loss: 4.19226,Valid loss: 5.30126, time : 10.449202299118042 lr : 0.7623427143471035\n",
      "epoch : 27 [11/23] Train loss: 4.11149,Valid loss: 4.64666, time : 9.894493579864502 lr : 0.7623427143471035\n",
      "epoch : 27 [12/23] Train loss: 4.18332,Valid loss: 4.62743, time : 10.167270421981812 lr : 0.7623427143471035\n",
      "epoch : 27 [13/23] Train loss: 4.13003,Valid loss: 4.46581, time : 10.092268228530884 lr : 0.7623427143471035\n",
      "epoch : 27 [14/23] Train loss: 4.17237,Valid loss: 4.63433, time : 10.118951559066772 lr : 0.7623427143471035\n",
      "epoch : 27 [15/23] Train loss: 4.09773,Valid loss: 4.49864, time : 10.430769920349121 lr : 0.7623427143471035\n",
      "epoch : 27 [16/23] Train loss: 4.18053,Valid loss: 4.75075, time : 10.48645567893982 lr : 0.7623427143471035\n",
      "epoch : 27 [17/23] Train loss: 4.09291,Valid loss: 4.51933, time : 10.211030960083008 lr : 0.7623427143471035\n",
      "epoch : 27 [18/23] Train loss: 4.11422,Valid loss: 4.66996, time : 10.318097114562988 lr : 0.7623427143471035\n",
      "epoch : 27 [19/23] Train loss: 4.09595,Valid loss: 4.79477, time : 10.110893726348877 lr : 0.7623427143471035\n",
      "epoch : 27 [20/23] Train loss: 4.18156,Valid loss: 4.64836, time : 10.026484966278076 lr : 0.7623427143471035\n",
      "epoch : 27 [21/23] Train loss: 4.08256,Valid loss: 4.63192, time : 10.13943600654602 lr : 0.7623427143471035\n",
      "epoch : 27 [22/23] Train loss: 4.07192,Valid loss: 4.57556, time : 9.706111192703247 lr : 0.7623427143471035\n",
      "epoch : 28 [0/23] Train loss: 4.07888,Valid loss: 4.61214, time : 9.982576370239258 lr : 0.7547192872036325\n",
      "epoch : 28 [1/23] Train loss: 4.11604,Valid loss: 4.56994, time : 10.331340312957764 lr : 0.7547192872036325\n",
      "epoch : 28 [2/23] Train loss: 4.11438,Valid loss: 4.53364, time : 9.491769313812256 lr : 0.7547192872036325\n",
      "epoch : 28 [3/23] Train loss: 4.15607,Valid loss: 4.78214, time : 9.757669925689697 lr : 0.7547192872036325\n",
      "epoch : 28 [4/23] Train loss: 4.07335,Valid loss: 4.52112, time : 9.695122718811035 lr : 0.7547192872036325\n",
      "epoch : 28 [5/23] Train loss: 4.06016,Valid loss: 4.96232, time : 9.958377838134766 lr : 0.7547192872036325\n",
      "epoch : 28 [6/23] Train loss: 4.09197,Valid loss: 4.50522, time : 10.226964950561523 lr : 0.7547192872036325\n",
      "epoch : 28 [7/23] Train loss: 4.15494,Valid loss: 4.71197, time : 9.974735260009766 lr : 0.7547192872036325\n",
      "epoch : 28 [8/23] Train loss: 4.05412,Valid loss: 4.54296, time : 10.142128467559814 lr : 0.7547192872036325\n",
      "epoch : 28 [9/23] Train loss: 4.06166,Valid loss: 4.62275, time : 9.947644233703613 lr : 0.7547192872036325\n",
      "epoch : 28 [10/23] Train loss: 4.07633,Valid loss: 5.16078, time : 9.984798431396484 lr : 0.7547192872036325\n",
      "epoch : 28 [11/23] Train loss: 4.15214,Valid loss: 4.69036, time : 9.993050575256348 lr : 0.7547192872036325\n",
      "epoch : 28 [12/23] Train loss: 4.06029,Valid loss: 4.86482, time : 9.975565433502197 lr : 0.7547192872036325\n",
      "epoch : 28 [13/23] Train loss: 4.07128,Valid loss: 4.66457, time : 10.126061201095581 lr : 0.7547192872036325\n",
      "epoch : 28 [14/23] Train loss: 4.08739,Valid loss: 5.08087, time : 9.890019655227661 lr : 0.7547192872036325\n",
      "epoch : 28 [15/23] Train loss: 4.12672,Valid loss: 4.54130, time : 9.991499900817871 lr : 0.7547192872036325\n",
      "epoch : 28 [16/23] Train loss: 4.09832,Valid loss: 4.68632, time : 10.3232581615448 lr : 0.7547192872036325\n",
      "epoch : 28 [17/23] Train loss: 4.09826,Valid loss: 4.68115, time : 10.164400339126587 lr : 0.7547192872036325\n",
      "epoch : 28 [18/23] Train loss: 4.11063,Valid loss: 4.74242, time : 10.315138339996338 lr : 0.7547192872036325\n",
      "epoch : 28 [19/23] Train loss: 4.28226,Valid loss: 4.68422, time : 10.263561487197876 lr : 0.7547192872036325\n",
      "epoch : 28 [20/23] Train loss: 4.13090,Valid loss: 4.52123, time : 10.12187671661377 lr : 0.7547192872036325\n",
      "epoch : 28 [21/23] Train loss: 4.08102,Valid loss: 4.55521, time : 10.240326881408691 lr : 0.7547192872036325\n",
      "epoch : 28 [22/23] Train loss: 4.04592,Valid loss: 4.44557, time : 9.47937822341919 lr : 0.7547192872036325\n",
      "epoch : 29 [0/23] Train loss: 4.02900,Valid loss: 4.69829, time : 10.546655416488647 lr : 0.7471720943315961\n",
      "epoch : 29 [1/23] Train loss: 4.03361,Valid loss: 4.51392, time : 9.778604984283447 lr : 0.7471720943315961\n",
      "epoch : 29 [2/23] Train loss: 4.08704,Valid loss: 5.21150, time : 10.151710510253906 lr : 0.7471720943315961\n",
      "epoch : 29 [3/23] Train loss: 4.10480,Valid loss: 4.75812, time : 10.25999927520752 lr : 0.7471720943315961\n",
      "epoch : 29 [4/23] Train loss: 4.14810,Valid loss: 5.07799, time : 10.260564804077148 lr : 0.7471720943315961\n",
      "epoch : 29 [5/23] Train loss: 4.08206,Valid loss: 4.53105, time : 9.993709325790405 lr : 0.7471720943315961\n",
      "epoch : 29 [6/23] Train loss: 4.06037,Valid loss: 4.58997, time : 10.433415651321411 lr : 0.7471720943315961\n",
      "epoch : 29 [7/23] Train loss: 4.01118,Valid loss: 4.51593, time : 9.888362646102905 lr : 0.7471720943315961\n",
      "epoch : 29 [8/23] Train loss: 4.04582,Valid loss: 4.52457, time : 9.82852292060852 lr : 0.7471720943315961\n",
      "epoch : 29 [9/23] Train loss: 4.02144,Valid loss: 4.68611, time : 10.060463666915894 lr : 0.7471720943315961\n",
      "epoch : 29 [10/23] Train loss: 4.06809,Valid loss: 4.71098, time : 9.797802925109863 lr : 0.7471720943315961\n",
      "epoch : 29 [11/23] Train loss: 4.04703,Valid loss: 4.77080, time : 10.090135335922241 lr : 0.7471720943315961\n",
      "epoch : 29 [12/23] Train loss: 4.01220,Valid loss: 4.76637, time : 9.709268569946289 lr : 0.7471720943315961\n",
      "epoch : 29 [13/23] Train loss: 4.00304,Valid loss: 4.66057, time : 9.978750944137573 lr : 0.7471720943315961\n",
      "epoch : 29 [14/23] Train loss: 4.08875,Valid loss: 4.87365, time : 10.130710124969482 lr : 0.7471720943315961\n",
      "epoch : 29 [15/23] Train loss: 4.01696,Valid loss: 4.61102, time : 10.432777881622314 lr : 0.7471720943315961\n",
      "epoch : 29 [16/23] Train loss: 4.03079,Valid loss: 5.15525, time : 10.213053703308105 lr : 0.7471720943315961\n",
      "epoch : 29 [17/23] Train loss: 4.01400,Valid loss: 4.45174, time : 10.406832218170166 lr : 0.7471720943315961\n",
      "epoch : 29 [18/23] Train loss: 4.09261,Valid loss: 4.97380, time : 9.746930599212646 lr : 0.7471720943315961\n",
      "epoch : 29 [19/23] Train loss: 4.00410,Valid loss: 4.47577, time : 10.213058471679688 lr : 0.7471720943315961\n",
      "epoch : 29 [20/23] Train loss: 4.01557,Valid loss: 4.58611, time : 10.195646047592163 lr : 0.7471720943315961\n",
      "epoch : 29 [21/23] Train loss: 4.01481,Valid loss: 4.81240, time : 10.101641416549683 lr : 0.7471720943315961\n",
      "epoch : 29 [22/23] Train loss: 3.99617,Valid loss: 4.64359, time : 9.43488359451294 lr : 0.7471720943315961\n",
      "epoch : 30 [0/23] Train loss: 4.00807,Valid loss: 4.51406, time : 10.418922901153564 lr : 0.7397003733882802\n",
      "epoch : 30 [1/23] Train loss: 4.00342,Valid loss: 4.69086, time : 10.017996788024902 lr : 0.7397003733882802\n",
      "epoch : 30 [2/23] Train loss: 3.97791,Valid loss: 4.52545, time : 10.13883376121521 lr : 0.7397003733882802\n",
      "epoch : 30 [3/23] Train loss: 4.06422,Valid loss: 4.98602, time : 9.942875862121582 lr : 0.7397003733882802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 30 [4/23] Train loss: 3.96387,Valid loss: 4.53181, time : 10.370133399963379 lr : 0.7397003733882802\n",
      "epoch : 30 [5/23] Train loss: 3.97055,Valid loss: 5.05821, time : 10.40762209892273 lr : 0.7397003733882802\n",
      "epoch : 30 [6/23] Train loss: 4.01660,Valid loss: 4.49583, time : 10.248480319976807 lr : 0.7397003733882802\n",
      "epoch : 30 [7/23] Train loss: 4.14833,Valid loss: 4.72725, time : 10.236930847167969 lr : 0.7397003733882802\n",
      "epoch : 30 [8/23] Train loss: 4.01802,Valid loss: 4.53145, time : 10.310962200164795 lr : 0.7397003733882802\n",
      "epoch : 30 [9/23] Train loss: 4.00697,Valid loss: 4.53249, time : 10.262171030044556 lr : 0.7397003733882802\n",
      "epoch : 30 [10/23] Train loss: 4.00047,Valid loss: 4.67330, time : 10.243249416351318 lr : 0.7397003733882802\n",
      "epoch : 30 [11/23] Train loss: 4.05291,Valid loss: 4.48901, time : 10.414995193481445 lr : 0.7397003733882802\n",
      "epoch : 30 [12/23] Train loss: 3.99524,Valid loss: 4.44968, time : 10.188841342926025 lr : 0.7397003733882802\n",
      "epoch : 30 [13/23] Train loss: 4.03496,Valid loss: 4.48573, time : 10.435301303863525 lr : 0.7397003733882802\n",
      "epoch : 30 [14/23] Train loss: 3.93374,Valid loss: 4.53636, time : 10.38459300994873 lr : 0.7397003733882802\n",
      "epoch : 30 [15/23] Train loss: 3.95728,Valid loss: 4.49380, time : 10.093184232711792 lr : 0.7397003733882802\n",
      "epoch : 30 [16/23] Train loss: 3.95278,Valid loss: 4.44407, time : 10.077270984649658 lr : 0.7397003733882802\n",
      "epoch : 30 [17/23] Train loss: 3.99856,Valid loss: 4.65792, time : 10.245142459869385 lr : 0.7397003733882802\n",
      "epoch : 30 [18/23] Train loss: 3.94605,Valid loss: 4.36257, time : 10.04771375656128 lr : 0.7397003733882802\n",
      "epoch : 30 [19/23] Train loss: 3.94756,Valid loss: 4.80012, time : 10.25108814239502 lr : 0.7397003733882802\n",
      "epoch : 30 [20/23] Train loss: 3.94284,Valid loss: 4.42794, time : 10.184350490570068 lr : 0.7397003733882802\n",
      "epoch : 30 [21/23] Train loss: 3.98891,Valid loss: 4.75473, time : 9.929396629333496 lr : 0.7397003733882802\n",
      "epoch : 30 [22/23] Train loss: 3.92143,Valid loss: 4.70351, time : 9.506752729415894 lr : 0.7397003733882802\n",
      "epoch : 31 [0/23] Train loss: 3.98052,Valid loss: 5.12398, time : 9.95002269744873 lr : 0.7323033696543974\n",
      "epoch : 31 [1/23] Train loss: 3.95010,Valid loss: 4.38878, time : 9.87287712097168 lr : 0.7323033696543974\n",
      "epoch : 31 [2/23] Train loss: 3.99110,Valid loss: 4.53471, time : 9.983046531677246 lr : 0.7323033696543974\n",
      "epoch : 31 [3/23] Train loss: 3.94738,Valid loss: 4.54123, time : 9.558942556381226 lr : 0.7323033696543974\n",
      "epoch : 31 [4/23] Train loss: 3.96259,Valid loss: 4.45775, time : 10.057685375213623 lr : 0.7323033696543974\n",
      "epoch : 31 [5/23] Train loss: 3.93327,Valid loss: 4.56909, time : 9.97303056716919 lr : 0.7323033696543974\n",
      "epoch : 31 [6/23] Train loss: 3.92534,Valid loss: 4.52222, time : 10.003335952758789 lr : 0.7323033696543974\n",
      "epoch : 31 [7/23] Train loss: 3.91732,Valid loss: 4.53034, time : 9.871374607086182 lr : 0.7323033696543974\n",
      "epoch : 31 [8/23] Train loss: 3.93095,Valid loss: 4.63878, time : 9.93190884590149 lr : 0.7323033696543974\n",
      "epoch : 31 [9/23] Train loss: 3.91920,Valid loss: 4.31791, time : 9.906273126602173 lr : 0.7323033696543974\n",
      "epoch : 31 [10/23] Train loss: 3.96290,Valid loss: 4.52129, time : 10.197708368301392 lr : 0.7323033696543974\n",
      "epoch : 31 [11/23] Train loss: 3.90827,Valid loss: 4.34787, time : 10.175079107284546 lr : 0.7323033696543974\n",
      "epoch : 31 [12/23] Train loss: 3.99366,Valid loss: 4.57152, time : 10.195090293884277 lr : 0.7323033696543974\n",
      "epoch : 31 [13/23] Train loss: 3.92903,Valid loss: 4.62642, time : 10.245675802230835 lr : 0.7323033696543974\n",
      "epoch : 31 [14/23] Train loss: 3.95856,Valid loss: 4.62524, time : 10.255950689315796 lr : 0.7323033696543974\n",
      "epoch : 31 [15/23] Train loss: 3.92983,Valid loss: 4.39089, time : 10.138511657714844 lr : 0.7323033696543974\n",
      "epoch : 31 [16/23] Train loss: 3.98594,Valid loss: 4.57018, time : 10.126879215240479 lr : 0.7323033696543974\n",
      "epoch : 31 [17/23] Train loss: 3.93599,Valid loss: 4.55221, time : 9.892989158630371 lr : 0.7323033696543974\n",
      "epoch : 31 [18/23] Train loss: 4.03743,Valid loss: 4.48390, time : 10.069099426269531 lr : 0.7323033696543974\n",
      "epoch : 31 [19/23] Train loss: 3.88997,Valid loss: 4.46460, time : 10.45213007926941 lr : 0.7323033696543974\n",
      "epoch : 31 [20/23] Train loss: 3.89169,Valid loss: 4.71122, time : 10.21561074256897 lr : 0.7323033696543974\n",
      "epoch : 31 [21/23] Train loss: 3.88287,Valid loss: 4.60758, time : 10.148969650268555 lr : 0.7323033696543974\n",
      "epoch : 31 [22/23] Train loss: 3.93719,Valid loss: 5.04705, time : 9.41102409362793 lr : 0.7323033696543974\n",
      "epoch : 32 [0/23] Train loss: 3.91772,Valid loss: 4.87979, time : 9.7225821018219 lr : 0.7249803359578534\n",
      "epoch : 32 [1/23] Train loss: 3.91472,Valid loss: 4.84911, time : 10.050044536590576 lr : 0.7249803359578534\n",
      "epoch : 32 [2/23] Train loss: 3.87061,Valid loss: 4.50016, time : 10.10990309715271 lr : 0.7249803359578534\n",
      "epoch : 32 [3/23] Train loss: 3.89201,Valid loss: 4.55311, time : 9.931207418441772 lr : 0.7249803359578534\n",
      "epoch : 32 [4/23] Train loss: 3.87546,Valid loss: 4.33683, time : 10.044598579406738 lr : 0.7249803359578534\n",
      "epoch : 32 [5/23] Train loss: 3.93550,Valid loss: 4.41846, time : 9.810596942901611 lr : 0.7249803359578534\n",
      "epoch : 32 [6/23] Train loss: 3.87168,Valid loss: 4.43578, time : 10.122879028320312 lr : 0.7249803359578534\n",
      "epoch : 32 [7/23] Train loss: 3.94384,Valid loss: 4.42678, time : 9.979385614395142 lr : 0.7249803359578534\n",
      "epoch : 32 [8/23] Train loss: 3.89462,Valid loss: 4.39077, time : 9.985992431640625 lr : 0.7249803359578534\n",
      "epoch : 32 [9/23] Train loss: 3.90956,Valid loss: 4.49478, time : 10.176741361618042 lr : 0.7249803359578534\n",
      "epoch : 32 [10/23] Train loss: 3.87126,Valid loss: 4.33452, time : 9.747870445251465 lr : 0.7249803359578534\n",
      "epoch : 32 [11/23] Train loss: 3.93423,Valid loss: 4.47582, time : 10.112948894500732 lr : 0.7249803359578534\n",
      "epoch : 32 [12/23] Train loss: 3.86215,Valid loss: 4.31790, time : 9.689318895339966 lr : 0.7249803359578534\n",
      "epoch : 32 [13/23] Train loss: 3.88435,Valid loss: 4.42169, time : 9.983185052871704 lr : 0.7249803359578534\n",
      "epoch : 32 [14/23] Train loss: 3.87531,Valid loss: 4.40682, time : 9.892131328582764 lr : 0.7249803359578534\n",
      "epoch : 32 [15/23] Train loss: 3.93229,Valid loss: 4.48515, time : 10.161992311477661 lr : 0.7249803359578534\n",
      "epoch : 32 [16/23] Train loss: 3.86194,Valid loss: 5.07549, time : 10.140840291976929 lr : 0.7249803359578534\n",
      "epoch : 32 [17/23] Train loss: 3.86595,Valid loss: 4.64767, time : 10.385963439941406 lr : 0.7249803359578534\n",
      "epoch : 32 [18/23] Train loss: 3.84331,Valid loss: 4.64472, time : 10.060308694839478 lr : 0.7249803359578534\n",
      "epoch : 32 [19/23] Train loss: 3.84873,Valid loss: 4.42676, time : 10.049550294876099 lr : 0.7249803359578534\n",
      "epoch : 32 [20/23] Train loss: 3.87773,Valid loss: 4.48903, time : 10.072320938110352 lr : 0.7249803359578534\n",
      "epoch : 32 [21/23] Train loss: 3.87905,Valid loss: 4.38375, time : 10.138341903686523 lr : 0.7249803359578534\n",
      "epoch : 32 [22/23] Train loss: 3.97392,Valid loss: 4.37767, time : 9.434450626373291 lr : 0.7249803359578534\n",
      "epoch : 33 [0/23] Train loss: 3.83218,Valid loss: 4.34823, time : 9.771170377731323 lr : 0.7177305325982748\n",
      "epoch : 33 [1/23] Train loss: 3.86449,Valid loss: 4.40297, time : 9.74581265449524 lr : 0.7177305325982748\n",
      "epoch : 33 [2/23] Train loss: 3.85616,Valid loss: 4.62643, time : 9.655275344848633 lr : 0.7177305325982748\n",
      "epoch : 33 [3/23] Train loss: 3.91962,Valid loss: 4.61838, time : 9.772978067398071 lr : 0.7177305325982748\n",
      "epoch : 33 [4/23] Train loss: 3.88808,Valid loss: 4.39581, time : 9.657372951507568 lr : 0.7177305325982748\n",
      "epoch : 33 [5/23] Train loss: 3.95652,Valid loss: 4.42024, time : 9.859557628631592 lr : 0.7177305325982748\n",
      "epoch : 33 [6/23] Train loss: 3.82877,Valid loss: 4.39960, time : 9.703182697296143 lr : 0.7177305325982748\n",
      "epoch : 33 [7/23] Train loss: 3.82640,Valid loss: 4.56181, time : 10.039202690124512 lr : 0.7177305325982748\n",
      "epoch : 33 [8/23] Train loss: 3.83537,Valid loss: 4.30550, time : 10.378695726394653 lr : 0.7177305325982748\n",
      "epoch : 33 [9/23] Train loss: 3.89404,Valid loss: 4.58980, time : 10.10130500793457 lr : 0.7177305325982748\n",
      "epoch : 33 [10/23] Train loss: 3.83113,Valid loss: 4.40299, time : 9.882465362548828 lr : 0.7177305325982748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 33 [11/23] Train loss: 3.86298,Valid loss: 4.58169, time : 10.202064990997314 lr : 0.7177305325982748\n",
      "epoch : 33 [12/23] Train loss: 3.80054,Valid loss: 4.22111, time : 9.745449542999268 lr : 0.7177305325982748\n",
      "epoch : 33 [13/23] Train loss: 3.81719,Valid loss: 4.44155, time : 9.909632205963135 lr : 0.7177305325982748\n",
      "epoch : 33 [14/23] Train loss: 3.81684,Valid loss: 4.23084, time : 10.227665662765503 lr : 0.7177305325982748\n",
      "epoch : 33 [15/23] Train loss: 3.84181,Valid loss: 4.59112, time : 10.589179992675781 lr : 0.7177305325982748\n",
      "epoch : 33 [16/23] Train loss: 3.80703,Valid loss: 4.48758, time : 10.158323049545288 lr : 0.7177305325982748\n",
      "epoch : 33 [17/23] Train loss: 3.81710,Valid loss: 5.10369, time : 9.785244703292847 lr : 0.7177305325982748\n",
      "epoch : 33 [18/23] Train loss: 3.78839,Valid loss: 4.48054, time : 9.832573413848877 lr : 0.7177305325982748\n",
      "epoch : 33 [19/23] Train loss: 3.82945,Valid loss: 5.01716, time : 9.733137607574463 lr : 0.7177305325982748\n",
      "epoch : 33 [20/23] Train loss: 3.80555,Valid loss: 4.70531, time : 10.164682149887085 lr : 0.7177305325982748\n",
      "epoch : 33 [21/23] Train loss: 3.81621,Valid loss: 5.55815, time : 10.037532329559326 lr : 0.7177305325982748\n",
      "epoch : 33 [22/23] Train loss: 3.82423,Valid loss: 4.48460, time : 9.563791513442993 lr : 0.7177305325982748\n",
      "epoch : 34 [0/23] Train loss: 3.96588,Valid loss: 4.71828, time : 10.379487752914429 lr : 0.7105532272722921\n",
      "epoch : 34 [1/23] Train loss: 3.79232,Valid loss: 4.34784, time : 10.12747073173523 lr : 0.7105532272722921\n",
      "epoch : 34 [2/23] Train loss: 3.77119,Valid loss: 4.56148, time : 10.109941482543945 lr : 0.7105532272722921\n",
      "epoch : 34 [3/23] Train loss: 3.77869,Valid loss: 4.39224, time : 10.063482999801636 lr : 0.7105532272722921\n",
      "epoch : 34 [4/23] Train loss: 3.83767,Valid loss: 4.55110, time : 10.192128896713257 lr : 0.7105532272722921\n",
      "epoch : 34 [5/23] Train loss: 3.80188,Valid loss: 4.34828, time : 10.277741432189941 lr : 0.7105532272722921\n",
      "epoch : 34 [6/23] Train loss: 3.90339,Valid loss: 4.69940, time : 10.521347522735596 lr : 0.7105532272722921\n",
      "epoch : 34 [7/23] Train loss: 3.77711,Valid loss: 4.30099, time : 10.301204204559326 lr : 0.7105532272722921\n",
      "epoch : 34 [8/23] Train loss: 3.74640,Valid loss: 4.35331, time : 9.791284084320068 lr : 0.7105532272722921\n",
      "epoch : 34 [9/23] Train loss: 3.76589,Valid loss: 4.49363, time : 10.143969297409058 lr : 0.7105532272722921\n",
      "epoch : 34 [10/23] Train loss: 3.86269,Valid loss: 4.36329, time : 10.268324136734009 lr : 0.7105532272722921\n",
      "epoch : 34 [11/23] Train loss: 3.75240,Valid loss: 4.32975, time : 10.275042533874512 lr : 0.7105532272722921\n",
      "epoch : 34 [12/23] Train loss: 3.82157,Valid loss: 4.37474, time : 10.287315130233765 lr : 0.7105532272722921\n",
      "epoch : 34 [13/23] Train loss: 3.74119,Valid loss: 4.20655, time : 10.424413204193115 lr : 0.7105532272722921\n",
      "epoch : 34 [14/23] Train loss: 3.82120,Valid loss: 4.38844, time : 10.41782832145691 lr : 0.7105532272722921\n",
      "epoch : 34 [15/23] Train loss: 3.77101,Valid loss: 4.27385, time : 9.714633464813232 lr : 0.7105532272722921\n",
      "epoch : 34 [16/23] Train loss: 3.77304,Valid loss: 4.30139, time : 9.920494556427002 lr : 0.7105532272722921\n",
      "epoch : 34 [17/23] Train loss: 3.77422,Valid loss: 4.23089, time : 9.681373357772827 lr : 0.7105532272722921\n",
      "epoch : 34 [18/23] Train loss: 3.81699,Valid loss: 4.46503, time : 9.637466669082642 lr : 0.7105532272722921\n",
      "epoch : 34 [19/23] Train loss: 3.77325,Valid loss: 4.67842, time : 10.438176393508911 lr : 0.7105532272722921\n",
      "epoch : 34 [20/23] Train loss: 3.86390,Valid loss: 4.50490, time : 10.147034883499146 lr : 0.7105532272722921\n",
      "epoch : 34 [21/23] Train loss: 3.72998,Valid loss: 4.26954, time : 10.213007688522339 lr : 0.7105532272722921\n",
      "epoch : 34 [22/23] Train loss: 3.69753,Valid loss: 4.45242, time : 9.334496974945068 lr : 0.7105532272722921\n",
      "epoch : 35 [0/23] Train loss: 3.71121,Valid loss: 4.36272, time : 10.379250526428223 lr : 0.7034476949995692\n",
      "epoch : 35 [1/23] Train loss: 3.84837,Valid loss: 4.57210, time : 9.74997329711914 lr : 0.7034476949995692\n",
      "epoch : 35 [2/23] Train loss: 3.74647,Valid loss: 4.38549, time : 10.183579921722412 lr : 0.7034476949995692\n",
      "epoch : 35 [3/23] Train loss: 3.82017,Valid loss: 4.50481, time : 9.699896335601807 lr : 0.7034476949995692\n",
      "epoch : 35 [4/23] Train loss: 3.72939,Valid loss: 4.14234, time : 10.119316101074219 lr : 0.7034476949995692\n",
      "epoch : 35 [5/23] Train loss: 3.77468,Valid loss: 4.47824, time : 9.825868129730225 lr : 0.7034476949995692\n",
      "epoch : 35 [6/23] Train loss: 3.73978,Valid loss: 4.19605, time : 10.066368818283081 lr : 0.7034476949995692\n",
      "epoch : 35 [7/23] Train loss: 3.82983,Valid loss: 4.29940, time : 9.766123533248901 lr : 0.7034476949995692\n",
      "epoch : 35 [8/23] Train loss: 3.73762,Valid loss: 4.45085, time : 10.133575439453125 lr : 0.7034476949995692\n",
      "epoch : 35 [9/23] Train loss: 3.78302,Valid loss: 4.64614, time : 9.587523221969604 lr : 0.7034476949995692\n",
      "epoch : 35 [10/23] Train loss: 3.73378,Valid loss: 4.32383, time : 9.656758546829224 lr : 0.7034476949995692\n",
      "epoch : 35 [11/23] Train loss: 3.76670,Valid loss: 4.26997, time : 9.683193683624268 lr : 0.7034476949995692\n",
      "epoch : 35 [12/23] Train loss: 3.70943,Valid loss: 4.30056, time : 9.952250719070435 lr : 0.7034476949995692\n",
      "epoch : 35 [13/23] Train loss: 3.77496,Valid loss: 4.37712, time : 9.696743965148926 lr : 0.7034476949995692\n",
      "epoch : 35 [14/23] Train loss: 3.70902,Valid loss: 4.33895, time : 10.234520435333252 lr : 0.7034476949995692\n",
      "epoch : 35 [15/23] Train loss: 3.74566,Valid loss: 4.33318, time : 9.581099510192871 lr : 0.7034476949995692\n",
      "epoch : 35 [16/23] Train loss: 3.68478,Valid loss: 4.15851, time : 10.14315915107727 lr : 0.7034476949995692\n",
      "epoch : 35 [17/23] Train loss: 3.75067,Valid loss: 4.30123, time : 9.645380020141602 lr : 0.7034476949995692\n",
      "epoch : 35 [18/23] Train loss: 3.73099,Valid loss: 4.47549, time : 9.944567918777466 lr : 0.7034476949995692\n",
      "epoch : 35 [19/23] Train loss: 3.76908,Valid loss: 4.31451, time : 9.902689456939697 lr : 0.7034476949995692\n",
      "epoch : 35 [20/23] Train loss: 3.71125,Valid loss: 4.39589, time : 10.180553436279297 lr : 0.7034476949995692\n",
      "epoch : 35 [21/23] Train loss: 3.71639,Valid loss: 4.31361, time : 9.875152587890625 lr : 0.7034476949995692\n",
      "epoch : 35 [22/23] Train loss: 3.69531,Valid loss: 4.18285, time : 9.418071508407593 lr : 0.7034476949995692\n",
      "epoch : 36 [0/23] Train loss: 3.78179,Valid loss: 4.30526, time : 9.916775703430176 lr : 0.6964132180495735\n",
      "epoch : 36 [1/23] Train loss: 3.69087,Valid loss: 4.35815, time : 10.356803894042969 lr : 0.6964132180495735\n",
      "epoch : 36 [2/23] Train loss: 3.74521,Valid loss: 4.56447, time : 10.209108352661133 lr : 0.6964132180495735\n",
      "epoch : 36 [3/23] Train loss: 3.69425,Valid loss: 4.27454, time : 9.909946203231812 lr : 0.6964132180495735\n",
      "epoch : 36 [4/23] Train loss: 3.76229,Valid loss: 4.20465, time : 10.040227890014648 lr : 0.6964132180495735\n",
      "epoch : 36 [5/23] Train loss: 3.63286,Valid loss: 4.15679, time : 10.165814638137817 lr : 0.6964132180495735\n",
      "epoch : 36 [6/23] Train loss: 3.73164,Valid loss: 4.28674, time : 10.134364604949951 lr : 0.6964132180495735\n",
      "epoch : 36 [7/23] Train loss: 3.67878,Valid loss: 4.38135, time : 10.006881475448608 lr : 0.6964132180495735\n",
      "epoch : 36 [8/23] Train loss: 3.73923,Valid loss: 4.71482, time : 10.161631107330322 lr : 0.6964132180495735\n",
      "epoch : 36 [9/23] Train loss: 3.67755,Valid loss: 4.58888, time : 10.474707126617432 lr : 0.6964132180495735\n",
      "epoch : 36 [10/23] Train loss: 3.74504,Valid loss: 4.51090, time : 9.793473720550537 lr : 0.6964132180495735\n",
      "epoch : 36 [11/23] Train loss: 3.66569,Valid loss: 4.34357, time : 10.017461776733398 lr : 0.6964132180495735\n",
      "epoch : 36 [12/23] Train loss: 3.71316,Valid loss: 4.48776, time : 10.105276823043823 lr : 0.6964132180495735\n",
      "epoch : 36 [13/23] Train loss: 3.66832,Valid loss: 4.60895, time : 10.548131942749023 lr : 0.6964132180495735\n",
      "epoch : 36 [14/23] Train loss: 3.72937,Valid loss: 4.51216, time : 10.345985174179077 lr : 0.6964132180495735\n",
      "epoch : 36 [15/23] Train loss: 3.65108,Valid loss: 4.13236, time : 10.169801712036133 lr : 0.6964132180495735\n",
      "epoch : 36 [16/23] Train loss: 3.68695,Valid loss: 4.18798, time : 10.183400869369507 lr : 0.6964132180495735\n",
      "epoch : 36 [17/23] Train loss: 3.69272,Valid loss: 4.14481, time : 9.926705360412598 lr : 0.6964132180495735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 36 [18/23] Train loss: 3.77191,Valid loss: 4.34609, time : 10.143784761428833 lr : 0.6964132180495735\n",
      "epoch : 36 [19/23] Train loss: 3.64926,Valid loss: 4.08745, time : 9.757611989974976 lr : 0.6964132180495735\n",
      "epoch : 36 [20/23] Train loss: 3.65379,Valid loss: 4.26903, time : 10.164063453674316 lr : 0.6964132180495735\n",
      "epoch : 36 [21/23] Train loss: 3.67692,Valid loss: 4.29721, time : 10.007594585418701 lr : 0.6964132180495735\n",
      "epoch : 36 [22/23] Train loss: 3.76832,Valid loss: 4.74336, time : 9.568183183670044 lr : 0.6964132180495735\n",
      "epoch : 37 [0/23] Train loss: 3.68014,Valid loss: 4.32812, time : 10.063311338424683 lr : 0.6894490858690777\n",
      "epoch : 37 [1/23] Train loss: 3.67011,Valid loss: 4.82165, time : 9.68401288986206 lr : 0.6894490858690777\n",
      "epoch : 37 [2/23] Train loss: 3.61943,Valid loss: 4.34481, time : 9.664910078048706 lr : 0.6894490858690777\n",
      "epoch : 37 [3/23] Train loss: 3.68306,Valid loss: 4.64778, time : 10.211230754852295 lr : 0.6894490858690777\n",
      "epoch : 37 [4/23] Train loss: 3.66643,Valid loss: 4.31544, time : 10.37671971321106 lr : 0.6894490858690777\n",
      "epoch : 37 [5/23] Train loss: 3.71876,Valid loss: 4.12517, time : 10.404614686965942 lr : 0.6894490858690777\n",
      "epoch : 37 [6/23] Train loss: 3.63315,Valid loss: 4.11975, time : 10.339439630508423 lr : 0.6894490858690777\n",
      "epoch : 37 [7/23] Train loss: 3.61011,Valid loss: 4.21592, time : 10.227549076080322 lr : 0.6894490858690777\n",
      "epoch : 37 [8/23] Train loss: 3.72286,Valid loss: 4.21396, time : 10.171729803085327 lr : 0.6894490858690777\n",
      "epoch : 37 [9/23] Train loss: 3.73100,Valid loss: 4.23414, time : 10.354684114456177 lr : 0.6894490858690777\n",
      "epoch : 37 [10/23] Train loss: 3.81496,Valid loss: 4.28683, time : 10.36807131767273 lr : 0.6894490858690777\n",
      "epoch : 37 [11/23] Train loss: 3.64874,Valid loss: 4.15241, time : 10.315752029418945 lr : 0.6894490858690777\n",
      "epoch : 37 [12/23] Train loss: 3.62034,Valid loss: 4.48851, time : 10.231923818588257 lr : 0.6894490858690777\n",
      "epoch : 37 [13/23] Train loss: 3.60394,Valid loss: 4.16544, time : 10.705424547195435 lr : 0.6894490858690777\n",
      "epoch : 37 [14/23] Train loss: 3.64783,Valid loss: 4.37942, time : 10.329710006713867 lr : 0.6894490858690777\n",
      "epoch : 37 [15/23] Train loss: 3.58964,Valid loss: 4.20430, time : 10.610373735427856 lr : 0.6894490858690777\n",
      "epoch : 37 [16/23] Train loss: 3.62354,Valid loss: 4.27498, time : 10.47006630897522 lr : 0.6894490858690777\n",
      "epoch : 37 [17/23] Train loss: 3.68376,Valid loss: 4.86496, time : 10.362576484680176 lr : 0.6894490858690777\n",
      "epoch : 37 [18/23] Train loss: 3.87556,Valid loss: 4.46507, time : 10.403133630752563 lr : 0.6894490858690777\n",
      "epoch : 37 [19/23] Train loss: 3.61539,Valid loss: 4.63586, time : 10.598869323730469 lr : 0.6894490858690777\n",
      "epoch : 37 [20/23] Train loss: 3.57109,Valid loss: 4.46255, time : 10.018206119537354 lr : 0.6894490858690777\n",
      "epoch : 37 [21/23] Train loss: 3.56351,Valid loss: 4.08587, time : 10.268051862716675 lr : 0.6894490858690777\n",
      "epoch : 37 [22/23] Train loss: 3.60004,Valid loss: 4.28886, time : 9.418660402297974 lr : 0.6894490858690777\n",
      "epoch : 38 [0/23] Train loss: 3.65311,Valid loss: 4.34172, time : 10.119765758514404 lr : 0.682554595010387\n",
      "epoch : 38 [1/23] Train loss: 3.79447,Valid loss: 4.34213, time : 9.930576086044312 lr : 0.682554595010387\n",
      "epoch : 38 [2/23] Train loss: 3.58926,Valid loss: 4.17552, time : 10.02541708946228 lr : 0.682554595010387\n",
      "epoch : 38 [3/23] Train loss: 3.56686,Valid loss: 4.25842, time : 9.988461017608643 lr : 0.682554595010387\n",
      "epoch : 38 [4/23] Train loss: 3.53761,Valid loss: 4.13347, time : 10.278690099716187 lr : 0.682554595010387\n",
      "epoch : 38 [5/23] Train loss: 3.56068,Valid loss: 4.57239, time : 10.044153451919556 lr : 0.682554595010387\n",
      "epoch : 38 [6/23] Train loss: 3.60747,Valid loss: 4.32661, time : 9.851227045059204 lr : 0.682554595010387\n",
      "epoch : 38 [7/23] Train loss: 3.76868,Valid loss: 4.21404, time : 9.742059469223022 lr : 0.682554595010387\n",
      "epoch : 38 [8/23] Train loss: 3.60164,Valid loss: 4.34967, time : 10.254142761230469 lr : 0.682554595010387\n",
      "epoch : 38 [9/23] Train loss: 3.60302,Valid loss: 4.29483, time : 9.939327716827393 lr : 0.682554595010387\n",
      "epoch : 38 [10/23] Train loss: 3.59631,Valid loss: 4.09940, time : 10.421168565750122 lr : 0.682554595010387\n",
      "epoch : 38 [11/23] Train loss: 3.68187,Valid loss: 4.09210, time : 10.05137324333191 lr : 0.682554595010387\n",
      "epoch : 38 [12/23] Train loss: 3.55930,Valid loss: 4.07826, time : 10.489717960357666 lr : 0.682554595010387\n",
      "epoch : 38 [13/23] Train loss: 3.55386,Valid loss: 4.21469, time : 10.194592952728271 lr : 0.682554595010387\n",
      "epoch : 38 [14/23] Train loss: 3.56868,Valid loss: 4.20377, time : 10.371018409729004 lr : 0.682554595010387\n",
      "epoch : 38 [15/23] Train loss: 3.66036,Valid loss: 4.22005, time : 10.118086099624634 lr : 0.682554595010387\n",
      "epoch : 38 [16/23] Train loss: 3.57979,Valid loss: 4.00815, time : 9.863565921783447 lr : 0.682554595010387\n",
      "epoch : 38 [17/23] Train loss: 3.67613,Valid loss: 4.34123, time : 9.645780324935913 lr : 0.682554595010387\n",
      "epoch : 38 [18/23] Train loss: 3.56466,Valid loss: 4.41225, time : 9.962337017059326 lr : 0.682554595010387\n",
      "epoch : 38 [19/23] Train loss: 3.62081,Valid loss: 4.62254, time : 10.062783479690552 lr : 0.682554595010387\n",
      "epoch : 38 [20/23] Train loss: 3.55570,Valid loss: 4.06016, time : 10.225502490997314 lr : 0.682554595010387\n",
      "epoch : 38 [21/23] Train loss: 3.65462,Valid loss: 4.24217, time : 10.303651094436646 lr : 0.682554595010387\n",
      "epoch : 38 [22/23] Train loss: 3.53999,Valid loss: 4.08012, time : 9.5298593044281 lr : 0.682554595010387\n",
      "epoch : 39 [0/23] Train loss: 3.57378,Valid loss: 4.27774, time : 10.282428741455078 lr : 0.6757290490602831\n",
      "epoch : 39 [1/23] Train loss: 3.56210,Valid loss: 4.04862, time : 10.313426494598389 lr : 0.6757290490602831\n",
      "epoch : 39 [2/23] Train loss: 3.56699,Valid loss: 4.20601, time : 10.104385375976562 lr : 0.6757290490602831\n",
      "epoch : 39 [3/23] Train loss: 3.53087,Valid loss: 4.06457, time : 10.31467318534851 lr : 0.6757290490602831\n",
      "epoch : 39 [4/23] Train loss: 3.62831,Valid loss: 4.67692, time : 10.341375589370728 lr : 0.6757290490602831\n",
      "epoch : 39 [5/23] Train loss: 3.59027,Valid loss: 4.61831, time : 10.004058599472046 lr : 0.6757290490602831\n",
      "epoch : 39 [6/23] Train loss: 3.72402,Valid loss: 4.84089, time : 10.355184316635132 lr : 0.6757290490602831\n",
      "epoch : 39 [7/23] Train loss: 3.55756,Valid loss: 4.49027, time : 10.166564226150513 lr : 0.6757290490602831\n",
      "epoch : 39 [8/23] Train loss: 3.60169,Valid loss: 4.40081, time : 10.137181520462036 lr : 0.6757290490602831\n",
      "epoch : 39 [9/23] Train loss: 3.51524,Valid loss: 3.99027, time : 10.142549753189087 lr : 0.6757290490602831\n",
      "epoch : 39 [10/23] Train loss: 3.54460,Valid loss: 4.00480, time : 9.842975854873657 lr : 0.6757290490602831\n",
      "epoch : 39 [11/23] Train loss: 3.50696,Valid loss: 3.99389, time : 10.141082048416138 lr : 0.6757290490602831\n",
      "epoch : 39 [12/23] Train loss: 3.57915,Valid loss: 4.05763, time : 9.699132442474365 lr : 0.6757290490602831\n",
      "epoch : 39 [13/23] Train loss: 3.54708,Valid loss: 3.96260, time : 10.117802143096924 lr : 0.6757290490602831\n",
      "epoch : 39 [14/23] Train loss: 3.62028,Valid loss: 3.98362, time : 9.736116886138916 lr : 0.6757290490602831\n",
      "epoch : 39 [15/23] Train loss: 3.50168,Valid loss: 4.01644, time : 10.044689893722534 lr : 0.6757290490602831\n",
      "epoch : 39 [16/23] Train loss: 3.51811,Valid loss: 4.12839, time : 10.030000925064087 lr : 0.6757290490602831\n",
      "epoch : 39 [17/23] Train loss: 3.52778,Valid loss: 3.90298, time : 10.063541173934937 lr : 0.6757290490602831\n",
      "epoch : 39 [18/23] Train loss: 3.63335,Valid loss: 4.13023, time : 10.092435598373413 lr : 0.6757290490602831\n",
      "epoch : 39 [19/23] Train loss: 3.48920,Valid loss: 4.02895, time : 10.486694812774658 lr : 0.6757290490602831\n",
      "epoch : 39 [20/23] Train loss: 3.50429,Valid loss: 4.81279, time : 10.187206268310547 lr : 0.6757290490602831\n",
      "epoch : 39 [21/23] Train loss: 3.49077,Valid loss: 4.32470, time : 10.23621940612793 lr : 0.6757290490602831\n",
      "epoch : 39 [22/23] Train loss: 3.62786,Valid loss: 4.26614, time : 9.662707328796387 lr : 0.6757290490602831\n",
      "epoch : 40 [0/23] Train loss: 3.55335,Valid loss: 4.21663, time : 10.043899059295654 lr : 0.6689717585696803\n",
      "epoch : 40 [1/23] Train loss: 3.63628,Valid loss: 4.21496, time : 9.619055271148682 lr : 0.6689717585696803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 [2/23] Train loss: 3.49931,Valid loss: 4.09732, time : 10.095470428466797 lr : 0.6689717585696803\n",
      "epoch : 40 [3/23] Train loss: 3.50410,Valid loss: 4.04796, time : 9.549561023712158 lr : 0.6689717585696803\n",
      "epoch : 40 [4/23] Train loss: 3.51057,Valid loss: 3.96639, time : 9.84846830368042 lr : 0.6689717585696803\n",
      "epoch : 40 [5/23] Train loss: 3.60175,Valid loss: 4.00404, time : 9.518466472625732 lr : 0.6689717585696803\n",
      "epoch : 40 [6/23] Train loss: 3.47816,Valid loss: 3.99556, time : 9.778520107269287 lr : 0.6689717585696803\n",
      "epoch : 40 [7/23] Train loss: 3.51222,Valid loss: 4.16757, time : 9.802612781524658 lr : 0.6689717585696803\n",
      "epoch : 40 [8/23] Train loss: 3.52611,Valid loss: 3.97996, time : 9.694129705429077 lr : 0.6689717585696803\n",
      "epoch : 40 [9/23] Train loss: 3.63116,Valid loss: 4.39935, time : 9.774779796600342 lr : 0.6689717585696803\n",
      "epoch : 40 [10/23] Train loss: 3.47789,Valid loss: 4.58944, time : 11.075457096099854 lr : 0.6689717585696803\n",
      "epoch : 40 [11/23] Train loss: 3.50403,Valid loss: 4.76460, time : 9.962096929550171 lr : 0.6689717585696803\n",
      "epoch : 40 [12/23] Train loss: 3.52592,Valid loss: 4.07123, time : 10.306081771850586 lr : 0.6689717585696803\n",
      "epoch : 40 [13/23] Train loss: 3.57545,Valid loss: 4.06271, time : 10.282064437866211 lr : 0.6689717585696803\n",
      "epoch : 40 [14/23] Train loss: 3.51946,Valid loss: 4.00862, time : 10.11865520477295 lr : 0.6689717585696803\n",
      "epoch : 40 [15/23] Train loss: 3.59234,Valid loss: 4.12380, time : 10.12994122505188 lr : 0.6689717585696803\n",
      "epoch : 40 [16/23] Train loss: 3.43981,Valid loss: 4.11881, time : 10.156140804290771 lr : 0.6689717585696803\n",
      "epoch : 40 [17/23] Train loss: 3.43582,Valid loss: 4.14311, time : 10.357794761657715 lr : 0.6689717585696803\n",
      "epoch : 40 [18/23] Train loss: 3.43078,Valid loss: 4.06927, time : 10.097533464431763 lr : 0.6689717585696803\n",
      "epoch : 40 [19/23] Train loss: 3.52814,Valid loss: 4.04413, time : 9.741037845611572 lr : 0.6689717585696803\n",
      "epoch : 40 [20/23] Train loss: 3.50793,Valid loss: 4.11113, time : 10.267934799194336 lr : 0.6689717585696803\n",
      "epoch : 40 [21/23] Train loss: 3.64303,Valid loss: 4.21118, time : 10.166396856307983 lr : 0.6689717585696803\n",
      "epoch : 40 [22/23] Train loss: 3.46078,Valid loss: 4.19478, time : 9.686681747436523 lr : 0.6689717585696803\n",
      "epoch : 41 [0/23] Train loss: 3.52372,Valid loss: 4.57121, time : 10.138330221176147 lr : 0.6622820409839835\n",
      "epoch : 41 [1/23] Train loss: 3.48933,Valid loss: 4.23971, time : 10.323056697845459 lr : 0.6622820409839835\n",
      "epoch : 41 [2/23] Train loss: 3.51461,Valid loss: 4.14816, time : 9.996121883392334 lr : 0.6622820409839835\n",
      "epoch : 41 [3/23] Train loss: 3.45406,Valid loss: 3.98126, time : 10.276644945144653 lr : 0.6622820409839835\n",
      "epoch : 41 [4/23] Train loss: 3.55144,Valid loss: 4.25001, time : 10.076531171798706 lr : 0.6622820409839835\n",
      "epoch : 41 [5/23] Train loss: 3.41194,Valid loss: 4.09241, time : 10.184043169021606 lr : 0.6622820409839835\n",
      "epoch : 41 [6/23] Train loss: 3.47155,Valid loss: 4.37100, time : 10.010838508605957 lr : 0.6622820409839835\n",
      "epoch : 41 [7/23] Train loss: 3.48950,Valid loss: 4.07903, time : 10.504762649536133 lr : 0.6622820409839835\n",
      "epoch : 41 [8/23] Train loss: 3.58661,Valid loss: 4.03618, time : 10.26924443244934 lr : 0.6622820409839835\n",
      "epoch : 41 [9/23] Train loss: 3.41633,Valid loss: 4.04458, time : 10.216848850250244 lr : 0.6622820409839835\n",
      "epoch : 41 [10/23] Train loss: 3.46482,Valid loss: 4.12508, time : 10.41144847869873 lr : 0.6622820409839835\n",
      "epoch : 41 [11/23] Train loss: 3.44975,Valid loss: 3.94713, time : 10.083828449249268 lr : 0.6622820409839835\n",
      "epoch : 41 [12/23] Train loss: 3.52433,Valid loss: 4.06098, time : 9.864685535430908 lr : 0.6622820409839835\n",
      "epoch : 41 [13/23] Train loss: 3.53302,Valid loss: 4.44257, time : 10.166404247283936 lr : 0.6622820409839835\n",
      "epoch : 41 [14/23] Train loss: 3.52524,Valid loss: 4.14777, time : 9.907650232315063 lr : 0.6622820409839835\n",
      "epoch : 41 [15/23] Train loss: 3.42929,Valid loss: 4.09073, time : 9.970421314239502 lr : 0.6622820409839835\n",
      "epoch : 41 [16/23] Train loss: 3.40504,Valid loss: 4.01814, time : 9.707611322402954 lr : 0.6622820409839835\n",
      "epoch : 41 [17/23] Train loss: 3.40992,Valid loss: 4.02025, time : 9.8271484375 lr : 0.6622820409839835\n",
      "epoch : 41 [18/23] Train loss: 3.50549,Valid loss: 4.07380, time : 10.044404029846191 lr : 0.6622820409839835\n",
      "epoch : 41 [19/23] Train loss: 3.43258,Valid loss: 4.29104, time : 9.985966682434082 lr : 0.6622820409839835\n",
      "epoch : 41 [20/23] Train loss: 3.55856,Valid loss: 4.97335, time : 10.101830959320068 lr : 0.6622820409839835\n",
      "epoch : 41 [21/23] Train loss: 3.44411,Valid loss: 4.71615, time : 10.056087493896484 lr : 0.6622820409839835\n",
      "epoch : 41 [22/23] Train loss: 3.53942,Valid loss: 4.10652, time : 9.477312803268433 lr : 0.6622820409839835\n",
      "epoch : 42 [0/23] Train loss: 3.43045,Valid loss: 4.11648, time : 9.82425856590271 lr : 0.6556592205741436\n",
      "epoch : 42 [1/23] Train loss: 3.43589,Valid loss: 4.31960, time : 10.084280252456665 lr : 0.6556592205741436\n",
      "epoch : 42 [2/23] Train loss: 3.42791,Valid loss: 4.24338, time : 10.158292770385742 lr : 0.6556592205741436\n",
      "epoch : 42 [3/23] Train loss: 3.42248,Valid loss: 4.29651, time : 10.302045106887817 lr : 0.6556592205741436\n",
      "epoch : 42 [4/23] Train loss: 3.41883,Valid loss: 3.97622, time : 10.247452020645142 lr : 0.6556592205741436\n",
      "epoch : 42 [5/23] Train loss: 3.54776,Valid loss: 3.87926, time : 10.175375699996948 lr : 0.6556592205741436\n",
      "epoch : 42 [6/23] Train loss: 3.41636,Valid loss: 4.10662, time : 10.0039644241333 lr : 0.6556592205741436\n",
      "epoch : 42 [7/23] Train loss: 3.39210,Valid loss: 4.04645, time : 9.717565536499023 lr : 0.6556592205741436\n",
      "epoch : 42 [8/23] Train loss: 3.39724,Valid loss: 3.91067, time : 9.799165964126587 lr : 0.6556592205741436\n",
      "epoch : 42 [9/23] Train loss: 3.56352,Valid loss: 3.94861, time : 9.833607912063599 lr : 0.6556592205741436\n",
      "epoch : 42 [10/23] Train loss: 3.37525,Valid loss: 3.90574, time : 10.17687177658081 lr : 0.6556592205741436\n",
      "epoch : 42 [11/23] Train loss: 3.39441,Valid loss: 4.78926, time : 9.957242488861084 lr : 0.6556592205741436\n",
      "epoch : 42 [12/23] Train loss: 3.38311,Valid loss: 4.18108, time : 10.144583463668823 lr : 0.6556592205741436\n",
      "epoch : 42 [13/23] Train loss: 3.38551,Valid loss: 4.22087, time : 9.863104820251465 lr : 0.6556592205741436\n",
      "epoch : 42 [14/23] Train loss: 3.42717,Valid loss: 3.84706, time : 10.003731489181519 lr : 0.6556592205741436\n",
      "epoch : 42 [15/23] Train loss: 3.53750,Valid loss: 3.89521, time : 9.942863702774048 lr : 0.6556592205741436\n",
      "epoch : 42 [16/23] Train loss: 3.36591,Valid loss: 4.30843, time : 9.904205560684204 lr : 0.6556592205741436\n",
      "epoch : 42 [17/23] Train loss: 3.34859,Valid loss: 4.68846, time : 9.66308856010437 lr : 0.6556592205741436\n",
      "epoch : 42 [18/23] Train loss: 3.35547,Valid loss: 4.41821, time : 9.747220277786255 lr : 0.6556592205741436\n",
      "epoch : 42 [19/23] Train loss: 3.40345,Valid loss: 3.98674, time : 9.583957195281982 lr : 0.6556592205741436\n",
      "epoch : 42 [20/23] Train loss: 3.41693,Valid loss: 3.83573, time : 9.840878009796143 lr : 0.6556592205741436\n",
      "epoch : 42 [21/23] Train loss: 3.55582,Valid loss: 3.99960, time : 9.612781286239624 lr : 0.6556592205741436\n",
      "epoch : 42 [22/23] Train loss: 3.37393,Valid loss: 3.89890, time : 9.346675157546997 lr : 0.6556592205741436\n",
      "epoch : 43 [0/23] Train loss: 3.39759,Valid loss: 3.96934, time : 9.940616607666016 lr : 0.6491026283684022\n",
      "epoch : 43 [1/23] Train loss: 3.51076,Valid loss: 4.24733, time : 9.979776620864868 lr : 0.6491026283684022\n",
      "epoch : 43 [2/23] Train loss: 3.65016,Valid loss: 4.46123, time : 9.88137435913086 lr : 0.6491026283684022\n",
      "epoch : 43 [3/23] Train loss: 3.37515,Valid loss: 3.97650, time : 10.24351692199707 lr : 0.6491026283684022\n",
      "epoch : 43 [4/23] Train loss: 3.32346,Valid loss: 4.19743, time : 9.884623050689697 lr : 0.6491026283684022\n",
      "epoch : 43 [5/23] Train loss: 3.30861,Valid loss: 3.90157, time : 10.125364542007446 lr : 0.6491026283684022\n",
      "epoch : 43 [6/23] Train loss: 3.38382,Valid loss: 3.97599, time : 9.953392505645752 lr : 0.6491026283684022\n",
      "epoch : 43 [7/23] Train loss: 3.40999,Valid loss: 3.95105, time : 10.302998781204224 lr : 0.6491026283684022\n",
      "epoch : 43 [8/23] Train loss: 3.46694,Valid loss: 3.99803, time : 10.149238586425781 lr : 0.6491026283684022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 43 [9/23] Train loss: 3.30666,Valid loss: 4.01265, time : 10.082927227020264 lr : 0.6491026283684022\n",
      "epoch : 43 [10/23] Train loss: 3.33725,Valid loss: 4.13635, time : 10.169979810714722 lr : 0.6491026283684022\n",
      "epoch : 43 [11/23] Train loss: 3.35588,Valid loss: 4.06366, time : 10.173388242721558 lr : 0.6491026283684022\n",
      "epoch : 43 [12/23] Train loss: 3.51624,Valid loss: 4.05010, time : 9.571259260177612 lr : 0.6491026283684022\n",
      "epoch : 43 [13/23] Train loss: 3.40702,Valid loss: 3.96111, time : 10.141630172729492 lr : 0.6491026283684022\n",
      "epoch : 43 [14/23] Train loss: 3.53319,Valid loss: 4.12079, time : 9.887616395950317 lr : 0.6491026283684022\n",
      "epoch : 43 [15/23] Train loss: 3.31254,Valid loss: 4.00185, time : 9.931653261184692 lr : 0.6491026283684022\n",
      "epoch : 43 [16/23] Train loss: 3.27743,Valid loss: 3.91160, time : 10.077452898025513 lr : 0.6491026283684022\n",
      "epoch : 43 [17/23] Train loss: 3.30697,Valid loss: 3.82569, time : 10.147282123565674 lr : 0.6491026283684022\n",
      "epoch : 43 [18/23] Train loss: 3.32220,Valid loss: 3.83986, time : 10.170259475708008 lr : 0.6491026283684022\n",
      "epoch : 43 [19/23] Train loss: 3.38419,Valid loss: 4.08026, time : 9.94700837135315 lr : 0.6491026283684022\n",
      "epoch : 43 [20/23] Train loss: 3.39440,Valid loss: 4.31975, time : 10.032602787017822 lr : 0.6491026283684022\n",
      "epoch : 43 [21/23] Train loss: 3.38895,Valid loss: 4.55043, time : 10.100560665130615 lr : 0.6491026283684022\n",
      "epoch : 43 [22/23] Train loss: 3.35013,Valid loss: 4.28688, time : 9.450642585754395 lr : 0.6491026283684022\n",
      "epoch : 44 [0/23] Train loss: 3.30233,Valid loss: 4.09919, time : 10.249793291091919 lr : 0.6426116020847181\n",
      "epoch : 44 [1/23] Train loss: 3.29419,Valid loss: 4.04179, time : 10.239202499389648 lr : 0.6426116020847181\n",
      "epoch : 44 [2/23] Train loss: 3.27764,Valid loss: 4.07217, time : 9.98528504371643 lr : 0.6426116020847181\n",
      "epoch : 44 [3/23] Train loss: 3.26887,Valid loss: 3.82051, time : 10.078493595123291 lr : 0.6426116020847181\n",
      "epoch : 44 [4/23] Train loss: 3.39981,Valid loss: 3.92328, time : 10.499106645584106 lr : 0.6426116020847181\n",
      "epoch : 44 [5/23] Train loss: 3.48896,Valid loss: 4.41447, time : 10.138254880905151 lr : 0.6426116020847181\n",
      "epoch : 44 [6/23] Train loss: 3.68835,Valid loss: 4.43051, time : 9.703655004501343 lr : 0.6426116020847181\n",
      "epoch : 44 [7/23] Train loss: 3.42113,Valid loss: 4.70928, time : 10.018307447433472 lr : 0.6426116020847181\n",
      "epoch : 44 [8/23] Train loss: 3.40439,Valid loss: 4.47761, time : 10.008195400238037 lr : 0.6426116020847181\n",
      "epoch : 44 [9/23] Train loss: 3.26807,Valid loss: 3.97441, time : 9.917146682739258 lr : 0.6426116020847181\n",
      "epoch : 44 [10/23] Train loss: 3.23489,Valid loss: 3.82149, time : 10.370770931243896 lr : 0.6426116020847181\n",
      "epoch : 44 [11/23] Train loss: 3.31099,Valid loss: 3.85493, time : 10.16932225227356 lr : 0.6426116020847181\n",
      "epoch : 44 [12/23] Train loss: 3.51609,Valid loss: 4.41585, time : 10.216250658035278 lr : 0.6426116020847181\n",
      "epoch : 44 [13/23] Train loss: 3.33076,Valid loss: 4.27576, time : 9.70265531539917 lr : 0.6426116020847181\n",
      "epoch : 44 [14/23] Train loss: 3.34188,Valid loss: 4.89276, time : 10.191606998443604 lr : 0.6426116020847181\n",
      "epoch : 44 [15/23] Train loss: 3.37748,Valid loss: 4.02520, time : 9.599146366119385 lr : 0.6426116020847181\n",
      "epoch : 44 [16/23] Train loss: 3.47580,Valid loss: 3.92488, time : 9.81627869606018 lr : 0.6426116020847181\n",
      "epoch : 44 [17/23] Train loss: 3.23816,Valid loss: 3.78538, time : 9.875128030776978 lr : 0.6426116020847181\n",
      "epoch : 44 [18/23] Train loss: 3.20875,Valid loss: 3.87247, time : 10.049659729003906 lr : 0.6426116020847181\n",
      "epoch : 44 [19/23] Train loss: 3.23983,Valid loss: 3.78584, time : 9.98802900314331 lr : 0.6426116020847181\n",
      "epoch : 44 [20/23] Train loss: 3.29614,Valid loss: 3.79908, time : 10.185104846954346 lr : 0.6426116020847181\n",
      "epoch : 44 [21/23] Train loss: 3.38527,Valid loss: 3.82670, time : 9.823169469833374 lr : 0.6426116020847181\n",
      "epoch : 44 [22/23] Train loss: 3.56666,Valid loss: 3.86830, time : 9.41282606124878 lr : 0.6426116020847181\n",
      "epoch : 45 [0/23] Train loss: 3.32543,Valid loss: 4.14056, time : 9.909345865249634 lr : 0.6361854860638709\n",
      "epoch : 45 [1/23] Train loss: 3.26858,Valid loss: 3.78255, time : 10.283392429351807 lr : 0.6361854860638709\n",
      "epoch : 45 [2/23] Train loss: 3.26436,Valid loss: 3.86688, time : 10.031845092773438 lr : 0.6361854860638709\n",
      "epoch : 45 [3/23] Train loss: 3.31639,Valid loss: 3.86274, time : 10.135076999664307 lr : 0.6361854860638709\n",
      "epoch : 45 [4/23] Train loss: 3.29217,Valid loss: 3.86393, time : 10.072736263275146 lr : 0.6361854860638709\n",
      "epoch : 45 [5/23] Train loss: 3.34515,Valid loss: 3.78784, time : 10.13338851928711 lr : 0.6361854860638709\n",
      "epoch : 45 [6/23] Train loss: 3.35282,Valid loss: 3.75709, time : 10.829152822494507 lr : 0.6361854860638709\n",
      "epoch : 45 [7/23] Train loss: 3.48951,Valid loss: 4.49913, time : 10.410726308822632 lr : 0.6361854860638709\n",
      "epoch : 45 [8/23] Train loss: 3.23497,Valid loss: 4.24388, time : 9.992969989776611 lr : 0.6361854860638709\n",
      "epoch : 45 [9/23] Train loss: 3.18997,Valid loss: 3.98763, time : 9.833765268325806 lr : 0.6361854860638709\n",
      "epoch : 45 [10/23] Train loss: 3.19817,Valid loss: 3.88668, time : 10.020625591278076 lr : 0.6361854860638709\n",
      "epoch : 45 [11/23] Train loss: 3.22187,Valid loss: 3.75049, time : 9.627780675888062 lr : 0.6361854860638709\n",
      "epoch : 45 [12/23] Train loss: 3.30260,Valid loss: 3.69168, time : 9.90341067314148 lr : 0.6361854860638709\n",
      "epoch : 45 [13/23] Train loss: 3.48948,Valid loss: 3.90393, time : 10.073261499404907 lr : 0.6361854860638709\n",
      "epoch : 45 [14/23] Train loss: 3.25695,Valid loss: 3.92758, time : 9.955200910568237 lr : 0.6361854860638709\n",
      "epoch : 45 [15/23] Train loss: 3.18719,Valid loss: 4.02873, time : 9.64174485206604 lr : 0.6361854860638709\n",
      "epoch : 45 [16/23] Train loss: 3.16825,Valid loss: 3.92632, time : 10.062012910842896 lr : 0.6361854860638709\n",
      "epoch : 45 [17/23] Train loss: 3.19009,Valid loss: 3.89393, time : 9.568840503692627 lr : 0.6361854860638709\n",
      "epoch : 45 [18/23] Train loss: 3.23524,Valid loss: 3.88715, time : 10.310494661331177 lr : 0.6361854860638709\n",
      "epoch : 45 [19/23] Train loss: 3.40707,Valid loss: 3.86362, time : 9.758088111877441 lr : 0.6361854860638709\n",
      "epoch : 45 [20/23] Train loss: 3.25589,Valid loss: 4.08458, time : 9.75052523612976 lr : 0.6361854860638709\n",
      "epoch : 45 [21/23] Train loss: 3.36612,Valid loss: 4.00257, time : 9.634750604629517 lr : 0.6361854860638709\n",
      "epoch : 45 [22/23] Train loss: 3.34625,Valid loss: 3.91642, time : 9.660156965255737 lr : 0.6361854860638709\n",
      "epoch : 46 [0/23] Train loss: 3.44954,Valid loss: 4.18248, time : 10.022725105285645 lr : 0.6298236312032323\n",
      "epoch : 46 [1/23] Train loss: 3.24078,Valid loss: 3.69399, time : 10.267189264297485 lr : 0.6298236312032323\n",
      "epoch : 46 [2/23] Train loss: 3.21810,Valid loss: 3.85857, time : 9.984174966812134 lr : 0.6298236312032323\n",
      "epoch : 46 [3/23] Train loss: 3.20523,Valid loss: 3.76573, time : 9.963350057601929 lr : 0.6298236312032323\n",
      "epoch : 46 [4/23] Train loss: 3.22943,Valid loss: 3.72014, time : 9.631078720092773 lr : 0.6298236312032323\n",
      "epoch : 46 [5/23] Train loss: 3.21770,Valid loss: 3.62086, time : 9.991038799285889 lr : 0.6298236312032323\n",
      "epoch : 46 [6/23] Train loss: 3.20958,Valid loss: 3.73520, time : 9.629225492477417 lr : 0.6298236312032323\n",
      "epoch : 46 [7/23] Train loss: 3.21443,Valid loss: 3.72235, time : 9.967347383499146 lr : 0.6298236312032323\n",
      "epoch : 46 [8/23] Train loss: 3.22071,Valid loss: 3.94398, time : 9.961287260055542 lr : 0.6298236312032323\n",
      "epoch : 46 [9/23] Train loss: 3.21180,Valid loss: 4.02007, time : 10.148033618927002 lr : 0.6298236312032323\n",
      "epoch : 46 [10/23] Train loss: 3.39647,Valid loss: 4.06096, time : 10.338055849075317 lr : 0.6298236312032323\n",
      "epoch : 46 [11/23] Train loss: 3.27318,Valid loss: 3.99553, time : 9.780574321746826 lr : 0.6298236312032323\n",
      "epoch : 46 [12/23] Train loss: 3.40401,Valid loss: 4.05535, time : 10.237394332885742 lr : 0.6298236312032323\n",
      "epoch : 46 [13/23] Train loss: 3.23608,Valid loss: 3.78158, time : 9.886731624603271 lr : 0.6298236312032323\n",
      "epoch : 46 [14/23] Train loss: 3.30411,Valid loss: 3.69203, time : 9.939525127410889 lr : 0.6298236312032323\n",
      "epoch : 46 [15/23] Train loss: 3.19433,Valid loss: 3.59542, time : 9.860236406326294 lr : 0.6298236312032323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 46 [16/23] Train loss: 3.17927,Valid loss: 3.57207, time : 10.274990797042847 lr : 0.6298236312032323\n",
      "epoch : 46 [17/23] Train loss: 3.19273,Valid loss: 3.60988, time : 9.914754390716553 lr : 0.6298236312032323\n",
      "epoch : 46 [18/23] Train loss: 3.28720,Valid loss: 3.71722, time : 10.085274457931519 lr : 0.6298236312032323\n",
      "epoch : 46 [19/23] Train loss: 3.14790,Valid loss: 3.85699, time : 9.846501350402832 lr : 0.6298236312032323\n",
      "epoch : 46 [20/23] Train loss: 3.13779,Valid loss: 4.00693, time : 10.228692293167114 lr : 0.6298236312032323\n",
      "epoch : 46 [21/23] Train loss: 3.19555,Valid loss: 3.98336, time : 10.067119836807251 lr : 0.6298236312032323\n",
      "epoch : 46 [22/23] Train loss: 3.26285,Valid loss: 4.63829, time : 9.505301237106323 lr : 0.6298236312032323\n",
      "epoch : 47 [0/23] Train loss: 3.23092,Valid loss: 4.27736, time : 10.518575429916382 lr : 0.6235253948912\n",
      "epoch : 47 [1/23] Train loss: 3.37640,Valid loss: 3.97123, time : 10.113019704818726 lr : 0.6235253948912\n",
      "epoch : 47 [2/23] Train loss: 3.19044,Valid loss: 4.12764, time : 10.16946005821228 lr : 0.6235253948912\n",
      "epoch : 47 [3/23] Train loss: 3.22292,Valid loss: 4.07371, time : 10.39945363998413 lr : 0.6235253948912\n",
      "epoch : 47 [4/23] Train loss: 3.20106,Valid loss: 3.92602, time : 10.282973289489746 lr : 0.6235253948912\n",
      "epoch : 47 [5/23] Train loss: 3.16137,Valid loss: 3.92270, time : 10.345016956329346 lr : 0.6235253948912\n",
      "epoch : 47 [6/23] Train loss: 3.16808,Valid loss: 3.65793, time : 10.38964581489563 lr : 0.6235253948912\n",
      "epoch : 47 [7/23] Train loss: 3.18085,Valid loss: 3.62563, time : 10.299443244934082 lr : 0.6235253948912\n",
      "epoch : 47 [8/23] Train loss: 3.16458,Valid loss: 3.82750, time : 10.555710315704346 lr : 0.6235253948912\n",
      "epoch : 47 [9/23] Train loss: 3.28230,Valid loss: 3.71704, time : 10.175273895263672 lr : 0.6235253948912\n",
      "epoch : 47 [10/23] Train loss: 3.19310,Valid loss: 4.26155, time : 10.231670379638672 lr : 0.6235253948912\n",
      "epoch : 47 [11/23] Train loss: 3.24498,Valid loss: 4.51458, time : 9.924295902252197 lr : 0.6235253948912\n",
      "epoch : 47 [12/23] Train loss: 3.18918,Valid loss: 4.60438, time : 10.33326268196106 lr : 0.6235253948912\n",
      "epoch : 47 [13/23] Train loss: 3.25393,Valid loss: 4.49710, time : 10.075376510620117 lr : 0.6235253948912\n",
      "epoch : 47 [14/23] Train loss: 3.17835,Valid loss: 3.73089, time : 10.162049531936646 lr : 0.6235253948912\n",
      "epoch : 47 [15/23] Train loss: 3.25890,Valid loss: 3.80680, time : 10.372674703598022 lr : 0.6235253948912\n",
      "epoch : 47 [16/23] Train loss: 3.12505,Valid loss: 3.58965, time : 10.388221025466919 lr : 0.6235253948912\n",
      "epoch : 47 [17/23] Train loss: 3.20320,Valid loss: 3.88675, time : 10.648799896240234 lr : 0.6235253948912\n",
      "epoch : 47 [18/23] Train loss: 3.22168,Valid loss: 3.68153, time : 10.552292585372925 lr : 0.6235253948912\n",
      "epoch : 47 [19/23] Train loss: 3.40798,Valid loss: 3.83573, time : 10.507150173187256 lr : 0.6235253948912\n",
      "epoch : 47 [20/23] Train loss: 3.11320,Valid loss: 3.69371, time : 10.307180643081665 lr : 0.6235253948912\n",
      "epoch : 47 [21/23] Train loss: 3.10149,Valid loss: 3.77722, time : 10.516382932662964 lr : 0.6235253948912\n",
      "epoch : 47 [22/23] Train loss: 3.09763,Valid loss: 3.92392, time : 10.024216175079346 lr : 0.6235253948912\n",
      "epoch : 48 [0/23] Train loss: 3.08045,Valid loss: 3.77325, time : 11.12067985534668 lr : 0.617290140942288\n",
      "epoch : 48 [1/23] Train loss: 3.12078,Valid loss: 3.69115, time : 10.916057348251343 lr : 0.617290140942288\n",
      "epoch : 48 [2/23] Train loss: 3.12089,Valid loss: 3.91203, time : 10.72569727897644 lr : 0.617290140942288\n",
      "epoch : 48 [3/23] Train loss: 3.20254,Valid loss: 3.77250, time : 10.796828508377075 lr : 0.617290140942288\n",
      "epoch : 48 [4/23] Train loss: 3.14676,Valid loss: 3.73064, time : 11.17591118812561 lr : 0.617290140942288\n",
      "epoch : 48 [5/23] Train loss: 3.29972,Valid loss: 3.87106, time : 10.587268590927124 lr : 0.617290140942288\n",
      "epoch : 48 [6/23] Train loss: 3.19882,Valid loss: 4.30429, time : 10.598716735839844 lr : 0.617290140942288\n",
      "epoch : 48 [7/23] Train loss: 3.26477,Valid loss: 4.52483, time : 10.599515914916992 lr : 0.617290140942288\n",
      "epoch : 48 [8/23] Train loss: 3.20088,Valid loss: 4.20096, time : 10.598212957382202 lr : 0.617290140942288\n",
      "epoch : 48 [9/23] Train loss: 3.24645,Valid loss: 3.75136, time : 10.630271196365356 lr : 0.617290140942288\n",
      "epoch : 48 [10/23] Train loss: 3.12911,Valid loss: 3.69218, time : 10.232688903808594 lr : 0.617290140942288\n",
      "epoch : 48 [11/23] Train loss: 3.09339,Valid loss: 3.76793, time : 10.514411211013794 lr : 0.617290140942288\n",
      "epoch : 48 [12/23] Train loss: 3.10155,Valid loss: 3.80265, time : 10.438371896743774 lr : 0.617290140942288\n",
      "epoch : 48 [13/23] Train loss: 3.15690,Valid loss: 3.92233, time : 10.535493850708008 lr : 0.617290140942288\n",
      "epoch : 48 [14/23] Train loss: 3.08133,Valid loss: 3.63761, time : 10.48227572441101 lr : 0.617290140942288\n",
      "epoch : 48 [15/23] Train loss: 3.16317,Valid loss: 3.74402, time : 10.59479308128357 lr : 0.617290140942288\n",
      "epoch : 48 [16/23] Train loss: 3.13808,Valid loss: 3.55377, time : 10.073282480239868 lr : 0.617290140942288\n",
      "epoch : 48 [17/23] Train loss: 3.24571,Valid loss: 3.74825, time : 10.496845483779907 lr : 0.617290140942288\n",
      "epoch : 48 [18/23] Train loss: 3.04928,Valid loss: 3.57911, time : 9.990020751953125 lr : 0.617290140942288\n",
      "epoch : 48 [19/23] Train loss: 3.03539,Valid loss: 3.51429, time : 10.41968321800232 lr : 0.617290140942288\n",
      "epoch : 48 [20/23] Train loss: 3.01178,Valid loss: 3.54920, time : 10.01925015449524 lr : 0.617290140942288\n",
      "epoch : 48 [21/23] Train loss: 3.03871,Valid loss: 3.67946, time : 10.324692726135254 lr : 0.617290140942288\n",
      "epoch : 48 [22/23] Train loss: 3.07201,Valid loss: 3.61939, time : 9.59151816368103 lr : 0.617290140942288\n",
      "epoch : 49 [0/23] Train loss: 3.09068,Valid loss: 3.68182, time : 10.261648654937744 lr : 0.6111172395328651\n",
      "epoch : 49 [1/23] Train loss: 3.14834,Valid loss: 3.62323, time : 10.196703672409058 lr : 0.6111172395328651\n",
      "epoch : 49 [2/23] Train loss: 3.02824,Valid loss: 3.58289, time : 10.130881071090698 lr : 0.6111172395328651\n",
      "epoch : 49 [3/23] Train loss: 3.04494,Valid loss: 3.67404, time : 10.531221151351929 lr : 0.6111172395328651\n",
      "epoch : 49 [4/23] Train loss: 3.13846,Valid loss: 3.53930, time : 10.575502634048462 lr : 0.6111172395328651\n",
      "epoch : 49 [5/23] Train loss: 3.16766,Valid loss: 3.56345, time : 10.188949346542358 lr : 0.6111172395328651\n",
      "epoch : 49 [6/23] Train loss: 3.04297,Valid loss: 3.82735, time : 10.537983179092407 lr : 0.6111172395328651\n",
      "epoch : 49 [7/23] Train loss: 3.04629,Valid loss: 3.63170, time : 10.01499319076538 lr : 0.6111172395328651\n",
      "epoch : 49 [8/23] Train loss: 3.10366,Valid loss: 3.88998, time : 10.425143957138062 lr : 0.6111172395328651\n",
      "epoch : 49 [9/23] Train loss: 3.36139,Valid loss: 4.03852, time : 10.28972339630127 lr : 0.6111172395328651\n",
      "epoch : 49 [10/23] Train loss: 3.19513,Valid loss: 4.85736, time : 10.494864702224731 lr : 0.6111172395328651\n",
      "epoch : 49 [11/23] Train loss: 3.26063,Valid loss: 4.98953, time : 10.266518115997314 lr : 0.6111172395328651\n",
      "epoch : 49 [12/23] Train loss: 3.12069,Valid loss: 3.74451, time : 10.255035877227783 lr : 0.6111172395328651\n",
      "epoch : 49 [13/23] Train loss: 3.12630,Valid loss: 3.59925, time : 10.415108919143677 lr : 0.6111172395328651\n",
      "epoch : 49 [14/23] Train loss: 3.05573,Valid loss: 3.49883, time : 10.442783832550049 lr : 0.6111172395328651\n",
      "epoch : 49 [15/23] Train loss: 3.12810,Valid loss: 3.51986, time : 10.426766157150269 lr : 0.6111172395328651\n",
      "epoch : 49 [16/23] Train loss: 3.03783,Valid loss: 3.46391, time : 10.597941160202026 lr : 0.6111172395328651\n",
      "epoch : 49 [17/23] Train loss: 3.14100,Valid loss: 3.55780, time : 10.841378211975098 lr : 0.6111172395328651\n",
      "epoch : 49 [18/23] Train loss: 3.08852,Valid loss: 3.60115, time : 10.695564270019531 lr : 0.6111172395328651\n",
      "epoch : 49 [19/23] Train loss: 3.16809,Valid loss: 3.59584, time : 10.537532091140747 lr : 0.6111172395328651\n",
      "epoch : 49 [20/23] Train loss: 3.05760,Valid loss: 3.61568, time : 10.691003322601318 lr : 0.6111172395328651\n",
      "epoch : 49 [21/23] Train loss: 3.07539,Valid loss: 3.66849, time : 10.631813526153564 lr : 0.6111172395328651\n",
      "epoch : 49 [22/23] Train loss: 3.00538,Valid loss: 3.69562, time : 9.581387519836426 lr : 0.6111172395328651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 50 [0/23] Train loss: 3.11931,Valid loss: 3.54083, time : 10.46264362335205 lr : 0.6050060671375365\n",
      "epoch : 50 [1/23] Train loss: 2.98974,Valid loss: 3.70631, time : 10.281896114349365 lr : 0.6050060671375365\n",
      "epoch : 50 [2/23] Train loss: 2.98351,Valid loss: 3.50267, time : 10.195658445358276 lr : 0.6050060671375365\n",
      "epoch : 50 [3/23] Train loss: 2.98355,Valid loss: 3.56923, time : 10.333815813064575 lr : 0.6050060671375365\n",
      "epoch : 50 [4/23] Train loss: 3.00295,Valid loss: 3.81191, time : 10.419759511947632 lr : 0.6050060671375365\n",
      "epoch : 50 [5/23] Train loss: 3.01631,Valid loss: 3.49024, time : 10.933224201202393 lr : 0.6050060671375365\n",
      "epoch : 50 [6/23] Train loss: 3.02717,Valid loss: 3.58523, time : 10.58827829360962 lr : 0.6050060671375365\n",
      "epoch : 50 [7/23] Train loss: 3.06453,Valid loss: 3.60384, time : 10.537707090377808 lr : 0.6050060671375365\n",
      "epoch : 50 [8/23] Train loss: 3.22566,Valid loss: 3.89416, time : 10.591031312942505 lr : 0.6050060671375365\n",
      "epoch : 50 [9/23] Train loss: 3.02229,Valid loss: 3.92633, time : 10.63709568977356 lr : 0.6050060671375365\n",
      "epoch : 50 [10/23] Train loss: 3.08310,Valid loss: 4.47321, time : 10.383974552154541 lr : 0.6050060671375365\n",
      "epoch : 50 [11/23] Train loss: 3.02833,Valid loss: 3.98549, time : 10.099767208099365 lr : 0.6050060671375365\n",
      "epoch : 50 [12/23] Train loss: 3.09336,Valid loss: 4.36715, time : 10.436599493026733 lr : 0.6050060671375365\n",
      "epoch : 50 [13/23] Train loss: 3.00058,Valid loss: 3.63813, time : 10.087397575378418 lr : 0.6050060671375365\n",
      "epoch : 50 [14/23] Train loss: 2.98168,Valid loss: 3.58316, time : 10.239665508270264 lr : 0.6050060671375365\n",
      "epoch : 50 [15/23] Train loss: 2.92980,Valid loss: 3.46077, time : 9.666049003601074 lr : 0.6050060671375365\n",
      "epoch : 50 [16/23] Train loss: 3.01008,Valid loss: 3.38870, time : 10.682228803634644 lr : 0.6050060671375365\n",
      "epoch : 50 [17/23] Train loss: 2.97155,Valid loss: 3.45903, time : 9.880499124526978 lr : 0.6050060671375365\n",
      "epoch : 50 [18/23] Train loss: 3.07424,Valid loss: 3.60209, time : 10.305853366851807 lr : 0.6050060671375365\n",
      "epoch : 50 [19/23] Train loss: 3.03555,Valid loss: 3.62023, time : 10.279095649719238 lr : 0.6050060671375365\n",
      "epoch : 50 [20/23] Train loss: 3.14693,Valid loss: 3.87568, time : 10.233181953430176 lr : 0.6050060671375365\n",
      "epoch : 50 [21/23] Train loss: 3.03537,Valid loss: 3.48898, time : 10.067224740982056 lr : 0.6050060671375365\n",
      "epoch : 50 [22/23] Train loss: 3.14076,Valid loss: 3.62664, time : 9.586302995681763 lr : 0.6050060671375365\n",
      "epoch : 51 [0/23] Train loss: 3.03979,Valid loss: 3.44573, time : 10.510246753692627 lr : 0.5989560064661611\n",
      "epoch : 51 [1/23] Train loss: 3.12172,Valid loss: 3.57895, time : 10.208848714828491 lr : 0.5989560064661611\n",
      "epoch : 51 [2/23] Train loss: 2.96317,Valid loss: 3.43827, time : 10.486564874649048 lr : 0.5989560064661611\n",
      "epoch : 51 [3/23] Train loss: 2.95004,Valid loss: 3.58427, time : 10.208642959594727 lr : 0.5989560064661611\n",
      "epoch : 51 [4/23] Train loss: 2.91952,Valid loss: 3.52295, time : 10.635369062423706 lr : 0.5989560064661611\n",
      "epoch : 51 [5/23] Train loss: 2.91890,Valid loss: 3.59738, time : 10.432509422302246 lr : 0.5989560064661611\n",
      "epoch : 51 [6/23] Train loss: 2.95987,Valid loss: 3.72909, time : 10.579186916351318 lr : 0.5989560064661611\n",
      "epoch : 51 [7/23] Train loss: 2.92370,Valid loss: 3.48495, time : 10.942258596420288 lr : 0.5989560064661611\n",
      "epoch : 51 [8/23] Train loss: 2.95245,Valid loss: 4.12071, time : 10.504889488220215 lr : 0.5989560064661611\n",
      "epoch : 51 [9/23] Train loss: 2.91230,Valid loss: 3.64454, time : 10.36360239982605 lr : 0.5989560064661611\n",
      "epoch : 51 [10/23] Train loss: 2.97050,Valid loss: 4.61719, time : 10.521516799926758 lr : 0.5989560064661611\n",
      "epoch : 51 [11/23] Train loss: 2.95279,Valid loss: 3.92682, time : 10.280052900314331 lr : 0.5989560064661611\n",
      "epoch : 51 [12/23] Train loss: 3.02812,Valid loss: 3.79079, time : 10.271533250808716 lr : 0.5989560064661611\n",
      "epoch : 51 [13/23] Train loss: 3.07993,Valid loss: 3.61270, time : 10.113089084625244 lr : 0.5989560064661611\n",
      "epoch : 51 [14/23] Train loss: 3.29683,Valid loss: 3.52436, time : 10.429572343826294 lr : 0.5989560064661611\n",
      "epoch : 51 [15/23] Train loss: 2.96886,Valid loss: 4.15200, time : 10.859523296356201 lr : 0.5989560064661611\n",
      "epoch : 51 [16/23] Train loss: 2.93087,Valid loss: 3.90081, time : 10.15977931022644 lr : 0.5989560064661611\n",
      "epoch : 51 [17/23] Train loss: 2.91721,Valid loss: 3.65379, time : 10.325161933898926 lr : 0.5989560064661611\n",
      "epoch : 51 [18/23] Train loss: 2.97595,Valid loss: 3.40926, time : 10.134032487869263 lr : 0.5989560064661611\n",
      "epoch : 51 [19/23] Train loss: 2.95223,Valid loss: 3.67208, time : 10.46510648727417 lr : 0.5989560064661611\n",
      "epoch : 51 [20/23] Train loss: 3.14178,Valid loss: 3.45728, time : 10.367050886154175 lr : 0.5989560064661611\n",
      "epoch : 51 [21/23] Train loss: 2.94318,Valid loss: 3.42816, time : 10.175913572311401 lr : 0.5989560064661611\n",
      "epoch : 51 [22/23] Train loss: 2.93978,Valid loss: 3.55360, time : 9.993131875991821 lr : 0.5989560064661611\n",
      "epoch : 52 [0/23] Train loss: 2.87253,Valid loss: 3.64737, time : 10.546334505081177 lr : 0.5929664464014994\n",
      "epoch : 52 [1/23] Train loss: 2.92206,Valid loss: 3.53240, time : 10.325045108795166 lr : 0.5929664464014994\n",
      "epoch : 52 [2/23] Train loss: 2.84506,Valid loss: 3.41432, time : 10.129982233047485 lr : 0.5929664464014994\n",
      "epoch : 52 [3/23] Train loss: 2.87042,Valid loss: 3.49467, time : 10.259635210037231 lr : 0.5929664464014994\n",
      "epoch : 52 [4/23] Train loss: 2.86860,Valid loss: 3.35949, time : 10.408341884613037 lr : 0.5929664464014994\n",
      "epoch : 52 [5/23] Train loss: 2.94633,Valid loss: 3.42472, time : 9.941463470458984 lr : 0.5929664464014994\n",
      "epoch : 52 [6/23] Train loss: 2.91487,Valid loss: 3.42748, time : 10.393265724182129 lr : 0.5929664464014994\n",
      "epoch : 52 [7/23] Train loss: 3.08714,Valid loss: 3.74799, time : 10.436572551727295 lr : 0.5929664464014994\n",
      "epoch : 52 [8/23] Train loss: 3.02044,Valid loss: 4.19732, time : 10.563294887542725 lr : 0.5929664464014994\n",
      "epoch : 52 [9/23] Train loss: 3.30144,Valid loss: 4.15741, time : 10.837715864181519 lr : 0.5929664464014994\n",
      "epoch : 52 [10/23] Train loss: 3.04929,Valid loss: 3.67131, time : 10.523355722427368 lr : 0.5929664464014994\n",
      "epoch : 52 [11/23] Train loss: 2.95218,Valid loss: 3.71096, time : 10.483365297317505 lr : 0.5929664464014994\n",
      "epoch : 52 [12/23] Train loss: 2.88211,Valid loss: 3.36196, time : 10.318321228027344 lr : 0.5929664464014994\n",
      "epoch : 52 [13/23] Train loss: 2.89656,Valid loss: 3.39982, time : 10.545315504074097 lr : 0.5929664464014994\n",
      "epoch : 52 [14/23] Train loss: 2.88347,Valid loss: 3.35971, time : 10.342202186584473 lr : 0.5929664464014994\n",
      "epoch : 52 [15/23] Train loss: 2.92879,Valid loss: 3.42001, time : 10.414684772491455 lr : 0.5929664464014994\n",
      "epoch : 52 [16/23] Train loss: 2.85067,Valid loss: 3.48510, time : 10.460048913955688 lr : 0.5929664464014994\n",
      "epoch : 52 [17/23] Train loss: 2.89542,Valid loss: 3.55915, time : 10.73520565032959 lr : 0.5929664464014994\n",
      "epoch : 52 [18/23] Train loss: 2.91296,Valid loss: 3.71531, time : 10.50056505203247 lr : 0.5929664464014994\n",
      "epoch : 52 [19/23] Train loss: 2.99274,Valid loss: 4.23502, time : 10.38755750656128 lr : 0.5929664464014994\n",
      "epoch : 52 [20/23] Train loss: 2.88978,Valid loss: 4.27282, time : 10.541387796401978 lr : 0.5929664464014994\n",
      "epoch : 52 [21/23] Train loss: 2.87670,Valid loss: 4.50692, time : 10.341569185256958 lr : 0.5929664464014994\n",
      "epoch : 52 [22/23] Train loss: 2.89692,Valid loss: 3.99646, time : 9.743601560592651 lr : 0.5929664464014994\n",
      "epoch : 53 [0/23] Train loss: 2.91481,Valid loss: 3.53549, time : 10.517177820205688 lr : 0.5870367819374844\n",
      "epoch : 53 [1/23] Train loss: 2.85266,Valid loss: 3.45598, time : 10.269547939300537 lr : 0.5870367819374844\n",
      "epoch : 53 [2/23] Train loss: 2.88655,Valid loss: 3.26647, time : 10.691991567611694 lr : 0.5870367819374844\n",
      "epoch : 53 [3/23] Train loss: 2.84606,Valid loss: 3.36665, time : 10.343520402908325 lr : 0.5870367819374844\n",
      "epoch : 53 [4/23] Train loss: 2.90651,Valid loss: 3.24219, time : 10.768263339996338 lr : 0.5870367819374844\n",
      "epoch : 53 [5/23] Train loss: 2.84694,Valid loss: 3.61164, time : 10.587536334991455 lr : 0.5870367819374844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 53 [6/23] Train loss: 2.91499,Valid loss: 3.33764, time : 10.700958251953125 lr : 0.5870367819374844\n",
      "epoch : 53 [7/23] Train loss: 2.83875,Valid loss: 3.54981, time : 10.397437572479248 lr : 0.5870367819374844\n",
      "epoch : 53 [8/23] Train loss: 3.01348,Valid loss: 3.45741, time : 10.48492693901062 lr : 0.5870367819374844\n",
      "epoch : 53 [9/23] Train loss: 2.91809,Valid loss: 3.37782, time : 10.461369037628174 lr : 0.5870367819374844\n",
      "epoch : 53 [10/23] Train loss: 2.86559,Valid loss: 3.36515, time : 10.389137744903564 lr : 0.5870367819374844\n",
      "epoch : 53 [11/23] Train loss: 2.75286,Valid loss: 3.53418, time : 10.226411819458008 lr : 0.5870367819374844\n",
      "epoch : 53 [12/23] Train loss: 2.70816,Valid loss: 3.40527, time : 10.238103866577148 lr : 0.5870367819374844\n",
      "epoch : 53 [13/23] Train loss: 2.72820,Valid loss: 3.51948, time : 10.147234678268433 lr : 0.5870367819374844\n",
      "epoch : 53 [14/23] Train loss: 2.74552,Valid loss: 3.43741, time : 10.568321466445923 lr : 0.5870367819374844\n",
      "epoch : 53 [15/23] Train loss: 2.81786,Valid loss: 3.37402, time : 9.898173332214355 lr : 0.5870367819374844\n",
      "epoch : 53 [16/23] Train loss: 2.96158,Valid loss: 3.68924, time : 10.10581111907959 lr : 0.5870367819374844\n",
      "epoch : 53 [17/23] Train loss: 2.94053,Valid loss: 3.60055, time : 10.351258039474487 lr : 0.5870367819374844\n",
      "epoch : 53 [18/23] Train loss: 3.03889,Valid loss: 3.79754, time : 9.672457218170166 lr : 0.5870367819374844\n",
      "epoch : 53 [19/23] Train loss: 2.97401,Valid loss: 3.69966, time : 9.934133768081665 lr : 0.5870367819374844\n",
      "epoch : 53 [20/23] Train loss: 3.00200,Valid loss: 4.10378, time : 10.086555242538452 lr : 0.5870367819374844\n",
      "epoch : 53 [21/23] Train loss: 2.84449,Valid loss: 3.50316, time : 9.8279709815979 lr : 0.5870367819374844\n",
      "epoch : 53 [22/23] Train loss: 2.99053,Valid loss: 3.38863, time : 9.237602472305298 lr : 0.5870367819374844\n",
      "epoch : 54 [0/23] Train loss: 2.96927,Valid loss: 3.43587, time : 10.162120342254639 lr : 0.5811664141181095\n",
      "epoch : 54 [1/23] Train loss: 3.27063,Valid loss: 3.72569, time : 10.036518812179565 lr : 0.5811664141181095\n",
      "epoch : 54 [2/23] Train loss: 2.89576,Valid loss: 3.54634, time : 10.199069261550903 lr : 0.5811664141181095\n",
      "epoch : 54 [3/23] Train loss: 2.80022,Valid loss: 3.33114, time : 10.444775104522705 lr : 0.5811664141181095\n",
      "epoch : 54 [4/23] Train loss: 2.78648,Valid loss: 3.25284, time : 10.166434526443481 lr : 0.5811664141181095\n",
      "epoch : 54 [5/23] Train loss: 2.74794,Valid loss: 3.26482, time : 10.528268337249756 lr : 0.5811664141181095\n",
      "epoch : 54 [6/23] Train loss: 2.72272,Valid loss: 3.22572, time : 10.550297498703003 lr : 0.5811664141181095\n",
      "epoch : 54 [7/23] Train loss: 2.70406,Valid loss: 3.47156, time : 10.222217798233032 lr : 0.5811664141181095\n",
      "epoch : 54 [8/23] Train loss: 2.69387,Valid loss: 3.26178, time : 10.368944644927979 lr : 0.5811664141181095\n",
      "epoch : 54 [9/23] Train loss: 2.68465,Valid loss: 3.26847, time : 10.519732236862183 lr : 0.5811664141181095\n",
      "epoch : 54 [10/23] Train loss: 2.77404,Valid loss: 3.61676, time : 10.684370040893555 lr : 0.5811664141181095\n",
      "epoch : 54 [11/23] Train loss: 2.80407,Valid loss: 3.45082, time : 10.467423677444458 lr : 0.5811664141181095\n",
      "epoch : 54 [12/23] Train loss: 2.96954,Valid loss: 3.50995, time : 10.657126903533936 lr : 0.5811664141181095\n",
      "epoch : 54 [13/23] Train loss: 2.88511,Valid loss: 3.66728, time : 10.326061248779297 lr : 0.5811664141181095\n",
      "epoch : 54 [14/23] Train loss: 3.07432,Valid loss: 3.53158, time : 10.508170127868652 lr : 0.5811664141181095\n",
      "epoch : 54 [15/23] Train loss: 2.78412,Valid loss: 3.56526, time : 10.441890001296997 lr : 0.5811664141181095\n",
      "epoch : 54 [16/23] Train loss: 2.72859,Valid loss: 3.63441, time : 10.567740201950073 lr : 0.5811664141181095\n",
      "epoch : 54 [17/23] Train loss: 2.68588,Valid loss: 3.31372, time : 10.132569551467896 lr : 0.5811664141181095\n",
      "epoch : 54 [18/23] Train loss: 2.72289,Valid loss: 3.28096, time : 10.250363111495972 lr : 0.5811664141181095\n",
      "epoch : 54 [19/23] Train loss: 2.70971,Valid loss: 3.21947, time : 9.991309881210327 lr : 0.5811664141181095\n",
      "epoch : 54 [20/23] Train loss: 2.70234,Valid loss: 3.59977, time : 10.505592346191406 lr : 0.5811664141181095\n",
      "epoch : 54 [21/23] Train loss: 2.76504,Valid loss: 3.50965, time : 10.159729957580566 lr : 0.5811664141181095\n",
      "epoch : 54 [22/23] Train loss: 2.72317,Valid loss: 3.33106, time : 9.637431144714355 lr : 0.5811664141181095\n",
      "epoch : 55 [0/23] Train loss: 2.69514,Valid loss: 3.37015, time : 10.081830978393555 lr : 0.5753547499769285\n",
      "epoch : 55 [1/23] Train loss: 2.65480,Valid loss: 3.22532, time : 10.110350608825684 lr : 0.5753547499769285\n",
      "epoch : 55 [2/23] Train loss: 2.66041,Valid loss: 3.29800, time : 9.831451654434204 lr : 0.5753547499769285\n",
      "epoch : 55 [3/23] Train loss: 2.67350,Valid loss: 3.53109, time : 10.283237934112549 lr : 0.5753547499769285\n",
      "epoch : 55 [4/23] Train loss: 2.67609,Valid loss: 3.34928, time : 9.935312747955322 lr : 0.5753547499769285\n",
      "epoch : 55 [5/23] Train loss: 2.76633,Valid loss: 3.30459, time : 10.371476411819458 lr : 0.5753547499769285\n",
      "epoch : 55 [6/23] Train loss: 2.87359,Valid loss: 3.94071, time : 9.796525001525879 lr : 0.5753547499769285\n",
      "epoch : 55 [7/23] Train loss: 3.15121,Valid loss: 3.28656, time : 10.538715600967407 lr : 0.5753547499769285\n",
      "epoch : 55 [8/23] Train loss: 2.74358,Valid loss: 3.85687, time : 10.043609619140625 lr : 0.5753547499769285\n",
      "epoch : 55 [9/23] Train loss: 2.66284,Valid loss: 3.41540, time : 10.470098972320557 lr : 0.5753547499769285\n",
      "epoch : 55 [10/23] Train loss: 2.65193,Valid loss: 3.36832, time : 10.050187826156616 lr : 0.5753547499769285\n",
      "epoch : 55 [11/23] Train loss: 2.62952,Valid loss: 3.80458, time : 10.376047849655151 lr : 0.5753547499769285\n",
      "epoch : 55 [12/23] Train loss: 2.61507,Valid loss: 3.71300, time : 9.888214826583862 lr : 0.5753547499769285\n",
      "epoch : 55 [13/23] Train loss: 2.65166,Valid loss: 3.93889, time : 10.415337800979614 lr : 0.5753547499769285\n",
      "epoch : 55 [14/23] Train loss: 2.68499,Valid loss: 3.67861, time : 10.121107816696167 lr : 0.5753547499769285\n",
      "epoch : 55 [15/23] Train loss: 2.76694,Valid loss: 3.41271, time : 10.333496570587158 lr : 0.5753547499769285\n",
      "epoch : 55 [16/23] Train loss: 2.73377,Valid loss: 3.55351, time : 10.218744277954102 lr : 0.5753547499769285\n",
      "epoch : 55 [17/23] Train loss: 2.77599,Valid loss: 3.15284, time : 10.295692443847656 lr : 0.5753547499769285\n",
      "epoch : 55 [18/23] Train loss: 2.64839,Valid loss: 3.24380, time : 10.412853240966797 lr : 0.5753547499769285\n",
      "epoch : 55 [19/23] Train loss: 2.68755,Valid loss: 3.22106, time : 10.822746992111206 lr : 0.5753547499769285\n",
      "epoch : 55 [20/23] Train loss: 2.68112,Valid loss: 3.17691, time : 10.528212547302246 lr : 0.5753547499769285\n",
      "epoch : 55 [21/23] Train loss: 2.69901,Valid loss: 3.12629, time : 10.473117351531982 lr : 0.5753547499769285\n",
      "epoch : 55 [22/23] Train loss: 2.77576,Valid loss: 3.77520, time : 9.555977582931519 lr : 0.5753547499769285\n",
      "epoch : 56 [0/23] Train loss: 3.32124,Valid loss: 3.95507, time : 10.094350337982178 lr : 0.5696012024771592\n",
      "epoch : 56 [1/23] Train loss: 2.86751,Valid loss: 4.31110, time : 10.115349292755127 lr : 0.5696012024771592\n",
      "epoch : 56 [2/23] Train loss: 2.76249,Valid loss: 3.39435, time : 10.350583553314209 lr : 0.5696012024771592\n",
      "epoch : 56 [3/23] Train loss: 2.62132,Valid loss: 3.17996, time : 10.504735469818115 lr : 0.5696012024771592\n",
      "epoch : 56 [4/23] Train loss: 2.58346,Valid loss: 3.20472, time : 10.379461288452148 lr : 0.5696012024771592\n",
      "epoch : 56 [5/23] Train loss: 2.55663,Valid loss: 3.18116, time : 9.941286325454712 lr : 0.5696012024771592\n",
      "epoch : 56 [6/23] Train loss: 2.56071,Valid loss: 3.12326, time : 10.057044744491577 lr : 0.5696012024771592\n",
      "epoch : 56 [7/23] Train loss: 2.56736,Valid loss: 3.13753, time : 9.961017608642578 lr : 0.5696012024771592\n",
      "epoch : 56 [8/23] Train loss: 2.64366,Valid loss: 3.12062, time : 10.32315731048584 lr : 0.5696012024771592\n",
      "epoch : 56 [9/23] Train loss: 2.63748,Valid loss: 3.13858, time : 10.000743865966797 lr : 0.5696012024771592\n",
      "epoch : 56 [10/23] Train loss: 2.71363,Valid loss: 3.04664, time : 10.49389386177063 lr : 0.5696012024771592\n",
      "epoch : 56 [11/23] Train loss: 2.69662,Valid loss: 3.27713, time : 10.308031797409058 lr : 0.5696012024771592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 56 [12/23] Train loss: 2.85809,Valid loss: 3.66189, time : 10.603828430175781 lr : 0.5696012024771592\n",
      "epoch : 56 [13/23] Train loss: 2.85622,Valid loss: 3.23012, time : 10.157017230987549 lr : 0.5696012024771592\n",
      "epoch : 56 [14/23] Train loss: 3.25936,Valid loss: 3.76216, time : 10.177952289581299 lr : 0.5696012024771592\n",
      "epoch : 56 [15/23] Train loss: 2.85786,Valid loss: 3.61062, time : 10.019472599029541 lr : 0.5696012024771592\n",
      "epoch : 56 [16/23] Train loss: 2.70667,Valid loss: 3.36923, time : 10.187075853347778 lr : 0.5696012024771592\n",
      "epoch : 56 [17/23] Train loss: 2.66959,Valid loss: 3.30470, time : 9.910898685455322 lr : 0.5696012024771592\n",
      "epoch : 56 [18/23] Train loss: 2.65015,Valid loss: 3.54565, time : 9.898782014846802 lr : 0.5696012024771592\n",
      "epoch : 56 [19/23] Train loss: 2.58591,Valid loss: 3.23952, time : 10.330038070678711 lr : 0.5696012024771592\n",
      "epoch : 56 [20/23] Train loss: 2.57974,Valid loss: 3.28567, time : 9.793938875198364 lr : 0.5696012024771592\n",
      "epoch : 56 [21/23] Train loss: 2.56839,Valid loss: 3.05521, time : 10.279186487197876 lr : 0.5696012024771592\n",
      "epoch : 56 [22/23] Train loss: 2.53264,Valid loss: 3.07810, time : 9.444854497909546 lr : 0.5696012024771592\n",
      "epoch : 57 [0/23] Train loss: 2.53926,Valid loss: 3.12001, time : 10.66144061088562 lr : 0.5639051904523876\n",
      "epoch : 57 [1/23] Train loss: 2.54589,Valid loss: 3.16610, time : 10.07025694847107 lr : 0.5639051904523876\n",
      "epoch : 57 [2/23] Train loss: 2.53806,Valid loss: 3.13777, time : 10.543877840042114 lr : 0.5639051904523876\n",
      "epoch : 57 [3/23] Train loss: 2.63398,Valid loss: 3.14285, time : 10.242659091949463 lr : 0.5639051904523876\n",
      "epoch : 57 [4/23] Train loss: 2.62696,Valid loss: 3.16347, time : 10.518709182739258 lr : 0.5639051904523876\n",
      "epoch : 57 [5/23] Train loss: 2.62278,Valid loss: 3.22087, time : 10.245934963226318 lr : 0.5639051904523876\n",
      "epoch : 57 [6/23] Train loss: 2.66968,Valid loss: 3.04176, time : 10.482625484466553 lr : 0.5639051904523876\n",
      "epoch : 57 [7/23] Train loss: 2.84196,Valid loss: 3.45490, time : 9.994131326675415 lr : 0.5639051904523876\n",
      "epoch : 57 [8/23] Train loss: 2.61440,Valid loss: 3.46092, time : 10.394335508346558 lr : 0.5639051904523876\n",
      "epoch : 57 [9/23] Train loss: 2.54359,Valid loss: 3.83301, time : 9.888633012771606 lr : 0.5639051904523876\n",
      "epoch : 57 [10/23] Train loss: 2.52049,Valid loss: 3.77001, time : 10.424631834030151 lr : 0.5639051904523876\n",
      "epoch : 57 [11/23] Train loss: 2.53566,Valid loss: 4.14827, time : 10.316726684570312 lr : 0.5639051904523876\n",
      "epoch : 57 [12/23] Train loss: 2.55341,Valid loss: 3.85656, time : 10.388564109802246 lr : 0.5639051904523876\n",
      "epoch : 57 [13/23] Train loss: 2.62685,Valid loss: 3.68334, time : 9.775128841400146 lr : 0.5639051904523876\n",
      "epoch : 57 [14/23] Train loss: 2.60920,Valid loss: 3.40748, time : 9.870529890060425 lr : 0.5639051904523876\n",
      "epoch : 57 [15/23] Train loss: 2.61571,Valid loss: 3.16891, time : 10.773853063583374 lr : 0.5639051904523876\n",
      "epoch : 57 [16/23] Train loss: 2.52948,Valid loss: 3.05063, time : 10.222439289093018 lr : 0.5639051904523876\n",
      "epoch : 57 [17/23] Train loss: 2.57318,Valid loss: 3.09207, time : 10.138456344604492 lr : 0.5639051904523876\n",
      "epoch : 57 [18/23] Train loss: 2.53005,Valid loss: 3.07690, time : 10.23553466796875 lr : 0.5639051904523876\n",
      "epoch : 57 [19/23] Train loss: 2.53103,Valid loss: 3.10503, time : 9.868340492248535 lr : 0.5639051904523876\n",
      "epoch : 57 [20/23] Train loss: 2.50282,Valid loss: 3.36203, time : 10.280524015426636 lr : 0.5639051904523876\n",
      "epoch : 57 [21/23] Train loss: 2.49635,Valid loss: 3.08493, time : 9.988079071044922 lr : 0.5639051904523876\n",
      "epoch : 57 [22/23] Train loss: 2.55670,Valid loss: 3.17906, time : 9.552186489105225 lr : 0.5639051904523876\n",
      "epoch : 58 [0/23] Train loss: 2.59921,Valid loss: 3.16735, time : 9.965958595275879 lr : 0.5582661385478638\n",
      "epoch : 58 [1/23] Train loss: 2.70348,Valid loss: 3.13333, time : 10.340850591659546 lr : 0.5582661385478638\n",
      "epoch : 58 [2/23] Train loss: 3.05166,Valid loss: 3.34039, time : 10.094731330871582 lr : 0.5582661385478638\n",
      "epoch : 58 [3/23] Train loss: 2.57653,Valid loss: 3.49117, time : 10.789644479751587 lr : 0.5582661385478638\n",
      "epoch : 58 [4/23] Train loss: 2.48220,Valid loss: 3.10157, time : 10.123883485794067 lr : 0.5582661385478638\n",
      "epoch : 58 [5/23] Train loss: 2.42584,Valid loss: 3.02344, time : 10.197347640991211 lr : 0.5582661385478638\n",
      "epoch : 58 [6/23] Train loss: 2.41414,Valid loss: 2.95040, time : 9.994128942489624 lr : 0.5582661385478638\n",
      "epoch : 58 [7/23] Train loss: 2.40442,Valid loss: 3.01749, time : 9.831982612609863 lr : 0.5582661385478638\n",
      "epoch : 58 [8/23] Train loss: 2.39158,Valid loss: 3.13505, time : 10.083573818206787 lr : 0.5582661385478638\n",
      "epoch : 58 [9/23] Train loss: 2.44668,Valid loss: 3.13930, time : 10.366098403930664 lr : 0.5582661385478638\n",
      "epoch : 58 [10/23] Train loss: 2.45907,Valid loss: 3.67947, time : 9.957026481628418 lr : 0.5582661385478638\n",
      "epoch : 58 [11/23] Train loss: 2.45583,Valid loss: 3.25137, time : 10.251651287078857 lr : 0.5582661385478638\n",
      "epoch : 58 [12/23] Train loss: 2.48702,Valid loss: 3.46715, time : 9.930391073226929 lr : 0.5582661385478638\n",
      "epoch : 58 [13/23] Train loss: 2.49578,Valid loss: 3.20064, time : 10.376707553863525 lr : 0.5582661385478638\n",
      "epoch : 58 [14/23] Train loss: 2.57796,Valid loss: 3.68342, time : 10.376048803329468 lr : 0.5582661385478638\n",
      "epoch : 58 [15/23] Train loss: 2.60806,Valid loss: 3.00410, time : 10.399131774902344 lr : 0.5582661385478638\n",
      "epoch : 58 [16/23] Train loss: 2.97965,Valid loss: 3.76159, time : 9.943084478378296 lr : 0.5582661385478638\n",
      "epoch : 58 [17/23] Train loss: 2.81389,Valid loss: 4.03818, time : 10.327759027481079 lr : 0.5582661385478638\n",
      "epoch : 58 [18/23] Train loss: 3.11037,Valid loss: 4.75036, time : 10.111845254898071 lr : 0.5582661385478638\n",
      "epoch : 58 [19/23] Train loss: 2.73670,Valid loss: 4.32051, time : 10.504807472229004 lr : 0.5582661385478638\n",
      "epoch : 58 [20/23] Train loss: 2.62385,Valid loss: 3.30591, time : 9.903837203979492 lr : 0.5582661385478638\n",
      "epoch : 58 [21/23] Train loss: 2.49392,Valid loss: 3.22430, time : 10.218588829040527 lr : 0.5582661385478638\n",
      "epoch : 58 [22/23] Train loss: 2.43068,Valid loss: 3.27340, time : 9.628557682037354 lr : 0.5582661385478638\n",
      "epoch : 59 [0/23] Train loss: 2.39566,Valid loss: 2.98160, time : 10.451005935668945 lr : 0.5526834771623851\n",
      "epoch : 59 [1/23] Train loss: 2.39744,Valid loss: 2.96598, time : 10.292557954788208 lr : 0.5526834771623851\n",
      "epoch : 59 [2/23] Train loss: 2.35358,Valid loss: 2.94874, time : 10.514101028442383 lr : 0.5526834771623851\n",
      "epoch : 59 [3/23] Train loss: 2.35254,Valid loss: 3.06546, time : 10.117070436477661 lr : 0.5526834771623851\n",
      "epoch : 59 [4/23] Train loss: 2.39547,Valid loss: 2.86164, time : 10.485943794250488 lr : 0.5526834771623851\n",
      "epoch : 59 [5/23] Train loss: 2.38685,Valid loss: 2.98971, time : 10.350330829620361 lr : 0.5526834771623851\n",
      "epoch : 59 [6/23] Train loss: 2.44161,Valid loss: 2.82929, time : 10.068402767181396 lr : 0.5526834771623851\n",
      "epoch : 59 [7/23] Train loss: 2.47968,Valid loss: 2.94210, time : 10.440375089645386 lr : 0.5526834771623851\n",
      "epoch : 59 [8/23] Train loss: 2.53375,Valid loss: 3.74161, time : 10.425660371780396 lr : 0.5526834771623851\n",
      "epoch : 59 [9/23] Train loss: 2.54742,Valid loss: 3.97151, time : 10.00955843925476 lr : 0.5526834771623851\n",
      "epoch : 59 [10/23] Train loss: 2.66747,Valid loss: 4.01089, time : 10.162602186203003 lr : 0.5526834771623851\n",
      "epoch : 59 [11/23] Train loss: 2.56720,Valid loss: 3.91836, time : 10.48503303527832 lr : 0.5526834771623851\n",
      "epoch : 59 [12/23] Train loss: 2.52284,Valid loss: 3.42907, time : 10.022964239120483 lr : 0.5526834771623851\n",
      "epoch : 59 [13/23] Train loss: 2.42332,Valid loss: 3.15076, time : 10.40332293510437 lr : 0.5526834771623851\n",
      "epoch : 59 [14/23] Train loss: 2.39641,Valid loss: 2.91074, time : 10.322209119796753 lr : 0.5526834771623851\n",
      "epoch : 59 [15/23] Train loss: 2.35629,Valid loss: 2.98478, time : 10.233217000961304 lr : 0.5526834771623851\n",
      "epoch : 59 [16/23] Train loss: 2.36634,Valid loss: 2.89892, time : 9.948004245758057 lr : 0.5526834771623851\n",
      "epoch : 59 [17/23] Train loss: 2.37084,Valid loss: 2.99862, time : 10.2185537815094 lr : 0.5526834771623851\n",
      "epoch : 59 [18/23] Train loss: 2.37313,Valid loss: 2.96834, time : 10.207778930664062 lr : 0.5526834771623851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 59 [19/23] Train loss: 2.40188,Valid loss: 3.03581, time : 10.279919624328613 lr : 0.5526834771623851\n",
      "epoch : 59 [20/23] Train loss: 2.38555,Valid loss: 3.00865, time : 10.161827564239502 lr : 0.5526834771623851\n",
      "epoch : 59 [21/23] Train loss: 2.40327,Valid loss: 2.84387, time : 10.34072995185852 lr : 0.5526834771623851\n",
      "epoch : 59 [22/23] Train loss: 2.46724,Valid loss: 3.18289, time : 9.433937788009644 lr : 0.5526834771623851\n",
      "epoch : 60 [0/23] Train loss: 2.69292,Valid loss: 3.63043, time : 10.106840133666992 lr : 0.5471566423907612\n",
      "epoch : 60 [1/23] Train loss: 2.97284,Valid loss: 3.28998, time : 10.107518434524536 lr : 0.5471566423907612\n",
      "epoch : 60 [2/23] Train loss: 2.65944,Valid loss: 3.15749, time : 10.251667022705078 lr : 0.5471566423907612\n",
      "epoch : 60 [3/23] Train loss: 2.55109,Valid loss: 3.02491, time : 9.809427499771118 lr : 0.5471566423907612\n",
      "epoch : 60 [4/23] Train loss: 2.39952,Valid loss: 3.12104, time : 10.171106100082397 lr : 0.5471566423907612\n",
      "epoch : 60 [5/23] Train loss: 2.38885,Valid loss: 2.88198, time : 10.252748012542725 lr : 0.5471566423907612\n",
      "epoch : 60 [6/23] Train loss: 2.32617,Valid loss: 2.95586, time : 10.821908950805664 lr : 0.5471566423907612\n",
      "epoch : 60 [7/23] Train loss: 2.33145,Valid loss: 2.89422, time : 10.274544477462769 lr : 0.5471566423907612\n",
      "epoch : 60 [8/23] Train loss: 2.31540,Valid loss: 2.96692, time : 10.191515445709229 lr : 0.5471566423907612\n",
      "epoch : 60 [9/23] Train loss: 2.37083,Valid loss: 3.04228, time : 10.018032789230347 lr : 0.5471566423907612\n",
      "epoch : 60 [10/23] Train loss: 2.38786,Valid loss: 2.99749, time : 10.350908517837524 lr : 0.5471566423907612\n",
      "epoch : 60 [11/23] Train loss: 2.40958,Valid loss: 3.07361, time : 10.1002676486969 lr : 0.5471566423907612\n",
      "epoch : 60 [12/23] Train loss: 2.39924,Valid loss: 3.04881, time : 10.430206298828125 lr : 0.5471566423907612\n",
      "epoch : 60 [13/23] Train loss: 2.44518,Valid loss: 3.35190, time : 10.071684122085571 lr : 0.5471566423907612\n",
      "epoch : 60 [14/23] Train loss: 2.36960,Valid loss: 3.18449, time : 10.53988528251648 lr : 0.5471566423907612\n",
      "epoch : 60 [15/23] Train loss: 2.39284,Valid loss: 3.27403, time : 10.113819599151611 lr : 0.5471566423907612\n",
      "epoch : 60 [16/23] Train loss: 2.34195,Valid loss: 3.13602, time : 10.331399917602539 lr : 0.5471566423907612\n",
      "epoch : 60 [17/23] Train loss: 2.34561,Valid loss: 2.96909, time : 10.29642391204834 lr : 0.5471566423907612\n",
      "epoch : 60 [18/23] Train loss: 2.28104,Valid loss: 2.88006, time : 10.100711107254028 lr : 0.5471566423907612\n",
      "epoch : 60 [19/23] Train loss: 2.31667,Valid loss: 2.76654, time : 10.23371696472168 lr : 0.5471566423907612\n",
      "epoch : 60 [20/23] Train loss: 2.30667,Valid loss: 2.77242, time : 9.890477895736694 lr : 0.5471566423907612\n",
      "epoch : 60 [21/23] Train loss: 2.31981,Valid loss: 2.78309, time : 10.070677280426025 lr : 0.5471566423907612\n",
      "epoch : 60 [22/23] Train loss: 2.32377,Valid loss: 2.88335, time : 9.803755521774292 lr : 0.5471566423907612\n",
      "epoch : 61 [0/23] Train loss: 2.31192,Valid loss: 2.80422, time : 10.344594240188599 lr : 0.5416850759668536\n",
      "epoch : 61 [1/23] Train loss: 2.29270,Valid loss: 2.76424, time : 10.266251564025879 lr : 0.5416850759668536\n",
      "epoch : 61 [2/23] Train loss: 2.31810,Valid loss: 2.85334, time : 10.506562232971191 lr : 0.5416850759668536\n",
      "epoch : 61 [3/23] Train loss: 2.31752,Valid loss: 2.78897, time : 10.268578290939331 lr : 0.5416850759668536\n",
      "epoch : 61 [4/23] Train loss: 2.30891,Valid loss: 2.78514, time : 10.362999677658081 lr : 0.5416850759668536\n",
      "epoch : 61 [5/23] Train loss: 2.35007,Valid loss: 2.81107, time : 10.359129428863525 lr : 0.5416850759668536\n",
      "epoch : 61 [6/23] Train loss: 2.49131,Valid loss: 3.03772, time : 10.366873025894165 lr : 0.5416850759668536\n",
      "epoch : 61 [7/23] Train loss: 2.72487,Valid loss: 3.39178, time : 10.202488899230957 lr : 0.5416850759668536\n",
      "epoch : 61 [8/23] Train loss: 2.74249,Valid loss: 3.04645, time : 10.13413119316101 lr : 0.5416850759668536\n",
      "epoch : 61 [9/23] Train loss: 2.56848,Valid loss: 3.50962, time : 10.038713216781616 lr : 0.5416850759668536\n",
      "epoch : 61 [10/23] Train loss: 2.65015,Valid loss: 3.39229, time : 10.501739978790283 lr : 0.5416850759668536\n",
      "epoch : 61 [11/23] Train loss: 2.57575,Valid loss: 3.94703, time : 10.361077308654785 lr : 0.5416850759668536\n",
      "epoch : 61 [12/23] Train loss: 2.71304,Valid loss: 3.64626, time : 10.469825506210327 lr : 0.5416850759668536\n",
      "epoch : 61 [13/23] Train loss: 2.49001,Valid loss: 3.23379, time : 10.324203729629517 lr : 0.5416850759668536\n",
      "epoch : 61 [14/23] Train loss: 2.38796,Valid loss: 3.07817, time : 10.25043272972107 lr : 0.5416850759668536\n",
      "epoch : 61 [15/23] Train loss: 2.28738,Valid loss: 2.93128, time : 10.556230545043945 lr : 0.5416850759668536\n",
      "epoch : 61 [16/23] Train loss: 2.25169,Valid loss: 2.79829, time : 10.768342971801758 lr : 0.5416850759668536\n",
      "epoch : 61 [17/23] Train loss: 2.25324,Valid loss: 2.80410, time : 10.493537425994873 lr : 0.5416850759668536\n",
      "epoch : 61 [18/23] Train loss: 2.23701,Valid loss: 2.73158, time : 10.282646656036377 lr : 0.5416850759668536\n",
      "epoch : 61 [19/23] Train loss: 2.25561,Valid loss: 2.80862, time : 10.306401491165161 lr : 0.5416850759668536\n",
      "epoch : 61 [20/23] Train loss: 2.23600,Valid loss: 2.74818, time : 10.68071460723877 lr : 0.5416850759668536\n",
      "epoch : 61 [21/23] Train loss: 2.23426,Valid loss: 2.85431, time : 10.020805358886719 lr : 0.5416850759668536\n",
      "epoch : 61 [22/23] Train loss: 2.25589,Valid loss: 2.89694, time : 10.18486213684082 lr : 0.5416850759668536\n",
      "epoch : 62 [0/23] Train loss: 2.26755,Valid loss: 2.89062, time : 10.76939845085144 lr : 0.536268225207185\n",
      "epoch : 62 [1/23] Train loss: 2.29432,Valid loss: 2.85819, time : 10.53163743019104 lr : 0.536268225207185\n",
      "epoch : 62 [2/23] Train loss: 2.29887,Valid loss: 2.98357, time : 10.68741750717163 lr : 0.536268225207185\n",
      "epoch : 62 [3/23] Train loss: 2.24812,Valid loss: 3.14806, time : 10.56843614578247 lr : 0.536268225207185\n",
      "epoch : 62 [4/23] Train loss: 2.24471,Valid loss: 2.91130, time : 11.65802264213562 lr : 0.536268225207185\n",
      "epoch : 62 [5/23] Train loss: 2.23223,Valid loss: 2.89090, time : 10.536684274673462 lr : 0.536268225207185\n",
      "epoch : 62 [6/23] Train loss: 2.23236,Valid loss: 2.91683, time : 10.760155439376831 lr : 0.536268225207185\n",
      "epoch : 62 [7/23] Train loss: 2.23160,Valid loss: 2.99630, time : 10.412008047103882 lr : 0.536268225207185\n",
      "epoch : 62 [8/23] Train loss: 2.24248,Valid loss: 2.79764, time : 10.472248077392578 lr : 0.536268225207185\n",
      "epoch : 62 [9/23] Train loss: 2.19844,Valid loss: 2.81961, time : 10.588073253631592 lr : 0.536268225207185\n",
      "epoch : 62 [10/23] Train loss: 2.19280,Valid loss: 2.69761, time : 10.766969919204712 lr : 0.536268225207185\n",
      "epoch : 62 [11/23] Train loss: 2.17981,Valid loss: 2.75208, time : 10.418489456176758 lr : 0.536268225207185\n",
      "epoch : 62 [12/23] Train loss: 2.15510,Valid loss: 2.72143, time : 10.294017791748047 lr : 0.536268225207185\n",
      "epoch : 62 [13/23] Train loss: 2.18264,Valid loss: 2.68239, time : 10.322000503540039 lr : 0.536268225207185\n",
      "epoch : 62 [14/23] Train loss: 2.21768,Valid loss: 2.69660, time : 10.499881029129028 lr : 0.536268225207185\n",
      "epoch : 62 [15/23] Train loss: 2.25184,Valid loss: 2.79427, time : 10.21912956237793 lr : 0.536268225207185\n",
      "epoch : 62 [16/23] Train loss: 2.24251,Valid loss: 2.88275, time : 10.05201244354248 lr : 0.536268225207185\n",
      "epoch : 62 [17/23] Train loss: 2.25069,Valid loss: 2.72379, time : 10.16680645942688 lr : 0.536268225207185\n",
      "epoch : 62 [18/23] Train loss: 2.26066,Valid loss: 2.79513, time : 10.738202095031738 lr : 0.536268225207185\n",
      "epoch : 62 [19/23] Train loss: 2.26166,Valid loss: 3.02059, time : 10.933205366134644 lr : 0.536268225207185\n",
      "epoch : 62 [20/23] Train loss: 2.25296,Valid loss: 3.38617, time : 10.221573114395142 lr : 0.536268225207185\n",
      "epoch : 62 [21/23] Train loss: 2.25076,Valid loss: 3.09438, time : 10.558546543121338 lr : 0.536268225207185\n",
      "epoch : 62 [22/23] Train loss: 2.24333,Valid loss: 3.31535, time : 9.726064205169678 lr : 0.536268225207185\n",
      "epoch : 63 [0/23] Train loss: 2.23508,Valid loss: 3.02182, time : 10.301097393035889 lr : 0.5309055429551132\n",
      "epoch : 63 [1/23] Train loss: 2.18840,Valid loss: 3.02645, time : 10.588028192520142 lr : 0.5309055429551132\n",
      "epoch : 63 [2/23] Train loss: 2.17871,Valid loss: 2.73145, time : 10.06230902671814 lr : 0.5309055429551132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 63 [3/23] Train loss: 2.17868,Valid loss: 2.74312, time : 9.77068281173706 lr : 0.5309055429551132\n",
      "epoch : 63 [4/23] Train loss: 2.14749,Valid loss: 2.69576, time : 10.22560167312622 lr : 0.5309055429551132\n",
      "epoch : 63 [5/23] Train loss: 2.17577,Valid loss: 2.73205, time : 10.1162748336792 lr : 0.5309055429551132\n",
      "epoch : 63 [6/23] Train loss: 2.18975,Valid loss: 2.64792, time : 10.665790796279907 lr : 0.5309055429551132\n",
      "epoch : 63 [7/23] Train loss: 2.36197,Valid loss: 3.15697, time : 9.784960985183716 lr : 0.5309055429551132\n",
      "epoch : 63 [8/23] Train loss: 2.79548,Valid loss: 2.98824, time : 9.700691223144531 lr : 0.5309055429551132\n",
      "epoch : 63 [9/23] Train loss: 2.44368,Valid loss: 4.06386, time : 9.70277214050293 lr : 0.5309055429551132\n",
      "epoch : 63 [10/23] Train loss: 2.56562,Valid loss: 2.88659, time : 9.715802669525146 lr : 0.5309055429551132\n",
      "epoch : 63 [11/23] Train loss: 2.34734,Valid loss: 3.19325, time : 9.728524208068848 lr : 0.5309055429551132\n",
      "epoch : 63 [12/23] Train loss: 2.36167,Valid loss: 3.02726, time : 9.827153444290161 lr : 0.5309055429551132\n",
      "epoch : 63 [13/23] Train loss: 2.27850,Valid loss: 3.22364, time : 9.656541109085083 lr : 0.5309055429551132\n",
      "epoch : 63 [14/23] Train loss: 2.33637,Valid loss: 3.31139, time : 9.965822219848633 lr : 0.5309055429551132\n",
      "epoch : 63 [15/23] Train loss: 2.26466,Valid loss: 2.86864, time : 10.07829236984253 lr : 0.5309055429551132\n",
      "epoch : 63 [16/23] Train loss: 2.21341,Valid loss: 2.73647, time : 9.849375009536743 lr : 0.5309055429551132\n",
      "epoch : 63 [17/23] Train loss: 2.13255,Valid loss: 2.69089, time : 9.935315370559692 lr : 0.5309055429551132\n",
      "epoch : 63 [18/23] Train loss: 2.12198,Valid loss: 2.61701, time : 9.799814939498901 lr : 0.5309055429551132\n",
      "epoch : 63 [19/23] Train loss: 2.12116,Valid loss: 2.61688, time : 10.271040916442871 lr : 0.5309055429551132\n",
      "epoch : 63 [20/23] Train loss: 2.10007,Valid loss: 2.63089, time : 10.32011079788208 lr : 0.5309055429551132\n",
      "epoch : 63 [21/23] Train loss: 2.09415,Valid loss: 2.57232, time : 10.221432447433472 lr : 0.5309055429551132\n",
      "epoch : 63 [22/23] Train loss: 2.15782,Valid loss: 2.68945, time : 9.505167007446289 lr : 0.5309055429551132\n",
      "epoch : 64 [0/23] Train loss: 2.14541,Valid loss: 2.68693, time : 10.457067251205444 lr : 0.525596487525562\n",
      "epoch : 64 [1/23] Train loss: 2.16383,Valid loss: 2.63039, time : 10.403729915618896 lr : 0.525596487525562\n",
      "epoch : 64 [2/23] Train loss: 2.11972,Valid loss: 2.58363, time : 10.357488632202148 lr : 0.525596487525562\n",
      "epoch : 64 [3/23] Train loss: 2.11445,Valid loss: 2.63238, time : 9.765657424926758 lr : 0.525596487525562\n",
      "epoch : 64 [4/23] Train loss: 2.06467,Valid loss: 2.57521, time : 10.022988319396973 lr : 0.525596487525562\n",
      "epoch : 64 [5/23] Train loss: 2.10484,Valid loss: 2.78678, time : 9.586517810821533 lr : 0.525596487525562\n",
      "epoch : 64 [6/23] Train loss: 2.09679,Valid loss: 2.76925, time : 9.606176614761353 lr : 0.525596487525562\n",
      "epoch : 64 [7/23] Train loss: 2.14146,Valid loss: 3.32430, time : 9.770693063735962 lr : 0.525596487525562\n",
      "epoch : 64 [8/23] Train loss: 2.16186,Valid loss: 3.12456, time : 9.952917337417603 lr : 0.525596487525562\n",
      "epoch : 64 [9/23] Train loss: 2.12814,Valid loss: 3.67138, time : 9.572917222976685 lr : 0.525596487525562\n",
      "epoch : 64 [10/23] Train loss: 2.14128,Valid loss: 3.48334, time : 10.1673583984375 lr : 0.525596487525562\n",
      "epoch : 64 [11/23] Train loss: 2.16788,Valid loss: 3.47767, time : 9.78592300415039 lr : 0.525596487525562\n",
      "epoch : 64 [12/23] Train loss: 2.14060,Valid loss: 3.17077, time : 9.982680559158325 lr : 0.525596487525562\n",
      "epoch : 64 [13/23] Train loss: 2.14806,Valid loss: 3.09540, time : 9.968892097473145 lr : 0.525596487525562\n",
      "epoch : 64 [14/23] Train loss: 2.11159,Valid loss: 3.10977, time : 9.882574319839478 lr : 0.525596487525562\n",
      "epoch : 64 [15/23] Train loss: 2.11413,Valid loss: 2.78707, time : 9.47596263885498 lr : 0.525596487525562\n",
      "epoch : 64 [16/23] Train loss: 2.10677,Valid loss: 2.58008, time : 9.903147220611572 lr : 0.525596487525562\n",
      "epoch : 64 [17/23] Train loss: 2.09937,Valid loss: 2.49930, time : 10.270972728729248 lr : 0.525596487525562\n",
      "epoch : 64 [18/23] Train loss: 2.12327,Valid loss: 2.56720, time : 10.25661563873291 lr : 0.525596487525562\n",
      "epoch : 64 [19/23] Train loss: 2.12223,Valid loss: 2.56942, time : 10.239430904388428 lr : 0.525596487525562\n",
      "epoch : 64 [20/23] Train loss: 2.09018,Valid loss: 2.79345, time : 10.55909252166748 lr : 0.525596487525562\n",
      "epoch : 64 [21/23] Train loss: 2.12685,Valid loss: 2.57871, time : 10.614444494247437 lr : 0.525596487525562\n",
      "epoch : 64 [22/23] Train loss: 2.16611,Valid loss: 2.71589, time : 9.380812644958496 lr : 0.525596487525562\n",
      "epoch : 65 [0/23] Train loss: 2.18627,Valid loss: 2.66821, time : 10.058584690093994 lr : 0.5203405226503064\n",
      "epoch : 65 [1/23] Train loss: 2.20479,Valid loss: 2.67795, time : 9.989404678344727 lr : 0.5203405226503064\n",
      "epoch : 65 [2/23] Train loss: 2.18226,Valid loss: 2.51770, time : 10.117313146591187 lr : 0.5203405226503064\n",
      "epoch : 65 [3/23] Train loss: 2.15575,Valid loss: 2.89047, time : 10.407399654388428 lr : 0.5203405226503064\n",
      "epoch : 65 [4/23] Train loss: 2.12350,Valid loss: 3.06483, time : 9.459200859069824 lr : 0.5203405226503064\n",
      "epoch : 65 [5/23] Train loss: 2.08978,Valid loss: 3.16121, time : 10.07992434501648 lr : 0.5203405226503064\n",
      "epoch : 65 [6/23] Train loss: 2.09054,Valid loss: 2.65248, time : 9.807726860046387 lr : 0.5203405226503064\n",
      "epoch : 65 [7/23] Train loss: 2.04651,Valid loss: 2.58953, time : 10.154082775115967 lr : 0.5203405226503064\n",
      "epoch : 65 [8/23] Train loss: 2.04561,Valid loss: 2.56609, time : 9.98780632019043 lr : 0.5203405226503064\n",
      "epoch : 65 [9/23] Train loss: 1.98860,Valid loss: 2.51237, time : 10.511464357376099 lr : 0.5203405226503064\n",
      "epoch : 65 [10/23] Train loss: 2.00437,Valid loss: 2.48578, time : 10.310717105865479 lr : 0.5203405226503064\n",
      "epoch : 65 [11/23] Train loss: 1.99837,Valid loss: 2.53454, time : 10.37550950050354 lr : 0.5203405226503064\n",
      "epoch : 65 [12/23] Train loss: 2.05156,Valid loss: 2.63686, time : 10.22012996673584 lr : 0.5203405226503064\n",
      "epoch : 65 [13/23] Train loss: 2.07656,Valid loss: 2.56612, time : 10.478878021240234 lr : 0.5203405226503064\n",
      "epoch : 65 [14/23] Train loss: 2.11330,Valid loss: 2.89639, time : 10.17330813407898 lr : 0.5203405226503064\n",
      "epoch : 65 [15/23] Train loss: 2.12654,Valid loss: 2.79239, time : 10.212065696716309 lr : 0.5203405226503064\n",
      "epoch : 65 [16/23] Train loss: 2.13745,Valid loss: 3.41215, time : 9.876569271087646 lr : 0.5203405226503064\n",
      "epoch : 65 [17/23] Train loss: 2.12716,Valid loss: 3.15025, time : 10.319059133529663 lr : 0.5203405226503064\n",
      "epoch : 65 [18/23] Train loss: 2.21383,Valid loss: 3.09726, time : 9.895790815353394 lr : 0.5203405226503064\n",
      "epoch : 65 [19/23] Train loss: 2.17717,Valid loss: 2.65819, time : 10.518606662750244 lr : 0.5203405226503064\n",
      "epoch : 65 [20/23] Train loss: 2.25396,Valid loss: 2.67043, time : 10.0975501537323 lr : 0.5203405226503064\n",
      "epoch : 65 [21/23] Train loss: 2.69797,Valid loss: 2.67482, time : 10.106592655181885 lr : 0.5203405226503064\n",
      "epoch : 65 [22/23] Train loss: 2.48010,Valid loss: 2.77567, time : 9.75482726097107 lr : 0.5203405226503064\n",
      "epoch : 66 [0/23] Train loss: 2.32524,Valid loss: 2.67023, time : 10.254257202148438 lr : 0.5151371174238033\n",
      "epoch : 66 [1/23] Train loss: 2.32155,Valid loss: 3.55713, time : 9.702218770980835 lr : 0.5151371174238033\n",
      "epoch : 66 [2/23] Train loss: 2.18252,Valid loss: 2.65761, time : 9.93505072593689 lr : 0.5151371174238033\n",
      "epoch : 66 [3/23] Train loss: 2.07231,Valid loss: 2.47890, time : 9.69331169128418 lr : 0.5151371174238033\n",
      "epoch : 66 [4/23] Train loss: 1.98847,Valid loss: 2.47206, time : 9.770751476287842 lr : 0.5151371174238033\n",
      "epoch : 66 [5/23] Train loss: 2.00412,Valid loss: 2.45899, time : 10.436461448669434 lr : 0.5151371174238033\n",
      "epoch : 66 [6/23] Train loss: 1.97030,Valid loss: 2.47630, time : 10.204010963439941 lr : 0.5151371174238033\n",
      "epoch : 66 [7/23] Train loss: 1.98143,Valid loss: 2.46508, time : 9.904008626937866 lr : 0.5151371174238033\n",
      "epoch : 66 [8/23] Train loss: 1.99213,Valid loss: 2.43105, time : 10.0489342212677 lr : 0.5151371174238033\n",
      "epoch : 66 [9/23] Train loss: 1.98686,Valid loss: 2.43100, time : 9.943595886230469 lr : 0.5151371174238033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 66 [10/23] Train loss: 1.97396,Valid loss: 2.53708, time : 10.21066927909851 lr : 0.5151371174238033\n",
      "epoch : 66 [11/23] Train loss: 1.97397,Valid loss: 2.55235, time : 9.566193580627441 lr : 0.5151371174238033\n",
      "epoch : 66 [12/23] Train loss: 1.97074,Valid loss: 2.50362, time : 10.410332202911377 lr : 0.5151371174238033\n",
      "epoch : 66 [13/23] Train loss: 1.97504,Valid loss: 2.66617, time : 10.291033029556274 lr : 0.5151371174238033\n",
      "epoch : 66 [14/23] Train loss: 1.95774,Valid loss: 2.70723, time : 9.906577110290527 lr : 0.5151371174238033\n",
      "epoch : 66 [15/23] Train loss: 1.98724,Valid loss: 2.81594, time : 9.733392000198364 lr : 0.5151371174238033\n",
      "epoch : 66 [16/23] Train loss: 1.98889,Valid loss: 2.98538, time : 9.976226091384888 lr : 0.5151371174238033\n",
      "epoch : 66 [17/23] Train loss: 1.96318,Valid loss: 3.57316, time : 9.73068642616272 lr : 0.5151371174238033\n",
      "epoch : 66 [18/23] Train loss: 1.99731,Valid loss: 3.28583, time : 10.006288766860962 lr : 0.5151371174238033\n",
      "epoch : 66 [19/23] Train loss: 2.04167,Valid loss: 3.58383, time : 10.076371431350708 lr : 0.5151371174238033\n",
      "epoch : 66 [20/23] Train loss: 2.06566,Valid loss: 3.21174, time : 9.86301302909851 lr : 0.5151371174238033\n",
      "epoch : 66 [21/23] Train loss: 2.22722,Valid loss: 3.06564, time : 9.601243495941162 lr : 0.5151371174238033\n",
      "epoch : 66 [22/23] Train loss: 2.24468,Valid loss: 3.01088, time : 9.756574153900146 lr : 0.5151371174238033\n",
      "epoch : 67 [0/23] Train loss: 2.28324,Valid loss: 2.51550, time : 10.287982702255249 lr : 0.5099857462495653\n",
      "epoch : 67 [1/23] Train loss: 2.16799,Valid loss: 2.67030, time : 10.068629503250122 lr : 0.5099857462495653\n",
      "epoch : 67 [2/23] Train loss: 2.10671,Valid loss: 2.49230, time : 10.303851842880249 lr : 0.5099857462495653\n",
      "epoch : 67 [3/23] Train loss: 2.04912,Valid loss: 2.45064, time : 10.277320861816406 lr : 0.5099857462495653\n",
      "epoch : 67 [4/23] Train loss: 1.96601,Valid loss: 2.35488, time : 10.684893369674683 lr : 0.5099857462495653\n",
      "epoch : 67 [5/23] Train loss: 1.94350,Valid loss: 2.42273, time : 10.422537088394165 lr : 0.5099857462495653\n",
      "epoch : 67 [6/23] Train loss: 1.93106,Valid loss: 2.39387, time : 10.450058937072754 lr : 0.5099857462495653\n",
      "epoch : 67 [7/23] Train loss: 1.87413,Valid loss: 2.39166, time : 10.422001600265503 lr : 0.5099857462495653\n",
      "epoch : 67 [8/23] Train loss: 1.90398,Valid loss: 2.37784, time : 10.431859970092773 lr : 0.5099857462495653\n",
      "epoch : 67 [9/23] Train loss: 1.91104,Valid loss: 2.41907, time : 10.446434497833252 lr : 0.5099857462495653\n",
      "epoch : 67 [10/23] Train loss: 1.89747,Valid loss: 2.43089, time : 10.695592641830444 lr : 0.5099857462495653\n",
      "epoch : 67 [11/23] Train loss: 1.91228,Valid loss: 2.40268, time : 10.15198826789856 lr : 0.5099857462495653\n",
      "epoch : 67 [12/23] Train loss: 1.90790,Valid loss: 2.46934, time : 10.636252403259277 lr : 0.5099857462495653\n",
      "epoch : 67 [13/23] Train loss: 1.90824,Valid loss: 2.40008, time : 10.277220964431763 lr : 0.5099857462495653\n",
      "epoch : 67 [14/23] Train loss: 1.94392,Valid loss: 2.57035, time : 10.578118562698364 lr : 0.5099857462495653\n",
      "epoch : 67 [15/23] Train loss: 1.99370,Valid loss: 2.60750, time : 10.848861694335938 lr : 0.5099857462495653\n",
      "epoch : 67 [16/23] Train loss: 2.05222,Valid loss: 2.50901, time : 10.679009199142456 lr : 0.5099857462495653\n",
      "epoch : 67 [17/23] Train loss: 2.07251,Valid loss: 2.54035, time : 10.150181770324707 lr : 0.5099857462495653\n",
      "epoch : 67 [18/23] Train loss: 2.30996,Valid loss: 2.55310, time : 10.539466381072998 lr : 0.5099857462495653\n",
      "epoch : 67 [19/23] Train loss: 2.30050,Valid loss: 2.43162, time : 9.909171104431152 lr : 0.5099857462495653\n",
      "epoch : 67 [20/23] Train loss: 2.22625,Valid loss: 2.83519, time : 10.323446273803711 lr : 0.5099857462495653\n",
      "epoch : 67 [21/23] Train loss: 2.30596,Valid loss: 2.54036, time : 10.535943269729614 lr : 0.5099857462495653\n",
      "epoch : 67 [22/23] Train loss: 2.20628,Valid loss: 2.81412, time : 9.543292760848999 lr : 0.5099857462495653\n",
      "epoch : 68 [0/23] Train loss: 2.06764,Valid loss: 2.55000, time : 9.974976539611816 lr : 0.5048858887870696\n",
      "epoch : 68 [1/23] Train loss: 2.01759,Valid loss: 2.52296, time : 10.217940092086792 lr : 0.5048858887870696\n",
      "epoch : 68 [2/23] Train loss: 1.93503,Valid loss: 2.69918, time : 9.874682664871216 lr : 0.5048858887870696\n",
      "epoch : 68 [3/23] Train loss: 1.92800,Valid loss: 2.90471, time : 10.232059240341187 lr : 0.5048858887870696\n",
      "epoch : 68 [4/23] Train loss: 1.89153,Valid loss: 2.79686, time : 10.17936897277832 lr : 0.5048858887870696\n",
      "epoch : 68 [5/23] Train loss: 1.92093,Valid loss: 2.70176, time : 10.342491865158081 lr : 0.5048858887870696\n",
      "epoch : 68 [6/23] Train loss: 1.89931,Valid loss: 2.55993, time : 9.910156965255737 lr : 0.5048858887870696\n",
      "epoch : 68 [7/23] Train loss: 1.88428,Valid loss: 2.54401, time : 10.09905195236206 lr : 0.5048858887870696\n",
      "epoch : 68 [8/23] Train loss: 1.86330,Valid loss: 2.40927, time : 9.951429605484009 lr : 0.5048858887870696\n",
      "epoch : 68 [9/23] Train loss: 1.87820,Valid loss: 2.38019, time : 9.86968731880188 lr : 0.5048858887870696\n",
      "epoch : 68 [10/23] Train loss: 1.87977,Valid loss: 2.31297, time : 10.13706922531128 lr : 0.5048858887870696\n",
      "epoch : 68 [11/23] Train loss: 1.86097,Valid loss: 2.40137, time : 10.699049472808838 lr : 0.5048858887870696\n",
      "epoch : 68 [12/23] Train loss: 1.87985,Valid loss: 2.34361, time : 10.34148645401001 lr : 0.5048858887870696\n",
      "epoch : 68 [13/23] Train loss: 1.87820,Valid loss: 2.55890, time : 10.135535955429077 lr : 0.5048858887870696\n",
      "epoch : 68 [14/23] Train loss: 1.90906,Valid loss: 2.34444, time : 10.028574705123901 lr : 0.5048858887870696\n",
      "epoch : 68 [15/23] Train loss: 1.95553,Valid loss: 2.58713, time : 10.175277471542358 lr : 0.5048858887870696\n",
      "epoch : 68 [16/23] Train loss: 1.99648,Valid loss: 2.61676, time : 10.705182313919067 lr : 0.5048858887870696\n",
      "epoch : 68 [17/23] Train loss: 2.06447,Valid loss: 3.38118, time : 10.403483152389526 lr : 0.5048858887870696\n",
      "epoch : 68 [18/23] Train loss: 2.02085,Valid loss: 3.13330, time : 10.230696201324463 lr : 0.5048858887870696\n",
      "epoch : 68 [19/23] Train loss: 2.05136,Valid loss: 3.00715, time : 10.167247295379639 lr : 0.5048858887870696\n",
      "epoch : 68 [20/23] Train loss: 1.96847,Valid loss: 3.11624, time : 10.121042013168335 lr : 0.5048858887870696\n",
      "epoch : 68 [21/23] Train loss: 1.96801,Valid loss: 2.43191, time : 10.398736953735352 lr : 0.5048858887870696\n",
      "epoch : 68 [22/23] Train loss: 1.88435,Valid loss: 2.37091, time : 9.883084535598755 lr : 0.5048858887870696\n",
      "epoch : 69 [0/23] Train loss: 1.86003,Valid loss: 2.28651, time : 9.67065715789795 lr : 0.4998370298991989\n",
      "epoch : 69 [1/23] Train loss: 1.84440,Valid loss: 2.32953, time : 10.188002347946167 lr : 0.4998370298991989\n",
      "epoch : 69 [2/23] Train loss: 1.83201,Valid loss: 2.29864, time : 9.522064685821533 lr : 0.4998370298991989\n",
      "epoch : 69 [3/23] Train loss: 1.79906,Valid loss: 2.27768, time : 10.118797779083252 lr : 0.4998370298991989\n",
      "epoch : 69 [4/23] Train loss: 1.82258,Valid loss: 2.26963, time : 9.93159532546997 lr : 0.4998370298991989\n",
      "epoch : 69 [5/23] Train loss: 1.81004,Valid loss: 2.28081, time : 10.168172597885132 lr : 0.4998370298991989\n",
      "epoch : 69 [6/23] Train loss: 1.83024,Valid loss: 2.22906, time : 9.541616916656494 lr : 0.4998370298991989\n",
      "epoch : 69 [7/23] Train loss: 1.81675,Valid loss: 2.29733, time : 10.256154775619507 lr : 0.4998370298991989\n",
      "epoch : 69 [8/23] Train loss: 1.85436,Valid loss: 2.24529, time : 9.531112909317017 lr : 0.4998370298991989\n",
      "epoch : 69 [9/23] Train loss: 1.83718,Valid loss: 2.32456, time : 9.752327680587769 lr : 0.4998370298991989\n",
      "epoch : 69 [10/23] Train loss: 1.85404,Valid loss: 2.26026, time : 10.157361507415771 lr : 0.4998370298991989\n",
      "epoch : 69 [11/23] Train loss: 1.84223,Valid loss: 2.40036, time : 9.919349193572998 lr : 0.4998370298991989\n",
      "epoch : 69 [12/23] Train loss: 1.79652,Valid loss: 2.30752, time : 9.593378782272339 lr : 0.4998370298991989\n",
      "epoch : 69 [13/23] Train loss: 1.83911,Valid loss: 2.30912, time : 9.860258340835571 lr : 0.4998370298991989\n",
      "epoch : 69 [14/23] Train loss: 1.85691,Valid loss: 2.40126, time : 10.130187034606934 lr : 0.4998370298991989\n",
      "epoch : 69 [15/23] Train loss: 1.84803,Valid loss: 2.48007, time : 10.112451076507568 lr : 0.4998370298991989\n",
      "epoch : 69 [16/23] Train loss: 1.88282,Valid loss: 2.48752, time : 9.996991157531738 lr : 0.4998370298991989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 69 [17/23] Train loss: 1.92335,Valid loss: 2.48435, time : 10.231948137283325 lr : 0.4998370298991989\n",
      "epoch : 69 [18/23] Train loss: 1.90500,Valid loss: 2.49200, time : 10.533339262008667 lr : 0.4998370298991989\n",
      "epoch : 69 [19/23] Train loss: 1.87838,Valid loss: 2.35045, time : 10.586742639541626 lr : 0.4998370298991989\n",
      "epoch : 69 [20/23] Train loss: 1.86858,Valid loss: 2.37877, time : 10.43090033531189 lr : 0.4998370298991989\n",
      "epoch : 69 [21/23] Train loss: 1.85884,Valid loss: 2.43571, time : 10.198725938796997 lr : 0.4998370298991989\n",
      "epoch : 69 [22/23] Train loss: 1.87808,Valid loss: 3.24560, time : 9.300388813018799 lr : 0.4998370298991989\n",
      "epoch : 70 [0/23] Train loss: 1.87103,Valid loss: 2.93877, time : 10.354146242141724 lr : 0.49483865960020695\n",
      "epoch : 70 [1/23] Train loss: 1.88127,Valid loss: 3.06732, time : 9.665493965148926 lr : 0.49483865960020695\n",
      "epoch : 70 [2/23] Train loss: 1.87218,Valid loss: 2.89357, time : 10.10942816734314 lr : 0.49483865960020695\n",
      "epoch : 70 [3/23] Train loss: 1.95551,Valid loss: 2.92608, time : 9.527214288711548 lr : 0.49483865960020695\n",
      "epoch : 70 [4/23] Train loss: 1.93413,Valid loss: 3.15489, time : 10.261731147766113 lr : 0.49483865960020695\n",
      "epoch : 70 [5/23] Train loss: 2.04890,Valid loss: 2.70074, time : 9.62729811668396 lr : 0.49483865960020695\n",
      "epoch : 70 [6/23] Train loss: 2.04240,Valid loss: 3.16371, time : 10.122299671173096 lr : 0.49483865960020695\n",
      "epoch : 70 [7/23] Train loss: 2.18265,Valid loss: 3.26572, time : 9.690839290618896 lr : 0.49483865960020695\n",
      "epoch : 70 [8/23] Train loss: 2.00961,Valid loss: 2.65349, time : 9.99265718460083 lr : 0.49483865960020695\n",
      "epoch : 70 [9/23] Train loss: 1.93844,Valid loss: 2.49272, time : 10.024353742599487 lr : 0.49483865960020695\n",
      "epoch : 70 [10/23] Train loss: 1.85175,Valid loss: 2.28177, time : 9.581698179244995 lr : 0.49483865960020695\n",
      "epoch : 70 [11/23] Train loss: 1.85995,Valid loss: 2.28325, time : 10.039942502975464 lr : 0.49483865960020695\n",
      "epoch : 70 [12/23] Train loss: 1.92917,Valid loss: 2.59221, time : 9.987830877304077 lr : 0.49483865960020695\n",
      "epoch : 70 [13/23] Train loss: 2.39207,Valid loss: 2.59408, time : 9.84199857711792 lr : 0.49483865960020695\n",
      "epoch : 70 [14/23] Train loss: 1.97716,Valid loss: 4.01136, time : 9.613402605056763 lr : 0.49483865960020695\n",
      "epoch : 70 [15/23] Train loss: 1.96631,Valid loss: 2.54547, time : 9.59789228439331 lr : 0.49483865960020695\n",
      "epoch : 70 [16/23] Train loss: 1.98759,Valid loss: 2.43470, time : 9.786796808242798 lr : 0.49483865960020695\n",
      "epoch : 70 [17/23] Train loss: 1.96102,Valid loss: 2.66247, time : 10.060922861099243 lr : 0.49483865960020695\n",
      "epoch : 70 [18/23] Train loss: 1.87543,Valid loss: 2.32529, time : 9.789268016815186 lr : 0.49483865960020695\n",
      "epoch : 70 [19/23] Train loss: 1.79977,Valid loss: 2.20538, time : 9.722391843795776 lr : 0.49483865960020695\n",
      "epoch : 70 [20/23] Train loss: 1.78365,Valid loss: 2.27910, time : 10.076666831970215 lr : 0.49483865960020695\n",
      "epoch : 70 [21/23] Train loss: 1.78949,Valid loss: 2.16308, time : 9.773205518722534 lr : 0.49483865960020695\n",
      "epoch : 70 [22/23] Train loss: 1.79748,Valid loss: 2.31784, time : 9.430023193359375 lr : 0.49483865960020695\n",
      "epoch : 71 [0/23] Train loss: 1.78170,Valid loss: 2.23042, time : 10.682402849197388 lr : 0.4898902730042049\n",
      "epoch : 71 [1/23] Train loss: 1.79823,Valid loss: 2.15452, time : 10.286245584487915 lr : 0.4898902730042049\n",
      "epoch : 71 [2/23] Train loss: 1.79283,Valid loss: 2.15901, time : 10.201236724853516 lr : 0.4898902730042049\n",
      "epoch : 71 [3/23] Train loss: 1.76821,Valid loss: 2.21091, time : 10.123562812805176 lr : 0.4898902730042049\n",
      "epoch : 71 [4/23] Train loss: 1.77629,Valid loss: 2.20782, time : 9.663256406784058 lr : 0.4898902730042049\n",
      "epoch : 71 [5/23] Train loss: 1.77728,Valid loss: 2.22862, time : 10.46878695487976 lr : 0.4898902730042049\n",
      "epoch : 71 [6/23] Train loss: 1.79807,Valid loss: 2.19746, time : 10.330734491348267 lr : 0.4898902730042049\n",
      "epoch : 71 [7/23] Train loss: 1.76071,Valid loss: 2.14792, time : 10.08790135383606 lr : 0.4898902730042049\n",
      "epoch : 71 [8/23] Train loss: 1.75283,Valid loss: 2.26535, time : 9.913857221603394 lr : 0.4898902730042049\n",
      "epoch : 71 [9/23] Train loss: 1.74474,Valid loss: 2.13715, time : 10.318200826644897 lr : 0.4898902730042049\n",
      "epoch : 71 [10/23] Train loss: 1.73025,Valid loss: 2.17544, time : 10.224926471710205 lr : 0.4898902730042049\n",
      "epoch : 71 [11/23] Train loss: 1.74251,Valid loss: 2.18368, time : 10.512123346328735 lr : 0.4898902730042049\n",
      "epoch : 71 [12/23] Train loss: 1.74365,Valid loss: 2.25366, time : 10.40221619606018 lr : 0.4898902730042049\n",
      "epoch : 71 [13/23] Train loss: 1.73948,Valid loss: 2.34468, time : 10.131097555160522 lr : 0.4898902730042049\n",
      "epoch : 71 [14/23] Train loss: 1.74503,Valid loss: 2.51701, time : 10.03260326385498 lr : 0.4898902730042049\n",
      "epoch : 71 [15/23] Train loss: 1.75437,Valid loss: 2.44063, time : 10.231548547744751 lr : 0.4898902730042049\n",
      "epoch : 71 [16/23] Train loss: 1.76365,Valid loss: 2.60318, time : 10.238864183425903 lr : 0.4898902730042049\n",
      "epoch : 71 [17/23] Train loss: 1.74041,Valid loss: 2.45967, time : 9.895976066589355 lr : 0.4898902730042049\n",
      "epoch : 71 [18/23] Train loss: 1.76744,Valid loss: 2.72333, time : 10.26381540298462 lr : 0.4898902730042049\n",
      "epoch : 71 [19/23] Train loss: 1.73024,Valid loss: 2.25939, time : 9.860980987548828 lr : 0.4898902730042049\n",
      "epoch : 71 [20/23] Train loss: 1.73306,Valid loss: 2.40803, time : 10.304513216018677 lr : 0.4898902730042049\n",
      "epoch : 71 [21/23] Train loss: 1.73656,Valid loss: 2.20985, time : 10.28534483909607 lr : 0.4898902730042049\n",
      "epoch : 71 [22/23] Train loss: 1.76571,Valid loss: 2.39829, time : 9.378604888916016 lr : 0.4898902730042049\n",
      "epoch : 72 [0/23] Train loss: 1.77321,Valid loss: 2.18960, time : 10.306987285614014 lr : 0.48499137027416284\n",
      "epoch : 72 [1/23] Train loss: 1.77044,Valid loss: 2.20614, time : 9.743849039077759 lr : 0.48499137027416284\n",
      "epoch : 72 [2/23] Train loss: 1.80192,Valid loss: 2.10544, time : 10.14930272102356 lr : 0.48499137027416284\n",
      "epoch : 72 [3/23] Train loss: 1.84450,Valid loss: 2.14992, time : 10.118231058120728 lr : 0.48499137027416284\n",
      "epoch : 72 [4/23] Train loss: 1.85888,Valid loss: 2.23688, time : 9.717522621154785 lr : 0.48499137027416284\n",
      "epoch : 72 [5/23] Train loss: 1.90293,Valid loss: 2.21366, time : 9.784752368927002 lr : 0.48499137027416284\n",
      "epoch : 72 [6/23] Train loss: 1.89363,Valid loss: 2.34853, time : 10.01224136352539 lr : 0.48499137027416284\n",
      "epoch : 72 [7/23] Train loss: 1.93615,Valid loss: 2.43711, time : 9.72745656967163 lr : 0.48499137027416284\n",
      "epoch : 72 [8/23] Train loss: 1.92419,Valid loss: 2.87010, time : 10.111584901809692 lr : 0.48499137027416284\n",
      "epoch : 72 [9/23] Train loss: 2.01141,Valid loss: 3.17066, time : 9.722588062286377 lr : 0.48499137027416284\n",
      "epoch : 72 [10/23] Train loss: 1.90071,Valid loss: 2.57447, time : 10.111674785614014 lr : 0.48499137027416284\n",
      "epoch : 72 [11/23] Train loss: 1.98514,Valid loss: 2.44239, time : 9.960584878921509 lr : 0.48499137027416284\n",
      "epoch : 72 [12/23] Train loss: 2.21429,Valid loss: 2.33754, time : 10.255688905715942 lr : 0.48499137027416284\n",
      "epoch : 72 [13/23] Train loss: 1.93044,Valid loss: 2.89893, time : 9.978276014328003 lr : 0.48499137027416284\n",
      "epoch : 72 [14/23] Train loss: 2.04100,Valid loss: 3.24103, time : 10.395014524459839 lr : 0.48499137027416284\n",
      "epoch : 72 [15/23] Train loss: 2.07305,Valid loss: 2.28820, time : 9.920125961303711 lr : 0.48499137027416284\n",
      "epoch : 72 [16/23] Train loss: 1.81210,Valid loss: 2.34793, time : 9.810574531555176 lr : 0.48499137027416284\n",
      "epoch : 72 [17/23] Train loss: 1.77350,Valid loss: 2.16168, time : 10.035179615020752 lr : 0.48499137027416284\n",
      "epoch : 72 [18/23] Train loss: 1.70575,Valid loss: 2.16929, time : 10.342288970947266 lr : 0.48499137027416284\n",
      "epoch : 72 [19/23] Train loss: 1.69531,Valid loss: 2.13352, time : 10.442524671554565 lr : 0.48499137027416284\n",
      "epoch : 72 [20/23] Train loss: 1.69021,Valid loss: 2.15502, time : 10.226216316223145 lr : 0.48499137027416284\n",
      "epoch : 72 [21/23] Train loss: 1.69053,Valid loss: 2.16295, time : 10.505326747894287 lr : 0.48499137027416284\n",
      "epoch : 72 [22/23] Train loss: 1.69219,Valid loss: 2.15825, time : 9.457122564315796 lr : 0.48499137027416284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 73 [0/23] Train loss: 1.63772,Valid loss: 2.12135, time : 10.652161359786987 lr : 0.4801414565714212\n",
      "epoch : 73 [1/23] Train loss: 1.64084,Valid loss: 2.10950, time : 10.410850763320923 lr : 0.4801414565714212\n",
      "epoch : 73 [2/23] Train loss: 1.65894,Valid loss: 2.11631, time : 9.777489423751831 lr : 0.4801414565714212\n",
      "epoch : 73 [3/23] Train loss: 1.66807,Valid loss: 2.11624, time : 10.15065598487854 lr : 0.4801414565714212\n",
      "epoch : 73 [4/23] Train loss: 1.66729,Valid loss: 2.18333, time : 10.110905408859253 lr : 0.4801414565714212\n",
      "epoch : 73 [5/23] Train loss: 1.67136,Valid loss: 2.10460, time : 10.418827533721924 lr : 0.4801414565714212\n",
      "epoch : 73 [6/23] Train loss: 1.69203,Valid loss: 2.14753, time : 10.399747610092163 lr : 0.4801414565714212\n",
      "epoch : 73 [7/23] Train loss: 1.68513,Valid loss: 2.09172, time : 10.684078454971313 lr : 0.4801414565714212\n",
      "epoch : 73 [8/23] Train loss: 1.66399,Valid loss: 2.08632, time : 9.979625940322876 lr : 0.4801414565714212\n",
      "epoch : 73 [9/23] Train loss: 1.65979,Valid loss: 2.04895, time : 10.43149471282959 lr : 0.4801414565714212\n",
      "epoch : 73 [10/23] Train loss: 1.63827,Valid loss: 2.09696, time : 10.416734218597412 lr : 0.4801414565714212\n",
      "epoch : 73 [11/23] Train loss: 1.65739,Valid loss: 2.08299, time : 10.557499408721924 lr : 0.4801414565714212\n",
      "epoch : 73 [12/23] Train loss: 1.67314,Valid loss: 2.10788, time : 9.951077461242676 lr : 0.4801414565714212\n",
      "epoch : 73 [13/23] Train loss: 1.64004,Valid loss: 2.08314, time : 9.986377954483032 lr : 0.4801414565714212\n",
      "epoch : 73 [14/23] Train loss: 1.68005,Valid loss: 2.08443, time : 10.045060634613037 lr : 0.4801414565714212\n",
      "epoch : 73 [15/23] Train loss: 1.65973,Valid loss: 2.10616, time : 10.23348355293274 lr : 0.4801414565714212\n",
      "epoch : 73 [16/23] Train loss: 1.69575,Valid loss: 2.13704, time : 10.488840103149414 lr : 0.4801414565714212\n",
      "epoch : 73 [17/23] Train loss: 1.68243,Valid loss: 2.08891, time : 10.179754495620728 lr : 0.4801414565714212\n",
      "epoch : 73 [18/23] Train loss: 1.69813,Valid loss: 2.55366, time : 9.89052152633667 lr : 0.4801414565714212\n",
      "epoch : 73 [19/23] Train loss: 1.70797,Valid loss: 2.75714, time : 10.233592987060547 lr : 0.4801414565714212\n",
      "epoch : 73 [20/23] Train loss: 1.75468,Valid loss: 3.51763, time : 10.62262225151062 lr : 0.4801414565714212\n",
      "epoch : 73 [21/23] Train loss: 1.75132,Valid loss: 3.16180, time : 10.085707664489746 lr : 0.4801414565714212\n",
      "epoch : 73 [22/23] Train loss: 1.81623,Valid loss: 3.40116, time : 9.617217302322388 lr : 0.4801414565714212\n",
      "epoch : 74 [0/23] Train loss: 1.77665,Valid loss: 2.60984, time : 10.279392957687378 lr : 0.475340042005707\n",
      "epoch : 74 [1/23] Train loss: 1.76216,Valid loss: 2.47907, time : 10.340411901473999 lr : 0.475340042005707\n",
      "epoch : 74 [2/23] Train loss: 1.67255,Valid loss: 2.15696, time : 9.811071157455444 lr : 0.475340042005707\n",
      "epoch : 74 [3/23] Train loss: 1.66470,Valid loss: 2.06643, time : 10.13410997390747 lr : 0.475340042005707\n",
      "epoch : 74 [4/23] Train loss: 1.63505,Valid loss: 2.03748, time : 9.84162950515747 lr : 0.475340042005707\n",
      "epoch : 74 [5/23] Train loss: 1.60166,Valid loss: 2.06185, time : 10.248079299926758 lr : 0.475340042005707\n",
      "epoch : 74 [6/23] Train loss: 1.61116,Valid loss: 2.10221, time : 9.928615093231201 lr : 0.475340042005707\n",
      "epoch : 74 [7/23] Train loss: 1.61958,Valid loss: 2.04830, time : 10.231945514678955 lr : 0.475340042005707\n",
      "epoch : 74 [8/23] Train loss: 1.64240,Valid loss: 2.12887, time : 9.783327579498291 lr : 0.475340042005707\n",
      "epoch : 74 [9/23] Train loss: 1.60668,Valid loss: 2.02090, time : 10.067361116409302 lr : 0.475340042005707\n",
      "epoch : 74 [10/23] Train loss: 1.61853,Valid loss: 2.07940, time : 9.787922620773315 lr : 0.475340042005707\n",
      "epoch : 74 [11/23] Train loss: 1.66785,Valid loss: 2.05330, time : 10.772895336151123 lr : 0.475340042005707\n",
      "epoch : 74 [12/23] Train loss: 1.66685,Valid loss: 2.12255, time : 9.760156154632568 lr : 0.475340042005707\n",
      "epoch : 74 [13/23] Train loss: 1.67429,Valid loss: 2.07418, time : 10.190579652786255 lr : 0.475340042005707\n",
      "epoch : 74 [14/23] Train loss: 1.67405,Valid loss: 2.01114, time : 9.994792938232422 lr : 0.475340042005707\n",
      "epoch : 74 [15/23] Train loss: 1.65732,Valid loss: 2.05134, time : 9.945908069610596 lr : 0.475340042005707\n",
      "epoch : 74 [16/23] Train loss: 1.63243,Valid loss: 2.14244, time : 9.682812929153442 lr : 0.475340042005707\n",
      "epoch : 74 [17/23] Train loss: 1.63919,Valid loss: 2.06814, time : 10.145989656448364 lr : 0.475340042005707\n",
      "epoch : 74 [18/23] Train loss: 1.61429,Valid loss: 2.09094, time : 9.723650455474854 lr : 0.475340042005707\n",
      "epoch : 74 [19/23] Train loss: 1.64808,Valid loss: 2.09315, time : 10.079941272735596 lr : 0.475340042005707\n",
      "epoch : 74 [20/23] Train loss: 1.61610,Valid loss: 2.20168, time : 9.948325395584106 lr : 0.475340042005707\n",
      "epoch : 74 [21/23] Train loss: 1.63227,Valid loss: 2.16592, time : 9.928106307983398 lr : 0.475340042005707\n",
      "epoch : 74 [22/23] Train loss: 1.59179,Valid loss: 2.06522, time : 9.326799631118774 lr : 0.475340042005707\n",
      "epoch : 75 [0/23] Train loss: 1.58959,Valid loss: 2.15717, time : 10.02052092552185 lr : 0.47058664158564995\n",
      "epoch : 75 [1/23] Train loss: 1.60062,Valid loss: 2.04910, time : 9.707666635513306 lr : 0.47058664158564995\n",
      "epoch : 75 [2/23] Train loss: 1.59787,Valid loss: 2.02038, time : 9.971540927886963 lr : 0.47058664158564995\n",
      "epoch : 75 [3/23] Train loss: 1.59141,Valid loss: 2.02451, time : 9.893951654434204 lr : 0.47058664158564995\n",
      "epoch : 75 [4/23] Train loss: 1.58725,Valid loss: 2.04454, time : 10.18987250328064 lr : 0.47058664158564995\n",
      "epoch : 75 [5/23] Train loss: 1.57495,Valid loss: 2.03574, time : 10.181954622268677 lr : 0.47058664158564995\n",
      "epoch : 75 [6/23] Train loss: 1.59785,Valid loss: 2.09496, time : 10.266204595565796 lr : 0.47058664158564995\n",
      "epoch : 75 [7/23] Train loss: 1.61515,Valid loss: 2.01362, time : 10.223618268966675 lr : 0.47058664158564995\n",
      "epoch : 75 [8/23] Train loss: 1.58337,Valid loss: 2.06909, time : 10.343919515609741 lr : 0.47058664158564995\n",
      "epoch : 75 [9/23] Train loss: 1.59107,Valid loss: 1.99512, time : 9.931537628173828 lr : 0.47058664158564995\n",
      "epoch : 75 [10/23] Train loss: 1.64557,Valid loss: 2.06374, time : 10.037508249282837 lr : 0.47058664158564995\n",
      "epoch : 75 [11/23] Train loss: 1.65682,Valid loss: 2.02573, time : 10.047154426574707 lr : 0.47058664158564995\n",
      "epoch : 75 [12/23] Train loss: 1.70388,Valid loss: 2.10142, time : 10.24479627609253 lr : 0.47058664158564995\n",
      "epoch : 75 [13/23] Train loss: 1.78381,Valid loss: 2.38445, time : 9.468871593475342 lr : 0.47058664158564995\n",
      "epoch : 75 [14/23] Train loss: 1.88184,Valid loss: 2.23683, time : 9.894400358200073 lr : 0.47058664158564995\n",
      "epoch : 75 [15/23] Train loss: 1.95984,Valid loss: 2.62632, time : 9.486169576644897 lr : 0.47058664158564995\n",
      "epoch : 75 [16/23] Train loss: 2.00001,Valid loss: 2.57793, time : 9.752444505691528 lr : 0.47058664158564995\n",
      "epoch : 75 [17/23] Train loss: 1.75490,Valid loss: 2.39617, time : 9.929408311843872 lr : 0.47058664158564995\n",
      "epoch : 75 [18/23] Train loss: 1.84157,Valid loss: 1.99576, time : 9.541542768478394 lr : 0.47058664158564995\n",
      "epoch : 75 [19/23] Train loss: 1.85652,Valid loss: 3.31426, time : 9.916719198226929 lr : 0.47058664158564995\n",
      "epoch : 75 [20/23] Train loss: 1.80004,Valid loss: 2.14461, time : 9.814528942108154 lr : 0.47058664158564995\n",
      "epoch : 75 [21/23] Train loss: 1.77385,Valid loss: 2.29926, time : 9.900453567504883 lr : 0.47058664158564995\n",
      "epoch : 75 [22/23] Train loss: 1.72635,Valid loss: 2.22405, time : 9.306154251098633 lr : 0.47058664158564995\n",
      "epoch : 76 [0/23] Train loss: 1.64245,Valid loss: 2.06192, time : 10.591520071029663 lr : 0.4658807751697934\n",
      "epoch : 76 [1/23] Train loss: 1.59668,Valid loss: 2.01815, time : 10.566018342971802 lr : 0.4658807751697934\n",
      "epoch : 76 [2/23] Train loss: 1.55316,Valid loss: 1.98479, time : 10.389465093612671 lr : 0.4658807751697934\n",
      "epoch : 76 [3/23] Train loss: 1.58350,Valid loss: 1.97012, time : 10.290448904037476 lr : 0.4658807751697934\n",
      "epoch : 76 [4/23] Train loss: 1.53040,Valid loss: 1.95589, time : 10.966418743133545 lr : 0.4658807751697934\n",
      "epoch : 76 [5/23] Train loss: 1.53295,Valid loss: 1.97047, time : 10.211893081665039 lr : 0.4658807751697934\n",
      "epoch : 76 [6/23] Train loss: 1.53540,Valid loss: 1.94102, time : 10.484994649887085 lr : 0.4658807751697934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 76 [7/23] Train loss: 1.55448,Valid loss: 1.95615, time : 10.086878061294556 lr : 0.4658807751697934\n",
      "epoch : 76 [8/23] Train loss: 1.52741,Valid loss: 1.96231, time : 10.225327253341675 lr : 0.4658807751697934\n",
      "epoch : 76 [9/23] Train loss: 1.51626,Valid loss: 1.94350, time : 10.27592396736145 lr : 0.4658807751697934\n",
      "epoch : 76 [10/23] Train loss: 1.52281,Valid loss: 1.90998, time : 10.082875490188599 lr : 0.4658807751697934\n",
      "epoch : 76 [11/23] Train loss: 1.54996,Valid loss: 1.97119, time : 9.859148979187012 lr : 0.4658807751697934\n",
      "epoch : 76 [12/23] Train loss: 1.50831,Valid loss: 1.93650, time : 10.114457130432129 lr : 0.4658807751697934\n",
      "epoch : 76 [13/23] Train loss: 1.49039,Valid loss: 1.99179, time : 10.189106225967407 lr : 0.4658807751697934\n",
      "epoch : 76 [14/23] Train loss: 1.53582,Valid loss: 1.92641, time : 10.050164937973022 lr : 0.4658807751697934\n",
      "epoch : 76 [15/23] Train loss: 1.51417,Valid loss: 2.19002, time : 10.071727275848389 lr : 0.4658807751697934\n",
      "epoch : 76 [16/23] Train loss: 1.52506,Valid loss: 2.03399, time : 9.892786741256714 lr : 0.4658807751697934\n",
      "epoch : 76 [17/23] Train loss: 1.54143,Valid loss: 2.05902, time : 10.178861379623413 lr : 0.4658807751697934\n",
      "epoch : 76 [18/23] Train loss: 1.55262,Valid loss: 2.04097, time : 9.995062351226807 lr : 0.4658807751697934\n",
      "epoch : 76 [19/23] Train loss: 1.55517,Valid loss: 2.09621, time : 10.604925632476807 lr : 0.4658807751697934\n",
      "epoch : 76 [20/23] Train loss: 1.52920,Valid loss: 2.01831, time : 10.03220510482788 lr : 0.4658807751697934\n",
      "epoch : 76 [21/23] Train loss: 1.55880,Valid loss: 2.10475, time : 10.28703260421753 lr : 0.4658807751697934\n",
      "epoch : 76 [22/23] Train loss: 1.56933,Valid loss: 1.90639, time : 9.675474405288696 lr : 0.4658807751697934\n",
      "epoch : 77 [0/23] Train loss: 1.57208,Valid loss: 1.99422, time : 10.480835676193237 lr : 0.4612219674180955\n",
      "epoch : 77 [1/23] Train loss: 1.57689,Valid loss: 2.09485, time : 10.273036003112793 lr : 0.4612219674180955\n",
      "epoch : 77 [2/23] Train loss: 1.60790,Valid loss: 1.99132, time : 10.105250597000122 lr : 0.4612219674180955\n",
      "epoch : 77 [3/23] Train loss: 1.58985,Valid loss: 2.01639, time : 10.566430568695068 lr : 0.4612219674180955\n",
      "epoch : 77 [4/23] Train loss: 1.57887,Valid loss: 2.06207, time : 10.470607042312622 lr : 0.4612219674180955\n",
      "epoch : 77 [5/23] Train loss: 1.52097,Valid loss: 2.04856, time : 10.065497159957886 lr : 0.4612219674180955\n",
      "epoch : 77 [6/23] Train loss: 1.53456,Valid loss: 2.37117, time : 10.250106573104858 lr : 0.4612219674180955\n",
      "epoch : 77 [7/23] Train loss: 1.56304,Valid loss: 2.51555, time : 10.446510314941406 lr : 0.4612219674180955\n",
      "epoch : 77 [8/23] Train loss: 1.52638,Valid loss: 2.23091, time : 10.01223111152649 lr : 0.4612219674180955\n",
      "epoch : 77 [9/23] Train loss: 1.53481,Valid loss: 1.97498, time : 9.972151756286621 lr : 0.4612219674180955\n",
      "epoch : 77 [10/23] Train loss: 1.50712,Valid loss: 2.12021, time : 10.461076259613037 lr : 0.4612219674180955\n",
      "epoch : 77 [11/23] Train loss: 1.47308,Valid loss: 1.88982, time : 10.224262237548828 lr : 0.4612219674180955\n",
      "epoch : 77 [12/23] Train loss: 1.49689,Valid loss: 1.94901, time : 9.849864482879639 lr : 0.4612219674180955\n",
      "epoch : 77 [13/23] Train loss: 1.48576,Valid loss: 1.93896, time : 10.43125033378601 lr : 0.4612219674180955\n",
      "epoch : 77 [14/23] Train loss: 1.47230,Valid loss: 1.86144, time : 10.151022672653198 lr : 0.4612219674180955\n",
      "epoch : 77 [15/23] Train loss: 1.47834,Valid loss: 1.87251, time : 10.19879937171936 lr : 0.4612219674180955\n",
      "epoch : 77 [16/23] Train loss: 1.47938,Valid loss: 1.94779, time : 9.86761999130249 lr : 0.4612219674180955\n",
      "epoch : 77 [17/23] Train loss: 1.49531,Valid loss: 1.91433, time : 10.336981058120728 lr : 0.4612219674180955\n",
      "epoch : 77 [18/23] Train loss: 1.47983,Valid loss: 1.93901, time : 10.485929727554321 lr : 0.4612219674180955\n",
      "epoch : 77 [19/23] Train loss: 1.49855,Valid loss: 1.98759, time : 10.340771913528442 lr : 0.4612219674180955\n",
      "epoch : 77 [20/23] Train loss: 1.52139,Valid loss: 2.02733, time : 10.389849185943604 lr : 0.4612219674180955\n",
      "epoch : 77 [21/23] Train loss: 1.49558,Valid loss: 1.96686, time : 10.442984104156494 lr : 0.4612219674180955\n",
      "epoch : 77 [22/23] Train loss: 1.50498,Valid loss: 2.03156, time : 9.780770540237427 lr : 0.4612219674180955\n",
      "epoch : 78 [0/23] Train loss: 1.50222,Valid loss: 1.89720, time : 10.569362878799438 lr : 0.45660974774391455\n",
      "epoch : 78 [1/23] Train loss: 1.50749,Valid loss: 2.03460, time : 10.482410669326782 lr : 0.45660974774391455\n",
      "epoch : 78 [2/23] Train loss: 1.50197,Valid loss: 1.94584, time : 10.394886255264282 lr : 0.45660974774391455\n",
      "epoch : 78 [3/23] Train loss: 1.50419,Valid loss: 1.89192, time : 10.463056802749634 lr : 0.45660974774391455\n",
      "epoch : 78 [4/23] Train loss: 1.53493,Valid loss: 1.96209, time : 10.154007911682129 lr : 0.45660974774391455\n",
      "epoch : 78 [5/23] Train loss: 1.55943,Valid loss: 2.00025, time : 10.2110013961792 lr : 0.45660974774391455\n",
      "epoch : 78 [6/23] Train loss: 1.62887,Valid loss: 2.02222, time : 10.617639064788818 lr : 0.45660974774391455\n",
      "epoch : 78 [7/23] Train loss: 1.68810,Valid loss: 2.08935, time : 10.166778564453125 lr : 0.45660974774391455\n",
      "epoch : 78 [8/23] Train loss: 1.87474,Valid loss: 1.91903, time : 10.396458864212036 lr : 0.45660974774391455\n",
      "epoch : 78 [9/23] Train loss: 1.67635,Valid loss: 2.55521, time : 10.38589334487915 lr : 0.45660974774391455\n",
      "epoch : 78 [10/23] Train loss: 1.58508,Valid loss: 2.15103, time : 10.55767560005188 lr : 0.45660974774391455\n",
      "epoch : 78 [11/23] Train loss: 1.53457,Valid loss: 2.41877, time : 10.734587907791138 lr : 0.45660974774391455\n",
      "epoch : 78 [12/23] Train loss: 1.52165,Valid loss: 2.78407, time : 10.157305717468262 lr : 0.45660974774391455\n",
      "epoch : 78 [13/23] Train loss: 1.57351,Valid loss: 3.70579, time : 10.504979372024536 lr : 0.45660974774391455\n",
      "epoch : 78 [14/23] Train loss: 1.75008,Valid loss: 4.26572, time : 10.109744548797607 lr : 0.45660974774391455\n",
      "epoch : 78 [15/23] Train loss: 2.17124,Valid loss: 2.55724, time : 10.17704725265503 lr : 0.45660974774391455\n",
      "epoch : 78 [16/23] Train loss: 1.61227,Valid loss: 2.06811, time : 10.096111536026001 lr : 0.45660974774391455\n",
      "epoch : 78 [17/23] Train loss: 1.51364,Valid loss: 1.97275, time : 10.227508306503296 lr : 0.45660974774391455\n",
      "epoch : 78 [18/23] Train loss: 1.46217,Valid loss: 1.84114, time : 10.34975290298462 lr : 0.45660974774391455\n",
      "epoch : 78 [19/23] Train loss: 1.45376,Valid loss: 1.88219, time : 10.08183741569519 lr : 0.45660974774391455\n",
      "epoch : 78 [20/23] Train loss: 1.45993,Valid loss: 1.95425, time : 10.447757720947266 lr : 0.45660974774391455\n",
      "epoch : 78 [21/23] Train loss: 1.43858,Valid loss: 1.91962, time : 10.37447214126587 lr : 0.45660974774391455\n",
      "epoch : 78 [22/23] Train loss: 1.45973,Valid loss: 1.89506, time : 9.6751127243042 lr : 0.45660974774391455\n",
      "epoch : 79 [0/23] Train loss: 1.45866,Valid loss: 1.94683, time : 10.924350500106812 lr : 0.4520436502664754\n",
      "epoch : 79 [1/23] Train loss: 1.46661,Valid loss: 1.88460, time : 10.426451921463013 lr : 0.4520436502664754\n",
      "epoch : 79 [2/23] Train loss: 1.41474,Valid loss: 1.82814, time : 10.445577621459961 lr : 0.4520436502664754\n",
      "epoch : 79 [3/23] Train loss: 1.44953,Valid loss: 1.82313, time : 10.472472667694092 lr : 0.4520436502664754\n",
      "epoch : 79 [4/23] Train loss: 1.44198,Valid loss: 1.81984, time : 10.268140316009521 lr : 0.4520436502664754\n",
      "epoch : 79 [5/23] Train loss: 1.45346,Valid loss: 1.85004, time : 10.55644965171814 lr : 0.4520436502664754\n",
      "epoch : 79 [6/23] Train loss: 1.45269,Valid loss: 1.88480, time : 10.90635085105896 lr : 0.4520436502664754\n",
      "epoch : 79 [7/23] Train loss: 1.44475,Valid loss: 1.84262, time : 10.240023136138916 lr : 0.4520436502664754\n",
      "epoch : 79 [8/23] Train loss: 1.44411,Valid loss: 1.85076, time : 10.415266036987305 lr : 0.4520436502664754\n",
      "epoch : 79 [9/23] Train loss: 1.47279,Valid loss: 1.80321, time : 9.894641876220703 lr : 0.4520436502664754\n",
      "epoch : 79 [10/23] Train loss: 1.44789,Valid loss: 1.84913, time : 10.234778642654419 lr : 0.4520436502664754\n",
      "epoch : 79 [11/23] Train loss: 1.45738,Valid loss: 1.83611, time : 10.210439920425415 lr : 0.4520436502664754\n",
      "epoch : 79 [12/23] Train loss: 1.46268,Valid loss: 1.83068, time : 10.380396127700806 lr : 0.4520436502664754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 79 [13/23] Train loss: 1.46667,Valid loss: 1.81472, time : 10.516198873519897 lr : 0.4520436502664754\n",
      "epoch : 79 [14/23] Train loss: 1.44335,Valid loss: 1.81128, time : 10.268547773361206 lr : 0.4520436502664754\n",
      "epoch : 79 [15/23] Train loss: 1.46508,Valid loss: 1.89474, time : 9.849055051803589 lr : 0.4520436502664754\n",
      "epoch : 79 [16/23] Train loss: 1.46826,Valid loss: 1.88858, time : 10.313052415847778 lr : 0.4520436502664754\n",
      "epoch : 79 [17/23] Train loss: 1.48498,Valid loss: 2.09278, time : 9.821043252944946 lr : 0.4520436502664754\n",
      "epoch : 79 [18/23] Train loss: 1.53401,Valid loss: 1.81865, time : 10.132277250289917 lr : 0.4520436502664754\n",
      "epoch : 79 [19/23] Train loss: 1.55359,Valid loss: 1.94302, time : 10.613245248794556 lr : 0.4520436502664754\n",
      "epoch : 79 [20/23] Train loss: 1.52143,Valid loss: 1.84970, time : 10.193137407302856 lr : 0.4520436502664754\n",
      "epoch : 79 [21/23] Train loss: 1.50881,Valid loss: 1.89028, time : 9.883803129196167 lr : 0.4520436502664754\n",
      "epoch : 79 [22/23] Train loss: 1.44707,Valid loss: 1.97992, time : 9.749560356140137 lr : 0.4520436502664754\n",
      "epoch : 80 [0/23] Train loss: 1.45735,Valid loss: 2.09284, time : 10.426298141479492 lr : 0.44752321376381066\n",
      "epoch : 80 [1/23] Train loss: 1.46980,Valid loss: 2.37367, time : 10.416043281555176 lr : 0.44752321376381066\n",
      "epoch : 80 [2/23] Train loss: 1.46194,Valid loss: 2.26811, time : 10.670400619506836 lr : 0.44752321376381066\n",
      "epoch : 80 [3/23] Train loss: 1.46746,Valid loss: 2.29905, time : 10.657226800918579 lr : 0.44752321376381066\n",
      "epoch : 80 [4/23] Train loss: 1.45783,Valid loss: 2.02607, time : 10.76309061050415 lr : 0.44752321376381066\n",
      "epoch : 80 [5/23] Train loss: 1.43785,Valid loss: 1.83351, time : 10.461139440536499 lr : 0.44752321376381066\n",
      "epoch : 80 [6/23] Train loss: 1.42769,Valid loss: 1.84631, time : 10.652596712112427 lr : 0.44752321376381066\n",
      "epoch : 80 [7/23] Train loss: 1.37117,Valid loss: 1.79309, time : 10.763924598693848 lr : 0.44752321376381066\n",
      "epoch : 80 [8/23] Train loss: 1.38295,Valid loss: 1.79564, time : 10.881523847579956 lr : 0.44752321376381066\n",
      "epoch : 80 [9/23] Train loss: 1.41814,Valid loss: 1.77956, time : 10.443643808364868 lr : 0.44752321376381066\n",
      "epoch : 80 [10/23] Train loss: 1.36410,Valid loss: 1.78349, time : 10.465282678604126 lr : 0.44752321376381066\n",
      "epoch : 80 [11/23] Train loss: 1.36768,Valid loss: 1.89076, time : 10.356603145599365 lr : 0.44752321376381066\n",
      "epoch : 80 [12/23] Train loss: 1.42164,Valid loss: 1.84113, time : 10.784478902816772 lr : 0.44752321376381066\n",
      "epoch : 80 [13/23] Train loss: 1.38420,Valid loss: 1.77946, time : 10.795575380325317 lr : 0.44752321376381066\n",
      "epoch : 80 [14/23] Train loss: 1.39350,Valid loss: 1.86935, time : 10.778286933898926 lr : 0.44752321376381066\n",
      "epoch : 80 [15/23] Train loss: 1.40357,Valid loss: 1.93388, time : 10.568784236907959 lr : 0.44752321376381066\n",
      "epoch : 80 [16/23] Train loss: 1.39997,Valid loss: 1.88377, time : 10.865842819213867 lr : 0.44752321376381066\n",
      "epoch : 80 [17/23] Train loss: 1.38947,Valid loss: 1.86958, time : 10.708619356155396 lr : 0.44752321376381066\n",
      "epoch : 80 [18/23] Train loss: 1.38627,Valid loss: 1.82736, time : 10.97005033493042 lr : 0.44752321376381066\n",
      "epoch : 80 [19/23] Train loss: 1.40307,Valid loss: 1.75592, time : 10.901416301727295 lr : 0.44752321376381066\n",
      "epoch : 80 [20/23] Train loss: 1.38736,Valid loss: 1.76793, time : 10.823841571807861 lr : 0.44752321376381066\n",
      "epoch : 80 [21/23] Train loss: 1.39965,Valid loss: 1.78242, time : 10.797203779220581 lr : 0.44752321376381066\n",
      "epoch : 80 [22/23] Train loss: 1.40996,Valid loss: 1.86348, time : 9.8584144115448 lr : 0.44752321376381066\n",
      "epoch : 81 [0/23] Train loss: 1.38444,Valid loss: 1.89267, time : 10.420371294021606 lr : 0.44304798162617254\n",
      "epoch : 81 [1/23] Train loss: 1.39832,Valid loss: 1.81569, time : 10.055278301239014 lr : 0.44304798162617254\n",
      "epoch : 81 [2/23] Train loss: 1.39864,Valid loss: 1.82709, time : 10.23080825805664 lr : 0.44304798162617254\n",
      "epoch : 81 [3/23] Train loss: 1.40541,Valid loss: 1.81252, time : 10.100418329238892 lr : 0.44304798162617254\n",
      "epoch : 81 [4/23] Train loss: 1.36714,Valid loss: 1.87952, time : 9.699379205703735 lr : 0.44304798162617254\n",
      "epoch : 81 [5/23] Train loss: 1.40996,Valid loss: 1.81263, time : 10.09124231338501 lr : 0.44304798162617254\n",
      "epoch : 81 [6/23] Train loss: 1.39658,Valid loss: 1.96415, time : 9.63882040977478 lr : 0.44304798162617254\n",
      "epoch : 81 [7/23] Train loss: 1.41612,Valid loss: 1.93200, time : 9.865824460983276 lr : 0.44304798162617254\n",
      "epoch : 81 [8/23] Train loss: 1.48327,Valid loss: 2.14452, time : 9.58748173713684 lr : 0.44304798162617254\n",
      "epoch : 81 [9/23] Train loss: 1.54710,Valid loss: 2.41251, time : 9.722218990325928 lr : 0.44304798162617254\n",
      "epoch : 81 [10/23] Train loss: 1.75440,Valid loss: 2.37408, time : 10.285346984863281 lr : 0.44304798162617254\n",
      "epoch : 81 [11/23] Train loss: 1.85637,Valid loss: 2.21600, time : 9.818714618682861 lr : 0.44304798162617254\n",
      "epoch : 81 [12/23] Train loss: 1.59462,Valid loss: 2.02258, time : 10.280537605285645 lr : 0.44304798162617254\n",
      "epoch : 81 [13/23] Train loss: 1.64049,Valid loss: 1.87759, time : 10.311432123184204 lr : 0.44304798162617254\n",
      "epoch : 81 [14/23] Train loss: 1.47650,Valid loss: 1.84309, time : 10.088513612747192 lr : 0.44304798162617254\n",
      "epoch : 81 [15/23] Train loss: 1.39327,Valid loss: 1.82976, time : 10.079752922058105 lr : 0.44304798162617254\n",
      "epoch : 81 [16/23] Train loss: 1.38877,Valid loss: 1.81662, time : 9.875986337661743 lr : 0.44304798162617254\n",
      "epoch : 81 [17/23] Train loss: 1.34904,Valid loss: 1.83437, time : 10.229995012283325 lr : 0.44304798162617254\n",
      "epoch : 81 [18/23] Train loss: 1.36547,Valid loss: 1.77785, time : 10.291933536529541 lr : 0.44304798162617254\n",
      "epoch : 81 [19/23] Train loss: 1.34392,Valid loss: 1.82846, time : 10.39756989479065 lr : 0.44304798162617254\n",
      "epoch : 81 [20/23] Train loss: 1.33328,Valid loss: 1.73456, time : 10.126360416412354 lr : 0.44304798162617254\n",
      "epoch : 81 [21/23] Train loss: 1.35250,Valid loss: 1.73056, time : 10.342714786529541 lr : 0.44304798162617254\n",
      "epoch : 81 [22/23] Train loss: 1.35686,Valid loss: 1.80284, time : 9.377441883087158 lr : 0.44304798162617254\n",
      "epoch : 82 [0/23] Train loss: 1.35288,Valid loss: 1.81072, time : 10.404689073562622 lr : 0.4386175018099108\n",
      "epoch : 82 [1/23] Train loss: 1.36449,Valid loss: 1.83241, time : 10.169755220413208 lr : 0.4386175018099108\n",
      "epoch : 82 [2/23] Train loss: 1.32581,Valid loss: 1.77474, time : 9.87199878692627 lr : 0.4386175018099108\n",
      "epoch : 82 [3/23] Train loss: 1.36818,Valid loss: 1.81025, time : 10.09709620475769 lr : 0.4386175018099108\n",
      "epoch : 82 [4/23] Train loss: 1.33992,Valid loss: 1.71662, time : 9.799555778503418 lr : 0.4386175018099108\n",
      "epoch : 82 [5/23] Train loss: 1.37655,Valid loss: 2.06539, time : 10.433004379272461 lr : 0.4386175018099108\n",
      "epoch : 82 [6/23] Train loss: 1.41605,Valid loss: 1.73993, time : 10.285685777664185 lr : 0.4386175018099108\n",
      "epoch : 82 [7/23] Train loss: 1.38039,Valid loss: 1.82387, time : 9.968374252319336 lr : 0.4386175018099108\n",
      "epoch : 82 [8/23] Train loss: 1.41344,Valid loss: 1.77511, time : 10.233037948608398 lr : 0.4386175018099108\n",
      "epoch : 82 [9/23] Train loss: 1.42977,Valid loss: 1.83139, time : 10.577544927597046 lr : 0.4386175018099108\n",
      "epoch : 82 [10/23] Train loss: 1.48691,Valid loss: 1.77914, time : 10.19390869140625 lr : 0.4386175018099108\n",
      "epoch : 82 [11/23] Train loss: 1.50525,Valid loss: 2.09206, time : 10.56885290145874 lr : 0.4386175018099108\n",
      "epoch : 82 [12/23] Train loss: 1.55024,Valid loss: 1.94900, time : 10.09460997581482 lr : 0.4386175018099108\n",
      "epoch : 82 [13/23] Train loss: 1.69164,Valid loss: 2.47118, time : 10.520345687866211 lr : 0.4386175018099108\n",
      "epoch : 82 [14/23] Train loss: 1.60474,Valid loss: 3.30121, time : 10.398157119750977 lr : 0.4386175018099108\n",
      "epoch : 82 [15/23] Train loss: 1.71317,Valid loss: 4.00314, time : 10.578886985778809 lr : 0.4386175018099108\n",
      "epoch : 82 [16/23] Train loss: 1.58867,Valid loss: 3.56856, time : 10.86002802848816 lr : 0.4386175018099108\n",
      "epoch : 82 [17/23] Train loss: 1.67160,Valid loss: 3.69593, time : 10.581929206848145 lr : 0.4386175018099108\n",
      "epoch : 82 [18/23] Train loss: 1.61914,Valid loss: 2.32975, time : 10.191134214401245 lr : 0.4386175018099108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 82 [19/23] Train loss: 1.61530,Valid loss: 1.95940, time : 10.438536643981934 lr : 0.4386175018099108\n",
      "epoch : 82 [20/23] Train loss: 1.42415,Valid loss: 1.80265, time : 10.669006586074829 lr : 0.4386175018099108\n",
      "epoch : 82 [21/23] Train loss: 1.36952,Valid loss: 1.80881, time : 10.653128147125244 lr : 0.4386175018099108\n",
      "epoch : 82 [22/23] Train loss: 1.34569,Valid loss: 1.84046, time : 9.638592004776001 lr : 0.4386175018099108\n",
      "epoch : 83 [0/23] Train loss: 1.33772,Valid loss: 1.74011, time : 10.469688415527344 lr : 0.4342313267918117\n",
      "epoch : 83 [1/23] Train loss: 1.34534,Valid loss: 1.73711, time : 9.947286367416382 lr : 0.4342313267918117\n",
      "epoch : 83 [2/23] Train loss: 1.33771,Valid loss: 1.73218, time : 10.398574113845825 lr : 0.4342313267918117\n",
      "epoch : 83 [3/23] Train loss: 1.30892,Valid loss: 1.72850, time : 10.322141408920288 lr : 0.4342313267918117\n",
      "epoch : 83 [4/23] Train loss: 1.31313,Valid loss: 1.78506, time : 10.579391717910767 lr : 0.4342313267918117\n",
      "epoch : 83 [5/23] Train loss: 1.29710,Valid loss: 1.75066, time : 10.4896559715271 lr : 0.4342313267918117\n",
      "epoch : 83 [6/23] Train loss: 1.31361,Valid loss: 1.70971, time : 10.859258651733398 lr : 0.4342313267918117\n",
      "epoch : 83 [7/23] Train loss: 1.33364,Valid loss: 1.71244, time : 10.344793558120728 lr : 0.4342313267918117\n",
      "epoch : 83 [8/23] Train loss: 1.31261,Valid loss: 1.70766, time : 10.511126279830933 lr : 0.4342313267918117\n",
      "epoch : 83 [9/23] Train loss: 1.30868,Valid loss: 1.77105, time : 10.638964891433716 lr : 0.4342313267918117\n",
      "epoch : 83 [10/23] Train loss: 1.31112,Valid loss: 1.69933, time : 10.828311443328857 lr : 0.4342313267918117\n",
      "epoch : 83 [11/23] Train loss: 1.31299,Valid loss: 1.69887, time : 10.29425311088562 lr : 0.4342313267918117\n",
      "epoch : 83 [12/23] Train loss: 1.31015,Valid loss: 1.70206, time : 10.85722303390503 lr : 0.4342313267918117\n",
      "epoch : 83 [13/23] Train loss: 1.31671,Valid loss: 1.75840, time : 10.160779237747192 lr : 0.4342313267918117\n",
      "epoch : 83 [14/23] Train loss: 1.27629,Valid loss: 1.69747, time : 10.477257013320923 lr : 0.4342313267918117\n",
      "epoch : 83 [15/23] Train loss: 1.29168,Valid loss: 1.73078, time : 10.503681421279907 lr : 0.4342313267918117\n",
      "epoch : 83 [16/23] Train loss: 1.30627,Valid loss: 1.67682, time : 10.359366655349731 lr : 0.4342313267918117\n",
      "epoch : 83 [17/23] Train loss: 1.29264,Valid loss: 1.70979, time : 10.200201272964478 lr : 0.4342313267918117\n",
      "epoch : 83 [18/23] Train loss: 1.29057,Valid loss: 1.63493, time : 10.66980791091919 lr : 0.4342313267918117\n",
      "epoch : 83 [19/23] Train loss: 1.28572,Valid loss: 1.65287, time : 9.89814805984497 lr : 0.4342313267918117\n",
      "epoch : 83 [20/23] Train loss: 1.29990,Valid loss: 1.66088, time : 10.02715802192688 lr : 0.4342313267918117\n",
      "epoch : 83 [21/23] Train loss: 1.29104,Valid loss: 1.66276, time : 9.78986668586731 lr : 0.4342313267918117\n",
      "epoch : 83 [22/23] Train loss: 1.28672,Valid loss: 1.68013, time : 9.469192028045654 lr : 0.4342313267918117\n",
      "epoch : 84 [0/23] Train loss: 1.27516,Valid loss: 1.80188, time : 10.290510654449463 lr : 0.4298890135238936\n",
      "epoch : 84 [1/23] Train loss: 1.26745,Valid loss: 1.76376, time : 10.367233991622925 lr : 0.4298890135238936\n",
      "epoch : 84 [2/23] Train loss: 1.26998,Valid loss: 1.65910, time : 10.105781078338623 lr : 0.4298890135238936\n",
      "epoch : 84 [3/23] Train loss: 1.28463,Valid loss: 1.69389, time : 10.825062036514282 lr : 0.4298890135238936\n",
      "epoch : 84 [4/23] Train loss: 1.27675,Valid loss: 1.70021, time : 10.278781175613403 lr : 0.4298890135238936\n",
      "epoch : 84 [5/23] Train loss: 1.29870,Valid loss: 1.80320, time : 10.099513292312622 lr : 0.4298890135238936\n",
      "epoch : 84 [6/23] Train loss: 1.28385,Valid loss: 1.69103, time : 10.494792222976685 lr : 0.4298890135238936\n",
      "epoch : 84 [7/23] Train loss: 1.30420,Valid loss: 1.64680, time : 9.989990949630737 lr : 0.4298890135238936\n",
      "epoch : 84 [8/23] Train loss: 1.28948,Valid loss: 1.66835, time : 10.23167085647583 lr : 0.4298890135238936\n",
      "epoch : 84 [9/23] Train loss: 1.32431,Valid loss: 1.73872, time : 9.813427686691284 lr : 0.4298890135238936\n",
      "epoch : 84 [10/23] Train loss: 1.33619,Valid loss: 1.72768, time : 9.76052737236023 lr : 0.4298890135238936\n",
      "epoch : 84 [11/23] Train loss: 1.31580,Valid loss: 1.70120, time : 10.094645023345947 lr : 0.4298890135238936\n",
      "epoch : 84 [12/23] Train loss: 1.32443,Valid loss: 1.66815, time : 10.315800189971924 lr : 0.4298890135238936\n",
      "epoch : 84 [13/23] Train loss: 1.33418,Valid loss: 1.80311, time : 10.004704236984253 lr : 0.4298890135238936\n",
      "epoch : 84 [14/23] Train loss: 1.39030,Valid loss: 1.77392, time : 10.194913625717163 lr : 0.4298890135238936\n",
      "epoch : 84 [15/23] Train loss: 1.36915,Valid loss: 1.96194, time : 10.599790096282959 lr : 0.4298890135238936\n",
      "epoch : 84 [16/23] Train loss: 1.37961,Valid loss: 1.80880, time : 10.738109350204468 lr : 0.4298890135238936\n",
      "epoch : 84 [17/23] Train loss: 1.35943,Valid loss: 2.11645, time : 10.357815265655518 lr : 0.4298890135238936\n",
      "epoch : 84 [18/23] Train loss: 1.33195,Valid loss: 2.40553, time : 10.262845277786255 lr : 0.4298890135238936\n",
      "epoch : 84 [19/23] Train loss: 1.32913,Valid loss: 2.04787, time : 10.331439733505249 lr : 0.4298890135238936\n",
      "epoch : 84 [20/23] Train loss: 1.35980,Valid loss: 3.15290, time : 10.391393423080444 lr : 0.4298890135238936\n",
      "epoch : 84 [21/23] Train loss: 1.39102,Valid loss: 2.63269, time : 10.15718388557434 lr : 0.4298890135238936\n",
      "epoch : 84 [22/23] Train loss: 1.36140,Valid loss: 3.43838, time : 9.733535528182983 lr : 0.4298890135238936\n",
      "epoch : 85 [0/23] Train loss: 1.36130,Valid loss: 2.31131, time : 10.27850341796875 lr : 0.42559012338865465\n",
      "epoch : 85 [1/23] Train loss: 1.33724,Valid loss: 1.73878, time : 10.35994267463684 lr : 0.42559012338865465\n",
      "epoch : 85 [2/23] Train loss: 1.28972,Valid loss: 1.65642, time : 9.82847785949707 lr : 0.42559012338865465\n",
      "epoch : 85 [3/23] Train loss: 1.24343,Valid loss: 1.60333, time : 10.314915657043457 lr : 0.42559012338865465\n",
      "epoch : 85 [4/23] Train loss: 1.26670,Valid loss: 1.65036, time : 10.419271230697632 lr : 0.42559012338865465\n",
      "epoch : 85 [5/23] Train loss: 1.25706,Valid loss: 1.62133, time : 10.515341997146606 lr : 0.42559012338865465\n",
      "epoch : 85 [6/23] Train loss: 1.24439,Valid loss: 1.62054, time : 10.041162729263306 lr : 0.42559012338865465\n",
      "epoch : 85 [7/23] Train loss: 1.25730,Valid loss: 1.63738, time : 10.48166298866272 lr : 0.42559012338865465\n",
      "epoch : 85 [8/23] Train loss: 1.24256,Valid loss: 1.60911, time : 10.281388282775879 lr : 0.42559012338865465\n",
      "epoch : 85 [9/23] Train loss: 1.26628,Valid loss: 1.67177, time : 10.432451486587524 lr : 0.42559012338865465\n",
      "epoch : 85 [10/23] Train loss: 1.24616,Valid loss: 1.60583, time : 10.20616888999939 lr : 0.42559012338865465\n",
      "epoch : 85 [11/23] Train loss: 1.25821,Valid loss: 1.66194, time : 10.134903907775879 lr : 0.42559012338865465\n",
      "epoch : 85 [12/23] Train loss: 1.25261,Valid loss: 1.69763, time : 10.246376037597656 lr : 0.42559012338865465\n",
      "epoch : 85 [13/23] Train loss: 1.25023,Valid loss: 1.67015, time : 10.378212928771973 lr : 0.42559012338865465\n",
      "epoch : 85 [14/23] Train loss: 1.27023,Valid loss: 1.64662, time : 10.384704113006592 lr : 0.42559012338865465\n",
      "epoch : 85 [15/23] Train loss: 1.24012,Valid loss: 1.63118, time : 10.586915016174316 lr : 0.42559012338865465\n",
      "epoch : 85 [16/23] Train loss: 1.24289,Valid loss: 1.72677, time : 10.452124834060669 lr : 0.42559012338865465\n",
      "epoch : 85 [17/23] Train loss: 1.26143,Valid loss: 1.61484, time : 10.451219081878662 lr : 0.42559012338865465\n",
      "epoch : 85 [18/23] Train loss: 1.25990,Valid loss: 1.76679, time : 10.13362431526184 lr : 0.42559012338865465\n",
      "epoch : 85 [19/23] Train loss: 1.26209,Valid loss: 1.58489, time : 9.95831036567688 lr : 0.42559012338865465\n",
      "epoch : 85 [20/23] Train loss: 1.24103,Valid loss: 1.64560, time : 10.516400575637817 lr : 0.42559012338865465\n",
      "epoch : 85 [21/23] Train loss: 1.24139,Valid loss: 1.65370, time : 9.906296491622925 lr : 0.42559012338865465\n",
      "epoch : 85 [22/23] Train loss: 1.26773,Valid loss: 1.71969, time : 9.523433446884155 lr : 0.42559012338865465\n",
      "epoch : 86 [0/23] Train loss: 1.24438,Valid loss: 1.57477, time : 10.416638374328613 lr : 0.4213342221547681\n",
      "epoch : 86 [1/23] Train loss: 1.25169,Valid loss: 2.02219, time : 10.29093623161316 lr : 0.4213342221547681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 86 [2/23] Train loss: 1.23423,Valid loss: 1.62322, time : 10.517728567123413 lr : 0.4213342221547681\n",
      "epoch : 86 [3/23] Train loss: 1.21940,Valid loss: 1.68949, time : 10.372400283813477 lr : 0.4213342221547681\n",
      "epoch : 86 [4/23] Train loss: 1.23196,Valid loss: 1.69132, time : 10.414977788925171 lr : 0.4213342221547681\n",
      "epoch : 86 [5/23] Train loss: 1.22966,Valid loss: 1.64352, time : 10.43511176109314 lr : 0.4213342221547681\n",
      "epoch : 86 [6/23] Train loss: 1.23026,Valid loss: 1.60586, time : 10.50178575515747 lr : 0.4213342221547681\n",
      "epoch : 86 [7/23] Train loss: 1.23811,Valid loss: 1.64116, time : 9.879457712173462 lr : 0.4213342221547681\n",
      "epoch : 86 [8/23] Train loss: 1.22743,Valid loss: 1.59000, time : 10.355633020401001 lr : 0.4213342221547681\n",
      "epoch : 86 [9/23] Train loss: 1.23268,Valid loss: 1.59262, time : 10.189321041107178 lr : 0.4213342221547681\n",
      "epoch : 86 [10/23] Train loss: 1.23784,Valid loss: 1.60832, time : 10.129473209381104 lr : 0.4213342221547681\n",
      "epoch : 86 [11/23] Train loss: 1.21803,Valid loss: 1.62504, time : 10.139882564544678 lr : 0.4213342221547681\n",
      "epoch : 86 [12/23] Train loss: 1.21855,Valid loss: 1.62316, time : 10.393855094909668 lr : 0.4213342221547681\n",
      "epoch : 86 [13/23] Train loss: 1.23082,Valid loss: 1.63915, time : 10.493979454040527 lr : 0.4213342221547681\n",
      "epoch : 86 [14/23] Train loss: 1.29492,Valid loss: 1.73663, time : 10.345042943954468 lr : 0.4213342221547681\n",
      "epoch : 86 [15/23] Train loss: 1.47577,Valid loss: 1.75034, time : 10.079338312149048 lr : 0.4213342221547681\n",
      "epoch : 86 [16/23] Train loss: 1.68155,Valid loss: 1.73815, time : 9.99628496170044 lr : 0.4213342221547681\n",
      "epoch : 86 [17/23] Train loss: 1.47574,Valid loss: 1.84148, time : 9.990424394607544 lr : 0.4213342221547681\n",
      "epoch : 86 [18/23] Train loss: 1.42176,Valid loss: 1.83188, time : 10.010499477386475 lr : 0.4213342221547681\n",
      "epoch : 86 [19/23] Train loss: 1.33215,Valid loss: 1.73083, time : 10.39863133430481 lr : 0.4213342221547681\n",
      "epoch : 86 [20/23] Train loss: 1.28983,Valid loss: 1.76420, time : 10.058641910552979 lr : 0.4213342221547681\n",
      "epoch : 86 [21/23] Train loss: 1.27766,Valid loss: 1.71406, time : 10.166631698608398 lr : 0.4213342221547681\n",
      "epoch : 86 [22/23] Train loss: 1.29680,Valid loss: 1.73794, time : 9.346284866333008 lr : 0.4213342221547681\n",
      "epoch : 87 [0/23] Train loss: 1.30889,Valid loss: 1.59824, time : 10.239293575286865 lr : 0.41712087993322045\n",
      "epoch : 87 [1/23] Train loss: 1.29634,Valid loss: 1.70347, time : 10.03658390045166 lr : 0.41712087993322045\n",
      "epoch : 87 [2/23] Train loss: 1.31159,Valid loss: 1.64326, time : 9.962253332138062 lr : 0.41712087993322045\n",
      "epoch : 87 [3/23] Train loss: 1.31827,Valid loss: 1.70902, time : 9.973777532577515 lr : 0.41712087993322045\n",
      "epoch : 87 [4/23] Train loss: 1.28525,Valid loss: 1.87857, time : 10.278497695922852 lr : 0.41712087993322045\n",
      "epoch : 87 [5/23] Train loss: 1.29132,Valid loss: 2.15001, time : 10.23296046257019 lr : 0.41712087993322045\n",
      "epoch : 87 [6/23] Train loss: 1.29937,Valid loss: 1.89229, time : 10.264468908309937 lr : 0.41712087993322045\n",
      "epoch : 87 [7/23] Train loss: 1.27060,Valid loss: 2.42201, time : 10.419920444488525 lr : 0.41712087993322045\n",
      "epoch : 87 [8/23] Train loss: 1.23763,Valid loss: 1.70909, time : 10.31386423110962 lr : 0.41712087993322045\n",
      "epoch : 87 [9/23] Train loss: 1.24505,Valid loss: 1.90797, time : 10.40264105796814 lr : 0.41712087993322045\n",
      "epoch : 87 [10/23] Train loss: 1.21692,Valid loss: 1.67372, time : 10.190669298171997 lr : 0.41712087993322045\n",
      "epoch : 87 [11/23] Train loss: 1.18102,Valid loss: 1.56716, time : 10.545666217803955 lr : 0.41712087993322045\n",
      "epoch : 87 [12/23] Train loss: 1.21029,Valid loss: 1.64043, time : 10.611029386520386 lr : 0.41712087993322045\n",
      "epoch : 87 [13/23] Train loss: 1.19645,Valid loss: 1.59322, time : 10.41137409210205 lr : 0.41712087993322045\n",
      "epoch : 87 [14/23] Train loss: 1.18422,Valid loss: 1.57590, time : 10.29639196395874 lr : 0.41712087993322045\n",
      "epoch : 87 [15/23] Train loss: 1.19247,Valid loss: 1.56602, time : 10.531145811080933 lr : 0.41712087993322045\n",
      "epoch : 87 [16/23] Train loss: 1.16389,Valid loss: 1.58924, time : 10.26698923110962 lr : 0.41712087993322045\n",
      "epoch : 87 [17/23] Train loss: 1.21648,Valid loss: 1.59266, time : 10.159506797790527 lr : 0.41712087993322045\n",
      "epoch : 87 [18/23] Train loss: 1.17780,Valid loss: 1.57475, time : 9.94821310043335 lr : 0.41712087993322045\n",
      "epoch : 87 [19/23] Train loss: 1.17776,Valid loss: 1.55978, time : 10.030813217163086 lr : 0.41712087993322045\n",
      "epoch : 87 [20/23] Train loss: 1.19465,Valid loss: 1.58035, time : 10.310232162475586 lr : 0.41712087993322045\n",
      "epoch : 87 [21/23] Train loss: 1.17469,Valid loss: 1.69644, time : 10.311618089675903 lr : 0.41712087993322045\n",
      "epoch : 87 [22/23] Train loss: 1.19463,Valid loss: 1.57980, time : 10.016233205795288 lr : 0.41712087993322045\n",
      "epoch : 88 [0/23] Train loss: 1.20183,Valid loss: 1.66853, time : 10.703391790390015 lr : 0.41294967113388825\n",
      "epoch : 88 [1/23] Train loss: 1.19413,Valid loss: 1.58776, time : 10.727444887161255 lr : 0.41294967113388825\n",
      "epoch : 88 [2/23] Train loss: 1.19755,Valid loss: 1.67392, time : 10.544870615005493 lr : 0.41294967113388825\n",
      "epoch : 88 [3/23] Train loss: 1.17547,Valid loss: 1.53910, time : 10.687768936157227 lr : 0.41294967113388825\n",
      "epoch : 88 [4/23] Train loss: 1.22754,Valid loss: 1.67952, time : 10.645089149475098 lr : 0.41294967113388825\n",
      "epoch : 88 [5/23] Train loss: 1.26808,Valid loss: 1.57604, time : 9.95927906036377 lr : 0.41294967113388825\n",
      "epoch : 88 [6/23] Train loss: 1.35019,Valid loss: 1.67052, time : 10.24124526977539 lr : 0.41294967113388825\n",
      "epoch : 88 [7/23] Train loss: 1.37559,Valid loss: 1.63329, time : 10.357542276382446 lr : 0.41294967113388825\n",
      "epoch : 88 [8/23] Train loss: 1.44454,Valid loss: 1.84347, time : 10.163785696029663 lr : 0.41294967113388825\n",
      "epoch : 88 [9/23] Train loss: 1.35964,Valid loss: 1.80305, time : 9.84428358078003 lr : 0.41294967113388825\n",
      "epoch : 88 [10/23] Train loss: 1.25302,Valid loss: 1.82453, time : 10.25414252281189 lr : 0.41294967113388825\n",
      "epoch : 88 [11/23] Train loss: 1.21851,Valid loss: 1.62062, time : 9.726426839828491 lr : 0.41294967113388825\n",
      "epoch : 88 [12/23] Train loss: 1.19438,Valid loss: 1.54812, time : 9.980488061904907 lr : 0.41294967113388825\n",
      "epoch : 88 [13/23] Train loss: 1.17730,Valid loss: 1.63883, time : 10.094110250473022 lr : 0.41294967113388825\n",
      "epoch : 88 [14/23] Train loss: 1.19961,Valid loss: 1.53930, time : 10.235921144485474 lr : 0.41294967113388825\n",
      "epoch : 88 [15/23] Train loss: 1.16998,Valid loss: 1.52137, time : 10.510259628295898 lr : 0.41294967113388825\n",
      "epoch : 88 [16/23] Train loss: 1.19160,Valid loss: 1.54132, time : 10.302882432937622 lr : 0.41294967113388825\n",
      "epoch : 88 [17/23] Train loss: 1.15921,Valid loss: 1.51777, time : 9.788184881210327 lr : 0.41294967113388825\n",
      "epoch : 88 [18/23] Train loss: 1.16502,Valid loss: 1.54210, time : 9.818697929382324 lr : 0.41294967113388825\n",
      "epoch : 88 [19/23] Train loss: 1.15042,Valid loss: 1.55464, time : 10.370139122009277 lr : 0.41294967113388825\n",
      "epoch : 88 [20/23] Train loss: 1.16846,Valid loss: 1.52423, time : 10.20819091796875 lr : 0.41294967113388825\n",
      "epoch : 88 [21/23] Train loss: 1.16655,Valid loss: 1.53904, time : 10.062979459762573 lr : 0.41294967113388825\n",
      "epoch : 88 [22/23] Train loss: 1.16803,Valid loss: 1.50640, time : 9.500230312347412 lr : 0.41294967113388825\n",
      "epoch : 89 [0/23] Train loss: 1.14349,Valid loss: 1.53273, time : 10.15129566192627 lr : 0.40882017442254937\n",
      "epoch : 89 [1/23] Train loss: 1.15459,Valid loss: 1.49312, time : 10.17813777923584 lr : 0.40882017442254937\n",
      "epoch : 89 [2/23] Train loss: 1.15708,Valid loss: 1.51542, time : 9.883756875991821 lr : 0.40882017442254937\n",
      "epoch : 89 [3/23] Train loss: 1.15758,Valid loss: 1.57267, time : 10.451080799102783 lr : 0.40882017442254937\n",
      "epoch : 89 [4/23] Train loss: 1.15928,Valid loss: 1.59032, time : 10.306270599365234 lr : 0.40882017442254937\n",
      "epoch : 89 [5/23] Train loss: 1.14267,Valid loss: 1.52429, time : 10.090437650680542 lr : 0.40882017442254937\n",
      "epoch : 89 [6/23] Train loss: 1.14165,Valid loss: 1.51436, time : 10.515846490859985 lr : 0.40882017442254937\n",
      "epoch : 89 [7/23] Train loss: 1.14174,Valid loss: 1.52937, time : 10.284854412078857 lr : 0.40882017442254937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 89 [8/23] Train loss: 1.16837,Valid loss: 1.52681, time : 10.344171524047852 lr : 0.40882017442254937\n",
      "epoch : 89 [9/23] Train loss: 1.16612,Valid loss: 1.49953, time : 10.193037509918213 lr : 0.40882017442254937\n",
      "epoch : 89 [10/23] Train loss: 1.16370,Valid loss: 1.53003, time : 10.002145767211914 lr : 0.40882017442254937\n",
      "epoch : 89 [11/23] Train loss: 1.15237,Valid loss: 1.50153, time : 10.182010889053345 lr : 0.40882017442254937\n",
      "epoch : 89 [12/23] Train loss: 1.15796,Valid loss: 1.55842, time : 10.230648756027222 lr : 0.40882017442254937\n",
      "epoch : 89 [13/23] Train loss: 1.15313,Valid loss: 1.53463, time : 10.007330894470215 lr : 0.40882017442254937\n",
      "epoch : 89 [14/23] Train loss: 1.16601,Valid loss: 1.50495, time : 10.243282794952393 lr : 0.40882017442254937\n",
      "epoch : 89 [15/23] Train loss: 1.16908,Valid loss: 1.53108, time : 9.880455255508423 lr : 0.40882017442254937\n",
      "epoch : 89 [16/23] Train loss: 1.19084,Valid loss: 1.54528, time : 10.031579732894897 lr : 0.40882017442254937\n",
      "epoch : 89 [17/23] Train loss: 1.16957,Valid loss: 1.49587, time : 9.944981336593628 lr : 0.40882017442254937\n",
      "epoch : 89 [18/23] Train loss: 1.16173,Valid loss: 1.54920, time : 9.655415773391724 lr : 0.40882017442254937\n",
      "epoch : 89 [19/23] Train loss: 1.14038,Valid loss: 1.52568, time : 9.962472677230835 lr : 0.40882017442254937\n",
      "epoch : 89 [20/23] Train loss: 1.14309,Valid loss: 1.62633, time : 9.843045949935913 lr : 0.40882017442254937\n",
      "epoch : 89 [21/23] Train loss: 1.12960,Valid loss: 1.50227, time : 9.87337350845337 lr : 0.40882017442254937\n",
      "epoch : 89 [22/23] Train loss: 1.15209,Valid loss: 1.70023, time : 9.391741275787354 lr : 0.40882017442254937\n",
      "epoch : 90 [0/23] Train loss: 1.16123,Valid loss: 1.62411, time : 10.270755290985107 lr : 0.4047319726783239\n",
      "epoch : 90 [1/23] Train loss: 1.15235,Valid loss: 1.61291, time : 9.991828680038452 lr : 0.4047319726783239\n",
      "epoch : 90 [2/23] Train loss: 1.15197,Valid loss: 1.50436, time : 10.275936126708984 lr : 0.4047319726783239\n",
      "epoch : 90 [3/23] Train loss: 1.14547,Valid loss: 1.60464, time : 9.910244464874268 lr : 0.4047319726783239\n",
      "epoch : 90 [4/23] Train loss: 1.16406,Valid loss: 2.10359, time : 10.70845651626587 lr : 0.4047319726783239\n",
      "epoch : 90 [5/23] Train loss: 1.15234,Valid loss: 1.68080, time : 10.467846870422363 lr : 0.4047319726783239\n",
      "epoch : 90 [6/23] Train loss: 1.17322,Valid loss: 1.58796, time : 10.13468313217163 lr : 0.4047319726783239\n",
      "epoch : 90 [7/23] Train loss: 1.21294,Valid loss: 1.55447, time : 10.287689685821533 lr : 0.4047319726783239\n",
      "epoch : 90 [8/23] Train loss: 1.29194,Valid loss: 1.55714, time : 10.201544761657715 lr : 0.4047319726783239\n",
      "epoch : 90 [9/23] Train loss: 1.35071,Valid loss: 2.01262, time : 9.71346402168274 lr : 0.4047319726783239\n",
      "epoch : 90 [10/23] Train loss: 1.34002,Valid loss: 1.67750, time : 9.744853973388672 lr : 0.4047319726783239\n",
      "epoch : 90 [11/23] Train loss: 1.34083,Valid loss: 2.23248, time : 10.154164791107178 lr : 0.4047319726783239\n",
      "epoch : 90 [12/23] Train loss: 1.34149,Valid loss: 2.21553, time : 10.02080225944519 lr : 0.4047319726783239\n",
      "epoch : 90 [13/23] Train loss: 1.44852,Valid loss: 3.82194, time : 9.575545072555542 lr : 0.4047319726783239\n",
      "epoch : 90 [14/23] Train loss: 1.45611,Valid loss: 3.51180, time : 9.96513319015503 lr : 0.4047319726783239\n",
      "epoch : 90 [15/23] Train loss: 1.47763,Valid loss: 3.18173, time : 9.605851650238037 lr : 0.4047319726783239\n",
      "epoch : 90 [16/23] Train loss: 1.32614,Valid loss: 1.81129, time : 9.833480596542358 lr : 0.4047319726783239\n",
      "epoch : 90 [17/23] Train loss: 1.26190,Valid loss: 1.67397, time : 9.91719913482666 lr : 0.4047319726783239\n",
      "epoch : 90 [18/23] Train loss: 1.18883,Valid loss: 1.57592, time : 9.988770484924316 lr : 0.4047319726783239\n",
      "epoch : 90 [19/23] Train loss: 1.15766,Valid loss: 1.48274, time : 10.362798690795898 lr : 0.4047319726783239\n",
      "epoch : 90 [20/23] Train loss: 1.13488,Valid loss: 1.54111, time : 10.101025104522705 lr : 0.4047319726783239\n",
      "epoch : 90 [21/23] Train loss: 1.12351,Valid loss: 1.49618, time : 9.85104250907898 lr : 0.4047319726783239\n",
      "epoch : 90 [22/23] Train loss: 1.14702,Valid loss: 1.53318, time : 9.371774673461914 lr : 0.4047319726783239\n",
      "epoch : 91 [0/23] Train loss: 1.11659,Valid loss: 1.49575, time : 10.170485973358154 lr : 0.40068465295154065\n",
      "epoch : 91 [1/23] Train loss: 1.09088,Valid loss: 1.48046, time : 9.922941446304321 lr : 0.40068465295154065\n",
      "epoch : 91 [2/23] Train loss: 1.11764,Valid loss: 1.48348, time : 9.943427085876465 lr : 0.40068465295154065\n",
      "epoch : 91 [3/23] Train loss: 1.10211,Valid loss: 1.45189, time : 9.900628805160522 lr : 0.40068465295154065\n",
      "epoch : 91 [4/23] Train loss: 1.09879,Valid loss: 1.46361, time : 10.483898878097534 lr : 0.40068465295154065\n",
      "epoch : 91 [5/23] Train loss: 1.12238,Valid loss: 1.46262, time : 9.63174319267273 lr : 0.40068465295154065\n",
      "epoch : 91 [6/23] Train loss: 1.09386,Valid loss: 1.49383, time : 10.151674032211304 lr : 0.40068465295154065\n",
      "epoch : 91 [7/23] Train loss: 1.11738,Valid loss: 1.44613, time : 9.60617208480835 lr : 0.40068465295154065\n",
      "epoch : 91 [8/23] Train loss: 1.12417,Valid loss: 1.45608, time : 10.019510984420776 lr : 0.40068465295154065\n",
      "epoch : 91 [9/23] Train loss: 1.10648,Valid loss: 1.46081, time : 9.736412048339844 lr : 0.40068465295154065\n",
      "epoch : 91 [10/23] Train loss: 1.07956,Valid loss: 1.43596, time : 10.119925737380981 lr : 0.40068465295154065\n",
      "epoch : 91 [11/23] Train loss: 1.11484,Valid loss: 1.44542, time : 9.564471960067749 lr : 0.40068465295154065\n",
      "epoch : 91 [12/23] Train loss: 1.09699,Valid loss: 1.46393, time : 9.88610577583313 lr : 0.40068465295154065\n",
      "epoch : 91 [13/23] Train loss: 1.08900,Valid loss: 1.48486, time : 10.104857683181763 lr : 0.40068465295154065\n",
      "epoch : 91 [14/23] Train loss: 1.09012,Valid loss: 1.49736, time : 10.473706007003784 lr : 0.40068465295154065\n",
      "epoch : 91 [15/23] Train loss: 1.09757,Valid loss: 1.48540, time : 10.128827333450317 lr : 0.40068465295154065\n",
      "epoch : 91 [16/23] Train loss: 1.11884,Valid loss: 1.46112, time : 9.929320812225342 lr : 0.40068465295154065\n",
      "epoch : 91 [17/23] Train loss: 1.08987,Valid loss: 1.45228, time : 9.975764989852905 lr : 0.40068465295154065\n",
      "epoch : 91 [18/23] Train loss: 1.11466,Valid loss: 1.46517, time : 10.406317234039307 lr : 0.40068465295154065\n",
      "epoch : 91 [19/23] Train loss: 1.10265,Valid loss: 1.50649, time : 9.8638174533844 lr : 0.40068465295154065\n",
      "epoch : 91 [20/23] Train loss: 1.11286,Valid loss: 1.47675, time : 10.13083815574646 lr : 0.40068465295154065\n",
      "epoch : 91 [21/23] Train loss: 1.09722,Valid loss: 1.45605, time : 10.256095886230469 lr : 0.40068465295154065\n",
      "epoch : 91 [22/23] Train loss: 1.08685,Valid loss: 1.44871, time : 9.826300621032715 lr : 0.40068465295154065\n",
      "epoch : 92 [0/23] Train loss: 1.07191,Valid loss: 1.45685, time : 9.98181962966919 lr : 0.39667780642202527\n",
      "epoch : 92 [1/23] Train loss: 1.07505,Valid loss: 1.45265, time : 10.215378999710083 lr : 0.39667780642202527\n",
      "epoch : 92 [2/23] Train loss: 1.09592,Valid loss: 1.46103, time : 9.995502233505249 lr : 0.39667780642202527\n",
      "epoch : 92 [3/23] Train loss: 1.06688,Valid loss: 1.42409, time : 9.93299150466919 lr : 0.39667780642202527\n",
      "epoch : 92 [4/23] Train loss: 1.08388,Valid loss: 1.45825, time : 10.150750160217285 lr : 0.39667780642202527\n",
      "epoch : 92 [5/23] Train loss: 1.09698,Valid loss: 1.46094, time : 9.697232007980347 lr : 0.39667780642202527\n",
      "epoch : 92 [6/23] Train loss: 1.08514,Valid loss: 1.43114, time : 10.080641746520996 lr : 0.39667780642202527\n",
      "epoch : 92 [7/23] Train loss: 1.08522,Valid loss: 1.47969, time : 9.963922023773193 lr : 0.39667780642202527\n",
      "epoch : 92 [8/23] Train loss: 1.12801,Valid loss: 1.44489, time : 10.279735326766968 lr : 0.39667780642202527\n",
      "epoch : 92 [9/23] Train loss: 1.10929,Valid loss: 1.62809, time : 10.425682544708252 lr : 0.39667780642202527\n",
      "epoch : 92 [10/23] Train loss: 1.17046,Valid loss: 1.45084, time : 10.597269058227539 lr : 0.39667780642202527\n",
      "epoch : 92 [11/23] Train loss: 1.24416,Valid loss: 1.69917, time : 9.954777717590332 lr : 0.39667780642202527\n",
      "epoch : 92 [12/23] Train loss: 1.37109,Valid loss: 1.47848, time : 9.961952209472656 lr : 0.39667780642202527\n",
      "epoch : 92 [13/23] Train loss: 1.23063,Valid loss: 1.46987, time : 10.37363052368164 lr : 0.39667780642202527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 92 [14/23] Train loss: 1.29005,Valid loss: 1.75206, time : 10.662154197692871 lr : 0.39667780642202527\n",
      "epoch : 92 [15/23] Train loss: 1.23571,Valid loss: 1.50229, time : 10.357159614562988 lr : 0.39667780642202527\n",
      "epoch : 92 [16/23] Train loss: 1.25028,Valid loss: 2.84335, time : 10.402148723602295 lr : 0.39667780642202527\n",
      "epoch : 92 [17/23] Train loss: 1.22721,Valid loss: 2.22666, time : 10.298630475997925 lr : 0.39667780642202527\n",
      "epoch : 92 [18/23] Train loss: 1.17155,Valid loss: 1.56365, time : 10.229295253753662 lr : 0.39667780642202527\n",
      "epoch : 92 [19/23] Train loss: 1.16378,Valid loss: 1.52375, time : 10.390625953674316 lr : 0.39667780642202527\n",
      "epoch : 92 [20/23] Train loss: 1.10375,Valid loss: 1.51093, time : 10.273593664169312 lr : 0.39667780642202527\n",
      "epoch : 92 [21/23] Train loss: 1.11777,Valid loss: 1.45762, time : 10.348048210144043 lr : 0.39667780642202527\n",
      "epoch : 92 [22/23] Train loss: 1.11038,Valid loss: 1.45652, time : 9.635679483413696 lr : 0.39667780642202527\n",
      "epoch : 93 [0/23] Train loss: 1.08218,Valid loss: 1.45902, time : 10.760583639144897 lr : 0.392711028357805\n",
      "epoch : 93 [1/23] Train loss: 1.08073,Valid loss: 1.41522, time : 10.416974544525146 lr : 0.392711028357805\n",
      "epoch : 93 [2/23] Train loss: 1.09937,Valid loss: 1.45616, time : 9.922854661941528 lr : 0.392711028357805\n",
      "epoch : 93 [3/23] Train loss: 1.04978,Valid loss: 1.41353, time : 10.514081478118896 lr : 0.392711028357805\n",
      "epoch : 93 [4/23] Train loss: 1.06604,Valid loss: 1.43321, time : 10.29643988609314 lr : 0.392711028357805\n",
      "epoch : 93 [5/23] Train loss: 1.07097,Valid loss: 1.40986, time : 10.057092905044556 lr : 0.392711028357805\n",
      "epoch : 93 [6/23] Train loss: 1.06977,Valid loss: 1.41844, time : 9.893133878707886 lr : 0.392711028357805\n",
      "epoch : 93 [7/23] Train loss: 1.05247,Valid loss: 1.41764, time : 10.386593103408813 lr : 0.392711028357805\n",
      "epoch : 93 [8/23] Train loss: 1.05639,Valid loss: 1.44952, time : 9.713369607925415 lr : 0.392711028357805\n",
      "epoch : 93 [9/23] Train loss: 1.07835,Valid loss: 1.39527, time : 10.128221035003662 lr : 0.392711028357805\n",
      "epoch : 93 [10/23] Train loss: 1.05724,Valid loss: 1.40539, time : 9.797369003295898 lr : 0.392711028357805\n",
      "epoch : 93 [11/23] Train loss: 1.05623,Valid loss: 1.37822, time : 9.928999423980713 lr : 0.392711028357805\n",
      "epoch : 93 [12/23] Train loss: 1.05849,Valid loss: 1.39716, time : 10.486201763153076 lr : 0.392711028357805\n",
      "epoch : 93 [13/23] Train loss: 1.08141,Valid loss: 1.38288, time : 10.125064134597778 lr : 0.392711028357805\n",
      "epoch : 93 [14/23] Train loss: 1.04370,Valid loss: 1.38491, time : 9.858973026275635 lr : 0.392711028357805\n",
      "epoch : 93 [15/23] Train loss: 1.05896,Valid loss: 1.40408, time : 9.946749925613403 lr : 0.392711028357805\n",
      "epoch : 93 [16/23] Train loss: 1.05442,Valid loss: 1.38226, time : 10.178329944610596 lr : 0.392711028357805\n",
      "epoch : 93 [17/23] Train loss: 1.05373,Valid loss: 1.40151, time : 9.608073711395264 lr : 0.392711028357805\n",
      "epoch : 93 [18/23] Train loss: 1.06358,Valid loss: 1.40269, time : 10.272050619125366 lr : 0.392711028357805\n",
      "epoch : 93 [19/23] Train loss: 1.04105,Valid loss: 1.39282, time : 10.203584909439087 lr : 0.392711028357805\n",
      "epoch : 93 [20/23] Train loss: 1.05564,Valid loss: 1.46237, time : 10.155418634414673 lr : 0.392711028357805\n",
      "epoch : 93 [21/23] Train loss: 1.11370,Valid loss: 1.41417, time : 10.26738452911377 lr : 0.392711028357805\n",
      "epoch : 93 [22/23] Train loss: 1.08193,Valid loss: 1.37844, time : 9.483670234680176 lr : 0.392711028357805\n",
      "epoch : 94 [0/23] Train loss: 1.07409,Valid loss: 1.43133, time : 10.590858221054077 lr : 0.38878391807422696\n",
      "epoch : 94 [1/23] Train loss: 1.05254,Valid loss: 1.41780, time : 10.136064052581787 lr : 0.38878391807422696\n",
      "epoch : 94 [2/23] Train loss: 1.04539,Valid loss: 1.44424, time : 10.276555061340332 lr : 0.38878391807422696\n",
      "epoch : 94 [3/23] Train loss: 1.03674,Valid loss: 1.39516, time : 10.315189599990845 lr : 0.38878391807422696\n",
      "epoch : 94 [4/23] Train loss: 1.03592,Valid loss: 1.41469, time : 10.291349411010742 lr : 0.38878391807422696\n",
      "epoch : 94 [5/23] Train loss: 1.04591,Valid loss: 1.40722, time : 10.171459197998047 lr : 0.38878391807422696\n",
      "epoch : 94 [6/23] Train loss: 1.04924,Valid loss: 1.40128, time : 10.151530504226685 lr : 0.38878391807422696\n",
      "epoch : 94 [7/23] Train loss: 1.05029,Valid loss: 1.40849, time : 10.523047924041748 lr : 0.38878391807422696\n",
      "epoch : 94 [8/23] Train loss: 1.04291,Valid loss: 1.38567, time : 10.273878574371338 lr : 0.38878391807422696\n",
      "epoch : 94 [9/23] Train loss: 1.03910,Valid loss: 1.37187, time : 9.852282524108887 lr : 0.38878391807422696\n",
      "epoch : 94 [10/23] Train loss: 1.05048,Valid loss: 1.39757, time : 9.974839448928833 lr : 0.38878391807422696\n",
      "epoch : 94 [11/23] Train loss: 1.02677,Valid loss: 1.41211, time : 9.82097864151001 lr : 0.38878391807422696\n",
      "epoch : 94 [12/23] Train loss: 1.04999,Valid loss: 1.42452, time : 10.347069025039673 lr : 0.38878391807422696\n",
      "epoch : 94 [13/23] Train loss: 1.07843,Valid loss: 1.47099, time : 9.945665121078491 lr : 0.38878391807422696\n",
      "epoch : 94 [14/23] Train loss: 1.07980,Valid loss: 1.44550, time : 10.431666374206543 lr : 0.38878391807422696\n",
      "epoch : 94 [15/23] Train loss: 1.05618,Valid loss: 1.40714, time : 10.39863395690918 lr : 0.38878391807422696\n",
      "epoch : 94 [16/23] Train loss: 1.14645,Valid loss: 1.44003, time : 10.322248458862305 lr : 0.38878391807422696\n",
      "epoch : 94 [17/23] Train loss: 1.19203,Valid loss: 1.49690, time : 10.518455505371094 lr : 0.38878391807422696\n",
      "epoch : 94 [18/23] Train loss: 1.35609,Valid loss: 1.54898, time : 10.299939155578613 lr : 0.38878391807422696\n",
      "epoch : 94 [19/23] Train loss: 1.24261,Valid loss: 1.42940, time : 10.250202655792236 lr : 0.38878391807422696\n",
      "epoch : 94 [20/23] Train loss: 1.17395,Valid loss: 1.49085, time : 10.129618406295776 lr : 0.38878391807422696\n",
      "epoch : 94 [21/23] Train loss: 1.10971,Valid loss: 1.47293, time : 9.873267650604248 lr : 0.38878391807422696\n",
      "epoch : 94 [22/23] Train loss: 1.06511,Valid loss: 1.39624, time : 9.318400144577026 lr : 0.38878391807422696\n",
      "epoch : 95 [0/23] Train loss: 1.04989,Valid loss: 1.37553, time : 10.468337535858154 lr : 0.3848960788934847\n",
      "epoch : 95 [1/23] Train loss: 1.04029,Valid loss: 1.40048, time : 10.116652250289917 lr : 0.3848960788934847\n",
      "epoch : 95 [2/23] Train loss: 1.03755,Valid loss: 1.34479, time : 10.157643556594849 lr : 0.3848960788934847\n",
      "epoch : 95 [3/23] Train loss: 1.03990,Valid loss: 1.37897, time : 10.210229873657227 lr : 0.3848960788934847\n",
      "epoch : 95 [4/23] Train loss: 1.02141,Valid loss: 1.41038, time : 10.171533584594727 lr : 0.3848960788934847\n",
      "epoch : 95 [5/23] Train loss: 1.02175,Valid loss: 1.35931, time : 10.040615320205688 lr : 0.3848960788934847\n",
      "epoch : 95 [6/23] Train loss: 1.01162,Valid loss: 1.34934, time : 9.884945631027222 lr : 0.3848960788934847\n",
      "epoch : 95 [7/23] Train loss: 1.03494,Valid loss: 1.37357, time : 10.359578847885132 lr : 0.3848960788934847\n",
      "epoch : 95 [8/23] Train loss: 1.01257,Valid loss: 1.33999, time : 9.989773511886597 lr : 0.3848960788934847\n",
      "epoch : 95 [9/23] Train loss: 1.03134,Valid loss: 1.34647, time : 10.22043514251709 lr : 0.3848960788934847\n",
      "epoch : 95 [10/23] Train loss: 1.03835,Valid loss: 1.39097, time : 10.139309167861938 lr : 0.3848960788934847\n",
      "epoch : 95 [11/23] Train loss: 1.01449,Valid loss: 1.39446, time : 9.807759284973145 lr : 0.3848960788934847\n",
      "epoch : 95 [12/23] Train loss: 1.02659,Valid loss: 1.33999, time : 9.823904752731323 lr : 0.3848960788934847\n",
      "epoch : 95 [13/23] Train loss: 1.01693,Valid loss: 1.38243, time : 9.787343740463257 lr : 0.3848960788934847\n",
      "epoch : 95 [14/23] Train loss: 1.01388,Valid loss: 1.36265, time : 9.972894430160522 lr : 0.3848960788934847\n",
      "epoch : 95 [15/23] Train loss: 1.02593,Valid loss: 1.38954, time : 10.319690942764282 lr : 0.3848960788934847\n",
      "epoch : 95 [16/23] Train loss: 1.01474,Valid loss: 1.36211, time : 10.551345109939575 lr : 0.3848960788934847\n",
      "epoch : 95 [17/23] Train loss: 1.01384,Valid loss: 1.36383, time : 10.208855628967285 lr : 0.3848960788934847\n",
      "epoch : 95 [18/23] Train loss: 1.01389,Valid loss: 1.33605, time : 10.34866976737976 lr : 0.3848960788934847\n",
      "epoch : 95 [19/23] Train loss: 1.01885,Valid loss: 1.43248, time : 10.553487777709961 lr : 0.3848960788934847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 95 [20/23] Train loss: 1.02329,Valid loss: 1.32100, time : 10.487249374389648 lr : 0.3848960788934847\n",
      "epoch : 95 [21/23] Train loss: 0.99198,Valid loss: 1.37025, time : 10.197225570678711 lr : 0.3848960788934847\n",
      "epoch : 95 [22/23] Train loss: 1.02930,Valid loss: 1.32680, time : 9.483563661575317 lr : 0.3848960788934847\n",
      "epoch : 96 [0/23] Train loss: 0.99027,Valid loss: 1.32344, time : 10.111774921417236 lr : 0.38104711810454983\n",
      "epoch : 96 [1/23] Train loss: 1.00349,Valid loss: 1.37943, time : 10.407362699508667 lr : 0.38104711810454983\n",
      "epoch : 96 [2/23] Train loss: 1.02065,Valid loss: 1.36820, time : 9.936426401138306 lr : 0.38104711810454983\n",
      "epoch : 96 [3/23] Train loss: 1.03182,Valid loss: 1.40255, time : 10.26964282989502 lr : 0.38104711810454983\n",
      "epoch : 96 [4/23] Train loss: 1.03929,Valid loss: 1.32961, time : 9.995673179626465 lr : 0.38104711810454983\n",
      "epoch : 96 [5/23] Train loss: 1.04826,Valid loss: 1.38653, time : 11.293402910232544 lr : 0.38104711810454983\n",
      "epoch : 96 [6/23] Train loss: 1.09548,Valid loss: 1.38872, time : 10.288122653961182 lr : 0.38104711810454983\n",
      "epoch : 96 [7/23] Train loss: 1.13211,Valid loss: 1.42102, time : 10.681310176849365 lr : 0.38104711810454983\n",
      "epoch : 96 [8/23] Train loss: 1.16887,Valid loss: 1.36375, time : 10.067437648773193 lr : 0.38104711810454983\n",
      "epoch : 96 [9/23] Train loss: 1.04087,Valid loss: 1.37050, time : 9.989180088043213 lr : 0.38104711810454983\n",
      "epoch : 96 [10/23] Train loss: 1.01862,Valid loss: 1.37971, time : 10.151055097579956 lr : 0.38104711810454983\n",
      "epoch : 96 [11/23] Train loss: 1.01150,Valid loss: 1.34816, time : 10.133304357528687 lr : 0.38104711810454983\n",
      "epoch : 96 [12/23] Train loss: 1.00444,Valid loss: 1.35780, time : 9.91734790802002 lr : 0.38104711810454983\n",
      "epoch : 96 [13/23] Train loss: 0.99653,Valid loss: 1.30096, time : 10.263497829437256 lr : 0.38104711810454983\n",
      "epoch : 96 [14/23] Train loss: 0.99063,Valid loss: 1.35407, time : 10.002594947814941 lr : 0.38104711810454983\n",
      "epoch : 96 [15/23] Train loss: 0.99937,Valid loss: 1.37621, time : 10.393956184387207 lr : 0.38104711810454983\n",
      "epoch : 96 [16/23] Train loss: 1.03576,Valid loss: 1.34813, time : 9.774059534072876 lr : 0.38104711810454983\n",
      "epoch : 96 [17/23] Train loss: 1.01606,Valid loss: 1.34874, time : 10.544770956039429 lr : 0.38104711810454983\n",
      "epoch : 96 [18/23] Train loss: 1.04463,Valid loss: 1.38187, time : 9.875237464904785 lr : 0.38104711810454983\n",
      "epoch : 96 [19/23] Train loss: 1.02500,Valid loss: 1.36416, time : 10.309311389923096 lr : 0.38104711810454983\n",
      "epoch : 96 [20/23] Train loss: 1.03235,Valid loss: 1.39070, time : 9.984180450439453 lr : 0.38104711810454983\n",
      "epoch : 96 [21/23] Train loss: 1.02724,Valid loss: 1.33863, time : 10.177159547805786 lr : 0.38104711810454983\n",
      "epoch : 96 [22/23] Train loss: 1.03220,Valid loss: 1.31047, time : 9.680076837539673 lr : 0.38104711810454983\n",
      "epoch : 97 [0/23] Train loss: 1.01393,Valid loss: 1.35150, time : 10.563809156417847 lr : 0.37723664692350434\n",
      "epoch : 97 [1/23] Train loss: 1.00160,Valid loss: 1.43911, time : 10.014707326889038 lr : 0.37723664692350434\n",
      "epoch : 97 [2/23] Train loss: 1.00157,Valid loss: 1.40333, time : 10.286384105682373 lr : 0.37723664692350434\n",
      "epoch : 97 [3/23] Train loss: 1.02466,Valid loss: 1.38687, time : 10.384350299835205 lr : 0.37723664692350434\n",
      "epoch : 97 [4/23] Train loss: 0.99975,Valid loss: 1.36873, time : 10.312504053115845 lr : 0.37723664692350434\n",
      "epoch : 97 [5/23] Train loss: 1.00673,Valid loss: 1.37579, time : 10.29565143585205 lr : 0.37723664692350434\n",
      "epoch : 97 [6/23] Train loss: 0.99220,Valid loss: 1.35179, time : 10.199445486068726 lr : 0.37723664692350434\n",
      "epoch : 97 [7/23] Train loss: 0.97962,Valid loss: 1.34763, time : 9.729284524917603 lr : 0.37723664692350434\n",
      "epoch : 97 [8/23] Train loss: 1.00415,Valid loss: 1.30626, time : 10.095929622650146 lr : 0.37723664692350434\n",
      "epoch : 97 [9/23] Train loss: 0.98677,Valid loss: 1.31419, time : 9.599114656448364 lr : 0.37723664692350434\n",
      "epoch : 97 [10/23] Train loss: 0.99893,Valid loss: 1.31792, time : 10.00583028793335 lr : 0.37723664692350434\n",
      "epoch : 97 [11/23] Train loss: 0.98403,Valid loss: 1.32839, time : 10.328742265701294 lr : 0.37723664692350434\n",
      "epoch : 97 [12/23] Train loss: 0.97393,Valid loss: 1.32805, time : 10.295490741729736 lr : 0.37723664692350434\n",
      "epoch : 97 [13/23] Train loss: 0.99566,Valid loss: 1.33524, time : 10.284826040267944 lr : 0.37723664692350434\n",
      "epoch : 97 [14/23] Train loss: 0.98691,Valid loss: 1.29999, time : 10.376466035842896 lr : 0.37723664692350434\n",
      "epoch : 97 [15/23] Train loss: 1.01335,Valid loss: 1.35785, time : 10.098026990890503 lr : 0.37723664692350434\n",
      "epoch : 97 [16/23] Train loss: 1.01698,Valid loss: 1.31181, time : 10.51052451133728 lr : 0.37723664692350434\n",
      "epoch : 97 [17/23] Train loss: 1.00388,Valid loss: 1.41266, time : 10.13500452041626 lr : 0.37723664692350434\n",
      "epoch : 97 [18/23] Train loss: 0.99195,Valid loss: 1.32813, time : 10.753455400466919 lr : 0.37723664692350434\n",
      "epoch : 97 [19/23] Train loss: 1.00300,Valid loss: 1.53236, time : 10.408035278320312 lr : 0.37723664692350434\n",
      "epoch : 97 [20/23] Train loss: 1.00541,Valid loss: 1.46378, time : 10.349727153778076 lr : 0.37723664692350434\n",
      "epoch : 97 [21/23] Train loss: 1.00824,Valid loss: 1.55940, time : 10.295208930969238 lr : 0.37723664692350434\n",
      "epoch : 97 [22/23] Train loss: 1.04283,Valid loss: 1.64355, time : 9.606705904006958 lr : 0.37723664692350434\n",
      "epoch : 98 [0/23] Train loss: 1.12408,Valid loss: 1.86239, time : 10.314830541610718 lr : 0.37346428045426927\n",
      "epoch : 98 [1/23] Train loss: 1.10218,Valid loss: 2.28341, time : 10.187777042388916 lr : 0.37346428045426927\n",
      "epoch : 98 [2/23] Train loss: 1.17175,Valid loss: 1.46385, time : 10.494422674179077 lr : 0.37346428045426927\n",
      "epoch : 98 [3/23] Train loss: 1.17730,Valid loss: 1.51753, time : 10.343022584915161 lr : 0.37346428045426927\n",
      "epoch : 98 [4/23] Train loss: 1.08644,Valid loss: 1.46902, time : 10.556516885757446 lr : 0.37346428045426927\n",
      "epoch : 98 [5/23] Train loss: 1.06328,Valid loss: 1.37794, time : 10.25194764137268 lr : 0.37346428045426927\n",
      "epoch : 98 [6/23] Train loss: 1.03282,Valid loss: 1.47272, time : 10.030336856842041 lr : 0.37346428045426927\n",
      "epoch : 98 [7/23] Train loss: 1.05101,Valid loss: 1.40296, time : 9.735360622406006 lr : 0.37346428045426927\n",
      "epoch : 98 [8/23] Train loss: 1.07293,Valid loss: 1.54118, time : 10.029143810272217 lr : 0.37346428045426927\n",
      "epoch : 98 [9/23] Train loss: 1.18252,Valid loss: 1.75335, time : 9.779861450195312 lr : 0.37346428045426927\n",
      "epoch : 98 [10/23] Train loss: 1.36238,Valid loss: 2.29313, time : 10.037259101867676 lr : 0.37346428045426927\n",
      "epoch : 98 [11/23] Train loss: 1.21508,Valid loss: 2.13833, time : 10.308053016662598 lr : 0.37346428045426927\n",
      "epoch : 98 [12/23] Train loss: 1.28249,Valid loss: 4.67639, time : 10.392146825790405 lr : 0.37346428045426927\n",
      "epoch : 98 [13/23] Train loss: 1.22442,Valid loss: 3.14609, time : 10.349913597106934 lr : 0.37346428045426927\n",
      "epoch : 98 [14/23] Train loss: 1.28942,Valid loss: 3.22607, time : 10.660785675048828 lr : 0.37346428045426927\n",
      "epoch : 98 [15/23] Train loss: 1.13859,Valid loss: 1.80043, time : 10.617943525314331 lr : 0.37346428045426927\n",
      "epoch : 98 [16/23] Train loss: 1.08873,Valid loss: 1.64628, time : 10.372155666351318 lr : 0.37346428045426927\n",
      "epoch : 98 [17/23] Train loss: 1.07643,Valid loss: 1.47780, time : 10.587003231048584 lr : 0.37346428045426927\n",
      "epoch : 98 [18/23] Train loss: 1.01996,Valid loss: 1.38073, time : 10.500890254974365 lr : 0.37346428045426927\n",
      "epoch : 98 [19/23] Train loss: 1.00002,Valid loss: 1.36111, time : 10.233406782150269 lr : 0.37346428045426927\n",
      "epoch : 98 [20/23] Train loss: 0.98745,Valid loss: 1.32418, time : 10.399112701416016 lr : 0.37346428045426927\n",
      "epoch : 98 [21/23] Train loss: 0.98585,Valid loss: 1.33077, time : 10.116798162460327 lr : 0.37346428045426927\n",
      "epoch : 98 [22/23] Train loss: 0.99336,Valid loss: 1.30646, time : 9.605438470840454 lr : 0.37346428045426927\n",
      "epoch : 99 [0/23] Train loss: 0.97766,Valid loss: 1.32607, time : 10.314788103103638 lr : 0.36972963764972655\n",
      "epoch : 99 [1/23] Train loss: 0.97742,Valid loss: 1.31304, time : 10.354745149612427 lr : 0.36972963764972655\n",
      "epoch : 99 [2/23] Train loss: 0.97346,Valid loss: 1.28565, time : 10.77488398551941 lr : 0.36972963764972655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 99 [3/23] Train loss: 0.96241,Valid loss: 1.28615, time : 10.257898569107056 lr : 0.36972963764972655\n",
      "epoch : 99 [4/23] Train loss: 0.94768,Valid loss: 1.38309, time : 10.500288963317871 lr : 0.36972963764972655\n",
      "epoch : 99 [5/23] Train loss: 0.95136,Valid loss: 1.27439, time : 10.37733769416809 lr : 0.36972963764972655\n",
      "epoch : 99 [6/23] Train loss: 0.96386,Valid loss: 1.27477, time : 10.860740423202515 lr : 0.36972963764972655\n",
      "epoch : 99 [7/23] Train loss: 0.95666,Valid loss: 1.27074, time : 10.467849969863892 lr : 0.36972963764972655\n",
      "epoch : 99 [8/23] Train loss: 0.95058,Valid loss: 1.30477, time : 10.816752672195435 lr : 0.36972963764972655\n",
      "epoch : 99 [9/23] Train loss: 0.95913,Valid loss: 1.26174, time : 10.432599544525146 lr : 0.36972963764972655\n",
      "epoch : 99 [10/23] Train loss: 0.96156,Valid loss: 1.25463, time : 10.374996662139893 lr : 0.36972963764972655\n",
      "epoch : 99 [11/23] Train loss: 0.96069,Valid loss: 1.26520, time : 10.07514238357544 lr : 0.36972963764972655\n",
      "epoch : 99 [12/23] Train loss: 0.96437,Valid loss: 1.27006, time : 10.491693019866943 lr : 0.36972963764972655\n",
      "epoch : 99 [13/23] Train loss: 0.93669,Valid loss: 1.26228, time : 10.348693370819092 lr : 0.36972963764972655\n",
      "epoch : 99 [14/23] Train loss: 0.95962,Valid loss: 1.26748, time : 10.43553638458252 lr : 0.36972963764972655\n",
      "epoch : 99 [15/23] Train loss: 0.93966,Valid loss: 1.27820, time : 10.218889236450195 lr : 0.36972963764972655\n",
      "epoch : 99 [16/23] Train loss: 0.94675,Valid loss: 1.34845, time : 11.019214153289795 lr : 0.36972963764972655\n",
      "epoch : 99 [17/23] Train loss: 0.96952,Valid loss: 1.25480, time : 10.649183511734009 lr : 0.36972963764972655\n",
      "epoch : 99 [18/23] Train loss: 0.94815,Valid loss: 1.30285, time : 10.64953899383545 lr : 0.36972963764972655\n",
      "epoch : 99 [19/23] Train loss: 0.94530,Valid loss: 1.34916, time : 10.640191078186035 lr : 0.36972963764972655\n",
      "epoch : 99 [20/23] Train loss: 0.97424,Valid loss: 1.27937, time : 10.73568844795227 lr : 0.36972963764972655\n",
      "epoch : 99 [21/23] Train loss: 0.95061,Valid loss: 1.30653, time : 10.307451725006104 lr : 0.36972963764972655\n",
      "epoch : 99 [22/23] Train loss: 0.98594,Valid loss: 1.30665, time : 9.556171894073486 lr : 0.36972963764972655\n",
      "epoch : 100 [0/23] Train loss: 0.95969,Valid loss: 1.26801, time : 10.448336601257324 lr : 0.36603234127322926\n",
      "epoch : 100 [1/23] Train loss: 0.93715,Valid loss: 1.34095, time : 10.87558627128601 lr : 0.36603234127322926\n",
      "epoch : 100 [2/23] Train loss: 0.93690,Valid loss: 1.27094, time : 10.503256797790527 lr : 0.36603234127322926\n",
      "epoch : 100 [3/23] Train loss: 0.95034,Valid loss: 1.27779, time : 10.541512489318848 lr : 0.36603234127322926\n",
      "epoch : 100 [4/23] Train loss: 0.96723,Valid loss: 1.26694, time : 10.595865726470947 lr : 0.36603234127322926\n",
      "epoch : 100 [5/23] Train loss: 0.94328,Valid loss: 1.25588, time : 10.351033210754395 lr : 0.36603234127322926\n",
      "epoch : 100 [6/23] Train loss: 0.96539,Valid loss: 1.25670, time : 10.610337495803833 lr : 0.36603234127322926\n",
      "epoch : 100 [7/23] Train loss: 0.93880,Valid loss: 1.26529, time : 10.54921269416809 lr : 0.36603234127322926\n",
      "epoch : 100 [8/23] Train loss: 0.93534,Valid loss: 1.24940, time : 10.454701900482178 lr : 0.36603234127322926\n",
      "epoch : 100 [9/23] Train loss: 0.95607,Valid loss: 1.26072, time : 10.560580015182495 lr : 0.36603234127322926\n",
      "epoch : 100 [10/23] Train loss: 0.94457,Valid loss: 1.29414, time : 10.852717876434326 lr : 0.36603234127322926\n",
      "epoch : 100 [11/23] Train loss: 0.97384,Valid loss: 1.31038, time : 10.693243980407715 lr : 0.36603234127322926\n",
      "epoch : 100 [12/23] Train loss: 0.94571,Valid loss: 1.48468, time : 10.638304710388184 lr : 0.36603234127322926\n",
      "epoch : 100 [13/23] Train loss: 0.98187,Valid loss: 1.28135, time : 10.697452545166016 lr : 0.36603234127322926\n",
      "epoch : 100 [14/23] Train loss: 0.99408,Valid loss: 1.27911, time : 10.56710147857666 lr : 0.36603234127322926\n",
      "epoch : 100 [15/23] Train loss: 0.98382,Valid loss: 1.27631, time : 10.368138551712036 lr : 0.36603234127322926\n",
      "epoch : 100 [16/23] Train loss: 1.03581,Valid loss: 1.37001, time : 10.480483770370483 lr : 0.36603234127322926\n",
      "epoch : 100 [17/23] Train loss: 1.01678,Valid loss: 1.35313, time : 10.641146421432495 lr : 0.36603234127322926\n",
      "epoch : 100 [18/23] Train loss: 0.97329,Valid loss: 1.28790, time : 11.01376748085022 lr : 0.36603234127322926\n",
      "epoch : 100 [19/23] Train loss: 0.96336,Valid loss: 1.26404, time : 10.550843477249146 lr : 0.36603234127322926\n",
      "epoch : 100 [20/23] Train loss: 0.94879,Valid loss: 1.26379, time : 10.623813152313232 lr : 0.36603234127322926\n",
      "epoch : 100 [21/23] Train loss: 0.93810,Valid loss: 1.27840, time : 10.813683271408081 lr : 0.36603234127322926\n",
      "epoch : 100 [22/23] Train loss: 0.95297,Valid loss: 1.26737, time : 9.62347412109375 lr : 0.36603234127322926\n",
      "epoch : 101 [0/23] Train loss: 0.94687,Valid loss: 1.28079, time : 9.787861824035645 lr : 0.36237201786049694\n",
      "epoch : 101 [1/23] Train loss: 0.93178,Valid loss: 1.22966, time : 10.70815920829773 lr : 0.36237201786049694\n",
      "epoch : 101 [2/23] Train loss: 0.93072,Valid loss: 1.23559, time : 10.02135682106018 lr : 0.36237201786049694\n",
      "epoch : 101 [3/23] Train loss: 0.93018,Valid loss: 1.22042, time : 10.213002920150757 lr : 0.36237201786049694\n",
      "epoch : 101 [4/23] Train loss: 0.91776,Valid loss: 1.25863, time : 10.005838871002197 lr : 0.36237201786049694\n",
      "epoch : 101 [5/23] Train loss: 0.91925,Valid loss: 1.25621, time : 10.103949308395386 lr : 0.36237201786049694\n",
      "epoch : 101 [6/23] Train loss: 0.92296,Valid loss: 1.22737, time : 10.469136238098145 lr : 0.36237201786049694\n",
      "epoch : 101 [7/23] Train loss: 0.91768,Valid loss: 1.23610, time : 10.253193140029907 lr : 0.36237201786049694\n",
      "epoch : 101 [8/23] Train loss: 0.92589,Valid loss: 1.23436, time : 9.699723482131958 lr : 0.36237201786049694\n",
      "epoch : 101 [9/23] Train loss: 0.90779,Valid loss: 1.26615, time : 9.700740098953247 lr : 0.36237201786049694\n",
      "epoch : 101 [10/23] Train loss: 0.95009,Valid loss: 1.24349, time : 9.62942624092102 lr : 0.36237201786049694\n",
      "epoch : 101 [11/23] Train loss: 0.91062,Valid loss: 1.23596, time : 9.87062692642212 lr : 0.36237201786049694\n",
      "epoch : 101 [12/23] Train loss: 0.89792,Valid loss: 1.27597, time : 9.61137080192566 lr : 0.36237201786049694\n",
      "epoch : 101 [13/23] Train loss: 0.90400,Valid loss: 1.21828, time : 10.062394142150879 lr : 0.36237201786049694\n",
      "epoch : 101 [14/23] Train loss: 0.94670,Valid loss: 1.26796, time : 9.50923776626587 lr : 0.36237201786049694\n",
      "epoch : 101 [15/23] Train loss: 0.91831,Valid loss: 1.21721, time : 10.02063274383545 lr : 0.36237201786049694\n",
      "epoch : 101 [16/23] Train loss: 0.94352,Valid loss: 1.26530, time : 9.90763521194458 lr : 0.36237201786049694\n",
      "epoch : 101 [17/23] Train loss: 0.91778,Valid loss: 1.23069, time : 9.960022211074829 lr : 0.36237201786049694\n",
      "epoch : 101 [18/23] Train loss: 0.94497,Valid loss: 1.25489, time : 10.146082878112793 lr : 0.36237201786049694\n",
      "epoch : 101 [19/23] Train loss: 0.93092,Valid loss: 1.25788, time : 9.798328638076782 lr : 0.36237201786049694\n",
      "epoch : 101 [20/23] Train loss: 0.92655,Valid loss: 1.30045, time : 9.968568563461304 lr : 0.36237201786049694\n",
      "epoch : 101 [21/23] Train loss: 0.94620,Valid loss: 1.27086, time : 10.08025312423706 lr : 0.36237201786049694\n",
      "epoch : 101 [22/23] Train loss: 0.91632,Valid loss: 1.31817, time : 9.705058097839355 lr : 0.36237201786049694\n",
      "epoch : 102 [0/23] Train loss: 0.91894,Valid loss: 1.25543, time : 10.446410894393921 lr : 0.358748297681892\n",
      "epoch : 102 [1/23] Train loss: 0.93122,Valid loss: 1.26826, time : 10.872440338134766 lr : 0.358748297681892\n",
      "epoch : 102 [2/23] Train loss: 0.91787,Valid loss: 1.29216, time : 10.332788705825806 lr : 0.358748297681892\n",
      "epoch : 102 [3/23] Train loss: 0.93237,Valid loss: 1.32603, time : 10.290274143218994 lr : 0.358748297681892\n",
      "epoch : 102 [4/23] Train loss: 0.93849,Valid loss: 1.30301, time : 9.835589170455933 lr : 0.358748297681892\n",
      "epoch : 102 [5/23] Train loss: 0.91387,Valid loss: 1.25568, time : 10.381689548492432 lr : 0.358748297681892\n",
      "epoch : 102 [6/23] Train loss: 0.92563,Valid loss: 1.25307, time : 10.412798643112183 lr : 0.358748297681892\n",
      "epoch : 102 [7/23] Train loss: 0.93323,Valid loss: 1.25788, time : 10.03055214881897 lr : 0.358748297681892\n",
      "epoch : 102 [8/23] Train loss: 0.91896,Valid loss: 1.27650, time : 10.082804441452026 lr : 0.358748297681892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 102 [9/23] Train loss: 0.91049,Valid loss: 1.27239, time : 9.948959827423096 lr : 0.358748297681892\n",
      "epoch : 102 [10/23] Train loss: 0.93099,Valid loss: 1.25997, time : 10.337670803070068 lr : 0.358748297681892\n",
      "epoch : 102 [11/23] Train loss: 0.92826,Valid loss: 1.28036, time : 10.253393650054932 lr : 0.358748297681892\n",
      "epoch : 102 [12/23] Train loss: 0.92886,Valid loss: 1.29342, time : 10.175116777420044 lr : 0.358748297681892\n",
      "epoch : 102 [13/23] Train loss: 0.91845,Valid loss: 1.28878, time : 9.983469486236572 lr : 0.358748297681892\n",
      "epoch : 102 [14/23] Train loss: 0.91476,Valid loss: 1.23454, time : 10.120220184326172 lr : 0.358748297681892\n",
      "epoch : 102 [15/23] Train loss: 0.91757,Valid loss: 1.32612, time : 9.971319675445557 lr : 0.358748297681892\n",
      "epoch : 102 [16/23] Train loss: 0.95668,Valid loss: 1.33397, time : 10.11944055557251 lr : 0.358748297681892\n",
      "epoch : 102 [17/23] Train loss: 0.96767,Valid loss: 1.30746, time : 9.909835815429688 lr : 0.358748297681892\n",
      "epoch : 102 [18/23] Train loss: 1.14129,Valid loss: 1.30662, time : 10.310123205184937 lr : 0.358748297681892\n",
      "epoch : 102 [19/23] Train loss: 0.95207,Valid loss: 1.27107, time : 10.212948560714722 lr : 0.358748297681892\n",
      "epoch : 102 [20/23] Train loss: 0.91418,Valid loss: 1.26219, time : 10.188429832458496 lr : 0.358748297681892\n",
      "epoch : 102 [21/23] Train loss: 0.89297,Valid loss: 1.24031, time : 10.16724419593811 lr : 0.358748297681892\n",
      "epoch : 102 [22/23] Train loss: 0.90813,Valid loss: 1.25743, time : 9.60139274597168 lr : 0.358748297681892\n",
      "epoch : 103 [0/23] Train loss: 0.92948,Valid loss: 1.25688, time : 11.154807090759277 lr : 0.35516081470507305\n",
      "epoch : 103 [1/23] Train loss: 0.90067,Valid loss: 1.28354, time : 10.356131792068481 lr : 0.35516081470507305\n",
      "epoch : 103 [2/23] Train loss: 0.90850,Valid loss: 1.22342, time : 10.41431713104248 lr : 0.35516081470507305\n",
      "epoch : 103 [3/23] Train loss: 0.91679,Valid loss: 1.25464, time : 10.146730899810791 lr : 0.35516081470507305\n",
      "epoch : 103 [4/23] Train loss: 0.90668,Valid loss: 1.26024, time : 10.054541826248169 lr : 0.35516081470507305\n",
      "epoch : 103 [5/23] Train loss: 0.88267,Valid loss: 1.28121, time : 10.239264965057373 lr : 0.35516081470507305\n",
      "epoch : 103 [6/23] Train loss: 0.93802,Valid loss: 1.28890, time : 10.431460618972778 lr : 0.35516081470507305\n",
      "epoch : 103 [7/23] Train loss: 1.03604,Valid loss: 1.33823, time : 10.283809423446655 lr : 0.35516081470507305\n",
      "epoch : 103 [8/23] Train loss: 1.21248,Valid loss: 1.34452, time : 10.376644611358643 lr : 0.35516081470507305\n",
      "epoch : 103 [9/23] Train loss: 1.15310,Valid loss: 1.38274, time : 10.260654211044312 lr : 0.35516081470507305\n",
      "epoch : 103 [10/23] Train loss: 1.07179,Valid loss: 1.31590, time : 10.307260990142822 lr : 0.35516081470507305\n",
      "epoch : 103 [11/23] Train loss: 1.14107,Valid loss: 1.28599, time : 10.285723447799683 lr : 0.35516081470507305\n",
      "epoch : 103 [12/23] Train loss: 1.08440,Valid loss: 1.34444, time : 10.389038324356079 lr : 0.35516081470507305\n",
      "epoch : 103 [13/23] Train loss: 0.97542,Valid loss: 1.25530, time : 10.51920461654663 lr : 0.35516081470507305\n",
      "epoch : 103 [14/23] Train loss: 0.93582,Valid loss: 1.28290, time : 10.290409564971924 lr : 0.35516081470507305\n",
      "epoch : 103 [15/23] Train loss: 0.93708,Valid loss: 1.20823, time : 10.35753345489502 lr : 0.35516081470507305\n",
      "epoch : 103 [16/23] Train loss: 0.90009,Valid loss: 1.24640, time : 10.718359470367432 lr : 0.35516081470507305\n",
      "epoch : 103 [17/23] Train loss: 0.89039,Valid loss: 1.20392, time : 10.499767780303955 lr : 0.35516081470507305\n",
      "epoch : 103 [18/23] Train loss: 0.91684,Valid loss: 1.22298, time : 10.572103261947632 lr : 0.35516081470507305\n",
      "epoch : 103 [19/23] Train loss: 0.90231,Valid loss: 1.18766, time : 10.623878002166748 lr : 0.35516081470507305\n",
      "epoch : 103 [20/23] Train loss: 0.90469,Valid loss: 1.22124, time : 10.268556594848633 lr : 0.35516081470507305\n",
      "epoch : 103 [21/23] Train loss: 0.89518,Valid loss: 1.21684, time : 10.312161445617676 lr : 0.35516081470507305\n",
      "epoch : 103 [22/23] Train loss: 0.90126,Valid loss: 1.21494, time : 9.664100646972656 lr : 0.35516081470507305\n",
      "epoch : 104 [0/23] Train loss: 0.88832,Valid loss: 1.19870, time : 10.250193119049072 lr : 0.3516092065580223\n",
      "epoch : 104 [1/23] Train loss: 0.89184,Valid loss: 1.23032, time : 10.299412965774536 lr : 0.3516092065580223\n",
      "epoch : 104 [2/23] Train loss: 0.89367,Valid loss: 1.19481, time : 9.876883268356323 lr : 0.3516092065580223\n",
      "epoch : 104 [3/23] Train loss: 0.89431,Valid loss: 1.19166, time : 10.402257442474365 lr : 0.3516092065580223\n",
      "epoch : 104 [4/23] Train loss: 0.88254,Valid loss: 1.17700, time : 9.90357780456543 lr : 0.3516092065580223\n",
      "epoch : 104 [5/23] Train loss: 0.86740,Valid loss: 1.18703, time : 9.991338014602661 lr : 0.3516092065580223\n",
      "epoch : 104 [6/23] Train loss: 0.88867,Valid loss: 1.22973, time : 9.681180000305176 lr : 0.3516092065580223\n",
      "epoch : 104 [7/23] Train loss: 0.90771,Valid loss: 1.20945, time : 9.942811012268066 lr : 0.3516092065580223\n",
      "epoch : 104 [8/23] Train loss: 0.87129,Valid loss: 1.20589, time : 10.342196702957153 lr : 0.3516092065580223\n",
      "epoch : 104 [9/23] Train loss: 0.86753,Valid loss: 1.27354, time : 10.053661823272705 lr : 0.3516092065580223\n",
      "epoch : 104 [10/23] Train loss: 0.87250,Valid loss: 1.21840, time : 10.143603801727295 lr : 0.3516092065580223\n",
      "epoch : 104 [11/23] Train loss: 0.89524,Valid loss: 1.17381, time : 10.184690475463867 lr : 0.3516092065580223\n",
      "epoch : 104 [12/23] Train loss: 0.87966,Valid loss: 1.18294, time : 9.933603286743164 lr : 0.3516092065580223\n",
      "epoch : 104 [13/23] Train loss: 0.88350,Valid loss: 1.32287, time : 10.116398572921753 lr : 0.3516092065580223\n",
      "epoch : 104 [14/23] Train loss: 0.86744,Valid loss: 1.18611, time : 10.054850339889526 lr : 0.3516092065580223\n",
      "epoch : 104 [15/23] Train loss: 0.89294,Valid loss: 1.19455, time : 10.070437908172607 lr : 0.3516092065580223\n",
      "epoch : 104 [16/23] Train loss: 0.87577,Valid loss: 1.17944, time : 10.15554666519165 lr : 0.3516092065580223\n",
      "epoch : 104 [17/23] Train loss: 0.87884,Valid loss: 1.20375, time : 10.157102584838867 lr : 0.3516092065580223\n",
      "epoch : 104 [18/23] Train loss: 0.85748,Valid loss: 1.18627, time : 10.265079259872437 lr : 0.3516092065580223\n",
      "epoch : 104 [19/23] Train loss: 0.87697,Valid loss: 1.19641, time : 9.92490267753601 lr : 0.3516092065580223\n",
      "epoch : 104 [20/23] Train loss: 0.88174,Valid loss: 1.19178, time : 10.471944093704224 lr : 0.3516092065580223\n",
      "epoch : 104 [21/23] Train loss: 0.89790,Valid loss: 1.17226, time : 10.335041999816895 lr : 0.3516092065580223\n",
      "epoch : 104 [22/23] Train loss: 0.87292,Valid loss: 1.19402, time : 9.299869537353516 lr : 0.3516092065580223\n",
      "epoch : 105 [0/23] Train loss: 0.86843,Valid loss: 1.21108, time : 10.059478759765625 lr : 0.34809311449244207\n",
      "epoch : 105 [1/23] Train loss: 0.86127,Valid loss: 1.19937, time : 10.244631052017212 lr : 0.34809311449244207\n",
      "epoch : 105 [2/23] Train loss: 0.87694,Valid loss: 1.18985, time : 10.252674102783203 lr : 0.34809311449244207\n",
      "epoch : 105 [3/23] Train loss: 0.87882,Valid loss: 1.18634, time : 10.069147109985352 lr : 0.34809311449244207\n",
      "epoch : 105 [4/23] Train loss: 0.87346,Valid loss: 1.18298, time : 10.236971616744995 lr : 0.34809311449244207\n",
      "epoch : 105 [5/23] Train loss: 0.87663,Valid loss: 1.20662, time : 9.926859855651855 lr : 0.34809311449244207\n",
      "epoch : 105 [6/23] Train loss: 0.88927,Valid loss: 1.19798, time : 9.978076457977295 lr : 0.34809311449244207\n",
      "epoch : 105 [7/23] Train loss: 0.87046,Valid loss: 1.25325, time : 10.274524450302124 lr : 0.34809311449244207\n",
      "epoch : 105 [8/23] Train loss: 0.89040,Valid loss: 1.27280, time : 10.082651138305664 lr : 0.34809311449244207\n",
      "epoch : 105 [9/23] Train loss: 0.89726,Valid loss: 1.22879, time : 9.990296840667725 lr : 0.34809311449244207\n",
      "epoch : 105 [10/23] Train loss: 0.91790,Valid loss: 1.22764, time : 10.040337562561035 lr : 0.34809311449244207\n",
      "epoch : 105 [11/23] Train loss: 0.89973,Valid loss: 1.33208, time : 10.139787912368774 lr : 0.34809311449244207\n",
      "epoch : 105 [12/23] Train loss: 0.93242,Valid loss: 1.18836, time : 10.270483493804932 lr : 0.34809311449244207\n",
      "epoch : 105 [13/23] Train loss: 0.93199,Valid loss: 1.39010, time : 9.926991701126099 lr : 0.34809311449244207\n",
      "epoch : 105 [14/23] Train loss: 0.99761,Valid loss: 1.63903, time : 10.021181583404541 lr : 0.34809311449244207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 105 [15/23] Train loss: 1.11702,Valid loss: 1.38604, time : 10.240927696228027 lr : 0.34809311449244207\n",
      "epoch : 105 [16/23] Train loss: 1.13739,Valid loss: 1.49396, time : 9.993682384490967 lr : 0.34809311449244207\n",
      "epoch : 105 [17/23] Train loss: 1.02553,Valid loss: 1.29516, time : 10.260764598846436 lr : 0.34809311449244207\n",
      "epoch : 105 [18/23] Train loss: 1.01680,Valid loss: 1.43053, time : 10.131214380264282 lr : 0.34809311449244207\n",
      "epoch : 105 [19/23] Train loss: 0.97695,Valid loss: 1.40781, time : 9.843347311019897 lr : 0.34809311449244207\n",
      "epoch : 105 [20/23] Train loss: 0.92836,Valid loss: 1.22972, time : 10.183223009109497 lr : 0.34809311449244207\n",
      "epoch : 105 [21/23] Train loss: 0.90685,Valid loss: 1.19009, time : 10.261677742004395 lr : 0.34809311449244207\n",
      "epoch : 105 [22/23] Train loss: 0.88609,Valid loss: 1.20665, time : 9.4791579246521 lr : 0.34809311449244207\n",
      "epoch : 106 [0/23] Train loss: 0.88059,Valid loss: 1.17161, time : 9.840012788772583 lr : 0.34461218334751764\n",
      "epoch : 106 [1/23] Train loss: 0.87957,Valid loss: 1.19130, time : 10.083614587783813 lr : 0.34461218334751764\n",
      "epoch : 106 [2/23] Train loss: 0.87420,Valid loss: 1.18161, time : 10.229395627975464 lr : 0.34461218334751764\n",
      "epoch : 106 [3/23] Train loss: 0.84674,Valid loss: 1.18105, time : 10.152084589004517 lr : 0.34461218334751764\n",
      "epoch : 106 [4/23] Train loss: 0.87279,Valid loss: 1.16997, time : 10.106947422027588 lr : 0.34461218334751764\n",
      "epoch : 106 [5/23] Train loss: 0.85114,Valid loss: 1.17288, time : 10.43395209312439 lr : 0.34461218334751764\n",
      "epoch : 106 [6/23] Train loss: 0.85707,Valid loss: 1.15574, time : 9.943180561065674 lr : 0.34461218334751764\n",
      "epoch : 106 [7/23] Train loss: 0.87765,Valid loss: 1.17634, time : 10.380185604095459 lr : 0.34461218334751764\n",
      "epoch : 106 [8/23] Train loss: 0.86301,Valid loss: 1.19042, time : 9.830514669418335 lr : 0.34461218334751764\n",
      "epoch : 106 [9/23] Train loss: 0.89817,Valid loss: 1.17799, time : 10.080118417739868 lr : 0.34461218334751764\n",
      "epoch : 106 [10/23] Train loss: 0.86820,Valid loss: 1.17979, time : 10.294731855392456 lr : 0.34461218334751764\n",
      "epoch : 106 [11/23] Train loss: 0.85304,Valid loss: 1.17653, time : 10.158999919891357 lr : 0.34461218334751764\n",
      "epoch : 106 [12/23] Train loss: 0.85565,Valid loss: 1.16070, time : 9.985015392303467 lr : 0.34461218334751764\n",
      "epoch : 106 [13/23] Train loss: 0.85879,Valid loss: 1.18086, time : 10.45177435874939 lr : 0.34461218334751764\n",
      "epoch : 106 [14/23] Train loss: 0.84275,Valid loss: 1.17207, time : 9.844782590866089 lr : 0.34461218334751764\n",
      "epoch : 106 [15/23] Train loss: 0.87237,Valid loss: 1.18501, time : 10.473281383514404 lr : 0.34461218334751764\n",
      "epoch : 106 [16/23] Train loss: 0.85177,Valid loss: 1.16736, time : 10.643264770507812 lr : 0.34461218334751764\n",
      "epoch : 106 [17/23] Train loss: 0.86156,Valid loss: 1.16787, time : 10.631051301956177 lr : 0.34461218334751764\n",
      "epoch : 106 [18/23] Train loss: 0.86467,Valid loss: 1.18877, time : 9.950387239456177 lr : 0.34461218334751764\n",
      "epoch : 106 [19/23] Train loss: 0.84659,Valid loss: 1.18372, time : 10.15567922592163 lr : 0.34461218334751764\n",
      "epoch : 106 [20/23] Train loss: 0.85321,Valid loss: 1.17973, time : 10.34354543685913 lr : 0.34461218334751764\n",
      "epoch : 106 [21/23] Train loss: 0.86666,Valid loss: 1.16413, time : 10.276032447814941 lr : 0.34461218334751764\n",
      "epoch : 106 [22/23] Train loss: 0.85514,Valid loss: 1.23441, time : 9.680914163589478 lr : 0.34461218334751764\n",
      "epoch : 107 [0/23] Train loss: 0.86027,Valid loss: 1.18056, time : 10.323229551315308 lr : 0.34116606151404244\n",
      "epoch : 107 [1/23] Train loss: 0.83488,Valid loss: 1.18109, time : 10.382701873779297 lr : 0.34116606151404244\n",
      "epoch : 107 [2/23] Train loss: 0.85602,Valid loss: 1.14376, time : 10.564097166061401 lr : 0.34116606151404244\n",
      "epoch : 107 [3/23] Train loss: 0.83562,Valid loss: 1.17698, time : 10.102832317352295 lr : 0.34116606151404244\n",
      "epoch : 107 [4/23] Train loss: 0.84225,Valid loss: 1.15332, time : 10.149274826049805 lr : 0.34116606151404244\n",
      "epoch : 107 [5/23] Train loss: 0.85071,Valid loss: 1.24985, time : 10.239885330200195 lr : 0.34116606151404244\n",
      "epoch : 107 [6/23] Train loss: 0.86082,Valid loss: 1.19734, time : 10.138992071151733 lr : 0.34116606151404244\n",
      "epoch : 107 [7/23] Train loss: 0.86745,Valid loss: 1.27073, time : 10.49133825302124 lr : 0.34116606151404244\n",
      "epoch : 107 [8/23] Train loss: 0.85041,Valid loss: 1.17650, time : 10.407634735107422 lr : 0.34116606151404244\n",
      "epoch : 107 [9/23] Train loss: 0.84768,Valid loss: 1.16348, time : 10.310118913650513 lr : 0.34116606151404244\n",
      "epoch : 107 [10/23] Train loss: 0.85440,Valid loss: 1.20681, time : 10.331368446350098 lr : 0.34116606151404244\n",
      "epoch : 107 [11/23] Train loss: 0.84392,Valid loss: 1.20333, time : 10.532373428344727 lr : 0.34116606151404244\n",
      "epoch : 107 [12/23] Train loss: 0.83976,Valid loss: 1.13831, time : 10.428009986877441 lr : 0.34116606151404244\n",
      "epoch : 107 [13/23] Train loss: 0.83194,Valid loss: 1.14465, time : 9.816978931427002 lr : 0.34116606151404244\n",
      "epoch : 107 [14/23] Train loss: 0.84704,Valid loss: 1.14269, time : 10.306583881378174 lr : 0.34116606151404244\n",
      "epoch : 107 [15/23] Train loss: 0.84643,Valid loss: 1.18712, time : 9.95179271697998 lr : 0.34116606151404244\n",
      "epoch : 107 [16/23] Train loss: 0.86759,Valid loss: 1.12666, time : 10.505770444869995 lr : 0.34116606151404244\n",
      "epoch : 107 [17/23] Train loss: 0.83615,Valid loss: 1.25123, time : 10.196308374404907 lr : 0.34116606151404244\n",
      "epoch : 107 [18/23] Train loss: 0.93633,Valid loss: 1.28665, time : 10.25768494606018 lr : 0.34116606151404244\n",
      "epoch : 107 [19/23] Train loss: 0.93249,Valid loss: 1.83952, time : 10.541707277297974 lr : 0.34116606151404244\n",
      "epoch : 107 [20/23] Train loss: 0.96616,Valid loss: 1.40101, time : 10.594195127487183 lr : 0.34116606151404244\n",
      "epoch : 107 [21/23] Train loss: 0.94064,Valid loss: 1.98630, time : 10.308871269226074 lr : 0.34116606151404244\n",
      "epoch : 107 [22/23] Train loss: 0.95501,Valid loss: 1.35583, time : 9.530240058898926 lr : 0.34116606151404244\n",
      "epoch : 108 [0/23] Train loss: 0.94031,Valid loss: 1.45148, time : 10.585723400115967 lr : 0.337754400898902\n",
      "epoch : 108 [1/23] Train loss: 0.93589,Valid loss: 1.50837, time : 11.128925323486328 lr : 0.337754400898902\n",
      "epoch : 108 [2/23] Train loss: 0.89148,Valid loss: 1.31769, time : 10.514275074005127 lr : 0.337754400898902\n",
      "epoch : 108 [3/23] Train loss: 0.85980,Valid loss: 1.22484, time : 10.812255859375 lr : 0.337754400898902\n",
      "epoch : 108 [4/23] Train loss: 0.86136,Valid loss: 1.26988, time : 10.644944429397583 lr : 0.337754400898902\n",
      "epoch : 108 [5/23] Train loss: 0.87801,Valid loss: 1.15135, time : 10.494946718215942 lr : 0.337754400898902\n",
      "epoch : 108 [6/23] Train loss: 0.86207,Valid loss: 1.16742, time : 10.267071962356567 lr : 0.337754400898902\n",
      "epoch : 108 [7/23] Train loss: 0.84845,Valid loss: 1.14487, time : 10.298606634140015 lr : 0.337754400898902\n",
      "epoch : 108 [8/23] Train loss: 0.83918,Valid loss: 1.14599, time : 9.865174293518066 lr : 0.337754400898902\n",
      "epoch : 108 [9/23] Train loss: 0.84450,Valid loss: 1.13109, time : 10.39818286895752 lr : 0.337754400898902\n",
      "epoch : 108 [10/23] Train loss: 0.83082,Valid loss: 1.16358, time : 10.293107748031616 lr : 0.337754400898902\n",
      "epoch : 108 [11/23] Train loss: 0.84909,Valid loss: 1.15012, time : 10.8390371799469 lr : 0.337754400898902\n",
      "epoch : 108 [12/23] Train loss: 0.81912,Valid loss: 1.14205, time : 10.606322765350342 lr : 0.337754400898902\n",
      "epoch : 108 [13/23] Train loss: 0.80562,Valid loss: 1.15175, time : 10.745791912078857 lr : 0.337754400898902\n",
      "epoch : 108 [14/23] Train loss: 0.81051,Valid loss: 1.15949, time : 10.467405796051025 lr : 0.337754400898902\n",
      "epoch : 108 [15/23] Train loss: 0.81814,Valid loss: 1.14892, time : 10.665825843811035 lr : 0.337754400898902\n",
      "epoch : 108 [16/23] Train loss: 0.82908,Valid loss: 1.13695, time : 10.681523084640503 lr : 0.337754400898902\n",
      "epoch : 108 [17/23] Train loss: 0.83848,Valid loss: 1.14777, time : 10.409173727035522 lr : 0.337754400898902\n",
      "epoch : 108 [18/23] Train loss: 0.84448,Valid loss: 1.15596, time : 10.156492471694946 lr : 0.337754400898902\n",
      "epoch : 108 [19/23] Train loss: 0.84218,Valid loss: 1.15681, time : 10.15903902053833 lr : 0.337754400898902\n",
      "epoch : 108 [20/23] Train loss: 0.83525,Valid loss: 1.14755, time : 10.264580965042114 lr : 0.337754400898902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 108 [21/23] Train loss: 0.82017,Valid loss: 1.17622, time : 10.399081945419312 lr : 0.337754400898902\n",
      "epoch : 108 [22/23] Train loss: 0.84978,Valid loss: 1.18238, time : 9.58926510810852 lr : 0.337754400898902\n",
      "epoch : 109 [0/23] Train loss: 0.81772,Valid loss: 1.14143, time : 10.712541580200195 lr : 0.334376856889913\n",
      "epoch : 109 [1/23] Train loss: 0.81249,Valid loss: 1.16893, time : 10.435680389404297 lr : 0.334376856889913\n",
      "epoch : 109 [2/23] Train loss: 0.80281,Valid loss: 1.11368, time : 10.034741401672363 lr : 0.334376856889913\n",
      "epoch : 109 [3/23] Train loss: 0.81106,Valid loss: 1.11472, time : 10.400614261627197 lr : 0.334376856889913\n",
      "epoch : 109 [4/23] Train loss: 0.81811,Valid loss: 1.12246, time : 10.3661208152771 lr : 0.334376856889913\n",
      "epoch : 109 [5/23] Train loss: 0.81953,Valid loss: 1.09948, time : 10.244548082351685 lr : 0.334376856889913\n",
      "epoch : 109 [6/23] Train loss: 0.80937,Valid loss: 1.14342, time : 10.068036079406738 lr : 0.334376856889913\n",
      "epoch : 109 [7/23] Train loss: 0.81819,Valid loss: 1.11533, time : 10.5059494972229 lr : 0.334376856889913\n",
      "epoch : 109 [8/23] Train loss: 0.81926,Valid loss: 1.12530, time : 10.112553119659424 lr : 0.334376856889913\n",
      "epoch : 109 [9/23] Train loss: 0.81721,Valid loss: 1.10607, time : 10.282756805419922 lr : 0.334376856889913\n",
      "epoch : 109 [10/23] Train loss: 0.80170,Valid loss: 1.15252, time : 10.31824016571045 lr : 0.334376856889913\n",
      "epoch : 109 [11/23] Train loss: 0.81840,Valid loss: 1.11698, time : 10.43628478050232 lr : 0.334376856889913\n",
      "epoch : 109 [12/23] Train loss: 0.81315,Valid loss: 1.11694, time : 10.370652198791504 lr : 0.334376856889913\n",
      "epoch : 109 [13/23] Train loss: 0.81079,Valid loss: 1.11890, time : 10.662203073501587 lr : 0.334376856889913\n",
      "epoch : 109 [14/23] Train loss: 0.83028,Valid loss: 1.11892, time : 10.305674076080322 lr : 0.334376856889913\n",
      "epoch : 109 [15/23] Train loss: 0.81647,Valid loss: 1.10239, time : 10.731165647506714 lr : 0.334376856889913\n",
      "epoch : 109 [16/23] Train loss: 0.81511,Valid loss: 1.10768, time : 10.491819143295288 lr : 0.334376856889913\n",
      "epoch : 109 [17/23] Train loss: 0.82109,Valid loss: 1.10327, time : 10.700747728347778 lr : 0.334376856889913\n",
      "epoch : 109 [18/23] Train loss: 0.80515,Valid loss: 1.14616, time : 10.474842309951782 lr : 0.334376856889913\n",
      "epoch : 109 [19/23] Train loss: 0.81660,Valid loss: 1.13783, time : 10.584707021713257 lr : 0.334376856889913\n",
      "epoch : 109 [20/23] Train loss: 0.80961,Valid loss: 1.11630, time : 10.318692207336426 lr : 0.334376856889913\n",
      "epoch : 109 [21/23] Train loss: 0.81872,Valid loss: 1.14185, time : 10.490509033203125 lr : 0.334376856889913\n",
      "epoch : 109 [22/23] Train loss: 0.81367,Valid loss: 1.14025, time : 9.57831072807312 lr : 0.334376856889913\n",
      "epoch : 110 [0/23] Train loss: 0.81346,Valid loss: 1.11901, time : 10.434568166732788 lr : 0.33103308832101386\n",
      "epoch : 110 [1/23] Train loss: 0.82240,Valid loss: 1.18851, time : 10.04938006401062 lr : 0.33103308832101386\n",
      "epoch : 110 [2/23] Train loss: 0.81487,Valid loss: 1.10744, time : 10.555239915847778 lr : 0.33103308832101386\n",
      "epoch : 110 [3/23] Train loss: 0.79563,Valid loss: 1.10790, time : 10.296935558319092 lr : 0.33103308832101386\n",
      "epoch : 110 [4/23] Train loss: 0.79590,Valid loss: 1.09864, time : 9.997796058654785 lr : 0.33103308832101386\n",
      "epoch : 110 [5/23] Train loss: 0.80880,Valid loss: 1.12796, time : 10.296105146408081 lr : 0.33103308832101386\n",
      "epoch : 110 [6/23] Train loss: 0.82804,Valid loss: 1.09918, time : 10.142123222351074 lr : 0.33103308832101386\n",
      "epoch : 110 [7/23] Train loss: 0.80268,Valid loss: 1.15242, time : 10.310512065887451 lr : 0.33103308832101386\n",
      "epoch : 110 [8/23] Train loss: 0.82532,Valid loss: 1.13318, time : 10.460257768630981 lr : 0.33103308832101386\n",
      "epoch : 110 [9/23] Train loss: 0.82005,Valid loss: 1.17248, time : 10.24036979675293 lr : 0.33103308832101386\n",
      "epoch : 110 [10/23] Train loss: 0.84927,Valid loss: 1.12514, time : 10.19898271560669 lr : 0.33103308832101386\n",
      "epoch : 110 [11/23] Train loss: 0.84586,Valid loss: 1.16892, time : 10.188368082046509 lr : 0.33103308832101386\n",
      "epoch : 110 [12/23] Train loss: 0.83338,Valid loss: 1.12759, time : 10.225778341293335 lr : 0.33103308832101386\n",
      "epoch : 110 [13/23] Train loss: 0.86737,Valid loss: 1.17151, time : 10.496973752975464 lr : 0.33103308832101386\n",
      "epoch : 110 [14/23] Train loss: 0.91064,Valid loss: 1.23225, time : 9.839427709579468 lr : 0.33103308832101386\n",
      "epoch : 110 [15/23] Train loss: 1.00499,Valid loss: 1.37705, time : 10.099359512329102 lr : 0.33103308832101386\n",
      "epoch : 110 [16/23] Train loss: 0.97547,Valid loss: 1.20828, time : 10.093201637268066 lr : 0.33103308832101386\n",
      "epoch : 110 [17/23] Train loss: 1.19927,Valid loss: 1.22104, time : 10.344375371932983 lr : 0.33103308832101386\n",
      "epoch : 110 [18/23] Train loss: 0.98202,Valid loss: 1.25364, time : 10.289912939071655 lr : 0.33103308832101386\n",
      "epoch : 110 [19/23] Train loss: 0.92207,Valid loss: 1.24699, time : 10.453537940979004 lr : 0.33103308832101386\n",
      "epoch : 110 [20/23] Train loss: 0.88276,Valid loss: 1.23312, time : 10.132091999053955 lr : 0.33103308832101386\n",
      "epoch : 110 [21/23] Train loss: 0.84922,Valid loss: 1.18890, time : 10.297460079193115 lr : 0.33103308832101386\n",
      "epoch : 110 [22/23] Train loss: 0.83685,Valid loss: 1.28352, time : 9.612586498260498 lr : 0.33103308832101386\n",
      "epoch : 111 [0/23] Train loss: 0.88479,Valid loss: 1.46188, time : 10.602759599685669 lr : 0.3277227574378037\n",
      "epoch : 111 [1/23] Train loss: 0.95827,Valid loss: 1.40987, time : 10.450371980667114 lr : 0.3277227574378037\n",
      "epoch : 111 [2/23] Train loss: 1.01519,Valid loss: 1.33976, time : 10.665077447891235 lr : 0.3277227574378037\n",
      "epoch : 111 [3/23] Train loss: 0.89234,Valid loss: 2.49936, time : 10.737488985061646 lr : 0.3277227574378037\n",
      "epoch : 111 [4/23] Train loss: 0.85656,Valid loss: 1.36730, time : 10.581409931182861 lr : 0.3277227574378037\n",
      "epoch : 111 [5/23] Train loss: 0.85007,Valid loss: 1.19797, time : 10.273582696914673 lr : 0.3277227574378037\n",
      "epoch : 111 [6/23] Train loss: 0.85256,Valid loss: 1.14956, time : 10.301296949386597 lr : 0.3277227574378037\n",
      "epoch : 111 [7/23] Train loss: 0.81841,Valid loss: 1.14256, time : 10.335864543914795 lr : 0.3277227574378037\n",
      "epoch : 111 [8/23] Train loss: 0.83343,Valid loss: 1.16212, time : 10.377005815505981 lr : 0.3277227574378037\n",
      "epoch : 111 [9/23] Train loss: 0.81879,Valid loss: 1.15666, time : 10.195597171783447 lr : 0.3277227574378037\n",
      "epoch : 111 [10/23] Train loss: 0.80193,Valid loss: 1.14652, time : 10.201481819152832 lr : 0.3277227574378037\n",
      "epoch : 111 [11/23] Train loss: 0.81870,Valid loss: 1.14248, time : 10.23361873626709 lr : 0.3277227574378037\n",
      "epoch : 111 [12/23] Train loss: 0.79873,Valid loss: 1.19550, time : 10.552895784378052 lr : 0.3277227574378037\n",
      "epoch : 111 [13/23] Train loss: 0.85742,Valid loss: 1.22822, time : 9.985016584396362 lr : 0.3277227574378037\n",
      "epoch : 111 [14/23] Train loss: 0.83034,Valid loss: 1.12668, time : 10.254787683486938 lr : 0.3277227574378037\n",
      "epoch : 111 [15/23] Train loss: 0.85579,Valid loss: 1.30701, time : 10.304091453552246 lr : 0.3277227574378037\n",
      "epoch : 111 [16/23] Train loss: 0.82081,Valid loss: 1.16423, time : 10.313547372817993 lr : 0.3277227574378037\n",
      "epoch : 111 [17/23] Train loss: 0.83554,Valid loss: 1.11875, time : 10.521642684936523 lr : 0.3277227574378037\n",
      "epoch : 111 [18/23] Train loss: 0.82130,Valid loss: 1.13158, time : 10.556646823883057 lr : 0.3277227574378037\n",
      "epoch : 111 [19/23] Train loss: 0.79833,Valid loss: 1.08823, time : 9.946853160858154 lr : 0.3277227574378037\n",
      "epoch : 111 [20/23] Train loss: 0.81309,Valid loss: 1.07779, time : 10.44686770439148 lr : 0.3277227574378037\n",
      "epoch : 111 [21/23] Train loss: 0.81817,Valid loss: 1.09561, time : 9.961094617843628 lr : 0.3277227574378037\n",
      "epoch : 111 [22/23] Train loss: 0.78556,Valid loss: 1.10125, time : 9.6281418800354 lr : 0.3277227574378037\n",
      "epoch : 112 [0/23] Train loss: 0.79223,Valid loss: 1.09719, time : 10.631297826766968 lr : 0.3244455298634257\n",
      "epoch : 112 [1/23] Train loss: 0.80720,Valid loss: 1.09833, time : 10.274515151977539 lr : 0.3244455298634257\n",
      "epoch : 112 [2/23] Train loss: 0.79297,Valid loss: 1.14726, time : 10.678126573562622 lr : 0.3244455298634257\n",
      "epoch : 112 [3/23] Train loss: 0.81947,Valid loss: 1.10471, time : 10.728657722473145 lr : 0.3244455298634257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 112 [4/23] Train loss: 0.81153,Valid loss: 1.12404, time : 10.520565748214722 lr : 0.3244455298634257\n",
      "epoch : 112 [5/23] Train loss: 0.77706,Valid loss: 1.10764, time : 10.51445984840393 lr : 0.3244455298634257\n",
      "epoch : 112 [6/23] Train loss: 0.79090,Valid loss: 1.10485, time : 10.824896574020386 lr : 0.3244455298634257\n",
      "epoch : 112 [7/23] Train loss: 0.78659,Valid loss: 1.12548, time : 10.50023341178894 lr : 0.3244455298634257\n",
      "epoch : 112 [8/23] Train loss: 0.78052,Valid loss: 1.16008, time : 10.194581747055054 lr : 0.3244455298634257\n",
      "epoch : 112 [9/23] Train loss: 0.78567,Valid loss: 1.10053, time : 10.295990228652954 lr : 0.3244455298634257\n",
      "epoch : 112 [10/23] Train loss: 0.78388,Valid loss: 1.10233, time : 10.317768335342407 lr : 0.3244455298634257\n",
      "epoch : 112 [11/23] Train loss: 0.79021,Valid loss: 1.11613, time : 10.885193109512329 lr : 0.3244455298634257\n",
      "epoch : 112 [12/23] Train loss: 0.78373,Valid loss: 1.08018, time : 10.288319826126099 lr : 0.3244455298634257\n",
      "epoch : 112 [13/23] Train loss: 0.77700,Valid loss: 1.13900, time : 10.57578182220459 lr : 0.3244455298634257\n",
      "epoch : 112 [14/23] Train loss: 0.80062,Valid loss: 1.08484, time : 10.586299657821655 lr : 0.3244455298634257\n",
      "epoch : 112 [15/23] Train loss: 0.78402,Valid loss: 1.15162, time : 10.469572305679321 lr : 0.3244455298634257\n",
      "epoch : 112 [16/23] Train loss: 0.78040,Valid loss: 1.12567, time : 10.198752880096436 lr : 0.3244455298634257\n",
      "epoch : 112 [17/23] Train loss: 0.78997,Valid loss: 1.10588, time : 10.062492609024048 lr : 0.3244455298634257\n",
      "epoch : 112 [18/23] Train loss: 0.79294,Valid loss: 1.11760, time : 10.437179565429688 lr : 0.3244455298634257\n",
      "epoch : 112 [19/23] Train loss: 0.78356,Valid loss: 1.09992, time : 10.546728134155273 lr : 0.3244455298634257\n",
      "epoch : 112 [20/23] Train loss: 0.75971,Valid loss: 1.06354, time : 10.608712434768677 lr : 0.3244455298634257\n",
      "epoch : 112 [21/23] Train loss: 0.79376,Valid loss: 1.10308, time : 10.26792287826538 lr : 0.3244455298634257\n",
      "epoch : 112 [22/23] Train loss: 0.78727,Valid loss: 1.08089, time : 9.594899654388428 lr : 0.3244455298634257\n",
      "epoch : 113 [0/23] Train loss: 0.77290,Valid loss: 1.12229, time : 10.08040189743042 lr : 0.3212010745647914\n",
      "epoch : 113 [1/23] Train loss: 0.78543,Valid loss: 1.09418, time : 10.368380308151245 lr : 0.3212010745647914\n",
      "epoch : 113 [2/23] Train loss: 0.80995,Valid loss: 1.09805, time : 10.814685583114624 lr : 0.3212010745647914\n",
      "epoch : 113 [3/23] Train loss: 0.77782,Valid loss: 1.10432, time : 10.423949241638184 lr : 0.3212010745647914\n",
      "epoch : 113 [4/23] Train loss: 0.78746,Valid loss: 1.11802, time : 10.027068376541138 lr : 0.3212010745647914\n",
      "epoch : 113 [5/23] Train loss: 0.79837,Valid loss: 1.10783, time : 10.215485095977783 lr : 0.3212010745647914\n",
      "epoch : 113 [6/23] Train loss: 0.78423,Valid loss: 1.15769, time : 10.520191431045532 lr : 0.3212010745647914\n",
      "epoch : 113 [7/23] Train loss: 0.79682,Valid loss: 1.12666, time : 10.56822419166565 lr : 0.3212010745647914\n",
      "epoch : 113 [8/23] Train loss: 0.78720,Valid loss: 1.67715, time : 9.867692232131958 lr : 0.3212010745647914\n",
      "epoch : 113 [9/23] Train loss: 0.80278,Valid loss: 1.31201, time : 10.189281702041626 lr : 0.3212010745647914\n",
      "epoch : 113 [10/23] Train loss: 0.81266,Valid loss: 1.33353, time : 10.031610012054443 lr : 0.3212010745647914\n",
      "epoch : 113 [11/23] Train loss: 0.79763,Valid loss: 1.51839, time : 10.461089611053467 lr : 0.3212010745647914\n",
      "epoch : 113 [12/23] Train loss: 0.84410,Valid loss: 1.58384, time : 10.34865140914917 lr : 0.3212010745647914\n",
      "epoch : 113 [13/23] Train loss: 0.80973,Valid loss: 1.27065, time : 10.300300121307373 lr : 0.3212010745647914\n",
      "epoch : 113 [14/23] Train loss: 0.81808,Valid loss: 1.38279, time : 10.319931507110596 lr : 0.3212010745647914\n",
      "epoch : 113 [15/23] Train loss: 0.79456,Valid loss: 1.07011, time : 10.38888144493103 lr : 0.3212010745647914\n",
      "epoch : 113 [16/23] Train loss: 0.81243,Valid loss: 1.13762, time : 10.407725811004639 lr : 0.3212010745647914\n",
      "epoch : 113 [17/23] Train loss: 0.82463,Valid loss: 1.13687, time : 10.44192123413086 lr : 0.3212010745647914\n",
      "epoch : 113 [18/23] Train loss: 0.85851,Valid loss: 1.11646, time : 9.836607694625854 lr : 0.3212010745647914\n",
      "epoch : 113 [19/23] Train loss: 0.85125,Valid loss: 1.10777, time : 10.423925876617432 lr : 0.3212010745647914\n",
      "epoch : 113 [20/23] Train loss: 0.83348,Valid loss: 1.10569, time : 9.902805805206299 lr : 0.3212010745647914\n",
      "epoch : 113 [21/23] Train loss: 0.83400,Valid loss: 1.10842, time : 10.302623510360718 lr : 0.3212010745647914\n",
      "epoch : 113 [22/23] Train loss: 0.82595,Valid loss: 1.17780, time : 9.584830284118652 lr : 0.3212010745647914\n",
      "epoch : 114 [0/23] Train loss: 0.82060,Valid loss: 1.07737, time : 10.616155624389648 lr : 0.3179890638191435\n",
      "epoch : 114 [1/23] Train loss: 0.81080,Valid loss: 1.08804, time : 10.577940225601196 lr : 0.3179890638191435\n",
      "epoch : 114 [2/23] Train loss: 0.79113,Valid loss: 1.10565, time : 10.267553091049194 lr : 0.3179890638191435\n",
      "epoch : 114 [3/23] Train loss: 0.78420,Valid loss: 1.07307, time : 10.345962285995483 lr : 0.3179890638191435\n",
      "epoch : 114 [4/23] Train loss: 0.77515,Valid loss: 1.07880, time : 10.262394428253174 lr : 0.3179890638191435\n",
      "epoch : 114 [5/23] Train loss: 0.76808,Valid loss: 1.07866, time : 9.738040208816528 lr : 0.3179890638191435\n",
      "epoch : 114 [6/23] Train loss: 0.77123,Valid loss: 1.09154, time : 9.989640235900879 lr : 0.3179890638191435\n",
      "epoch : 114 [7/23] Train loss: 0.76610,Valid loss: 1.07870, time : 9.99000096321106 lr : 0.3179890638191435\n",
      "epoch : 114 [8/23] Train loss: 0.79316,Valid loss: 1.08061, time : 10.168482065200806 lr : 0.3179890638191435\n",
      "epoch : 114 [9/23] Train loss: 0.76067,Valid loss: 1.08306, time : 9.838921308517456 lr : 0.3179890638191435\n",
      "epoch : 114 [10/23] Train loss: 0.76779,Valid loss: 1.09240, time : 10.459287166595459 lr : 0.3179890638191435\n",
      "epoch : 114 [11/23] Train loss: 0.76567,Valid loss: 1.06501, time : 9.615206956863403 lr : 0.3179890638191435\n",
      "epoch : 114 [12/23] Train loss: 0.76820,Valid loss: 1.07469, time : 10.332565546035767 lr : 0.3179890638191435\n",
      "epoch : 114 [13/23] Train loss: 0.76008,Valid loss: 1.06074, time : 10.38976788520813 lr : 0.3179890638191435\n",
      "epoch : 114 [14/23] Train loss: 0.78051,Valid loss: 1.09647, time : 10.390626192092896 lr : 0.3179890638191435\n",
      "epoch : 114 [15/23] Train loss: 0.74825,Valid loss: 1.07292, time : 10.263735055923462 lr : 0.3179890638191435\n",
      "epoch : 114 [16/23] Train loss: 0.78530,Valid loss: 1.09314, time : 10.233915567398071 lr : 0.3179890638191435\n",
      "epoch : 114 [17/23] Train loss: 0.76319,Valid loss: 1.09630, time : 10.019946575164795 lr : 0.3179890638191435\n",
      "epoch : 114 [18/23] Train loss: 0.76500,Valid loss: 1.11835, time : 10.398952007293701 lr : 0.3179890638191435\n",
      "epoch : 114 [19/23] Train loss: 0.76067,Valid loss: 1.08194, time : 9.996444940567017 lr : 0.3179890638191435\n",
      "epoch : 114 [20/23] Train loss: 0.76024,Valid loss: 1.10286, time : 9.644912958145142 lr : 0.3179890638191435\n",
      "epoch : 114 [21/23] Train loss: 0.75870,Valid loss: 1.10495, time : 9.866973161697388 lr : 0.3179890638191435\n",
      "epoch : 114 [22/23] Train loss: 0.76215,Valid loss: 1.07580, time : 9.291384935379028 lr : 0.3179890638191435\n",
      "epoch : 115 [0/23] Train loss: 0.74135,Valid loss: 1.06376, time : 10.30797553062439 lr : 0.31480917318095203\n",
      "epoch : 115 [1/23] Train loss: 0.73771,Valid loss: 1.06782, time : 10.67458176612854 lr : 0.31480917318095203\n",
      "epoch : 115 [2/23] Train loss: 0.73661,Valid loss: 1.07965, time : 10.408741474151611 lr : 0.31480917318095203\n",
      "epoch : 115 [3/23] Train loss: 0.75920,Valid loss: 1.08289, time : 10.034600019454956 lr : 0.31480917318095203\n",
      "epoch : 115 [4/23] Train loss: 0.77736,Valid loss: 1.08445, time : 10.018492221832275 lr : 0.31480917318095203\n",
      "epoch : 115 [5/23] Train loss: 0.76174,Valid loss: 1.05163, time : 9.926787376403809 lr : 0.31480917318095203\n",
      "epoch : 115 [6/23] Train loss: 0.75623,Valid loss: 1.05994, time : 9.952310800552368 lr : 0.31480917318095203\n",
      "epoch : 115 [7/23] Train loss: 0.74767,Valid loss: 1.14320, time : 10.158020257949829 lr : 0.31480917318095203\n",
      "epoch : 115 [8/23] Train loss: 0.78252,Valid loss: 1.05471, time : 10.147326946258545 lr : 0.31480917318095203\n",
      "epoch : 115 [9/23] Train loss: 0.76438,Valid loss: 1.06602, time : 10.416714191436768 lr : 0.31480917318095203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 115 [10/23] Train loss: 0.75342,Valid loss: 1.05375, time : 9.928698778152466 lr : 0.31480917318095203\n",
      "epoch : 115 [11/23] Train loss: 0.75601,Valid loss: 1.01695, time : 10.10627555847168 lr : 0.31480917318095203\n",
      "epoch : 115 [12/23] Train loss: 0.76534,Valid loss: 1.08996, time : 9.704918146133423 lr : 0.31480917318095203\n",
      "epoch : 115 [13/23] Train loss: 0.76909,Valid loss: 1.08462, time : 9.969254970550537 lr : 0.31480917318095203\n",
      "epoch : 115 [14/23] Train loss: 0.79237,Valid loss: 1.04403, time : 10.08017349243164 lr : 0.31480917318095203\n",
      "epoch : 115 [15/23] Train loss: 0.78532,Valid loss: 1.03953, time : 10.420085906982422 lr : 0.31480917318095203\n",
      "epoch : 115 [16/23] Train loss: 0.80560,Valid loss: 1.29826, time : 9.97502613067627 lr : 0.31480917318095203\n",
      "epoch : 115 [17/23] Train loss: 0.81805,Valid loss: 1.08453, time : 10.15475606918335 lr : 0.31480917318095203\n",
      "epoch : 115 [18/23] Train loss: 0.81296,Valid loss: 1.14077, time : 10.191505193710327 lr : 0.31480917318095203\n",
      "epoch : 115 [19/23] Train loss: 0.83453,Valid loss: 1.09090, time : 10.150521755218506 lr : 0.31480917318095203\n",
      "epoch : 115 [20/23] Train loss: 0.78720,Valid loss: 1.12290, time : 10.187519311904907 lr : 0.31480917318095203\n",
      "epoch : 115 [21/23] Train loss: 0.80108,Valid loss: 1.06524, time : 9.99397587776184 lr : 0.31480917318095203\n",
      "epoch : 115 [22/23] Train loss: 0.75396,Valid loss: 1.09176, time : 9.493646144866943 lr : 0.31480917318095203\n",
      "epoch : 116 [0/23] Train loss: 0.76491,Valid loss: 1.18036, time : 9.864013433456421 lr : 0.3116610814491425\n",
      "epoch : 116 [1/23] Train loss: 0.76411,Valid loss: 1.06323, time : 10.249736785888672 lr : 0.3116610814491425\n",
      "epoch : 116 [2/23] Train loss: 0.73130,Valid loss: 1.04808, time : 9.907567739486694 lr : 0.3116610814491425\n",
      "epoch : 116 [3/23] Train loss: 0.74010,Valid loss: 1.04135, time : 9.839128971099854 lr : 0.3116610814491425\n",
      "epoch : 116 [4/23] Train loss: 0.74712,Valid loss: 1.05410, time : 10.18706202507019 lr : 0.3116610814491425\n",
      "epoch : 116 [5/23] Train loss: 0.73399,Valid loss: 1.06635, time : 10.073264360427856 lr : 0.3116610814491425\n",
      "epoch : 116 [6/23] Train loss: 0.73324,Valid loss: 1.04059, time : 9.867175817489624 lr : 0.3116610814491425\n",
      "epoch : 116 [7/23] Train loss: 0.75349,Valid loss: 1.02684, time : 10.039262056350708 lr : 0.3116610814491425\n",
      "epoch : 116 [8/23] Train loss: 0.72197,Valid loss: 1.04253, time : 9.724605560302734 lr : 0.3116610814491425\n",
      "epoch : 116 [9/23] Train loss: 0.75116,Valid loss: 1.01788, time : 10.068145275115967 lr : 0.3116610814491425\n",
      "epoch : 116 [10/23] Train loss: 0.76079,Valid loss: 1.03284, time : 10.013743162155151 lr : 0.3116610814491425\n",
      "epoch : 116 [11/23] Train loss: 0.74337,Valid loss: 1.00510, time : 10.220055341720581 lr : 0.3116610814491425\n",
      "epoch : 116 [12/23] Train loss: 0.74466,Valid loss: 1.01270, time : 10.022603273391724 lr : 0.3116610814491425\n",
      "epoch : 116 [13/23] Train loss: 0.76113,Valid loss: 1.11154, time : 9.742552280426025 lr : 0.3116610814491425\n",
      "epoch : 116 [14/23] Train loss: 0.76417,Valid loss: 1.04725, time : 9.599359273910522 lr : 0.3116610814491425\n",
      "epoch : 116 [15/23] Train loss: 0.74342,Valid loss: 1.04559, time : 10.02830457687378 lr : 0.3116610814491425\n",
      "epoch : 116 [16/23] Train loss: 0.75550,Valid loss: 1.01660, time : 10.305997610092163 lr : 0.3116610814491425\n",
      "epoch : 116 [17/23] Train loss: 0.73017,Valid loss: 1.09094, time : 10.231192827224731 lr : 0.3116610814491425\n",
      "epoch : 116 [18/23] Train loss: 0.74092,Valid loss: 1.05981, time : 10.383289575576782 lr : 0.3116610814491425\n",
      "epoch : 116 [19/23] Train loss: 0.74669,Valid loss: 1.11004, time : 10.051019191741943 lr : 0.3116610814491425\n",
      "epoch : 116 [20/23] Train loss: 0.75817,Valid loss: 1.03017, time : 10.00413727760315 lr : 0.3116610814491425\n",
      "epoch : 116 [21/23] Train loss: 0.74235,Valid loss: 1.05813, time : 9.945459604263306 lr : 0.3116610814491425\n",
      "epoch : 116 [22/23] Train loss: 0.76773,Valid loss: 1.20430, time : 9.302253723144531 lr : 0.3116610814491425\n",
      "epoch : 117 [0/23] Train loss: 0.75804,Valid loss: 1.16631, time : 10.687999725341797 lr : 0.30854447063465107\n",
      "epoch : 117 [1/23] Train loss: 0.79232,Valid loss: 1.09390, time : 10.097305059432983 lr : 0.30854447063465107\n",
      "epoch : 117 [2/23] Train loss: 0.78745,Valid loss: 1.07217, time : 9.974987745285034 lr : 0.30854447063465107\n",
      "epoch : 117 [3/23] Train loss: 0.83238,Valid loss: 1.10505, time : 10.034543514251709 lr : 0.30854447063465107\n",
      "epoch : 117 [4/23] Train loss: 0.93133,Valid loss: 1.13732, time : 10.208786725997925 lr : 0.30854447063465107\n",
      "epoch : 117 [5/23] Train loss: 1.05842,Valid loss: 1.11154, time : 9.769401788711548 lr : 0.30854447063465107\n",
      "epoch : 117 [6/23] Train loss: 0.83030,Valid loss: 1.08755, time : 10.263910293579102 lr : 0.30854447063465107\n",
      "epoch : 117 [7/23] Train loss: 0.79379,Valid loss: 1.04095, time : 10.075763463973999 lr : 0.30854447063465107\n",
      "epoch : 117 [8/23] Train loss: 0.75899,Valid loss: 1.03014, time : 10.56696629524231 lr : 0.30854447063465107\n",
      "epoch : 117 [9/23] Train loss: 0.76755,Valid loss: 1.00713, time : 10.589969873428345 lr : 0.30854447063465107\n",
      "epoch : 117 [10/23] Train loss: 0.75605,Valid loss: 1.03984, time : 10.478625059127808 lr : 0.30854447063465107\n",
      "epoch : 117 [11/23] Train loss: 0.74993,Valid loss: 1.00466, time : 10.620615243911743 lr : 0.30854447063465107\n",
      "epoch : 117 [12/23] Train loss: 0.74396,Valid loss: 1.02369, time : 10.69577932357788 lr : 0.30854447063465107\n",
      "epoch : 117 [13/23] Train loss: 0.73767,Valid loss: 1.07785, time : 10.290703535079956 lr : 0.30854447063465107\n",
      "epoch : 117 [14/23] Train loss: 0.72706,Valid loss: 1.03499, time : 10.628951072692871 lr : 0.30854447063465107\n",
      "epoch : 117 [15/23] Train loss: 0.73949,Valid loss: 0.99493, time : 10.389663934707642 lr : 0.30854447063465107\n",
      "epoch : 117 [16/23] Train loss: 0.73058,Valid loss: 1.00452, time : 10.545323610305786 lr : 0.30854447063465107\n",
      "epoch : 117 [17/23] Train loss: 0.71734,Valid loss: 0.99653, time : 10.31582498550415 lr : 0.30854447063465107\n",
      "epoch : 117 [18/23] Train loss: 0.72943,Valid loss: 1.00966, time : 10.637677431106567 lr : 0.30854447063465107\n",
      "epoch : 117 [19/23] Train loss: 0.72044,Valid loss: 1.02117, time : 10.426206350326538 lr : 0.30854447063465107\n",
      "epoch : 117 [20/23] Train loss: 0.75114,Valid loss: 1.02519, time : 10.181425094604492 lr : 0.30854447063465107\n",
      "epoch : 117 [21/23] Train loss: 0.72828,Valid loss: 1.02163, time : 10.220449209213257 lr : 0.30854447063465107\n",
      "epoch : 117 [22/23] Train loss: 0.72651,Valid loss: 1.00221, time : 9.571979284286499 lr : 0.30854447063465107\n",
      "epoch : 118 [0/23] Train loss: 0.72081,Valid loss: 1.01998, time : 10.556394100189209 lr : 0.30545902592830454\n",
      "epoch : 118 [1/23] Train loss: 0.73005,Valid loss: 0.99379, time : 10.273787260055542 lr : 0.30545902592830454\n",
      "epoch : 118 [2/23] Train loss: 0.71215,Valid loss: 0.98605, time : 10.712998867034912 lr : 0.30545902592830454\n",
      "epoch : 118 [3/23] Train loss: 0.71404,Valid loss: 1.01355, time : 10.817602396011353 lr : 0.30545902592830454\n",
      "epoch : 118 [4/23] Train loss: 0.73729,Valid loss: 1.01080, time : 11.010141849517822 lr : 0.30545902592830454\n",
      "epoch : 118 [5/23] Train loss: 0.75694,Valid loss: 1.02669, time : 10.674463033676147 lr : 0.30545902592830454\n",
      "epoch : 118 [6/23] Train loss: 0.70311,Valid loss: 1.00561, time : 10.868215084075928 lr : 0.30545902592830454\n",
      "epoch : 118 [7/23] Train loss: 0.73397,Valid loss: 1.02851, time : 10.450461387634277 lr : 0.30545902592830454\n",
      "epoch : 118 [8/23] Train loss: 0.71777,Valid loss: 0.99313, time : 9.98455262184143 lr : 0.30545902592830454\n",
      "epoch : 118 [9/23] Train loss: 0.71713,Valid loss: 1.00235, time : 10.313025712966919 lr : 0.30545902592830454\n",
      "epoch : 118 [10/23] Train loss: 0.72159,Valid loss: 1.02997, time : 10.158371210098267 lr : 0.30545902592830454\n",
      "epoch : 118 [11/23] Train loss: 0.72101,Valid loss: 1.02034, time : 10.520522356033325 lr : 0.30545902592830454\n",
      "epoch : 118 [12/23] Train loss: 0.72967,Valid loss: 1.07837, time : 10.53490424156189 lr : 0.30545902592830454\n",
      "epoch : 118 [13/23] Train loss: 0.79938,Valid loss: 1.08237, time : 10.640168190002441 lr : 0.30545902592830454\n",
      "epoch : 118 [14/23] Train loss: 0.77546,Valid loss: 1.08010, time : 11.115058898925781 lr : 0.30545902592830454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 118 [15/23] Train loss: 0.78943,Valid loss: 1.19971, time : 10.67732572555542 lr : 0.30545902592830454\n",
      "epoch : 118 [16/23] Train loss: 0.78214,Valid loss: 1.23471, time : 10.351276636123657 lr : 0.30545902592830454\n",
      "epoch : 118 [17/23] Train loss: 0.86949,Valid loss: 1.69622, time : 10.618709802627563 lr : 0.30545902592830454\n",
      "epoch : 118 [18/23] Train loss: 0.90000,Valid loss: 1.23948, time : 10.348334074020386 lr : 0.30545902592830454\n",
      "epoch : 118 [19/23] Train loss: 0.80436,Valid loss: 1.12612, time : 10.19338607788086 lr : 0.30545902592830454\n",
      "epoch : 118 [20/23] Train loss: 0.75326,Valid loss: 1.05236, time : 10.449962377548218 lr : 0.30545902592830454\n",
      "epoch : 118 [21/23] Train loss: 0.75312,Valid loss: 1.04739, time : 10.06317687034607 lr : 0.30545902592830454\n",
      "epoch : 118 [22/23] Train loss: 0.76098,Valid loss: 1.02624, time : 9.694815158843994 lr : 0.30545902592830454\n",
      "epoch : 119 [0/23] Train loss: 0.73716,Valid loss: 1.03925, time : 10.570770025253296 lr : 0.3024044356690215\n",
      "epoch : 119 [1/23] Train loss: 0.74518,Valid loss: 1.00547, time : 10.59840703010559 lr : 0.3024044356690215\n",
      "epoch : 119 [2/23] Train loss: 0.71957,Valid loss: 1.04379, time : 10.86632513999939 lr : 0.3024044356690215\n",
      "epoch : 119 [3/23] Train loss: 0.72427,Valid loss: 1.05108, time : 10.668281078338623 lr : 0.3024044356690215\n",
      "epoch : 119 [4/23] Train loss: 0.74436,Valid loss: 0.99734, time : 10.319560527801514 lr : 0.3024044356690215\n",
      "epoch : 119 [5/23] Train loss: 0.71312,Valid loss: 1.07167, time : 10.123569965362549 lr : 0.3024044356690215\n",
      "epoch : 119 [6/23] Train loss: 0.73843,Valid loss: 1.00723, time : 10.282326459884644 lr : 0.3024044356690215\n",
      "epoch : 119 [7/23] Train loss: 0.72103,Valid loss: 1.01344, time : 10.439192533493042 lr : 0.3024044356690215\n",
      "epoch : 119 [8/23] Train loss: 0.75201,Valid loss: 1.01628, time : 10.606484651565552 lr : 0.3024044356690215\n",
      "epoch : 119 [9/23] Train loss: 0.74063,Valid loss: 1.03534, time : 10.62207818031311 lr : 0.3024044356690215\n",
      "epoch : 119 [10/23] Train loss: 0.71122,Valid loss: 1.02646, time : 10.821857690811157 lr : 0.3024044356690215\n",
      "epoch : 119 [11/23] Train loss: 0.73294,Valid loss: 0.97977, time : 10.678203582763672 lr : 0.3024044356690215\n",
      "epoch : 119 [12/23] Train loss: 0.71955,Valid loss: 1.00803, time : 10.751202821731567 lr : 0.3024044356690215\n",
      "epoch : 119 [13/23] Train loss: 0.72220,Valid loss: 0.99783, time : 10.72747015953064 lr : 0.3024044356690215\n",
      "epoch : 119 [14/23] Train loss: 0.70919,Valid loss: 1.00070, time : 10.571070194244385 lr : 0.3024044356690215\n",
      "epoch : 119 [15/23] Train loss: 0.71328,Valid loss: 1.03814, time : 11.02270221710205 lr : 0.3024044356690215\n",
      "epoch : 119 [16/23] Train loss: 0.71425,Valid loss: 1.00907, time : 10.534939289093018 lr : 0.3024044356690215\n",
      "epoch : 119 [17/23] Train loss: 0.71635,Valid loss: 0.99606, time : 10.390668153762817 lr : 0.3024044356690215\n",
      "epoch : 119 [18/23] Train loss: 0.71199,Valid loss: 1.01851, time : 10.358386754989624 lr : 0.3024044356690215\n",
      "epoch : 119 [19/23] Train loss: 0.70853,Valid loss: 0.99850, time : 10.463717460632324 lr : 0.3024044356690215\n",
      "epoch : 119 [20/23] Train loss: 0.70019,Valid loss: 1.04033, time : 10.548029899597168 lr : 0.3024044356690215\n",
      "epoch : 119 [21/23] Train loss: 0.71251,Valid loss: 0.99944, time : 10.366793632507324 lr : 0.3024044356690215\n",
      "epoch : 119 [22/23] Train loss: 0.70214,Valid loss: 0.96573, time : 9.731332302093506 lr : 0.3024044356690215\n",
      "epoch : 120 [0/23] Train loss: 0.71026,Valid loss: 0.95682, time : 10.185105085372925 lr : 0.29938039131233124\n",
      "epoch : 120 [1/23] Train loss: 0.71626,Valid loss: 0.97893, time : 10.522263288497925 lr : 0.29938039131233124\n",
      "epoch : 120 [2/23] Train loss: 0.71475,Valid loss: 0.98046, time : 10.246201038360596 lr : 0.29938039131233124\n",
      "epoch : 120 [3/23] Train loss: 0.71247,Valid loss: 0.96656, time : 10.683948993682861 lr : 0.29938039131233124\n",
      "epoch : 120 [4/23] Train loss: 0.70394,Valid loss: 0.99947, time : 10.585770845413208 lr : 0.29938039131233124\n",
      "epoch : 120 [5/23] Train loss: 0.70513,Valid loss: 1.00254, time : 11.385403871536255 lr : 0.29938039131233124\n",
      "epoch : 120 [6/23] Train loss: 0.71055,Valid loss: 1.00295, time : 10.432663440704346 lr : 0.29938039131233124\n",
      "epoch : 120 [7/23] Train loss: 0.70093,Valid loss: 1.00362, time : 10.239964962005615 lr : 0.29938039131233124\n",
      "epoch : 120 [8/23] Train loss: 0.69722,Valid loss: 0.95996, time : 9.87773847579956 lr : 0.29938039131233124\n",
      "epoch : 120 [9/23] Train loss: 0.70629,Valid loss: 0.97585, time : 10.09897780418396 lr : 0.29938039131233124\n",
      "epoch : 120 [10/23] Train loss: 0.73207,Valid loss: 1.01622, time : 9.864248037338257 lr : 0.29938039131233124\n",
      "epoch : 120 [11/23] Train loss: 0.76819,Valid loss: 1.08472, time : 10.434200286865234 lr : 0.29938039131233124\n",
      "epoch : 120 [12/23] Train loss: 0.77852,Valid loss: 1.84481, time : 9.939797639846802 lr : 0.29938039131233124\n",
      "epoch : 120 [13/23] Train loss: 0.80146,Valid loss: 1.09277, time : 10.451894044876099 lr : 0.29938039131233124\n",
      "epoch : 120 [14/23] Train loss: 0.75281,Valid loss: 1.11019, time : 9.79825758934021 lr : 0.29938039131233124\n",
      "epoch : 120 [15/23] Train loss: 0.77003,Valid loss: 1.12918, time : 10.05443811416626 lr : 0.29938039131233124\n",
      "epoch : 120 [16/23] Train loss: 0.79573,Valid loss: 1.12835, time : 10.62054443359375 lr : 0.29938039131233124\n",
      "epoch : 120 [17/23] Train loss: 0.74319,Valid loss: 1.02964, time : 10.071014881134033 lr : 0.29938039131233124\n",
      "epoch : 120 [18/23] Train loss: 0.72742,Valid loss: 1.00583, time : 9.924153089523315 lr : 0.29938039131233124\n",
      "epoch : 120 [19/23] Train loss: 0.70925,Valid loss: 1.05866, time : 10.26918339729309 lr : 0.29938039131233124\n",
      "epoch : 120 [20/23] Train loss: 0.72358,Valid loss: 1.03772, time : 9.973236799240112 lr : 0.29938039131233124\n",
      "epoch : 120 [21/23] Train loss: 0.70208,Valid loss: 0.98987, time : 10.311098337173462 lr : 0.29938039131233124\n",
      "epoch : 120 [22/23] Train loss: 0.71260,Valid loss: 0.97361, time : 9.58734655380249 lr : 0.29938039131233124\n",
      "epoch : 121 [0/23] Train loss: 0.70369,Valid loss: 0.96377, time : 10.596160173416138 lr : 0.2963865873992079\n",
      "epoch : 121 [1/23] Train loss: 0.72482,Valid loss: 0.96310, time : 10.234423398971558 lr : 0.2963865873992079\n",
      "epoch : 121 [2/23] Train loss: 0.70117,Valid loss: 0.99259, time : 10.617005109786987 lr : 0.2963865873992079\n",
      "epoch : 121 [3/23] Train loss: 0.69757,Valid loss: 0.98259, time : 10.16583251953125 lr : 0.2963865873992079\n",
      "epoch : 121 [4/23] Train loss: 0.69970,Valid loss: 0.99167, time : 10.616579055786133 lr : 0.2963865873992079\n",
      "epoch : 121 [5/23] Train loss: 0.70170,Valid loss: 1.00701, time : 10.59384799003601 lr : 0.2963865873992079\n",
      "epoch : 121 [6/23] Train loss: 0.69734,Valid loss: 0.96811, time : 10.72831678390503 lr : 0.2963865873992079\n",
      "epoch : 121 [7/23] Train loss: 0.69767,Valid loss: 1.00075, time : 10.72553038597107 lr : 0.2963865873992079\n",
      "epoch : 121 [8/23] Train loss: 0.69406,Valid loss: 1.02060, time : 10.545959711074829 lr : 0.2963865873992079\n",
      "epoch : 121 [9/23] Train loss: 0.71223,Valid loss: 0.96263, time : 10.452525615692139 lr : 0.2963865873992079\n",
      "epoch : 121 [10/23] Train loss: 0.70754,Valid loss: 1.01962, time : 10.461085319519043 lr : 0.2963865873992079\n",
      "epoch : 121 [11/23] Train loss: 0.71941,Valid loss: 1.03590, time : 10.602490425109863 lr : 0.2963865873992079\n",
      "epoch : 121 [12/23] Train loss: 0.70168,Valid loss: 0.96809, time : 10.767382144927979 lr : 0.2963865873992079\n",
      "epoch : 121 [13/23] Train loss: 0.70117,Valid loss: 0.99284, time : 10.826407432556152 lr : 0.2963865873992079\n",
      "epoch : 121 [14/23] Train loss: 0.70746,Valid loss: 1.01071, time : 10.977191925048828 lr : 0.2963865873992079\n",
      "epoch : 121 [15/23] Train loss: 0.70095,Valid loss: 1.02208, time : 10.83911681175232 lr : 0.2963865873992079\n",
      "epoch : 121 [16/23] Train loss: 0.68498,Valid loss: 1.02047, time : 10.330002784729004 lr : 0.2963865873992079\n",
      "epoch : 121 [17/23] Train loss: 0.74103,Valid loss: 0.99824, time : 10.377994537353516 lr : 0.2963865873992079\n",
      "epoch : 121 [18/23] Train loss: 0.73842,Valid loss: 1.01580, time : 10.49493408203125 lr : 0.2963865873992079\n",
      "epoch : 121 [19/23] Train loss: 0.70057,Valid loss: 1.00119, time : 10.601663827896118 lr : 0.2963865873992079\n",
      "epoch : 121 [20/23] Train loss: 0.72556,Valid loss: 1.02369, time : 10.467893600463867 lr : 0.2963865873992079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 121 [21/23] Train loss: 0.71417,Valid loss: 1.12185, time : 10.015025854110718 lr : 0.2963865873992079\n",
      "epoch : 121 [22/23] Train loss: 0.72000,Valid loss: 1.12362, time : 9.738416194915771 lr : 0.2963865873992079\n",
      "epoch : 122 [0/23] Train loss: 0.70932,Valid loss: 1.00094, time : 10.303746938705444 lr : 0.29342272152521587\n",
      "epoch : 122 [1/23] Train loss: 0.71865,Valid loss: 0.98380, time : 10.437352657318115 lr : 0.29342272152521587\n",
      "epoch : 122 [2/23] Train loss: 0.69228,Valid loss: 1.00033, time : 10.432620525360107 lr : 0.29342272152521587\n",
      "epoch : 122 [3/23] Train loss: 0.70590,Valid loss: 1.02937, time : 10.522311925888062 lr : 0.29342272152521587\n",
      "epoch : 122 [4/23] Train loss: 0.70098,Valid loss: 1.00006, time : 10.31177806854248 lr : 0.29342272152521587\n",
      "epoch : 122 [5/23] Train loss: 0.69496,Valid loss: 0.97633, time : 10.385267972946167 lr : 0.29342272152521587\n",
      "epoch : 122 [6/23] Train loss: 0.70192,Valid loss: 0.98636, time : 10.14695692062378 lr : 0.29342272152521587\n",
      "epoch : 122 [7/23] Train loss: 0.69298,Valid loss: 0.96680, time : 10.542694807052612 lr : 0.29342272152521587\n",
      "epoch : 122 [8/23] Train loss: 0.71149,Valid loss: 0.96161, time : 10.310779571533203 lr : 0.29342272152521587\n",
      "epoch : 122 [9/23] Train loss: 0.70015,Valid loss: 0.96749, time : 10.411503553390503 lr : 0.29342272152521587\n",
      "epoch : 122 [10/23] Train loss: 0.70379,Valid loss: 0.95469, time : 10.52229642868042 lr : 0.29342272152521587\n",
      "epoch : 122 [11/23] Train loss: 0.68568,Valid loss: 0.95916, time : 10.888692378997803 lr : 0.29342272152521587\n",
      "epoch : 122 [12/23] Train loss: 0.69004,Valid loss: 0.95636, time : 10.776124238967896 lr : 0.29342272152521587\n",
      "epoch : 122 [13/23] Train loss: 0.69190,Valid loss: 0.94611, time : 10.678330183029175 lr : 0.29342272152521587\n",
      "epoch : 122 [14/23] Train loss: 0.68822,Valid loss: 0.96663, time : 10.392100811004639 lr : 0.29342272152521587\n",
      "epoch : 122 [15/23] Train loss: 0.70294,Valid loss: 0.94773, time : 10.69421672821045 lr : 0.29342272152521587\n",
      "epoch : 122 [16/23] Train loss: 0.70545,Valid loss: 0.94825, time : 10.627107620239258 lr : 0.29342272152521587\n",
      "epoch : 122 [17/23] Train loss: 0.69048,Valid loss: 1.00235, time : 10.460750818252563 lr : 0.29342272152521587\n",
      "epoch : 122 [18/23] Train loss: 0.68701,Valid loss: 0.96783, time : 10.524960994720459 lr : 0.29342272152521587\n",
      "epoch : 122 [19/23] Train loss: 0.68843,Valid loss: 0.96690, time : 10.659295797348022 lr : 0.29342272152521587\n",
      "epoch : 122 [20/23] Train loss: 0.68588,Valid loss: 0.93732, time : 10.276325464248657 lr : 0.29342272152521587\n",
      "epoch : 122 [21/23] Train loss: 0.68373,Valid loss: 0.99720, time : 10.39378833770752 lr : 0.29342272152521587\n",
      "epoch : 122 [22/23] Train loss: 0.66589,Valid loss: 0.96486, time : 9.663612127304077 lr : 0.29342272152521587\n",
      "epoch : 123 [0/23] Train loss: 0.68769,Valid loss: 0.95188, time : 10.725918531417847 lr : 0.2904884943099637\n",
      "epoch : 123 [1/23] Train loss: 0.68546,Valid loss: 0.95104, time : 10.202707052230835 lr : 0.2904884943099637\n",
      "epoch : 123 [2/23] Train loss: 0.68585,Valid loss: 0.97339, time : 10.373852968215942 lr : 0.2904884943099637\n",
      "epoch : 123 [3/23] Train loss: 0.67983,Valid loss: 0.98959, time : 10.769083976745605 lr : 0.2904884943099637\n",
      "epoch : 123 [4/23] Train loss: 0.69595,Valid loss: 0.94362, time : 10.514020919799805 lr : 0.2904884943099637\n",
      "epoch : 123 [5/23] Train loss: 0.68936,Valid loss: 0.95661, time : 10.513269901275635 lr : 0.2904884943099637\n",
      "epoch : 123 [6/23] Train loss: 0.67036,Valid loss: 0.96716, time : 10.456066370010376 lr : 0.2904884943099637\n",
      "epoch : 123 [7/23] Train loss: 0.67773,Valid loss: 1.09033, time : 10.33581829071045 lr : 0.2904884943099637\n",
      "epoch : 123 [8/23] Train loss: 0.70546,Valid loss: 0.96755, time : 10.658591985702515 lr : 0.2904884943099637\n",
      "epoch : 123 [9/23] Train loss: 0.66819,Valid loss: 0.98153, time : 10.491099119186401 lr : 0.2904884943099637\n",
      "epoch : 123 [10/23] Train loss: 0.67391,Valid loss: 0.94061, time : 10.339239120483398 lr : 0.2904884943099637\n",
      "epoch : 123 [11/23] Train loss: 0.68173,Valid loss: 0.99351, time : 10.293673753738403 lr : 0.2904884943099637\n",
      "epoch : 123 [12/23] Train loss: 0.68968,Valid loss: 0.94389, time : 10.150741338729858 lr : 0.2904884943099637\n",
      "epoch : 123 [13/23] Train loss: 0.68706,Valid loss: 0.96782, time : 10.128108501434326 lr : 0.2904884943099637\n",
      "epoch : 123 [14/23] Train loss: 0.66573,Valid loss: 0.98413, time : 10.179614543914795 lr : 0.2904884943099637\n",
      "epoch : 123 [15/23] Train loss: 0.67590,Valid loss: 0.97532, time : 10.35455322265625 lr : 0.2904884943099637\n",
      "epoch : 123 [16/23] Train loss: 0.68266,Valid loss: 0.92205, time : 9.981451988220215 lr : 0.2904884943099637\n",
      "epoch : 123 [17/23] Train loss: 0.69211,Valid loss: 1.00626, time : 9.987741947174072 lr : 0.2904884943099637\n",
      "epoch : 123 [18/23] Train loss: 0.67607,Valid loss: 0.92926, time : 9.803678750991821 lr : 0.2904884943099637\n",
      "epoch : 123 [19/23] Train loss: 0.67395,Valid loss: 0.99581, time : 9.874621868133545 lr : 0.2904884943099637\n",
      "epoch : 123 [20/23] Train loss: 0.68986,Valid loss: 0.97268, time : 10.024881839752197 lr : 0.2904884943099637\n",
      "epoch : 123 [21/23] Train loss: 0.68122,Valid loss: 0.95375, time : 10.084192514419556 lr : 0.2904884943099637\n",
      "epoch : 123 [22/23] Train loss: 0.70047,Valid loss: 0.94471, time : 9.475226402282715 lr : 0.2904884943099637\n",
      "epoch : 124 [0/23] Train loss: 0.68594,Valid loss: 0.97349, time : 10.384557485580444 lr : 0.28758360936686406\n",
      "epoch : 124 [1/23] Train loss: 0.69596,Valid loss: 0.98770, time : 10.374568939208984 lr : 0.28758360936686406\n",
      "epoch : 124 [2/23] Train loss: 0.66657,Valid loss: 0.94205, time : 10.640841484069824 lr : 0.28758360936686406\n",
      "epoch : 124 [3/23] Train loss: 0.67724,Valid loss: 0.96061, time : 10.256980419158936 lr : 0.28758360936686406\n",
      "epoch : 124 [4/23] Train loss: 0.67603,Valid loss: 0.97468, time : 10.389388799667358 lr : 0.28758360936686406\n",
      "epoch : 124 [5/23] Train loss: 0.71787,Valid loss: 1.04786, time : 9.944230556488037 lr : 0.28758360936686406\n",
      "epoch : 124 [6/23] Train loss: 0.71356,Valid loss: 1.06842, time : 10.01323127746582 lr : 0.28758360936686406\n",
      "epoch : 124 [7/23] Train loss: 0.71963,Valid loss: 1.50026, time : 10.710186958312988 lr : 0.28758360936686406\n",
      "epoch : 124 [8/23] Train loss: 0.79513,Valid loss: 4.57109, time : 10.086950778961182 lr : 0.28758360936686406\n",
      "epoch : 124 [9/23] Train loss: 1.04050,Valid loss: 1.07166, time : 9.73273229598999 lr : 0.28758360936686406\n",
      "epoch : 124 [10/23] Train loss: 0.78311,Valid loss: 1.04414, time : 10.257364511489868 lr : 0.28758360936686406\n",
      "epoch : 124 [11/23] Train loss: 0.76125,Valid loss: 1.11097, time : 10.163844347000122 lr : 0.28758360936686406\n",
      "epoch : 124 [12/23] Train loss: 0.70244,Valid loss: 1.01856, time : 9.865156888961792 lr : 0.28758360936686406\n",
      "epoch : 124 [13/23] Train loss: 0.70300,Valid loss: 0.96671, time : 10.104423761367798 lr : 0.28758360936686406\n",
      "epoch : 124 [14/23] Train loss: 0.67200,Valid loss: 1.00232, time : 10.313589811325073 lr : 0.28758360936686406\n",
      "epoch : 124 [15/23] Train loss: 0.74095,Valid loss: 0.99670, time : 9.85873794555664 lr : 0.28758360936686406\n",
      "epoch : 124 [16/23] Train loss: 0.71572,Valid loss: 0.96802, time : 10.28226375579834 lr : 0.28758360936686406\n",
      "epoch : 124 [17/23] Train loss: 0.70369,Valid loss: 0.96012, time : 10.218969345092773 lr : 0.28758360936686406\n",
      "epoch : 124 [18/23] Train loss: 0.67283,Valid loss: 0.93524, time : 10.416637182235718 lr : 0.28758360936686406\n",
      "epoch : 124 [19/23] Train loss: 0.69174,Valid loss: 0.95996, time : 10.285278081893921 lr : 0.28758360936686406\n",
      "epoch : 124 [20/23] Train loss: 0.68252,Valid loss: 0.96215, time : 10.472413778305054 lr : 0.28758360936686406\n",
      "epoch : 124 [21/23] Train loss: 0.67357,Valid loss: 0.94077, time : 10.257896661758423 lr : 0.28758360936686406\n",
      "epoch : 124 [22/23] Train loss: 0.67368,Valid loss: 1.00019, time : 9.557582139968872 lr : 0.28758360936686406\n",
      "epoch : 125 [0/23] Train loss: 0.68884,Valid loss: 0.97117, time : 10.056300640106201 lr : 0.2847077732731954\n",
      "epoch : 125 [1/23] Train loss: 0.70875,Valid loss: 0.95097, time : 10.848233461380005 lr : 0.2847077732731954\n",
      "epoch : 125 [2/23] Train loss: 0.68582,Valid loss: 0.93201, time : 10.194272518157959 lr : 0.2847077732731954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 125 [3/23] Train loss: 0.66490,Valid loss: 0.95052, time : 10.295121669769287 lr : 0.2847077732731954\n",
      "epoch : 125 [4/23] Train loss: 0.66657,Valid loss: 0.96287, time : 9.9156014919281 lr : 0.2847077732731954\n",
      "epoch : 125 [5/23] Train loss: 0.69163,Valid loss: 0.94455, time : 10.34320592880249 lr : 0.2847077732731954\n",
      "epoch : 125 [6/23] Train loss: 0.67531,Valid loss: 0.93604, time : 10.131877183914185 lr : 0.2847077732731954\n",
      "epoch : 125 [7/23] Train loss: 0.68276,Valid loss: 0.92747, time : 10.709238290786743 lr : 0.2847077732731954\n",
      "epoch : 125 [8/23] Train loss: 0.66830,Valid loss: 0.96166, time : 10.449727058410645 lr : 0.2847077732731954\n",
      "epoch : 125 [9/23] Train loss: 0.67012,Valid loss: 0.94105, time : 10.476369619369507 lr : 0.2847077732731954\n",
      "epoch : 125 [10/23] Train loss: 0.68457,Valid loss: 0.95531, time : 10.377601146697998 lr : 0.2847077732731954\n",
      "epoch : 125 [11/23] Train loss: 0.66470,Valid loss: 0.94203, time : 10.547196626663208 lr : 0.2847077732731954\n",
      "epoch : 125 [12/23] Train loss: 0.66993,Valid loss: 0.96610, time : 10.477368116378784 lr : 0.2847077732731954\n",
      "epoch : 125 [13/23] Train loss: 0.66572,Valid loss: 0.92823, time : 10.477861166000366 lr : 0.2847077732731954\n",
      "epoch : 125 [14/23] Train loss: 0.66488,Valid loss: 0.94862, time : 10.517457723617554 lr : 0.2847077732731954\n",
      "epoch : 125 [15/23] Train loss: 0.65653,Valid loss: 0.96921, time : 10.271061420440674 lr : 0.2847077732731954\n",
      "epoch : 125 [16/23] Train loss: 0.69258,Valid loss: 0.94057, time : 10.159262418746948 lr : 0.2847077732731954\n",
      "epoch : 125 [17/23] Train loss: 0.66227,Valid loss: 0.95376, time : 10.131524085998535 lr : 0.2847077732731954\n",
      "epoch : 125 [18/23] Train loss: 0.67524,Valid loss: 1.04773, time : 10.420155763626099 lr : 0.2847077732731954\n",
      "epoch : 125 [19/23] Train loss: 0.69896,Valid loss: 1.00125, time : 10.210689306259155 lr : 0.2847077732731954\n",
      "epoch : 125 [20/23] Train loss: 0.69771,Valid loss: 0.99452, time : 10.033880710601807 lr : 0.2847077732731954\n",
      "epoch : 125 [21/23] Train loss: 0.71363,Valid loss: 1.04091, time : 10.418282270431519 lr : 0.2847077732731954\n",
      "epoch : 125 [22/23] Train loss: 0.74140,Valid loss: 1.00532, time : 9.677383661270142 lr : 0.2847077732731954\n",
      "epoch : 126 [0/23] Train loss: 0.73991,Valid loss: 1.00784, time : 10.780956983566284 lr : 0.28186069554046345\n",
      "epoch : 126 [1/23] Train loss: 0.70564,Valid loss: 0.93816, time : 9.769710779190063 lr : 0.28186069554046345\n",
      "epoch : 126 [2/23] Train loss: 0.69945,Valid loss: 0.96733, time : 10.212313413619995 lr : 0.28186069554046345\n",
      "epoch : 126 [3/23] Train loss: 0.69358,Valid loss: 0.95671, time : 10.339906930923462 lr : 0.28186069554046345\n",
      "epoch : 126 [4/23] Train loss: 0.71298,Valid loss: 0.96113, time : 9.794267892837524 lr : 0.28186069554046345\n",
      "epoch : 126 [5/23] Train loss: 0.69455,Valid loss: 0.98405, time : 9.882898092269897 lr : 0.28186069554046345\n",
      "epoch : 126 [6/23] Train loss: 0.68917,Valid loss: 0.99190, time : 9.842756748199463 lr : 0.28186069554046345\n",
      "epoch : 126 [7/23] Train loss: 0.66379,Valid loss: 0.97015, time : 10.246769666671753 lr : 0.28186069554046345\n",
      "epoch : 126 [8/23] Train loss: 0.67373,Valid loss: 0.96627, time : 10.334943771362305 lr : 0.28186069554046345\n",
      "epoch : 126 [9/23] Train loss: 0.66282,Valid loss: 0.94733, time : 10.08207654953003 lr : 0.28186069554046345\n",
      "epoch : 126 [10/23] Train loss: 0.64857,Valid loss: 0.95024, time : 10.08875560760498 lr : 0.28186069554046345\n",
      "epoch : 126 [11/23] Train loss: 0.68232,Valid loss: 0.92485, time : 9.847267866134644 lr : 0.28186069554046345\n",
      "epoch : 126 [12/23] Train loss: 0.66087,Valid loss: 0.94751, time : 10.002902030944824 lr : 0.28186069554046345\n",
      "epoch : 126 [13/23] Train loss: 0.66580,Valid loss: 0.94133, time : 10.355550527572632 lr : 0.28186069554046345\n",
      "epoch : 126 [14/23] Train loss: 0.64980,Valid loss: 0.93518, time : 10.299506664276123 lr : 0.28186069554046345\n",
      "epoch : 126 [15/23] Train loss: 0.67219,Valid loss: 0.92319, time : 10.189036846160889 lr : 0.28186069554046345\n",
      "epoch : 126 [16/23] Train loss: 0.66202,Valid loss: 0.94552, time : 10.423007488250732 lr : 0.28186069554046345\n",
      "epoch : 126 [17/23] Train loss: 0.67038,Valid loss: 0.91374, time : 10.389189958572388 lr : 0.28186069554046345\n",
      "epoch : 126 [18/23] Train loss: 0.66093,Valid loss: 0.94313, time : 10.378700971603394 lr : 0.28186069554046345\n",
      "epoch : 126 [19/23] Train loss: 0.66101,Valid loss: 0.95395, time : 10.650476217269897 lr : 0.28186069554046345\n",
      "epoch : 126 [20/23] Train loss: 0.66476,Valid loss: 0.94517, time : 10.905301809310913 lr : 0.28186069554046345\n",
      "epoch : 126 [21/23] Train loss: 0.67287,Valid loss: 0.95180, time : 9.926821947097778 lr : 0.28186069554046345\n",
      "epoch : 126 [22/23] Train loss: 0.65148,Valid loss: 0.96498, time : 9.506189107894897 lr : 0.28186069554046345\n",
      "epoch : 127 [0/23] Train loss: 0.64267,Valid loss: 0.94573, time : 10.4835524559021 lr : 0.2790420885850588\n",
      "epoch : 127 [1/23] Train loss: 0.64036,Valid loss: 0.98093, time : 10.105379581451416 lr : 0.2790420885850588\n",
      "epoch : 127 [2/23] Train loss: 0.65629,Valid loss: 0.93368, time : 9.888448238372803 lr : 0.2790420885850588\n",
      "epoch : 127 [3/23] Train loss: 0.64483,Valid loss: 0.97318, time : 10.283663034439087 lr : 0.2790420885850588\n",
      "epoch : 127 [4/23] Train loss: 0.66572,Valid loss: 0.93864, time : 10.271611452102661 lr : 0.2790420885850588\n",
      "epoch : 127 [5/23] Train loss: 0.65450,Valid loss: 0.92239, time : 10.125260829925537 lr : 0.2790420885850588\n",
      "epoch : 127 [6/23] Train loss: 0.64703,Valid loss: 0.90282, time : 10.473941802978516 lr : 0.2790420885850588\n",
      "epoch : 127 [7/23] Train loss: 0.63875,Valid loss: 0.96305, time : 10.421085834503174 lr : 0.2790420885850588\n",
      "epoch : 127 [8/23] Train loss: 0.64510,Valid loss: 0.90808, time : 10.510390758514404 lr : 0.2790420885850588\n",
      "epoch : 127 [9/23] Train loss: 0.65202,Valid loss: 0.93084, time : 10.546415090560913 lr : 0.2790420885850588\n",
      "epoch : 127 [10/23] Train loss: 0.65059,Valid loss: 0.91335, time : 10.375777959823608 lr : 0.2790420885850588\n",
      "epoch : 127 [11/23] Train loss: 0.62732,Valid loss: 0.92928, time : 10.395977258682251 lr : 0.2790420885850588\n",
      "epoch : 127 [12/23] Train loss: 0.66243,Valid loss: 0.93851, time : 10.49014163017273 lr : 0.2790420885850588\n",
      "epoch : 127 [13/23] Train loss: 0.64293,Valid loss: 0.94127, time : 10.706731081008911 lr : 0.2790420885850588\n",
      "epoch : 127 [14/23] Train loss: 0.64996,Valid loss: 0.93132, time : 10.326859474182129 lr : 0.2790420885850588\n",
      "epoch : 127 [15/23] Train loss: 0.65200,Valid loss: 0.96825, time : 10.317851305007935 lr : 0.2790420885850588\n",
      "epoch : 127 [16/23] Train loss: 0.63777,Valid loss: 0.90998, time : 10.421424627304077 lr : 0.2790420885850588\n",
      "epoch : 127 [17/23] Train loss: 0.63910,Valid loss: 0.90685, time : 10.262566566467285 lr : 0.2790420885850588\n",
      "epoch : 127 [18/23] Train loss: 0.64612,Valid loss: 0.92472, time : 10.492403030395508 lr : 0.2790420885850588\n",
      "epoch : 127 [19/23] Train loss: 0.65691,Valid loss: 0.91847, time : 10.213695049285889 lr : 0.2790420885850588\n",
      "epoch : 127 [20/23] Train loss: 0.64244,Valid loss: 0.89655, time : 10.165145635604858 lr : 0.2790420885850588\n",
      "epoch : 127 [21/23] Train loss: 0.64246,Valid loss: 0.96225, time : 10.188514947891235 lr : 0.2790420885850588\n",
      "epoch : 127 [22/23] Train loss: 0.66265,Valid loss: 0.98245, time : 9.475652694702148 lr : 0.2790420885850588\n",
      "epoch : 128 [0/23] Train loss: 0.66598,Valid loss: 0.89843, time : 9.791841983795166 lr : 0.2762516676992082\n",
      "epoch : 128 [1/23] Train loss: 0.63553,Valid loss: 0.90141, time : 9.972682237625122 lr : 0.2762516676992082\n",
      "epoch : 128 [2/23] Train loss: 0.64691,Valid loss: 0.93812, time : 10.155609130859375 lr : 0.2762516676992082\n",
      "epoch : 128 [3/23] Train loss: 0.62930,Valid loss: 0.89598, time : 10.151631116867065 lr : 0.2762516676992082\n",
      "epoch : 128 [4/23] Train loss: 0.65586,Valid loss: 0.91779, time : 10.226751804351807 lr : 0.2762516676992082\n",
      "epoch : 128 [5/23] Train loss: 0.64263,Valid loss: 0.90973, time : 9.780011653900146 lr : 0.2762516676992082\n",
      "epoch : 128 [6/23] Train loss: 0.65264,Valid loss: 0.92537, time : 10.137252569198608 lr : 0.2762516676992082\n",
      "epoch : 128 [7/23] Train loss: 0.65939,Valid loss: 0.91585, time : 10.415658473968506 lr : 0.2762516676992082\n",
      "epoch : 128 [8/23] Train loss: 0.65579,Valid loss: 0.94386, time : 9.961262941360474 lr : 0.2762516676992082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 128 [9/23] Train loss: 0.63511,Valid loss: 0.91975, time : 9.833699703216553 lr : 0.2762516676992082\n",
      "epoch : 128 [10/23] Train loss: 0.64431,Valid loss: 0.92044, time : 10.248563289642334 lr : 0.2762516676992082\n",
      "epoch : 128 [11/23] Train loss: 0.63758,Valid loss: 0.91423, time : 9.912006616592407 lr : 0.2762516676992082\n",
      "epoch : 128 [12/23] Train loss: 0.65616,Valid loss: 0.93253, time : 9.796207666397095 lr : 0.2762516676992082\n",
      "epoch : 128 [13/23] Train loss: 0.63121,Valid loss: 0.91504, time : 9.821356534957886 lr : 0.2762516676992082\n",
      "epoch : 128 [14/23] Train loss: 0.63711,Valid loss: 0.89429, time : 10.196449518203735 lr : 0.2762516676992082\n",
      "epoch : 128 [15/23] Train loss: 0.64136,Valid loss: 0.88195, time : 10.000086545944214 lr : 0.2762516676992082\n",
      "epoch : 128 [16/23] Train loss: 0.62594,Valid loss: 0.89667, time : 10.303102493286133 lr : 0.2762516676992082\n",
      "epoch : 128 [17/23] Train loss: 0.64657,Valid loss: 0.90359, time : 10.135109424591064 lr : 0.2762516676992082\n",
      "epoch : 128 [18/23] Train loss: 0.64183,Valid loss: 0.95406, time : 10.549201965332031 lr : 0.2762516676992082\n",
      "epoch : 128 [19/23] Train loss: 0.63760,Valid loss: 0.93386, time : 10.33819055557251 lr : 0.2762516676992082\n",
      "epoch : 128 [20/23] Train loss: 0.63209,Valid loss: 0.93153, time : 9.78488278388977 lr : 0.2762516676992082\n",
      "epoch : 128 [21/23] Train loss: 0.62918,Valid loss: 0.91418, time : 9.918769359588623 lr : 0.2762516676992082\n",
      "epoch : 128 [22/23] Train loss: 0.65131,Valid loss: 0.93496, time : 9.52917742729187 lr : 0.2762516676992082\n",
      "epoch : 129 [0/23] Train loss: 0.64092,Valid loss: 0.95076, time : 10.51373815536499 lr : 0.27348915102221616\n",
      "epoch : 129 [1/23] Train loss: 0.65409,Valid loss: 0.95514, time : 9.915932416915894 lr : 0.27348915102221616\n",
      "epoch : 129 [2/23] Train loss: 0.63047,Valid loss: 0.95138, time : 10.204668521881104 lr : 0.27348915102221616\n",
      "epoch : 129 [3/23] Train loss: 0.62946,Valid loss: 0.95262, time : 10.281981706619263 lr : 0.27348915102221616\n",
      "epoch : 129 [4/23] Train loss: 0.65827,Valid loss: 1.03794, time : 10.688527345657349 lr : 0.27348915102221616\n",
      "epoch : 129 [5/23] Train loss: 0.64485,Valid loss: 0.94388, time : 10.453080654144287 lr : 0.27348915102221616\n",
      "epoch : 129 [6/23] Train loss: 0.66155,Valid loss: 0.99549, time : 10.397853374481201 lr : 0.27348915102221616\n",
      "epoch : 129 [7/23] Train loss: 0.68557,Valid loss: 0.93322, time : 10.306349515914917 lr : 0.27348915102221616\n",
      "epoch : 129 [8/23] Train loss: 0.76592,Valid loss: 1.02647, time : 10.29783582687378 lr : 0.27348915102221616\n",
      "epoch : 129 [9/23] Train loss: 0.84731,Valid loss: 1.03346, time : 9.88305950164795 lr : 0.27348915102221616\n",
      "epoch : 129 [10/23] Train loss: 0.73597,Valid loss: 1.03658, time : 10.150718212127686 lr : 0.27348915102221616\n",
      "epoch : 129 [11/23] Train loss: 0.75622,Valid loss: 1.02706, time : 10.098190307617188 lr : 0.27348915102221616\n",
      "epoch : 129 [12/23] Train loss: 0.80157,Valid loss: 1.14827, time : 10.595122575759888 lr : 0.27348915102221616\n",
      "epoch : 129 [13/23] Train loss: 0.77569,Valid loss: 1.01134, time : 10.262259244918823 lr : 0.27348915102221616\n",
      "epoch : 129 [14/23] Train loss: 0.79528,Valid loss: 1.00567, time : 10.385704278945923 lr : 0.27348915102221616\n",
      "epoch : 129 [15/23] Train loss: 0.73856,Valid loss: 0.99389, time : 10.396852731704712 lr : 0.27348915102221616\n",
      "epoch : 129 [16/23] Train loss: 0.66498,Valid loss: 1.04301, time : 10.526427745819092 lr : 0.27348915102221616\n",
      "epoch : 129 [17/23] Train loss: 0.66770,Valid loss: 0.93240, time : 10.584782838821411 lr : 0.27348915102221616\n",
      "epoch : 129 [18/23] Train loss: 0.67163,Valid loss: 0.95544, time : 10.3102548122406 lr : 0.27348915102221616\n",
      "epoch : 129 [19/23] Train loss: 0.65277,Valid loss: 0.95056, time : 10.467673063278198 lr : 0.27348915102221616\n",
      "epoch : 129 [20/23] Train loss: 0.64720,Valid loss: 0.94173, time : 10.59131908416748 lr : 0.27348915102221616\n",
      "epoch : 129 [21/23] Train loss: 0.64620,Valid loss: 0.93758, time : 10.558303117752075 lr : 0.27348915102221616\n",
      "epoch : 129 [22/23] Train loss: 0.64136,Valid loss: 0.97345, time : 9.355576276779175 lr : 0.27348915102221616\n",
      "epoch : 130 [0/23] Train loss: 0.65916,Valid loss: 0.94048, time : 10.512461185455322 lr : 0.270754259511994\n",
      "epoch : 130 [1/23] Train loss: 0.64727,Valid loss: 0.96489, time : 10.481975078582764 lr : 0.270754259511994\n",
      "epoch : 130 [2/23] Train loss: 0.65590,Valid loss: 0.93489, time : 10.579898834228516 lr : 0.270754259511994\n",
      "epoch : 130 [3/23] Train loss: 0.66309,Valid loss: 0.95792, time : 10.497211456298828 lr : 0.270754259511994\n",
      "epoch : 130 [4/23] Train loss: 0.63116,Valid loss: 0.93162, time : 10.405285358428955 lr : 0.270754259511994\n",
      "epoch : 130 [5/23] Train loss: 0.64890,Valid loss: 0.90915, time : 10.34140920639038 lr : 0.270754259511994\n",
      "epoch : 130 [6/23] Train loss: 0.63705,Valid loss: 0.95077, time : 10.568010091781616 lr : 0.270754259511994\n",
      "epoch : 130 [7/23] Train loss: 0.62115,Valid loss: 0.90610, time : 10.567659139633179 lr : 0.270754259511994\n",
      "epoch : 130 [8/23] Train loss: 0.65028,Valid loss: 0.96931, time : 10.873538732528687 lr : 0.270754259511994\n",
      "epoch : 130 [9/23] Train loss: 0.63814,Valid loss: 0.95401, time : 10.824086904525757 lr : 0.270754259511994\n",
      "epoch : 130 [10/23] Train loss: 0.66329,Valid loss: 0.91937, time : 10.731585264205933 lr : 0.270754259511994\n",
      "epoch : 130 [11/23] Train loss: 0.64544,Valid loss: 0.91784, time : 10.738960266113281 lr : 0.270754259511994\n",
      "epoch : 130 [12/23] Train loss: 0.65043,Valid loss: 0.90376, time : 10.783798456192017 lr : 0.270754259511994\n",
      "epoch : 130 [13/23] Train loss: 0.64907,Valid loss: 0.89871, time : 10.797300815582275 lr : 0.270754259511994\n",
      "epoch : 130 [14/23] Train loss: 0.63081,Valid loss: 0.90504, time : 11.071520805358887 lr : 0.270754259511994\n",
      "epoch : 130 [15/23] Train loss: 0.62185,Valid loss: 0.89451, time : 10.83870530128479 lr : 0.270754259511994\n",
      "epoch : 130 [16/23] Train loss: 0.62106,Valid loss: 0.95938, time : 10.424448728561401 lr : 0.270754259511994\n",
      "epoch : 130 [17/23] Train loss: 0.64574,Valid loss: 0.91790, time : 10.469060897827148 lr : 0.270754259511994\n",
      "epoch : 130 [18/23] Train loss: 0.65078,Valid loss: 0.92126, time : 10.160873651504517 lr : 0.270754259511994\n",
      "epoch : 130 [19/23] Train loss: 0.63177,Valid loss: 0.90182, time : 10.471932649612427 lr : 0.270754259511994\n",
      "epoch : 130 [20/23] Train loss: 0.64790,Valid loss: 0.92348, time : 10.278003215789795 lr : 0.270754259511994\n",
      "epoch : 130 [21/23] Train loss: 0.63484,Valid loss: 0.91598, time : 10.415682315826416 lr : 0.270754259511994\n",
      "epoch : 130 [22/23] Train loss: 0.62189,Valid loss: 0.87980, time : 9.566298007965088 lr : 0.270754259511994\n",
      "epoch : 131 [0/23] Train loss: 0.64134,Valid loss: 0.92992, time : 10.595501899719238 lr : 0.26804671691687404\n",
      "epoch : 131 [1/23] Train loss: 0.64943,Valid loss: 0.91177, time : 10.507333040237427 lr : 0.26804671691687404\n",
      "epoch : 131 [2/23] Train loss: 0.63125,Valid loss: 0.90094, time : 10.360504627227783 lr : 0.26804671691687404\n",
      "epoch : 131 [3/23] Train loss: 0.63729,Valid loss: 0.91757, time : 10.356796741485596 lr : 0.26804671691687404\n",
      "epoch : 131 [4/23] Train loss: 0.62786,Valid loss: 0.90186, time : 10.138646841049194 lr : 0.26804671691687404\n",
      "epoch : 131 [5/23] Train loss: 0.64141,Valid loss: 0.92371, time : 10.656137704849243 lr : 0.26804671691687404\n",
      "epoch : 131 [6/23] Train loss: 0.63010,Valid loss: 0.89450, time : 10.247024536132812 lr : 0.26804671691687404\n",
      "epoch : 131 [7/23] Train loss: 0.63062,Valid loss: 0.91925, time : 10.544754266738892 lr : 0.26804671691687404\n",
      "epoch : 131 [8/23] Train loss: 0.61808,Valid loss: 0.90678, time : 10.428876161575317 lr : 0.26804671691687404\n",
      "epoch : 131 [9/23] Train loss: 0.63006,Valid loss: 0.94921, time : 10.451953887939453 lr : 0.26804671691687404\n",
      "epoch : 131 [10/23] Train loss: 0.61551,Valid loss: 0.92700, time : 10.507840871810913 lr : 0.26804671691687404\n",
      "epoch : 131 [11/23] Train loss: 0.63903,Valid loss: 0.96722, time : 10.919652938842773 lr : 0.26804671691687404\n",
      "epoch : 131 [12/23] Train loss: 0.65702,Valid loss: 0.94702, time : 10.743205785751343 lr : 0.26804671691687404\n",
      "epoch : 131 [13/23] Train loss: 0.64373,Valid loss: 0.93593, time : 10.53793716430664 lr : 0.26804671691687404\n",
      "epoch : 131 [14/23] Train loss: 0.64592,Valid loss: 0.97958, time : 11.09578561782837 lr : 0.26804671691687404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 131 [15/23] Train loss: 0.64796,Valid loss: 0.99355, time : 10.828458547592163 lr : 0.26804671691687404\n",
      "epoch : 131 [16/23] Train loss: 0.62947,Valid loss: 0.94961, time : 10.435680150985718 lr : 0.26804671691687404\n",
      "epoch : 131 [17/23] Train loss: 0.61338,Valid loss: 0.92765, time : 10.723259449005127 lr : 0.26804671691687404\n",
      "epoch : 131 [18/23] Train loss: 0.62845,Valid loss: 0.92495, time : 10.406003475189209 lr : 0.26804671691687404\n",
      "epoch : 131 [19/23] Train loss: 0.62907,Valid loss: 0.91582, time : 10.556801080703735 lr : 0.26804671691687404\n",
      "epoch : 131 [20/23] Train loss: 0.60537,Valid loss: 0.89990, time : 10.624452114105225 lr : 0.26804671691687404\n",
      "epoch : 131 [21/23] Train loss: 0.62021,Valid loss: 0.90926, time : 10.565414667129517 lr : 0.26804671691687404\n",
      "epoch : 131 [22/23] Train loss: 0.61056,Valid loss: 0.94139, time : 9.806398391723633 lr : 0.26804671691687404\n",
      "epoch : 132 [0/23] Train loss: 0.62318,Valid loss: 0.92479, time : 10.44360613822937 lr : 0.2653662497477053\n",
      "epoch : 132 [1/23] Train loss: 0.61421,Valid loss: 0.95343, time : 10.360673427581787 lr : 0.2653662497477053\n",
      "epoch : 132 [2/23] Train loss: 0.61847,Valid loss: 0.91001, time : 10.413835763931274 lr : 0.2653662497477053\n",
      "epoch : 132 [3/23] Train loss: 0.60958,Valid loss: 0.89622, time : 10.28233528137207 lr : 0.2653662497477053\n",
      "epoch : 132 [4/23] Train loss: 0.62102,Valid loss: 0.96261, time : 10.221298694610596 lr : 0.2653662497477053\n",
      "epoch : 132 [5/23] Train loss: 0.65529,Valid loss: 0.93062, time : 10.285831928253174 lr : 0.2653662497477053\n",
      "epoch : 132 [6/23] Train loss: 0.65442,Valid loss: 0.94639, time : 10.563003540039062 lr : 0.2653662497477053\n",
      "epoch : 132 [7/23] Train loss: 0.63815,Valid loss: 0.91398, time : 10.68036699295044 lr : 0.2653662497477053\n",
      "epoch : 132 [8/23] Train loss: 0.64209,Valid loss: 1.00178, time : 10.517405271530151 lr : 0.2653662497477053\n",
      "epoch : 132 [9/23] Train loss: 0.62094,Valid loss: 0.91982, time : 10.344107389450073 lr : 0.2653662497477053\n",
      "epoch : 132 [10/23] Train loss: 0.63119,Valid loss: 0.92144, time : 10.20189619064331 lr : 0.2653662497477053\n",
      "epoch : 132 [11/23] Train loss: 0.60912,Valid loss: 0.90873, time : 10.611665725708008 lr : 0.2653662497477053\n",
      "epoch : 132 [12/23] Train loss: 0.62231,Valid loss: 0.92139, time : 10.30879831314087 lr : 0.2653662497477053\n",
      "epoch : 132 [13/23] Train loss: 0.61991,Valid loss: 0.93834, time : 10.511759281158447 lr : 0.2653662497477053\n",
      "epoch : 132 [14/23] Train loss: 0.63843,Valid loss: 0.90499, time : 10.524016380310059 lr : 0.2653662497477053\n",
      "epoch : 132 [15/23] Train loss: 0.62145,Valid loss: 0.88771, time : 10.796159982681274 lr : 0.2653662497477053\n",
      "epoch : 132 [16/23] Train loss: 0.61974,Valid loss: 0.91501, time : 10.599272012710571 lr : 0.2653662497477053\n",
      "epoch : 132 [17/23] Train loss: 0.61276,Valid loss: 0.92916, time : 10.300793170928955 lr : 0.2653662497477053\n",
      "epoch : 132 [18/23] Train loss: 0.62386,Valid loss: 0.94356, time : 10.237563610076904 lr : 0.2653662497477053\n",
      "epoch : 132 [19/23] Train loss: 0.61945,Valid loss: 0.91022, time : 10.324517965316772 lr : 0.2653662497477053\n",
      "epoch : 132 [20/23] Train loss: 0.61641,Valid loss: 0.91837, time : 10.344514846801758 lr : 0.2653662497477053\n",
      "epoch : 132 [21/23] Train loss: 0.62426,Valid loss: 0.92610, time : 10.752636671066284 lr : 0.2653662497477053\n",
      "epoch : 132 [22/23] Train loss: 0.59493,Valid loss: 0.93499, time : 9.924338102340698 lr : 0.2653662497477053\n",
      "epoch : 133 [0/23] Train loss: 0.61189,Valid loss: 0.89506, time : 10.611701965332031 lr : 0.2627125872502282\n",
      "epoch : 133 [1/23] Train loss: 0.60026,Valid loss: 0.92193, time : 10.572864770889282 lr : 0.2627125872502282\n",
      "epoch : 133 [2/23] Train loss: 0.62304,Valid loss: 0.91601, time : 10.463566064834595 lr : 0.2627125872502282\n",
      "epoch : 133 [3/23] Train loss: 0.61496,Valid loss: 0.92487, time : 10.442710399627686 lr : 0.2627125872502282\n",
      "epoch : 133 [4/23] Train loss: 0.61436,Valid loss: 0.90776, time : 10.495147466659546 lr : 0.2627125872502282\n",
      "epoch : 133 [5/23] Train loss: 0.62005,Valid loss: 0.92910, time : 10.40380048751831 lr : 0.2627125872502282\n",
      "epoch : 133 [6/23] Train loss: 0.60383,Valid loss: 0.91640, time : 10.852721452713013 lr : 0.2627125872502282\n",
      "epoch : 133 [7/23] Train loss: 0.59465,Valid loss: 0.88638, time : 9.768766403198242 lr : 0.2627125872502282\n",
      "epoch : 133 [8/23] Train loss: 0.61458,Valid loss: 0.92850, time : 10.493633031845093 lr : 0.2627125872502282\n",
      "epoch : 133 [9/23] Train loss: 0.63348,Valid loss: 0.92685, time : 9.725338459014893 lr : 0.2627125872502282\n",
      "epoch : 133 [10/23] Train loss: 0.60920,Valid loss: 0.90608, time : 10.56239104270935 lr : 0.2627125872502282\n",
      "epoch : 133 [11/23] Train loss: 0.60751,Valid loss: 0.93804, time : 10.624233484268188 lr : 0.2627125872502282\n",
      "epoch : 133 [12/23] Train loss: 0.59707,Valid loss: 0.92277, time : 10.731404542922974 lr : 0.2627125872502282\n",
      "epoch : 133 [13/23] Train loss: 0.60625,Valid loss: 0.93393, time : 9.798546552658081 lr : 0.2627125872502282\n",
      "epoch : 133 [14/23] Train loss: 0.59262,Valid loss: 0.92236, time : 10.414970636367798 lr : 0.2627125872502282\n",
      "epoch : 133 [15/23] Train loss: 0.59825,Valid loss: 0.90959, time : 10.000507354736328 lr : 0.2627125872502282\n",
      "epoch : 133 [16/23] Train loss: 0.58457,Valid loss: 0.90995, time : 10.584131956100464 lr : 0.2627125872502282\n",
      "epoch : 133 [17/23] Train loss: 0.60394,Valid loss: 0.89389, time : 10.404579401016235 lr : 0.2627125872502282\n",
      "epoch : 133 [18/23] Train loss: 0.60646,Valid loss: 0.90005, time : 10.765645980834961 lr : 0.2627125872502282\n",
      "epoch : 133 [19/23] Train loss: 0.60841,Valid loss: 0.94282, time : 10.67066478729248 lr : 0.2627125872502282\n",
      "epoch : 133 [20/23] Train loss: 0.61608,Valid loss: 0.89093, time : 10.877262830734253 lr : 0.2627125872502282\n",
      "epoch : 133 [21/23] Train loss: 0.61721,Valid loss: 0.93514, time : 10.680289268493652 lr : 0.2627125872502282\n",
      "epoch : 133 [22/23] Train loss: 0.63681,Valid loss: 0.92174, time : 9.886499643325806 lr : 0.2627125872502282\n",
      "epoch : 134 [0/23] Train loss: 0.62383,Valid loss: 0.89673, time : 10.739044904708862 lr : 0.2600854613777259\n",
      "epoch : 134 [1/23] Train loss: 0.62118,Valid loss: 0.89283, time : 10.337614059448242 lr : 0.2600854613777259\n",
      "epoch : 134 [2/23] Train loss: 0.60173,Valid loss: 0.88268, time : 10.320343255996704 lr : 0.2600854613777259\n",
      "epoch : 134 [3/23] Train loss: 0.61006,Valid loss: 0.89539, time : 10.350393533706665 lr : 0.2600854613777259\n",
      "epoch : 134 [4/23] Train loss: 0.60843,Valid loss: 0.87753, time : 10.730444192886353 lr : 0.2600854613777259\n",
      "epoch : 134 [5/23] Train loss: 0.60564,Valid loss: 0.85614, time : 10.428856611251831 lr : 0.2600854613777259\n",
      "epoch : 134 [6/23] Train loss: 0.61569,Valid loss: 0.92638, time : 10.642439603805542 lr : 0.2600854613777259\n",
      "epoch : 134 [7/23] Train loss: 0.60596,Valid loss: 0.86470, time : 10.304531335830688 lr : 0.2600854613777259\n",
      "epoch : 134 [8/23] Train loss: 0.60705,Valid loss: 0.93315, time : 10.793649196624756 lr : 0.2600854613777259\n",
      "epoch : 134 [9/23] Train loss: 0.60284,Valid loss: 0.86613, time : 10.858050346374512 lr : 0.2600854613777259\n",
      "epoch : 134 [10/23] Train loss: 0.59368,Valid loss: 0.85871, time : 10.681185960769653 lr : 0.2600854613777259\n",
      "epoch : 134 [11/23] Train loss: 0.59313,Valid loss: 0.86748, time : 10.567217826843262 lr : 0.2600854613777259\n",
      "epoch : 134 [12/23] Train loss: 0.59607,Valid loss: 0.91085, time : 10.232604503631592 lr : 0.2600854613777259\n",
      "epoch : 134 [13/23] Train loss: 0.60163,Valid loss: 0.85414, time : 10.273636817932129 lr : 0.2600854613777259\n",
      "epoch : 134 [14/23] Train loss: 0.60710,Valid loss: 0.85892, time : 10.635247945785522 lr : 0.2600854613777259\n",
      "epoch : 134 [15/23] Train loss: 0.59804,Valid loss: 0.84720, time : 10.406943082809448 lr : 0.2600854613777259\n",
      "epoch : 134 [16/23] Train loss: 0.60156,Valid loss: 0.85508, time : 10.789785861968994 lr : 0.2600854613777259\n",
      "epoch : 134 [17/23] Train loss: 0.58453,Valid loss: 0.88170, time : 10.382858753204346 lr : 0.2600854613777259\n",
      "epoch : 134 [18/23] Train loss: 0.61746,Valid loss: 0.93567, time : 10.833553791046143 lr : 0.2600854613777259\n",
      "epoch : 134 [19/23] Train loss: 0.60311,Valid loss: 0.88155, time : 10.121991634368896 lr : 0.2600854613777259\n",
      "epoch : 134 [20/23] Train loss: 0.59259,Valid loss: 0.97962, time : 10.617605686187744 lr : 0.2600854613777259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 134 [21/23] Train loss: 0.61388,Valid loss: 0.86675, time : 10.60694432258606 lr : 0.2600854613777259\n",
      "epoch : 134 [22/23] Train loss: 0.59166,Valid loss: 0.88194, time : 10.240956544876099 lr : 0.2600854613777259\n",
      "epoch : 135 [0/23] Train loss: 0.59024,Valid loss: 0.85262, time : 11.227951288223267 lr : 0.2574846067639487\n",
      "epoch : 135 [1/23] Train loss: 0.58576,Valid loss: 0.87394, time : 11.23483943939209 lr : 0.2574846067639487\n",
      "epoch : 135 [2/23] Train loss: 0.60139,Valid loss: 0.83455, time : 10.82468032836914 lr : 0.2574846067639487\n",
      "epoch : 135 [3/23] Train loss: 0.59021,Valid loss: 0.91079, time : 11.055409669876099 lr : 0.2574846067639487\n",
      "epoch : 135 [4/23] Train loss: 0.59063,Valid loss: 0.84373, time : 10.823406457901001 lr : 0.2574846067639487\n",
      "epoch : 135 [5/23] Train loss: 0.60105,Valid loss: 0.93119, time : 11.019214391708374 lr : 0.2574846067639487\n",
      "epoch : 135 [6/23] Train loss: 0.60384,Valid loss: 0.91424, time : 10.687472105026245 lr : 0.2574846067639487\n",
      "epoch : 135 [7/23] Train loss: 0.59470,Valid loss: 0.88863, time : 10.974556922912598 lr : 0.2574846067639487\n",
      "epoch : 135 [8/23] Train loss: 0.62834,Valid loss: 0.90669, time : 10.966875791549683 lr : 0.2574846067639487\n",
      "epoch : 135 [9/23] Train loss: 0.67435,Valid loss: 0.95896, time : 10.74582576751709 lr : 0.2574846067639487\n",
      "epoch : 135 [10/23] Train loss: 0.73042,Valid loss: 0.95659, time : 10.922907829284668 lr : 0.2574846067639487\n",
      "epoch : 135 [11/23] Train loss: 0.67879,Valid loss: 0.90396, time : 10.680745124816895 lr : 0.2574846067639487\n",
      "epoch : 135 [12/23] Train loss: 0.64103,Valid loss: 0.91503, time : 10.206393718719482 lr : 0.2574846067639487\n",
      "epoch : 135 [13/23] Train loss: 0.63680,Valid loss: 0.85006, time : 10.547785758972168 lr : 0.2574846067639487\n",
      "epoch : 135 [14/23] Train loss: 0.62175,Valid loss: 0.87127, time : 10.654039144515991 lr : 0.2574846067639487\n",
      "epoch : 135 [15/23] Train loss: 0.61880,Valid loss: 0.84459, time : 10.318655252456665 lr : 0.2574846067639487\n",
      "epoch : 135 [16/23] Train loss: 0.62344,Valid loss: 0.85490, time : 10.23099422454834 lr : 0.2574846067639487\n",
      "epoch : 135 [17/23] Train loss: 0.60548,Valid loss: 0.84985, time : 10.344633102416992 lr : 0.2574846067639487\n",
      "epoch : 135 [18/23] Train loss: 0.58511,Valid loss: 0.86772, time : 10.599923849105835 lr : 0.2574846067639487\n",
      "epoch : 135 [19/23] Train loss: 0.58469,Valid loss: 0.85333, time : 10.848375797271729 lr : 0.2574846067639487\n",
      "epoch : 135 [20/23] Train loss: 0.60376,Valid loss: 0.85858, time : 10.134033918380737 lr : 0.2574846067639487\n",
      "epoch : 135 [21/23] Train loss: 0.61467,Valid loss: 0.85987, time : 10.355244874954224 lr : 0.2574846067639487\n",
      "epoch : 135 [22/23] Train loss: 0.60038,Valid loss: 0.86399, time : 9.6021728515625 lr : 0.2574846067639487\n",
      "epoch : 136 [0/23] Train loss: 0.61148,Valid loss: 0.94642, time : 10.267643690109253 lr : 0.2549097606963092\n",
      "epoch : 136 [1/23] Train loss: 0.59920,Valid loss: 0.90066, time : 10.284111499786377 lr : 0.2549097606963092\n",
      "epoch : 136 [2/23] Train loss: 0.58656,Valid loss: 0.84585, time : 10.719431400299072 lr : 0.2549097606963092\n",
      "epoch : 136 [3/23] Train loss: 0.61858,Valid loss: 0.85738, time : 10.423500537872314 lr : 0.2549097606963092\n",
      "epoch : 136 [4/23] Train loss: 0.58951,Valid loss: 0.87689, time : 10.799062490463257 lr : 0.2549097606963092\n",
      "epoch : 136 [5/23] Train loss: 0.58776,Valid loss: 0.86251, time : 10.50241732597351 lr : 0.2549097606963092\n",
      "epoch : 136 [6/23] Train loss: 0.59196,Valid loss: 0.87853, time : 10.602399826049805 lr : 0.2549097606963092\n",
      "epoch : 136 [7/23] Train loss: 0.59144,Valid loss: 0.91726, time : 10.626063585281372 lr : 0.2549097606963092\n",
      "epoch : 136 [8/23] Train loss: 0.58600,Valid loss: 0.89190, time : 10.652467727661133 lr : 0.2549097606963092\n",
      "epoch : 136 [9/23] Train loss: 0.59046,Valid loss: 0.83516, time : 10.176957845687866 lr : 0.2549097606963092\n",
      "epoch : 136 [10/23] Train loss: 0.59233,Valid loss: 0.85327, time : 10.327885150909424 lr : 0.2549097606963092\n",
      "epoch : 136 [11/23] Train loss: 0.58468,Valid loss: 0.84777, time : 10.279776811599731 lr : 0.2549097606963092\n",
      "epoch : 136 [12/23] Train loss: 0.59027,Valid loss: 0.86984, time : 10.43927788734436 lr : 0.2549097606963092\n",
      "epoch : 136 [13/23] Train loss: 0.59750,Valid loss: 0.87278, time : 10.09715485572815 lr : 0.2549097606963092\n",
      "epoch : 136 [14/23] Train loss: 0.57708,Valid loss: 0.86089, time : 10.047826051712036 lr : 0.2549097606963092\n",
      "epoch : 136 [15/23] Train loss: 0.58018,Valid loss: 0.85419, time : 10.039544343948364 lr : 0.2549097606963092\n",
      "epoch : 136 [16/23] Train loss: 0.59357,Valid loss: 0.85757, time : 10.031786680221558 lr : 0.2549097606963092\n",
      "epoch : 136 [17/23] Train loss: 0.60288,Valid loss: 0.87902, time : 10.284607648849487 lr : 0.2549097606963092\n",
      "epoch : 136 [18/23] Train loss: 0.59749,Valid loss: 0.88678, time : 9.955344676971436 lr : 0.2549097606963092\n",
      "epoch : 136 [19/23] Train loss: 0.59420,Valid loss: 0.92046, time : 10.169746398925781 lr : 0.2549097606963092\n",
      "epoch : 136 [20/23] Train loss: 0.57922,Valid loss: 0.86358, time : 10.091920614242554 lr : 0.2549097606963092\n",
      "epoch : 136 [21/23] Train loss: 0.56684,Valid loss: 0.90703, time : 10.513198137283325 lr : 0.2549097606963092\n",
      "epoch : 136 [22/23] Train loss: 0.61030,Valid loss: 0.87975, time : 9.696675300598145 lr : 0.2549097606963092\n",
      "epoch : 137 [0/23] Train loss: 0.59946,Valid loss: 0.90062, time : 11.019021272659302 lr : 0.2523606630893461\n",
      "epoch : 137 [1/23] Train loss: 0.59634,Valid loss: 0.86614, time : 10.448731184005737 lr : 0.2523606630893461\n",
      "epoch : 137 [2/23] Train loss: 0.59569,Valid loss: 0.89396, time : 10.2509446144104 lr : 0.2523606630893461\n",
      "epoch : 137 [3/23] Train loss: 0.58949,Valid loss: 0.89470, time : 10.304709911346436 lr : 0.2523606630893461\n",
      "epoch : 137 [4/23] Train loss: 0.60968,Valid loss: 0.91831, time : 10.332772016525269 lr : 0.2523606630893461\n",
      "epoch : 137 [5/23] Train loss: 0.61371,Valid loss: 0.91876, time : 10.477539300918579 lr : 0.2523606630893461\n",
      "epoch : 137 [6/23] Train loss: 0.59384,Valid loss: 0.88764, time : 10.574463844299316 lr : 0.2523606630893461\n",
      "epoch : 137 [7/23] Train loss: 0.60170,Valid loss: 0.85718, time : 10.234085321426392 lr : 0.2523606630893461\n",
      "epoch : 137 [8/23] Train loss: 0.57563,Valid loss: 0.85025, time : 10.569241046905518 lr : 0.2523606630893461\n",
      "epoch : 137 [9/23] Train loss: 0.59520,Valid loss: 0.85052, time : 10.79625678062439 lr : 0.2523606630893461\n",
      "epoch : 137 [10/23] Train loss: 0.59228,Valid loss: 0.87085, time : 10.67061161994934 lr : 0.2523606630893461\n",
      "epoch : 137 [11/23] Train loss: 0.58924,Valid loss: 0.89282, time : 10.653765439987183 lr : 0.2523606630893461\n",
      "epoch : 137 [12/23] Train loss: 0.57620,Valid loss: 0.87498, time : 10.714892148971558 lr : 0.2523606630893461\n",
      "epoch : 137 [13/23] Train loss: 0.59219,Valid loss: 0.83423, time : 10.736434936523438 lr : 0.2523606630893461\n",
      "epoch : 137 [14/23] Train loss: 0.57940,Valid loss: 0.87342, time : 10.461201190948486 lr : 0.2523606630893461\n",
      "epoch : 137 [15/23] Train loss: 0.58997,Valid loss: 0.81685, time : 10.756479740142822 lr : 0.2523606630893461\n",
      "epoch : 137 [16/23] Train loss: 0.58193,Valid loss: 0.85464, time : 10.685478448867798 lr : 0.2523606630893461\n",
      "epoch : 137 [17/23] Train loss: 0.57774,Valid loss: 0.85349, time : 10.616178750991821 lr : 0.2523606630893461\n",
      "epoch : 137 [18/23] Train loss: 0.59518,Valid loss: 0.82755, time : 10.873673915863037 lr : 0.2523606630893461\n",
      "epoch : 137 [19/23] Train loss: 0.58574,Valid loss: 0.85460, time : 10.715712308883667 lr : 0.2523606630893461\n",
      "epoch : 137 [20/23] Train loss: 0.59336,Valid loss: 0.86806, time : 10.713636636734009 lr : 0.2523606630893461\n",
      "epoch : 137 [21/23] Train loss: 0.59335,Valid loss: 0.84220, time : 10.48617696762085 lr : 0.2523606630893461\n",
      "epoch : 137 [22/23] Train loss: 0.60667,Valid loss: 0.94683, time : 9.773505926132202 lr : 0.2523606630893461\n",
      "epoch : 138 [0/23] Train loss: 0.60125,Valid loss: 0.90966, time : 10.414853811264038 lr : 0.24983705645845267\n",
      "epoch : 138 [1/23] Train loss: 0.60016,Valid loss: 0.87334, time : 10.519293308258057 lr : 0.24983705645845267\n",
      "epoch : 138 [2/23] Train loss: 0.57830,Valid loss: 0.82717, time : 11.128193616867065 lr : 0.24983705645845267\n",
      "epoch : 138 [3/23] Train loss: 0.58397,Valid loss: 0.90426, time : 10.56821870803833 lr : 0.24983705645845267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 138 [4/23] Train loss: 0.59904,Valid loss: 0.86128, time : 10.81711196899414 lr : 0.24983705645845267\n",
      "epoch : 138 [5/23] Train loss: 0.57724,Valid loss: 0.85327, time : 10.74061894416809 lr : 0.24983705645845267\n",
      "epoch : 138 [6/23] Train loss: 0.57369,Valid loss: 0.85863, time : 10.770637273788452 lr : 0.24983705645845267\n",
      "epoch : 138 [7/23] Train loss: 0.58424,Valid loss: 0.83369, time : 10.50908374786377 lr : 0.24983705645845267\n",
      "epoch : 138 [8/23] Train loss: 0.58699,Valid loss: 0.82641, time : 10.61374568939209 lr : 0.24983705645845267\n",
      "epoch : 138 [9/23] Train loss: 0.55923,Valid loss: 0.86662, time : 10.704900979995728 lr : 0.24983705645845267\n",
      "epoch : 138 [10/23] Train loss: 0.56318,Valid loss: 0.84451, time : 10.915932178497314 lr : 0.24983705645845267\n",
      "epoch : 138 [11/23] Train loss: 0.59633,Valid loss: 0.82687, time : 10.757262468338013 lr : 0.24983705645845267\n",
      "epoch : 138 [12/23] Train loss: 0.59062,Valid loss: 0.85201, time : 10.624607801437378 lr : 0.24983705645845267\n",
      "epoch : 138 [13/23] Train loss: 0.59550,Valid loss: 0.88326, time : 10.625364780426025 lr : 0.24983705645845267\n",
      "epoch : 138 [14/23] Train loss: 0.59810,Valid loss: 0.90122, time : 10.450090646743774 lr : 0.24983705645845267\n",
      "epoch : 138 [15/23] Train loss: 0.60536,Valid loss: 0.88188, time : 10.804372072219849 lr : 0.24983705645845267\n",
      "epoch : 138 [16/23] Train loss: 0.59285,Valid loss: 0.83524, time : 10.626704692840576 lr : 0.24983705645845267\n",
      "epoch : 138 [17/23] Train loss: 0.57507,Valid loss: 0.82943, time : 10.361347198486328 lr : 0.24983705645845267\n",
      "epoch : 138 [18/23] Train loss: 0.59657,Valid loss: 0.84226, time : 10.397224426269531 lr : 0.24983705645845267\n",
      "epoch : 138 [19/23] Train loss: 0.61792,Valid loss: 0.87955, time : 10.193371057510376 lr : 0.24983705645845267\n",
      "epoch : 138 [20/23] Train loss: 0.63197,Valid loss: 0.89726, time : 10.2303626537323 lr : 0.24983705645845267\n",
      "epoch : 138 [21/23] Train loss: 0.61779,Valid loss: 0.86821, time : 10.494940280914307 lr : 0.24983705645845267\n",
      "epoch : 138 [22/23] Train loss: 0.63006,Valid loss: 0.91178, time : 9.63952898979187 lr : 0.24983705645845267\n",
      "epoch : 139 [0/23] Train loss: 0.66883,Valid loss: 1.00798, time : 10.46451187133789 lr : 0.24733868589386815\n",
      "epoch : 139 [1/23] Train loss: 0.74686,Valid loss: 0.91836, time : 10.246125936508179 lr : 0.24733868589386815\n",
      "epoch : 139 [2/23] Train loss: 0.63053,Valid loss: 0.86072, time : 10.717227697372437 lr : 0.24733868589386815\n",
      "epoch : 139 [3/23] Train loss: 0.62309,Valid loss: 0.90817, time : 10.261131525039673 lr : 0.24733868589386815\n",
      "epoch : 139 [4/23] Train loss: 0.61983,Valid loss: 0.87940, time : 10.780519008636475 lr : 0.24733868589386815\n",
      "epoch : 139 [5/23] Train loss: 0.59887,Valid loss: 0.84687, time : 10.46578598022461 lr : 0.24733868589386815\n",
      "epoch : 139 [6/23] Train loss: 0.58696,Valid loss: 0.87099, time : 10.438392877578735 lr : 0.24733868589386815\n",
      "epoch : 139 [7/23] Train loss: 0.60566,Valid loss: 0.84598, time : 10.430604219436646 lr : 0.24733868589386815\n",
      "epoch : 139 [8/23] Train loss: 0.60368,Valid loss: 0.84833, time : 10.578236818313599 lr : 0.24733868589386815\n",
      "epoch : 139 [9/23] Train loss: 0.58682,Valid loss: 0.85611, time : 10.745233297348022 lr : 0.24733868589386815\n",
      "epoch : 139 [10/23] Train loss: 0.58541,Valid loss: 0.84721, time : 10.64372992515564 lr : 0.24733868589386815\n",
      "epoch : 139 [11/23] Train loss: 0.59241,Valid loss: 0.94398, time : 10.593436002731323 lr : 0.24733868589386815\n",
      "epoch : 139 [12/23] Train loss: 0.61641,Valid loss: 0.89220, time : 10.826953411102295 lr : 0.24733868589386815\n",
      "epoch : 139 [13/23] Train loss: 0.57752,Valid loss: 0.86159, time : 10.501771211624146 lr : 0.24733868589386815\n",
      "epoch : 139 [14/23] Train loss: 0.59951,Valid loss: 0.87578, time : 10.687891006469727 lr : 0.24733868589386815\n",
      "epoch : 139 [15/23] Train loss: 0.57890,Valid loss: 0.90003, time : 10.313177347183228 lr : 0.24733868589386815\n",
      "epoch : 139 [16/23] Train loss: 0.58682,Valid loss: 0.84621, time : 10.69955039024353 lr : 0.24733868589386815\n",
      "epoch : 139 [17/23] Train loss: 0.56023,Valid loss: 0.83561, time : 10.594864130020142 lr : 0.24733868589386815\n",
      "epoch : 139 [18/23] Train loss: 0.57529,Valid loss: 0.84817, time : 10.697173595428467 lr : 0.24733868589386815\n",
      "epoch : 139 [19/23] Train loss: 0.57537,Valid loss: 0.82674, time : 10.356568574905396 lr : 0.24733868589386815\n",
      "epoch : 139 [20/23] Train loss: 0.56687,Valid loss: 0.84236, time : 10.649349927902222 lr : 0.24733868589386815\n",
      "epoch : 139 [21/23] Train loss: 0.57103,Valid loss: 0.81789, time : 10.49208378791809 lr : 0.24733868589386815\n",
      "epoch : 139 [22/23] Train loss: 0.57337,Valid loss: 0.84628, time : 9.710240125656128 lr : 0.24733868589386815\n",
      "epoch : 140 [0/23] Train loss: 0.57436,Valid loss: 0.85136, time : 10.483731985092163 lr : 0.24486529903492946\n",
      "epoch : 140 [1/23] Train loss: 0.58875,Valid loss: 0.83330, time : 10.571440696716309 lr : 0.24486529903492946\n",
      "epoch : 140 [2/23] Train loss: 0.56910,Valid loss: 1.07305, time : 9.95847749710083 lr : 0.24486529903492946\n",
      "epoch : 140 [3/23] Train loss: 0.57317,Valid loss: 0.86936, time : 10.649614572525024 lr : 0.24486529903492946\n",
      "epoch : 140 [4/23] Train loss: 0.57518,Valid loss: 0.85730, time : 10.750232934951782 lr : 0.24486529903492946\n",
      "epoch : 140 [5/23] Train loss: 0.56567,Valid loss: 0.85757, time : 10.551981210708618 lr : 0.24486529903492946\n",
      "epoch : 140 [6/23] Train loss: 0.58085,Valid loss: 0.81444, time : 10.708997011184692 lr : 0.24486529903492946\n",
      "epoch : 140 [7/23] Train loss: 0.57148,Valid loss: 0.82831, time : 10.544158697128296 lr : 0.24486529903492946\n",
      "epoch : 140 [8/23] Train loss: 0.57851,Valid loss: 0.86147, time : 10.6569242477417 lr : 0.24486529903492946\n",
      "epoch : 140 [9/23] Train loss: 0.57236,Valid loss: 0.86524, time : 10.77600622177124 lr : 0.24486529903492946\n",
      "epoch : 140 [10/23] Train loss: 0.57153,Valid loss: 0.85246, time : 10.672745704650879 lr : 0.24486529903492946\n",
      "epoch : 140 [11/23] Train loss: 0.56131,Valid loss: 0.84080, time : 10.834432601928711 lr : 0.24486529903492946\n",
      "epoch : 140 [12/23] Train loss: 0.60670,Valid loss: 0.81473, time : 10.52286696434021 lr : 0.24486529903492946\n",
      "epoch : 140 [13/23] Train loss: 0.58069,Valid loss: 0.87527, time : 10.795896768569946 lr : 0.24486529903492946\n",
      "epoch : 140 [14/23] Train loss: 0.59025,Valid loss: 0.84520, time : 10.515864372253418 lr : 0.24486529903492946\n",
      "epoch : 140 [15/23] Train loss: 0.56444,Valid loss: 0.87372, time : 10.59094524383545 lr : 0.24486529903492946\n",
      "epoch : 140 [16/23] Train loss: 0.56804,Valid loss: 0.86276, time : 10.953647375106812 lr : 0.24486529903492946\n",
      "epoch : 140 [17/23] Train loss: 0.55627,Valid loss: 0.84906, time : 10.725771188735962 lr : 0.24486529903492946\n",
      "epoch : 140 [18/23] Train loss: 0.56834,Valid loss: 0.82659, time : 10.539437055587769 lr : 0.24486529903492946\n",
      "epoch : 140 [19/23] Train loss: 0.56533,Valid loss: 0.85538, time : 10.792352199554443 lr : 0.24486529903492946\n",
      "epoch : 140 [20/23] Train loss: 0.58016,Valid loss: 0.83535, time : 10.618870973587036 lr : 0.24486529903492946\n",
      "epoch : 140 [21/23] Train loss: 0.56041,Valid loss: 0.81274, time : 10.670016288757324 lr : 0.24486529903492946\n",
      "epoch : 140 [22/23] Train loss: 0.55904,Valid loss: 0.86644, time : 9.740042686462402 lr : 0.24486529903492946\n",
      "epoch : 141 [0/23] Train loss: 0.57272,Valid loss: 0.87774, time : 10.727883100509644 lr : 0.24241664604458016\n",
      "epoch : 141 [1/23] Train loss: 0.57209,Valid loss: 0.83720, time : 9.958232164382935 lr : 0.24241664604458016\n",
      "epoch : 141 [2/23] Train loss: 0.55370,Valid loss: 0.83011, time : 10.333064317703247 lr : 0.24241664604458016\n",
      "epoch : 141 [3/23] Train loss: 0.55410,Valid loss: 0.81938, time : 10.123329639434814 lr : 0.24241664604458016\n",
      "epoch : 141 [4/23] Train loss: 0.55769,Valid loss: 0.83513, time : 10.259091138839722 lr : 0.24241664604458016\n",
      "epoch : 141 [5/23] Train loss: 0.56917,Valid loss: 0.87402, time : 10.205336809158325 lr : 0.24241664604458016\n",
      "epoch : 141 [6/23] Train loss: 0.59845,Valid loss: 0.88831, time : 10.419894218444824 lr : 0.24241664604458016\n",
      "epoch : 141 [7/23] Train loss: 0.58193,Valid loss: 0.95158, time : 10.402873754501343 lr : 0.24241664604458016\n",
      "epoch : 141 [8/23] Train loss: 0.60431,Valid loss: 0.91637, time : 10.361797571182251 lr : 0.24241664604458016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 141 [9/23] Train loss: 0.64443,Valid loss: 1.00276, time : 10.324548244476318 lr : 0.24241664604458016\n",
      "epoch : 141 [10/23] Train loss: 0.61828,Valid loss: 0.92188, time : 10.44212818145752 lr : 0.24241664604458016\n",
      "epoch : 141 [11/23] Train loss: 0.59308,Valid loss: 0.87314, time : 10.103599309921265 lr : 0.24241664604458016\n",
      "epoch : 141 [12/23] Train loss: 0.58928,Valid loss: 0.86249, time : 10.428609848022461 lr : 0.24241664604458016\n",
      "epoch : 141 [13/23] Train loss: 0.57651,Valid loss: 0.87003, time : 10.300443887710571 lr : 0.24241664604458016\n",
      "epoch : 141 [14/23] Train loss: 0.57413,Valid loss: 0.85731, time : 10.635679244995117 lr : 0.24241664604458016\n",
      "epoch : 141 [15/23] Train loss: 0.58082,Valid loss: 0.85886, time : 10.478378295898438 lr : 0.24241664604458016\n",
      "epoch : 141 [16/23] Train loss: 0.58936,Valid loss: 0.81195, time : 10.953158378601074 lr : 0.24241664604458016\n",
      "epoch : 141 [17/23] Train loss: 0.57447,Valid loss: 0.82403, time : 10.68017315864563 lr : 0.24241664604458016\n",
      "epoch : 141 [18/23] Train loss: 0.57700,Valid loss: 0.81011, time : 10.481920003890991 lr : 0.24241664604458016\n",
      "epoch : 141 [19/23] Train loss: 0.56859,Valid loss: 0.86328, time : 11.266420125961304 lr : 0.24241664604458016\n",
      "epoch : 141 [20/23] Train loss: 0.58144,Valid loss: 0.84482, time : 10.531475305557251 lr : 0.24241664604458016\n",
      "epoch : 141 [21/23] Train loss: 0.59291,Valid loss: 0.91197, time : 10.381067276000977 lr : 0.24241664604458016\n",
      "epoch : 141 [22/23] Train loss: 0.56848,Valid loss: 0.86293, time : 9.791544437408447 lr : 0.24241664604458016\n",
      "epoch : 142 [0/23] Train loss: 0.59451,Valid loss: 0.85909, time : 10.623333930969238 lr : 0.23999247958413436\n",
      "epoch : 142 [1/23] Train loss: 0.57934,Valid loss: 0.87365, time : 10.419718503952026 lr : 0.23999247958413436\n",
      "epoch : 142 [2/23] Train loss: 0.57629,Valid loss: 0.85873, time : 10.86477017402649 lr : 0.23999247958413436\n",
      "epoch : 142 [3/23] Train loss: 0.57882,Valid loss: 0.84103, time : 10.149182558059692 lr : 0.23999247958413436\n",
      "epoch : 142 [4/23] Train loss: 0.57927,Valid loss: 0.81202, time : 10.578181505203247 lr : 0.23999247958413436\n",
      "epoch : 142 [5/23] Train loss: 0.56111,Valid loss: 0.86620, time : 10.642089605331421 lr : 0.23999247958413436\n",
      "epoch : 142 [6/23] Train loss: 0.58432,Valid loss: 0.93058, time : 10.479313850402832 lr : 0.23999247958413436\n",
      "epoch : 142 [7/23] Train loss: 0.60526,Valid loss: 0.84311, time : 10.39408540725708 lr : 0.23999247958413436\n",
      "epoch : 142 [8/23] Train loss: 0.56896,Valid loss: 0.90079, time : 10.555282354354858 lr : 0.23999247958413436\n",
      "epoch : 142 [9/23] Train loss: 0.56210,Valid loss: 0.85088, time : 10.844176769256592 lr : 0.23999247958413436\n",
      "epoch : 142 [10/23] Train loss: 0.57364,Valid loss: 0.83156, time : 10.780533075332642 lr : 0.23999247958413436\n",
      "epoch : 142 [11/23] Train loss: 0.56150,Valid loss: 0.81301, time : 11.167475938796997 lr : 0.23999247958413436\n",
      "epoch : 142 [12/23] Train loss: 0.55947,Valid loss: 0.81282, time : 10.831017255783081 lr : 0.23999247958413436\n",
      "epoch : 142 [13/23] Train loss: 0.57025,Valid loss: 0.84357, time : 10.916732549667358 lr : 0.23999247958413436\n",
      "epoch : 142 [14/23] Train loss: 0.56420,Valid loss: 0.80172, time : 10.534772157669067 lr : 0.23999247958413436\n",
      "epoch : 142 [15/23] Train loss: 0.55562,Valid loss: 0.88668, time : 10.550909280776978 lr : 0.23999247958413436\n",
      "epoch : 142 [16/23] Train loss: 0.57704,Valid loss: 0.84693, time : 10.470685243606567 lr : 0.23999247958413436\n",
      "epoch : 142 [17/23] Train loss: 0.58596,Valid loss: 0.83860, time : 10.316423654556274 lr : 0.23999247958413436\n",
      "epoch : 142 [18/23] Train loss: 0.56364,Valid loss: 0.80937, time : 10.45550012588501 lr : 0.23999247958413436\n",
      "epoch : 142 [19/23] Train loss: 0.56078,Valid loss: 0.86456, time : 10.24406385421753 lr : 0.23999247958413436\n",
      "epoch : 142 [20/23] Train loss: 0.56776,Valid loss: 0.86143, time : 10.574822187423706 lr : 0.23999247958413436\n",
      "epoch : 142 [21/23] Train loss: 0.56001,Valid loss: 0.82351, time : 10.803351163864136 lr : 0.23999247958413436\n",
      "epoch : 142 [22/23] Train loss: 0.54706,Valid loss: 0.81358, time : 9.795089960098267 lr : 0.23999247958413436\n",
      "epoch : 143 [0/23] Train loss: 0.56121,Valid loss: 0.82948, time : 10.885213136672974 lr : 0.23759255478829303\n",
      "epoch : 143 [1/23] Train loss: 0.56223,Valid loss: 0.79928, time : 10.382922887802124 lr : 0.23759255478829303\n",
      "epoch : 143 [2/23] Train loss: 0.55412,Valid loss: 0.79046, time : 10.01874828338623 lr : 0.23759255478829303\n",
      "epoch : 143 [3/23] Train loss: 0.55172,Valid loss: 0.84176, time : 10.39410662651062 lr : 0.23759255478829303\n",
      "epoch : 143 [4/23] Train loss: 0.55622,Valid loss: 0.80097, time : 10.15205717086792 lr : 0.23759255478829303\n",
      "epoch : 143 [5/23] Train loss: 0.53567,Valid loss: 0.87265, time : 10.384723424911499 lr : 0.23759255478829303\n",
      "epoch : 143 [6/23] Train loss: 0.56212,Valid loss: 0.80716, time : 10.511482954025269 lr : 0.23759255478829303\n",
      "epoch : 143 [7/23] Train loss: 0.55215,Valid loss: 0.84667, time : 10.434807300567627 lr : 0.23759255478829303\n",
      "epoch : 143 [8/23] Train loss: 0.54848,Valid loss: 0.80849, time : 9.850851774215698 lr : 0.23759255478829303\n",
      "epoch : 143 [9/23] Train loss: 0.54812,Valid loss: 0.84389, time : 10.310801029205322 lr : 0.23759255478829303\n",
      "epoch : 143 [10/23] Train loss: 0.55640,Valid loss: 0.79153, time : 9.846294403076172 lr : 0.23759255478829303\n",
      "epoch : 143 [11/23] Train loss: 0.56146,Valid loss: 0.79778, time : 10.443560361862183 lr : 0.23759255478829303\n",
      "epoch : 143 [12/23] Train loss: 0.56049,Valid loss: 0.79636, time : 10.528136014938354 lr : 0.23759255478829303\n",
      "epoch : 143 [13/23] Train loss: 0.55502,Valid loss: 0.82069, time : 10.250563144683838 lr : 0.23759255478829303\n",
      "epoch : 143 [14/23] Train loss: 0.55159,Valid loss: 0.82448, time : 10.355141401290894 lr : 0.23759255478829303\n",
      "epoch : 143 [15/23] Train loss: 0.57064,Valid loss: 0.81144, time : 10.407417297363281 lr : 0.23759255478829303\n",
      "epoch : 143 [16/23] Train loss: 0.56423,Valid loss: 0.81475, time : 10.287534236907959 lr : 0.23759255478829303\n",
      "epoch : 143 [17/23] Train loss: 0.56506,Valid loss: 0.79126, time : 10.246655464172363 lr : 0.23759255478829303\n",
      "epoch : 143 [18/23] Train loss: 0.56421,Valid loss: 0.87694, time : 10.212521314620972 lr : 0.23759255478829303\n",
      "epoch : 143 [19/23] Train loss: 0.55450,Valid loss: 0.79845, time : 9.97760558128357 lr : 0.23759255478829303\n",
      "epoch : 143 [20/23] Train loss: 0.56398,Valid loss: 0.80695, time : 10.43219804763794 lr : 0.23759255478829303\n",
      "epoch : 143 [21/23] Train loss: 0.55394,Valid loss: 0.80144, time : 10.540324926376343 lr : 0.23759255478829303\n",
      "epoch : 143 [22/23] Train loss: 0.56188,Valid loss: 0.89136, time : 9.517642498016357 lr : 0.23759255478829303\n",
      "epoch : 144 [0/23] Train loss: 0.56773,Valid loss: 0.79208, time : 10.683622598648071 lr : 0.2352166292404101\n",
      "epoch : 144 [1/23] Train loss: 0.55466,Valid loss: 0.82818, time : 10.362310409545898 lr : 0.2352166292404101\n",
      "epoch : 144 [2/23] Train loss: 0.54071,Valid loss: 0.78161, time : 10.15101146697998 lr : 0.2352166292404101\n",
      "epoch : 144 [3/23] Train loss: 0.55513,Valid loss: 0.79794, time : 10.425297260284424 lr : 0.2352166292404101\n",
      "epoch : 144 [4/23] Train loss: 0.53298,Valid loss: 0.79626, time : 10.451094150543213 lr : 0.2352166292404101\n",
      "epoch : 144 [5/23] Train loss: 0.54731,Valid loss: 0.79158, time : 10.331630229949951 lr : 0.2352166292404101\n",
      "epoch : 144 [6/23] Train loss: 0.52802,Valid loss: 0.82235, time : 10.380778312683105 lr : 0.2352166292404101\n",
      "epoch : 144 [7/23] Train loss: 0.55813,Valid loss: 0.79124, time : 10.23617959022522 lr : 0.2352166292404101\n",
      "epoch : 144 [8/23] Train loss: 0.54302,Valid loss: 0.80013, time : 10.083484172821045 lr : 0.2352166292404101\n",
      "epoch : 144 [9/23] Train loss: 0.53076,Valid loss: 0.79381, time : 10.495407342910767 lr : 0.2352166292404101\n",
      "epoch : 144 [10/23] Train loss: 0.57042,Valid loss: 0.78438, time : 10.979654312133789 lr : 0.2352166292404101\n",
      "epoch : 144 [11/23] Train loss: 0.54112,Valid loss: 0.80896, time : 10.614786148071289 lr : 0.2352166292404101\n",
      "epoch : 144 [12/23] Train loss: 0.54917,Valid loss: 0.80363, time : 10.14029836654663 lr : 0.2352166292404101\n",
      "epoch : 144 [13/23] Train loss: 0.54512,Valid loss: 0.79752, time : 10.62656307220459 lr : 0.2352166292404101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 144 [14/23] Train loss: 0.53417,Valid loss: 0.79101, time : 10.800448417663574 lr : 0.2352166292404101\n",
      "epoch : 144 [15/23] Train loss: 0.55764,Valid loss: 0.78221, time : 10.332665920257568 lr : 0.2352166292404101\n",
      "epoch : 144 [16/23] Train loss: 0.54592,Valid loss: 0.78408, time : 10.661656856536865 lr : 0.2352166292404101\n",
      "epoch : 144 [17/23] Train loss: 0.53397,Valid loss: 0.77750, time : 10.618871688842773 lr : 0.2352166292404101\n",
      "epoch : 144 [18/23] Train loss: 0.54275,Valid loss: 0.81903, time : 10.802757024765015 lr : 0.2352166292404101\n",
      "epoch : 144 [19/23] Train loss: 0.53994,Valid loss: 0.80246, time : 10.734979152679443 lr : 0.2352166292404101\n",
      "epoch : 144 [20/23] Train loss: 0.53057,Valid loss: 0.78561, time : 10.833553791046143 lr : 0.2352166292404101\n",
      "epoch : 144 [21/23] Train loss: 0.54779,Valid loss: 0.80588, time : 10.495180130004883 lr : 0.2352166292404101\n",
      "epoch : 144 [22/23] Train loss: 0.54135,Valid loss: 0.82740, time : 9.739106178283691 lr : 0.2352166292404101\n",
      "epoch : 145 [0/23] Train loss: 0.54614,Valid loss: 0.82426, time : 10.721822261810303 lr : 0.232864462948006\n",
      "epoch : 145 [1/23] Train loss: 0.52675,Valid loss: 0.78588, time : 10.084884405136108 lr : 0.232864462948006\n",
      "epoch : 145 [2/23] Train loss: 0.55507,Valid loss: 0.79096, time : 10.338937759399414 lr : 0.232864462948006\n",
      "epoch : 145 [3/23] Train loss: 0.53543,Valid loss: 0.80073, time : 9.934744596481323 lr : 0.232864462948006\n",
      "epoch : 145 [4/23] Train loss: 0.54358,Valid loss: 0.79069, time : 10.348630666732788 lr : 0.232864462948006\n",
      "epoch : 145 [5/23] Train loss: 0.53430,Valid loss: 0.81008, time : 9.865358591079712 lr : 0.232864462948006\n",
      "epoch : 145 [6/23] Train loss: 0.55445,Valid loss: 0.77971, time : 10.301734685897827 lr : 0.232864462948006\n",
      "epoch : 145 [7/23] Train loss: 0.53742,Valid loss: 0.83515, time : 10.136600732803345 lr : 0.232864462948006\n",
      "epoch : 145 [8/23] Train loss: 0.53342,Valid loss: 0.80025, time : 10.869449138641357 lr : 0.232864462948006\n",
      "epoch : 145 [9/23] Train loss: 0.53954,Valid loss: 0.79260, time : 10.324880599975586 lr : 0.232864462948006\n",
      "epoch : 145 [10/23] Train loss: 0.55551,Valid loss: 0.81290, time : 10.628383159637451 lr : 0.232864462948006\n",
      "epoch : 145 [11/23] Train loss: 0.56173,Valid loss: 0.79620, time : 10.014883518218994 lr : 0.232864462948006\n",
      "epoch : 145 [12/23] Train loss: 0.56287,Valid loss: 0.78179, time : 10.159506559371948 lr : 0.232864462948006\n",
      "epoch : 145 [13/23] Train loss: 0.54908,Valid loss: 0.78447, time : 10.440398216247559 lr : 0.232864462948006\n",
      "epoch : 145 [14/23] Train loss: 0.52862,Valid loss: 0.82725, time : 10.280535459518433 lr : 0.232864462948006\n",
      "epoch : 145 [15/23] Train loss: 0.55791,Valid loss: 0.87709, time : 10.016987800598145 lr : 0.232864462948006\n",
      "epoch : 145 [16/23] Train loss: 0.56801,Valid loss: 0.83436, time : 10.423062324523926 lr : 0.232864462948006\n",
      "epoch : 145 [17/23] Train loss: 0.55167,Valid loss: 0.80659, time : 10.623460292816162 lr : 0.232864462948006\n",
      "epoch : 145 [18/23] Train loss: 0.55294,Valid loss: 0.81411, time : 10.528247117996216 lr : 0.232864462948006\n",
      "epoch : 145 [19/23] Train loss: 0.56541,Valid loss: 0.85596, time : 11.017080783843994 lr : 0.232864462948006\n",
      "epoch : 145 [20/23] Train loss: 0.53478,Valid loss: 0.79908, time : 10.339719295501709 lr : 0.232864462948006\n",
      "epoch : 145 [21/23] Train loss: 0.54464,Valid loss: 0.78850, time : 10.40500783920288 lr : 0.232864462948006\n",
      "epoch : 145 [22/23] Train loss: 0.55247,Valid loss: 1.07379, time : 9.775147676467896 lr : 0.232864462948006\n",
      "epoch : 146 [0/23] Train loss: 0.55110,Valid loss: 0.83126, time : 9.919899463653564 lr : 0.23053581831852593\n",
      "epoch : 146 [1/23] Train loss: 0.56760,Valid loss: 0.82521, time : 10.717174768447876 lr : 0.23053581831852593\n",
      "epoch : 146 [2/23] Train loss: 0.59237,Valid loss: 0.85551, time : 10.082195281982422 lr : 0.23053581831852593\n",
      "epoch : 146 [3/23] Train loss: 0.56913,Valid loss: 0.84792, time : 10.233553409576416 lr : 0.23053581831852593\n",
      "epoch : 146 [4/23] Train loss: 0.59095,Valid loss: 0.84818, time : 10.222780466079712 lr : 0.23053581831852593\n",
      "epoch : 146 [5/23] Train loss: 0.64629,Valid loss: 0.93788, time : 10.483254671096802 lr : 0.23053581831852593\n",
      "epoch : 146 [6/23] Train loss: 0.62342,Valid loss: 1.04632, time : 10.220704078674316 lr : 0.23053581831852593\n",
      "epoch : 146 [7/23] Train loss: 0.61050,Valid loss: 1.04746, time : 10.602031946182251 lr : 0.23053581831852593\n",
      "epoch : 146 [8/23] Train loss: 0.59035,Valid loss: 0.91121, time : 10.221256732940674 lr : 0.23053581831852593\n",
      "epoch : 146 [9/23] Train loss: 0.58500,Valid loss: 0.87041, time : 10.48063063621521 lr : 0.23053581831852593\n",
      "epoch : 146 [10/23] Train loss: 0.57550,Valid loss: 0.80833, time : 10.25992465019226 lr : 0.23053581831852593\n",
      "epoch : 146 [11/23] Train loss: 0.55900,Valid loss: 0.82926, time : 10.453967809677124 lr : 0.23053581831852593\n",
      "epoch : 146 [12/23] Train loss: 0.54553,Valid loss: 0.82151, time : 10.383934736251831 lr : 0.23053581831852593\n",
      "epoch : 146 [13/23] Train loss: 0.54722,Valid loss: 0.80008, time : 10.422752618789673 lr : 0.23053581831852593\n",
      "epoch : 146 [14/23] Train loss: 0.55212,Valid loss: 0.83821, time : 10.593544960021973 lr : 0.23053581831852593\n",
      "epoch : 146 [15/23] Train loss: 0.55688,Valid loss: 0.85232, time : 10.548338651657104 lr : 0.23053581831852593\n",
      "epoch : 146 [16/23] Train loss: 0.53987,Valid loss: 0.80473, time : 10.472302675247192 lr : 0.23053581831852593\n",
      "epoch : 146 [17/23] Train loss: 0.53801,Valid loss: 0.79911, time : 10.595896482467651 lr : 0.23053581831852593\n",
      "epoch : 146 [18/23] Train loss: 0.53440,Valid loss: 0.80229, time : 10.732855081558228 lr : 0.23053581831852593\n",
      "epoch : 146 [19/23] Train loss: 0.55117,Valid loss: 0.80602, time : 10.40428376197815 lr : 0.23053581831852593\n",
      "epoch : 146 [20/23] Train loss: 0.54205,Valid loss: 0.81251, time : 10.448917627334595 lr : 0.23053581831852593\n",
      "epoch : 146 [21/23] Train loss: 0.56000,Valid loss: 0.83060, time : 10.469285249710083 lr : 0.23053581831852593\n",
      "epoch : 146 [22/23] Train loss: 0.54639,Valid loss: 0.79318, time : 9.595020771026611 lr : 0.23053581831852593\n",
      "epoch : 147 [0/23] Train loss: 0.55815,Valid loss: 0.80017, time : 11.266776084899902 lr : 0.22823046013534068\n",
      "epoch : 147 [1/23] Train loss: 0.55031,Valid loss: 0.78622, time : 10.366576194763184 lr : 0.22823046013534068\n",
      "epoch : 147 [2/23] Train loss: 0.52427,Valid loss: 0.77726, time : 10.040700674057007 lr : 0.22823046013534068\n",
      "epoch : 147 [3/23] Train loss: 0.52415,Valid loss: 0.77541, time : 10.300185441970825 lr : 0.22823046013534068\n",
      "epoch : 147 [4/23] Train loss: 0.53809,Valid loss: 0.76891, time : 9.680185317993164 lr : 0.22823046013534068\n",
      "epoch : 147 [5/23] Train loss: 0.53766,Valid loss: 0.84460, time : 10.160330295562744 lr : 0.22823046013534068\n",
      "epoch : 147 [6/23] Train loss: 0.54646,Valid loss: 0.77585, time : 9.832196950912476 lr : 0.22823046013534068\n",
      "epoch : 147 [7/23] Train loss: 0.52783,Valid loss: 0.78864, time : 10.28022313117981 lr : 0.22823046013534068\n",
      "epoch : 147 [8/23] Train loss: 0.52443,Valid loss: 0.83400, time : 10.030203580856323 lr : 0.22823046013534068\n",
      "epoch : 147 [9/23] Train loss: 0.52219,Valid loss: 0.78552, time : 10.230703115463257 lr : 0.22823046013534068\n",
      "epoch : 147 [10/23] Train loss: 0.52012,Valid loss: 0.78240, time : 9.96602988243103 lr : 0.22823046013534068\n",
      "epoch : 147 [11/23] Train loss: 0.53232,Valid loss: 0.76900, time : 10.25559115409851 lr : 0.22823046013534068\n",
      "epoch : 147 [12/23] Train loss: 0.53779,Valid loss: 0.77743, time : 10.07422161102295 lr : 0.22823046013534068\n",
      "epoch : 147 [13/23] Train loss: 0.53406,Valid loss: 0.77202, time : 9.958441257476807 lr : 0.22823046013534068\n",
      "epoch : 147 [14/23] Train loss: 0.52774,Valid loss: 0.77506, time : 10.52742600440979 lr : 0.22823046013534068\n",
      "epoch : 147 [15/23] Train loss: 0.52527,Valid loss: 0.77246, time : 10.391610145568848 lr : 0.22823046013534068\n",
      "epoch : 147 [16/23] Train loss: 0.53610,Valid loss: 0.78604, time : 10.026897668838501 lr : 0.22823046013534068\n",
      "epoch : 147 [17/23] Train loss: 0.53131,Valid loss: 0.76812, time : 10.277626037597656 lr : 0.22823046013534068\n",
      "epoch : 147 [18/23] Train loss: 0.53300,Valid loss: 0.78159, time : 10.420883178710938 lr : 0.22823046013534068\n",
      "epoch : 147 [19/23] Train loss: 0.52673,Valid loss: 0.78376, time : 10.194425106048584 lr : 0.22823046013534068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 147 [20/23] Train loss: 0.53821,Valid loss: 0.79254, time : 10.130561113357544 lr : 0.22823046013534068\n",
      "epoch : 147 [21/23] Train loss: 0.53011,Valid loss: 0.80261, time : 10.544157028198242 lr : 0.22823046013534068\n",
      "epoch : 147 [22/23] Train loss: 0.54048,Valid loss: 0.79067, time : 9.385972738265991 lr : 0.22823046013534068\n",
      "epoch : 148 [0/23] Train loss: 0.52354,Valid loss: 0.80651, time : 10.41209602355957 lr : 0.22594815553398728\n",
      "epoch : 148 [1/23] Train loss: 0.53433,Valid loss: 0.79058, time : 9.875791788101196 lr : 0.22594815553398728\n",
      "epoch : 148 [2/23] Train loss: 0.52343,Valid loss: 0.78083, time : 10.017206907272339 lr : 0.22594815553398728\n",
      "epoch : 148 [3/23] Train loss: 0.53738,Valid loss: 0.82189, time : 9.987891674041748 lr : 0.22594815553398728\n",
      "epoch : 148 [4/23] Train loss: 0.52783,Valid loss: 0.79982, time : 10.309359312057495 lr : 0.22594815553398728\n",
      "epoch : 148 [5/23] Train loss: 0.53609,Valid loss: 0.77932, time : 9.667407751083374 lr : 0.22594815553398728\n",
      "epoch : 148 [6/23] Train loss: 0.53482,Valid loss: 0.78190, time : 10.098910331726074 lr : 0.22594815553398728\n",
      "epoch : 148 [7/23] Train loss: 0.53104,Valid loss: 0.77740, time : 10.19147777557373 lr : 0.22594815553398728\n",
      "epoch : 148 [8/23] Train loss: 0.51158,Valid loss: 0.79929, time : 10.152894020080566 lr : 0.22594815553398728\n",
      "epoch : 148 [9/23] Train loss: 0.53859,Valid loss: 0.80098, time : 9.933641910552979 lr : 0.22594815553398728\n",
      "epoch : 148 [10/23] Train loss: 0.53778,Valid loss: 0.78592, time : 9.979923963546753 lr : 0.22594815553398728\n",
      "epoch : 148 [11/23] Train loss: 0.53387,Valid loss: 0.77200, time : 10.134439468383789 lr : 0.22594815553398728\n",
      "epoch : 148 [12/23] Train loss: 0.51747,Valid loss: 0.76513, time : 10.090559482574463 lr : 0.22594815553398728\n",
      "epoch : 148 [13/23] Train loss: 0.51858,Valid loss: 0.79141, time : 10.004127979278564 lr : 0.22594815553398728\n",
      "epoch : 148 [14/23] Train loss: 0.53104,Valid loss: 0.78109, time : 9.89109468460083 lr : 0.22594815553398728\n",
      "epoch : 148 [15/23] Train loss: 0.54741,Valid loss: 0.87474, time : 10.087878227233887 lr : 0.22594815553398728\n",
      "epoch : 148 [16/23] Train loss: 0.52948,Valid loss: 0.93629, time : 10.099420070648193 lr : 0.22594815553398728\n",
      "epoch : 148 [17/23] Train loss: 0.55378,Valid loss: 0.87337, time : 9.779642343521118 lr : 0.22594815553398728\n",
      "epoch : 148 [18/23] Train loss: 0.57547,Valid loss: 0.90212, time : 10.1032874584198 lr : 0.22594815553398728\n",
      "epoch : 148 [19/23] Train loss: 0.58657,Valid loss: 0.87925, time : 9.63866901397705 lr : 0.22594815553398728\n",
      "epoch : 148 [20/23] Train loss: 0.56343,Valid loss: 0.85043, time : 10.280450582504272 lr : 0.22594815553398728\n",
      "epoch : 148 [21/23] Train loss: 0.54704,Valid loss: 0.81953, time : 9.648622274398804 lr : 0.22594815553398728\n",
      "epoch : 148 [22/23] Train loss: 0.55610,Valid loss: 0.96864, time : 9.407254695892334 lr : 0.22594815553398728\n",
      "epoch : 149 [0/23] Train loss: 0.58431,Valid loss: 0.83516, time : 10.270643949508667 lr : 0.22368867397864742\n",
      "epoch : 149 [1/23] Train loss: 0.57939,Valid loss: 0.81278, time : 9.923947095870972 lr : 0.22368867397864742\n",
      "epoch : 149 [2/23] Train loss: 0.56273,Valid loss: 0.85346, time : 10.249995708465576 lr : 0.22368867397864742\n",
      "epoch : 149 [3/23] Train loss: 0.55300,Valid loss: 1.00299, time : 9.866486072540283 lr : 0.22368867397864742\n",
      "epoch : 149 [4/23] Train loss: 0.56244,Valid loss: 0.80838, time : 10.199799537658691 lr : 0.22368867397864742\n",
      "epoch : 149 [5/23] Train loss: 0.57651,Valid loss: 0.99972, time : 10.154948234558105 lr : 0.22368867397864742\n",
      "epoch : 149 [6/23] Train loss: 0.54945,Valid loss: 0.86283, time : 9.879945039749146 lr : 0.22368867397864742\n",
      "epoch : 149 [7/23] Train loss: 0.55570,Valid loss: 0.78906, time : 10.046850204467773 lr : 0.22368867397864742\n",
      "epoch : 149 [8/23] Train loss: 0.54793,Valid loss: 0.76791, time : 10.620912790298462 lr : 0.22368867397864742\n",
      "epoch : 149 [9/23] Train loss: 0.53925,Valid loss: 1.22550, time : 10.284783124923706 lr : 0.22368867397864742\n",
      "epoch : 149 [10/23] Train loss: 0.58838,Valid loss: 1.14486, time : 10.280910015106201 lr : 0.22368867397864742\n",
      "epoch : 149 [11/23] Train loss: 0.58719,Valid loss: 1.18558, time : 10.502934217453003 lr : 0.22368867397864742\n",
      "epoch : 149 [12/23] Train loss: 0.61933,Valid loss: 0.99840, time : 10.056222677230835 lr : 0.22368867397864742\n",
      "epoch : 149 [13/23] Train loss: 0.57627,Valid loss: 0.80460, time : 10.050084829330444 lr : 0.22368867397864742\n",
      "epoch : 149 [14/23] Train loss: 0.55710,Valid loss: 0.82476, time : 10.475821256637573 lr : 0.22368867397864742\n",
      "epoch : 149 [15/23] Train loss: 0.54622,Valid loss: 0.78394, time : 10.589101552963257 lr : 0.22368867397864742\n",
      "epoch : 149 [16/23] Train loss: 0.53983,Valid loss: 0.77911, time : 10.46143651008606 lr : 0.22368867397864742\n",
      "epoch : 149 [17/23] Train loss: 0.52977,Valid loss: 0.78493, time : 10.615269660949707 lr : 0.22368867397864742\n",
      "epoch : 149 [18/23] Train loss: 0.54747,Valid loss: 0.77384, time : 10.169638395309448 lr : 0.22368867397864742\n",
      "epoch : 149 [19/23] Train loss: 0.54697,Valid loss: 0.80069, time : 10.591914415359497 lr : 0.22368867397864742\n",
      "epoch : 149 [20/23] Train loss: 0.54128,Valid loss: 0.77393, time : 10.214154481887817 lr : 0.22368867397864742\n",
      "epoch : 149 [21/23] Train loss: 0.53490,Valid loss: 0.78579, time : 10.35423493385315 lr : 0.22368867397864742\n",
      "epoch : 149 [22/23] Train loss: 0.54720,Valid loss: 0.77851, time : 9.498959302902222 lr : 0.22368867397864742\n",
      "epoch : 150 [0/23] Train loss: 0.53449,Valid loss: 0.79020, time : 10.231935977935791 lr : 0.22145178723886094\n",
      "epoch : 150 [1/23] Train loss: 0.53404,Valid loss: 0.78686, time : 9.861480474472046 lr : 0.22145178723886094\n",
      "epoch : 150 [2/23] Train loss: 0.52907,Valid loss: 0.80538, time : 10.094700336456299 lr : 0.22145178723886094\n",
      "epoch : 150 [3/23] Train loss: 0.53253,Valid loss: 0.78895, time : 9.822115898132324 lr : 0.22145178723886094\n",
      "epoch : 150 [4/23] Train loss: 0.52783,Valid loss: 0.78470, time : 10.262060642242432 lr : 0.22145178723886094\n",
      "epoch : 150 [5/23] Train loss: 0.52815,Valid loss: 0.77964, time : 10.243167638778687 lr : 0.22145178723886094\n",
      "epoch : 150 [6/23] Train loss: 0.52241,Valid loss: 0.78232, time : 10.070297479629517 lr : 0.22145178723886094\n",
      "epoch : 150 [7/23] Train loss: 0.52050,Valid loss: 0.78155, time : 10.175490140914917 lr : 0.22145178723886094\n",
      "epoch : 150 [8/23] Train loss: 0.52985,Valid loss: 0.78788, time : 10.355864763259888 lr : 0.22145178723886094\n",
      "epoch : 150 [9/23] Train loss: 0.51251,Valid loss: 0.77954, time : 10.112463474273682 lr : 0.22145178723886094\n",
      "epoch : 150 [10/23] Train loss: 0.50402,Valid loss: 0.78242, time : 10.516398429870605 lr : 0.22145178723886094\n",
      "epoch : 150 [11/23] Train loss: 0.50694,Valid loss: 0.78444, time : 10.433568000793457 lr : 0.22145178723886094\n",
      "epoch : 150 [12/23] Train loss: 0.51085,Valid loss: 0.77092, time : 10.417652130126953 lr : 0.22145178723886094\n",
      "epoch : 150 [13/23] Train loss: 0.53935,Valid loss: 0.79323, time : 10.356383562088013 lr : 0.22145178723886094\n",
      "epoch : 150 [14/23] Train loss: 0.52510,Valid loss: 0.77665, time : 10.256355047225952 lr : 0.22145178723886094\n",
      "epoch : 150 [15/23] Train loss: 0.52862,Valid loss: 0.79314, time : 10.095503807067871 lr : 0.22145178723886094\n",
      "epoch : 150 [16/23] Train loss: 0.53076,Valid loss: 0.78411, time : 10.840124368667603 lr : 0.22145178723886094\n",
      "epoch : 150 [17/23] Train loss: 0.52618,Valid loss: 0.79052, time : 10.443420886993408 lr : 0.22145178723886094\n",
      "epoch : 150 [18/23] Train loss: 0.53763,Valid loss: 0.77422, time : 10.219298839569092 lr : 0.22145178723886094\n",
      "epoch : 150 [19/23] Train loss: 0.51083,Valid loss: 0.78263, time : 9.819687128067017 lr : 0.22145178723886094\n",
      "epoch : 150 [20/23] Train loss: 0.52408,Valid loss: 0.76986, time : 10.097679376602173 lr : 0.22145178723886094\n",
      "epoch : 150 [21/23] Train loss: 0.52841,Valid loss: 0.78516, time : 9.639834642410278 lr : 0.22145178723886094\n",
      "epoch : 150 [22/23] Train loss: 0.51815,Valid loss: 0.77310, time : 9.432689905166626 lr : 0.22145178723886094\n",
      "epoch : 151 [0/23] Train loss: 0.50846,Valid loss: 0.76180, time : 10.346774578094482 lr : 0.21923726936647234\n",
      "epoch : 151 [1/23] Train loss: 0.51705,Valid loss: 0.77799, time : 10.092645168304443 lr : 0.21923726936647234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 151 [2/23] Train loss: 0.51827,Valid loss: 0.75846, time : 10.45810604095459 lr : 0.21923726936647234\n",
      "epoch : 151 [3/23] Train loss: 0.48977,Valid loss: 0.78170, time : 10.338213682174683 lr : 0.21923726936647234\n",
      "epoch : 151 [4/23] Train loss: 0.51177,Valid loss: 0.77759, time : 10.32749891281128 lr : 0.21923726936647234\n",
      "epoch : 151 [5/23] Train loss: 0.51776,Valid loss: 0.78176, time : 10.416146278381348 lr : 0.21923726936647234\n",
      "epoch : 151 [6/23] Train loss: 0.50662,Valid loss: 0.75791, time : 10.397089004516602 lr : 0.21923726936647234\n",
      "epoch : 151 [7/23] Train loss: 0.51176,Valid loss: 0.76577, time : 10.80359697341919 lr : 0.21923726936647234\n",
      "epoch : 151 [8/23] Train loss: 0.51072,Valid loss: 0.78557, time : 10.530064582824707 lr : 0.21923726936647234\n",
      "epoch : 151 [9/23] Train loss: 0.51141,Valid loss: 0.77201, time : 10.41068434715271 lr : 0.21923726936647234\n",
      "epoch : 151 [10/23] Train loss: 0.50822,Valid loss: 0.77311, time : 10.545568704605103 lr : 0.21923726936647234\n",
      "epoch : 151 [11/23] Train loss: 0.51245,Valid loss: 0.76534, time : 10.309709310531616 lr : 0.21923726936647234\n",
      "epoch : 151 [12/23] Train loss: 0.49824,Valid loss: 0.77259, time : 10.665029287338257 lr : 0.21923726936647234\n",
      "epoch : 151 [13/23] Train loss: 0.52451,Valid loss: 0.77172, time : 10.914186000823975 lr : 0.21923726936647234\n",
      "epoch : 151 [14/23] Train loss: 0.51440,Valid loss: 0.76596, time : 10.656447172164917 lr : 0.21923726936647234\n",
      "epoch : 151 [15/23] Train loss: 0.52579,Valid loss: 0.75570, time : 10.488451719284058 lr : 0.21923726936647234\n",
      "epoch : 151 [16/23] Train loss: 0.51735,Valid loss: 0.76144, time : 10.593547582626343 lr : 0.21923726936647234\n",
      "epoch : 151 [17/23] Train loss: 0.53213,Valid loss: 0.76564, time : 10.71687626838684 lr : 0.21923726936647234\n",
      "epoch : 151 [18/23] Train loss: 0.51251,Valid loss: 0.77939, time : 10.314888954162598 lr : 0.21923726936647234\n",
      "epoch : 151 [19/23] Train loss: 0.52408,Valid loss: 0.76493, time : 10.735512733459473 lr : 0.21923726936647234\n",
      "epoch : 151 [20/23] Train loss: 0.51333,Valid loss: 0.75715, time : 10.621679306030273 lr : 0.21923726936647234\n",
      "epoch : 151 [21/23] Train loss: 0.50784,Valid loss: 0.75359, time : 10.29332423210144 lr : 0.21923726936647234\n",
      "epoch : 151 [22/23] Train loss: 0.52762,Valid loss: 0.79637, time : 9.470638990402222 lr : 0.21923726936647234\n",
      "epoch : 152 [0/23] Train loss: 0.50762,Valid loss: 0.75738, time : 10.230721473693848 lr : 0.2170448966728076\n",
      "epoch : 152 [1/23] Train loss: 0.50933,Valid loss: 0.75929, time : 10.202491760253906 lr : 0.2170448966728076\n",
      "epoch : 152 [2/23] Train loss: 0.50808,Valid loss: 0.75645, time : 10.454693078994751 lr : 0.2170448966728076\n",
      "epoch : 152 [3/23] Train loss: 0.50484,Valid loss: 0.79651, time : 10.33417534828186 lr : 0.2170448966728076\n",
      "epoch : 152 [4/23] Train loss: 0.50615,Valid loss: 0.84275, time : 10.088828325271606 lr : 0.2170448966728076\n",
      "epoch : 152 [5/23] Train loss: 0.54118,Valid loss: 0.78627, time : 10.225653171539307 lr : 0.2170448966728076\n",
      "epoch : 152 [6/23] Train loss: 0.52154,Valid loss: 0.79212, time : 9.760654211044312 lr : 0.2170448966728076\n",
      "epoch : 152 [7/23] Train loss: 0.50992,Valid loss: 0.80439, time : 10.093415021896362 lr : 0.2170448966728076\n",
      "epoch : 152 [8/23] Train loss: 0.51458,Valid loss: 0.80739, time : 10.310857772827148 lr : 0.2170448966728076\n",
      "epoch : 152 [9/23] Train loss: 0.52517,Valid loss: 0.77232, time : 10.36155891418457 lr : 0.2170448966728076\n",
      "epoch : 152 [10/23] Train loss: 0.51584,Valid loss: 0.76302, time : 10.446532964706421 lr : 0.2170448966728076\n",
      "epoch : 152 [11/23] Train loss: 0.51611,Valid loss: 0.76698, time : 10.43884539604187 lr : 0.2170448966728076\n",
      "epoch : 152 [12/23] Train loss: 0.51859,Valid loss: 0.78522, time : 10.272027492523193 lr : 0.2170448966728076\n",
      "epoch : 152 [13/23] Train loss: 0.50126,Valid loss: 0.78735, time : 9.931265830993652 lr : 0.2170448966728076\n",
      "epoch : 152 [14/23] Train loss: 0.50245,Valid loss: 0.77993, time : 10.188045263290405 lr : 0.2170448966728076\n",
      "epoch : 152 [15/23] Train loss: 0.50125,Valid loss: 0.75340, time : 9.80531620979309 lr : 0.2170448966728076\n",
      "epoch : 152 [16/23] Train loss: 0.50536,Valid loss: 0.75894, time : 10.191059112548828 lr : 0.2170448966728076\n",
      "epoch : 152 [17/23] Train loss: 0.51194,Valid loss: 0.81395, time : 10.07503628730774 lr : 0.2170448966728076\n",
      "epoch : 152 [18/23] Train loss: 0.53553,Valid loss: 0.78252, time : 10.220462083816528 lr : 0.2170448966728076\n",
      "epoch : 152 [19/23] Train loss: 0.51245,Valid loss: 0.81889, time : 10.201943397521973 lr : 0.2170448966728076\n",
      "epoch : 152 [20/23] Train loss: 0.51800,Valid loss: 0.81369, time : 10.389264106750488 lr : 0.2170448966728076\n",
      "epoch : 152 [21/23] Train loss: 0.51414,Valid loss: 0.82446, time : 9.7582106590271 lr : 0.2170448966728076\n",
      "epoch : 152 [22/23] Train loss: 0.52379,Valid loss: 0.84026, time : 9.393612623214722 lr : 0.2170448966728076\n",
      "epoch : 153 [0/23] Train loss: 0.52969,Valid loss: 0.79846, time : 10.105185747146606 lr : 0.21487444770607952\n",
      "epoch : 153 [1/23] Train loss: 0.54879,Valid loss: 0.78155, time : 10.290293216705322 lr : 0.21487444770607952\n",
      "epoch : 153 [2/23] Train loss: 0.53126,Valid loss: 0.76478, time : 10.458455085754395 lr : 0.21487444770607952\n",
      "epoch : 153 [3/23] Train loss: 0.52712,Valid loss: 0.77809, time : 10.138110160827637 lr : 0.21487444770607952\n",
      "epoch : 153 [4/23] Train loss: 0.53291,Valid loss: 0.85931, time : 10.421481370925903 lr : 0.21487444770607952\n",
      "epoch : 153 [5/23] Train loss: 0.52715,Valid loss: 0.76266, time : 10.124899625778198 lr : 0.21487444770607952\n",
      "epoch : 153 [6/23] Train loss: 0.52288,Valid loss: 0.77826, time : 10.374980449676514 lr : 0.21487444770607952\n",
      "epoch : 153 [7/23] Train loss: 0.52117,Valid loss: 0.80939, time : 10.348537683486938 lr : 0.21487444770607952\n",
      "epoch : 153 [8/23] Train loss: 0.51895,Valid loss: 0.79342, time : 10.186961889266968 lr : 0.21487444770607952\n",
      "epoch : 153 [9/23] Train loss: 0.52444,Valid loss: 0.83299, time : 10.302956581115723 lr : 0.21487444770607952\n",
      "epoch : 153 [10/23] Train loss: 0.53699,Valid loss: 0.80843, time : 10.094221353530884 lr : 0.21487444770607952\n",
      "epoch : 153 [11/23] Train loss: 0.54762,Valid loss: 0.78458, time : 10.28060245513916 lr : 0.21487444770607952\n",
      "epoch : 153 [12/23] Train loss: 0.54577,Valid loss: 0.80206, time : 10.343486785888672 lr : 0.21487444770607952\n",
      "epoch : 153 [13/23] Train loss: 0.53489,Valid loss: 0.77526, time : 10.29564905166626 lr : 0.21487444770607952\n",
      "epoch : 153 [14/23] Train loss: 0.52805,Valid loss: 0.77477, time : 10.326603889465332 lr : 0.21487444770607952\n",
      "epoch : 153 [15/23] Train loss: 0.52482,Valid loss: 0.81445, time : 10.500585317611694 lr : 0.21487444770607952\n",
      "epoch : 153 [16/23] Train loss: 0.52987,Valid loss: 0.80102, time : 10.520447015762329 lr : 0.21487444770607952\n",
      "epoch : 153 [17/23] Train loss: 0.51987,Valid loss: 0.91736, time : 10.612032890319824 lr : 0.21487444770607952\n",
      "epoch : 153 [18/23] Train loss: 0.51783,Valid loss: 0.81290, time : 10.455946683883667 lr : 0.21487444770607952\n",
      "epoch : 153 [19/23] Train loss: 0.51572,Valid loss: 0.77600, time : 10.392000198364258 lr : 0.21487444770607952\n",
      "epoch : 153 [20/23] Train loss: 0.51396,Valid loss: 0.78180, time : 10.446436166763306 lr : 0.21487444770607952\n",
      "epoch : 153 [21/23] Train loss: 0.51112,Valid loss: 0.76355, time : 10.51622986793518 lr : 0.21487444770607952\n",
      "epoch : 153 [22/23] Train loss: 0.50023,Valid loss: 0.78998, time : 9.504144668579102 lr : 0.21487444770607952\n",
      "epoch : 154 [0/23] Train loss: 0.51275,Valid loss: 0.76197, time : 9.834306001663208 lr : 0.21272570322901874\n",
      "epoch : 154 [1/23] Train loss: 0.50302,Valid loss: 0.74198, time : 10.248078107833862 lr : 0.21272570322901874\n",
      "epoch : 154 [2/23] Train loss: 0.52278,Valid loss: 0.74773, time : 10.166917324066162 lr : 0.21272570322901874\n",
      "epoch : 154 [3/23] Train loss: 0.50094,Valid loss: 0.77935, time : 10.369242906570435 lr : 0.21272570322901874\n",
      "epoch : 154 [4/23] Train loss: 0.51568,Valid loss: 0.76435, time : 10.038898706436157 lr : 0.21272570322901874\n",
      "epoch : 154 [5/23] Train loss: 0.48772,Valid loss: 0.73928, time : 10.048747301101685 lr : 0.21272570322901874\n",
      "epoch : 154 [6/23] Train loss: 0.50685,Valid loss: 0.74573, time : 10.258708000183105 lr : 0.21272570322901874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 154 [7/23] Train loss: 0.51491,Valid loss: 0.75542, time : 10.10034728050232 lr : 0.21272570322901874\n",
      "epoch : 154 [8/23] Train loss: 0.50191,Valid loss: 0.77990, time : 10.590778112411499 lr : 0.21272570322901874\n",
      "epoch : 154 [9/23] Train loss: 0.49647,Valid loss: 0.74192, time : 10.208715200424194 lr : 0.21272570322901874\n",
      "epoch : 154 [10/23] Train loss: 0.50329,Valid loss: 0.76526, time : 10.612825870513916 lr : 0.21272570322901874\n",
      "epoch : 154 [11/23] Train loss: 0.51432,Valid loss: 0.75166, time : 10.0995032787323 lr : 0.21272570322901874\n",
      "epoch : 154 [12/23] Train loss: 0.50695,Valid loss: 0.75780, time : 9.737230062484741 lr : 0.21272570322901874\n",
      "epoch : 154 [13/23] Train loss: 0.50182,Valid loss: 0.78775, time : 10.262217044830322 lr : 0.21272570322901874\n",
      "epoch : 154 [14/23] Train loss: 0.51154,Valid loss: 0.74715, time : 9.999321699142456 lr : 0.21272570322901874\n",
      "epoch : 154 [15/23] Train loss: 0.50003,Valid loss: 0.76779, time : 10.204262971878052 lr : 0.21272570322901874\n",
      "epoch : 154 [16/23] Train loss: 0.51354,Valid loss: 0.81307, time : 10.190532207489014 lr : 0.21272570322901874\n",
      "epoch : 154 [17/23] Train loss: 0.51962,Valid loss: 0.74882, time : 9.967085838317871 lr : 0.21272570322901874\n",
      "epoch : 154 [18/23] Train loss: 0.52803,Valid loss: 0.75884, time : 10.048004388809204 lr : 0.21272570322901874\n",
      "epoch : 154 [19/23] Train loss: 0.51035,Valid loss: 0.79024, time : 9.885295391082764 lr : 0.21272570322901874\n",
      "epoch : 154 [20/23] Train loss: 0.50503,Valid loss: 0.78239, time : 10.139086484909058 lr : 0.21272570322901874\n",
      "epoch : 154 [21/23] Train loss: 0.50577,Valid loss: 0.75227, time : 9.70032000541687 lr : 0.21272570322901874\n",
      "epoch : 154 [22/23] Train loss: 0.51320,Valid loss: 0.76669, time : 9.44497299194336 lr : 0.21272570322901874\n",
      "epoch : 155 [0/23] Train loss: 0.49719,Valid loss: 0.74340, time : 10.22781753540039 lr : 0.21059844619672854\n",
      "epoch : 155 [1/23] Train loss: 0.49825,Valid loss: 0.75407, time : 10.186213254928589 lr : 0.21059844619672854\n",
      "epoch : 155 [2/23] Train loss: 0.50736,Valid loss: 0.78168, time : 9.915964603424072 lr : 0.21059844619672854\n",
      "epoch : 155 [3/23] Train loss: 0.50932,Valid loss: 0.74590, time : 10.08756685256958 lr : 0.21059844619672854\n",
      "epoch : 155 [4/23] Train loss: 0.51536,Valid loss: 0.75700, time : 10.223791360855103 lr : 0.21059844619672854\n",
      "epoch : 155 [5/23] Train loss: 0.50850,Valid loss: 0.74842, time : 10.12313961982727 lr : 0.21059844619672854\n",
      "epoch : 155 [6/23] Train loss: 0.50878,Valid loss: 0.80574, time : 10.312512636184692 lr : 0.21059844619672854\n",
      "epoch : 155 [7/23] Train loss: 0.51422,Valid loss: 0.82045, time : 10.60311245918274 lr : 0.21059844619672854\n",
      "epoch : 155 [8/23] Train loss: 0.53544,Valid loss: 0.75248, time : 10.397795915603638 lr : 0.21059844619672854\n",
      "epoch : 155 [9/23] Train loss: 0.50527,Valid loss: 0.79162, time : 9.828581094741821 lr : 0.21059844619672854\n",
      "epoch : 155 [10/23] Train loss: 0.50334,Valid loss: 0.75683, time : 10.297175407409668 lr : 0.21059844619672854\n",
      "epoch : 155 [11/23] Train loss: 0.48741,Valid loss: 0.76781, time : 10.03920292854309 lr : 0.21059844619672854\n",
      "epoch : 155 [12/23] Train loss: 0.52474,Valid loss: 0.76631, time : 10.233115673065186 lr : 0.21059844619672854\n",
      "epoch : 155 [13/23] Train loss: 0.51080,Valid loss: 0.77159, time : 10.198764562606812 lr : 0.21059844619672854\n",
      "epoch : 155 [14/23] Train loss: 0.49617,Valid loss: 0.76623, time : 10.274149417877197 lr : 0.21059844619672854\n",
      "epoch : 155 [15/23] Train loss: 0.50000,Valid loss: 0.79730, time : 9.992675542831421 lr : 0.21059844619672854\n",
      "epoch : 155 [16/23] Train loss: 0.51856,Valid loss: 0.74935, time : 10.108134269714355 lr : 0.21059844619672854\n",
      "epoch : 155 [17/23] Train loss: 0.51373,Valid loss: 0.75363, time : 10.334219217300415 lr : 0.21059844619672854\n",
      "epoch : 155 [18/23] Train loss: 0.49703,Valid loss: 0.75899, time : 10.440513849258423 lr : 0.21059844619672854\n",
      "epoch : 155 [19/23] Train loss: 0.50654,Valid loss: 0.75758, time : 10.408482074737549 lr : 0.21059844619672854\n",
      "epoch : 155 [20/23] Train loss: 0.49294,Valid loss: 0.74357, time : 10.094608783721924 lr : 0.21059844619672854\n",
      "epoch : 155 [21/23] Train loss: 0.49762,Valid loss: 0.76408, time : 10.456071615219116 lr : 0.21059844619672854\n",
      "epoch : 155 [22/23] Train loss: 0.52763,Valid loss: 0.77096, time : 9.374586343765259 lr : 0.21059844619672854\n",
      "epoch : 156 [0/23] Train loss: 0.51172,Valid loss: 0.75508, time : 10.427111148834229 lr : 0.20849246173476127\n",
      "epoch : 156 [1/23] Train loss: 0.52081,Valid loss: 0.89225, time : 10.183796167373657 lr : 0.20849246173476127\n",
      "epoch : 156 [2/23] Train loss: 0.52743,Valid loss: 0.78057, time : 10.437507629394531 lr : 0.20849246173476127\n",
      "epoch : 156 [3/23] Train loss: 0.50439,Valid loss: 0.79198, time : 10.154473066329956 lr : 0.20849246173476127\n",
      "epoch : 156 [4/23] Train loss: 0.52161,Valid loss: 0.74354, time : 9.99440860748291 lr : 0.20849246173476127\n",
      "epoch : 156 [5/23] Train loss: 0.50777,Valid loss: 0.76063, time : 9.99506139755249 lr : 0.20849246173476127\n",
      "epoch : 156 [6/23] Train loss: 0.51567,Valid loss: 0.76363, time : 10.538184642791748 lr : 0.20849246173476127\n",
      "epoch : 156 [7/23] Train loss: 0.49716,Valid loss: 0.75471, time : 10.838422775268555 lr : 0.20849246173476127\n",
      "epoch : 156 [8/23] Train loss: 0.49477,Valid loss: 0.83563, time : 10.1690034866333 lr : 0.20849246173476127\n",
      "epoch : 156 [9/23] Train loss: 0.55061,Valid loss: 0.78918, time : 9.933261632919312 lr : 0.20849246173476127\n",
      "epoch : 156 [10/23] Train loss: 0.59292,Valid loss: 0.84785, time : 10.056239128112793 lr : 0.20849246173476127\n",
      "epoch : 156 [11/23] Train loss: 0.56481,Valid loss: 0.81884, time : 10.210120677947998 lr : 0.20849246173476127\n",
      "epoch : 156 [12/23] Train loss: 0.53838,Valid loss: 0.81734, time : 10.183189868927002 lr : 0.20849246173476127\n",
      "epoch : 156 [13/23] Train loss: 0.52997,Valid loss: 0.84259, time : 10.302542686462402 lr : 0.20849246173476127\n",
      "epoch : 156 [14/23] Train loss: 0.50874,Valid loss: 0.79029, time : 10.348477363586426 lr : 0.20849246173476127\n",
      "epoch : 156 [15/23] Train loss: 0.51947,Valid loss: 0.79519, time : 10.372445106506348 lr : 0.20849246173476127\n",
      "epoch : 156 [16/23] Train loss: 0.51048,Valid loss: 0.78754, time : 10.119141101837158 lr : 0.20849246173476127\n",
      "epoch : 156 [17/23] Train loss: 0.50536,Valid loss: 0.76257, time : 10.374426364898682 lr : 0.20849246173476127\n",
      "epoch : 156 [18/23] Train loss: 0.51480,Valid loss: 0.77078, time : 10.408742666244507 lr : 0.20849246173476127\n",
      "epoch : 156 [19/23] Train loss: 0.50874,Valid loss: 0.77020, time : 10.205106496810913 lr : 0.20849246173476127\n",
      "epoch : 156 [20/23] Train loss: 0.49680,Valid loss: 0.78685, time : 10.178836345672607 lr : 0.20849246173476127\n",
      "epoch : 156 [21/23] Train loss: 0.49922,Valid loss: 0.76998, time : 10.275272369384766 lr : 0.20849246173476127\n",
      "epoch : 156 [22/23] Train loss: 0.49942,Valid loss: 0.75353, time : 9.457133769989014 lr : 0.20849246173476127\n",
      "epoch : 157 [0/23] Train loss: 0.50995,Valid loss: 0.76278, time : 10.30687141418457 lr : 0.20640753711741366\n",
      "epoch : 157 [1/23] Train loss: 0.49190,Valid loss: 0.75449, time : 10.246091604232788 lr : 0.20640753711741366\n",
      "epoch : 157 [2/23] Train loss: 0.50490,Valid loss: 0.74524, time : 10.497376918792725 lr : 0.20640753711741366\n",
      "epoch : 157 [3/23] Train loss: 0.50262,Valid loss: 0.75202, time : 10.16601824760437 lr : 0.20640753711741366\n",
      "epoch : 157 [4/23] Train loss: 0.49273,Valid loss: 0.75499, time : 10.61564302444458 lr : 0.20640753711741366\n",
      "epoch : 157 [5/23] Train loss: 0.49463,Valid loss: 0.74805, time : 10.273426294326782 lr : 0.20640753711741366\n",
      "epoch : 157 [6/23] Train loss: 0.47642,Valid loss: 0.78800, time : 10.320852041244507 lr : 0.20640753711741366\n",
      "epoch : 157 [7/23] Train loss: 0.51060,Valid loss: 0.76236, time : 10.03283143043518 lr : 0.20640753711741366\n",
      "epoch : 157 [8/23] Train loss: 0.49182,Valid loss: 0.76429, time : 10.316373825073242 lr : 0.20640753711741366\n",
      "epoch : 157 [9/23] Train loss: 0.48484,Valid loss: 0.75606, time : 10.024608850479126 lr : 0.20640753711741366\n",
      "epoch : 157 [10/23] Train loss: 0.49052,Valid loss: 0.75495, time : 10.126818418502808 lr : 0.20640753711741366\n",
      "epoch : 157 [11/23] Train loss: 0.50691,Valid loss: 0.76373, time : 10.061790704727173 lr : 0.20640753711741366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 157 [12/23] Train loss: 0.48240,Valid loss: 0.75917, time : 9.739895343780518 lr : 0.20640753711741366\n",
      "epoch : 157 [13/23] Train loss: 0.51367,Valid loss: 0.73798, time : 9.934646844863892 lr : 0.20640753711741366\n",
      "epoch : 157 [14/23] Train loss: 0.50497,Valid loss: 0.73922, time : 10.23832106590271 lr : 0.20640753711741366\n",
      "epoch : 157 [15/23] Train loss: 0.50685,Valid loss: 0.75289, time : 10.04441213607788 lr : 0.20640753711741366\n",
      "epoch : 157 [16/23] Train loss: 0.48592,Valid loss: 0.74445, time : 9.797104597091675 lr : 0.20640753711741366\n",
      "epoch : 157 [17/23] Train loss: 0.50132,Valid loss: 0.77417, time : 9.64776062965393 lr : 0.20640753711741366\n",
      "epoch : 157 [18/23] Train loss: 0.49884,Valid loss: 0.77285, time : 9.65023422241211 lr : 0.20640753711741366\n",
      "epoch : 157 [19/23] Train loss: 0.50022,Valid loss: 0.76019, time : 10.175036907196045 lr : 0.20640753711741366\n",
      "epoch : 157 [20/23] Train loss: 0.49986,Valid loss: 0.79198, time : 9.94235348701477 lr : 0.20640753711741366\n",
      "epoch : 157 [21/23] Train loss: 0.49227,Valid loss: 0.75442, time : 10.031217575073242 lr : 0.20640753711741366\n",
      "epoch : 157 [22/23] Train loss: 0.50535,Valid loss: 0.74972, time : 9.454418182373047 lr : 0.20640753711741366\n",
      "epoch : 158 [0/23] Train loss: 0.49400,Valid loss: 0.74975, time : 10.358322143554688 lr : 0.20434346174623952\n",
      "epoch : 158 [1/23] Train loss: 0.49158,Valid loss: 0.73629, time : 10.153213500976562 lr : 0.20434346174623952\n",
      "epoch : 158 [2/23] Train loss: 0.48699,Valid loss: 0.75893, time : 10.170455694198608 lr : 0.20434346174623952\n",
      "epoch : 158 [3/23] Train loss: 0.47398,Valid loss: 0.76446, time : 10.035303354263306 lr : 0.20434346174623952\n",
      "epoch : 158 [4/23] Train loss: 0.49918,Valid loss: 0.75137, time : 9.9231116771698 lr : 0.20434346174623952\n",
      "epoch : 158 [5/23] Train loss: 0.48481,Valid loss: 0.73385, time : 9.903630018234253 lr : 0.20434346174623952\n",
      "epoch : 158 [6/23] Train loss: 0.47900,Valid loss: 0.77069, time : 10.103763341903687 lr : 0.20434346174623952\n",
      "epoch : 158 [7/23] Train loss: 0.50358,Valid loss: 0.73986, time : 10.16170334815979 lr : 0.20434346174623952\n",
      "epoch : 158 [8/23] Train loss: 0.49424,Valid loss: 0.74805, time : 9.69534969329834 lr : 0.20434346174623952\n",
      "epoch : 158 [9/23] Train loss: 0.47875,Valid loss: 0.75083, time : 9.840264081954956 lr : 0.20434346174623952\n",
      "epoch : 158 [10/23] Train loss: 0.46922,Valid loss: 0.74980, time : 9.77407193183899 lr : 0.20434346174623952\n",
      "epoch : 158 [11/23] Train loss: 0.49346,Valid loss: 0.74667, time : 10.16083836555481 lr : 0.20434346174623952\n",
      "epoch : 158 [12/23] Train loss: 0.47162,Valid loss: 0.72737, time : 10.180702209472656 lr : 0.20434346174623952\n",
      "epoch : 158 [13/23] Train loss: 0.50872,Valid loss: 0.73810, time : 10.52762770652771 lr : 0.20434346174623952\n",
      "epoch : 158 [14/23] Train loss: 0.47766,Valid loss: 0.72615, time : 10.267814874649048 lr : 0.20434346174623952\n",
      "epoch : 158 [15/23] Train loss: 0.48893,Valid loss: 0.76809, time : 10.408889055252075 lr : 0.20434346174623952\n",
      "epoch : 158 [16/23] Train loss: 0.48847,Valid loss: 0.75666, time : 10.385776281356812 lr : 0.20434346174623952\n",
      "epoch : 158 [17/23] Train loss: 0.50646,Valid loss: 0.77157, time : 10.613085985183716 lr : 0.20434346174623952\n",
      "epoch : 158 [18/23] Train loss: 0.47877,Valid loss: 0.72958, time : 10.29261064529419 lr : 0.20434346174623952\n",
      "epoch : 158 [19/23] Train loss: 0.48278,Valid loss: 0.74481, time : 10.446171283721924 lr : 0.20434346174623952\n",
      "epoch : 158 [20/23] Train loss: 0.49071,Valid loss: 0.75372, time : 9.71918511390686 lr : 0.20434346174623952\n",
      "epoch : 158 [21/23] Train loss: 0.49338,Valid loss: 0.72129, time : 10.155930519104004 lr : 0.20434346174623952\n",
      "epoch : 158 [22/23] Train loss: 0.49220,Valid loss: 0.74281, time : 9.784598588943481 lr : 0.20434346174623952\n",
      "epoch : 159 [0/23] Train loss: 0.48209,Valid loss: 0.74333, time : 10.247190237045288 lr : 0.20230002712877712\n",
      "epoch : 159 [1/23] Train loss: 0.48391,Valid loss: 0.75261, time : 10.020938158035278 lr : 0.20230002712877712\n",
      "epoch : 159 [2/23] Train loss: 0.49427,Valid loss: 0.72411, time : 10.039028406143188 lr : 0.20230002712877712\n",
      "epoch : 159 [3/23] Train loss: 0.48646,Valid loss: 0.74739, time : 10.52799367904663 lr : 0.20230002712877712\n",
      "epoch : 159 [4/23] Train loss: 0.48624,Valid loss: 0.72939, time : 10.400250434875488 lr : 0.20230002712877712\n",
      "epoch : 159 [5/23] Train loss: 0.46439,Valid loss: 0.76201, time : 10.033861875534058 lr : 0.20230002712877712\n",
      "epoch : 159 [6/23] Train loss: 0.47531,Valid loss: 0.73025, time : 10.493735313415527 lr : 0.20230002712877712\n",
      "epoch : 159 [7/23] Train loss: 0.46795,Valid loss: 0.73540, time : 10.379822969436646 lr : 0.20230002712877712\n",
      "epoch : 159 [8/23] Train loss: 0.48470,Valid loss: 0.76220, time : 10.520187854766846 lr : 0.20230002712877712\n",
      "epoch : 159 [9/23] Train loss: 0.47620,Valid loss: 0.79752, time : 9.998265743255615 lr : 0.20230002712877712\n",
      "epoch : 159 [10/23] Train loss: 0.47482,Valid loss: 0.76631, time : 10.240776777267456 lr : 0.20230002712877712\n",
      "epoch : 159 [11/23] Train loss: 0.49309,Valid loss: 0.72239, time : 9.911381721496582 lr : 0.20230002712877712\n",
      "epoch : 159 [12/23] Train loss: 0.47520,Valid loss: 0.73136, time : 10.101164817810059 lr : 0.20230002712877712\n",
      "epoch : 159 [13/23] Train loss: 0.49109,Valid loss: 0.72319, time : 10.1763756275177 lr : 0.20230002712877712\n",
      "epoch : 159 [14/23] Train loss: 0.48819,Valid loss: 0.73028, time : 10.239336490631104 lr : 0.20230002712877712\n",
      "epoch : 159 [15/23] Train loss: 0.48591,Valid loss: 0.74080, time : 10.409886121749878 lr : 0.20230002712877712\n",
      "epoch : 159 [16/23] Train loss: 0.47540,Valid loss: 0.75202, time : 10.359569311141968 lr : 0.20230002712877712\n",
      "epoch : 159 [17/23] Train loss: 0.48063,Valid loss: 0.74182, time : 10.021665811538696 lr : 0.20230002712877712\n",
      "epoch : 159 [18/23] Train loss: 0.48876,Valid loss: 0.73534, time : 10.451151371002197 lr : 0.20230002712877712\n",
      "epoch : 159 [19/23] Train loss: 0.48439,Valid loss: 0.72948, time : 10.016506671905518 lr : 0.20230002712877712\n",
      "epoch : 159 [20/23] Train loss: 0.46970,Valid loss: 0.73628, time : 10.338590383529663 lr : 0.20230002712877712\n",
      "epoch : 159 [21/23] Train loss: 0.48425,Valid loss: 0.73326, time : 9.869248628616333 lr : 0.20230002712877712\n",
      "epoch : 159 [22/23] Train loss: 0.47345,Valid loss: 0.73714, time : 9.602687120437622 lr : 0.20230002712877712\n",
      "epoch : 160 [0/23] Train loss: 0.47470,Valid loss: 0.77268, time : 10.350188255310059 lr : 0.20027702685748935\n",
      "epoch : 160 [1/23] Train loss: 0.47367,Valid loss: 0.73799, time : 10.074190378189087 lr : 0.20027702685748935\n",
      "epoch : 160 [2/23] Train loss: 0.46894,Valid loss: 0.72278, time : 10.413016557693481 lr : 0.20027702685748935\n",
      "epoch : 160 [3/23] Train loss: 0.47577,Valid loss: 0.73632, time : 10.414878845214844 lr : 0.20027702685748935\n",
      "epoch : 160 [4/23] Train loss: 0.46731,Valid loss: 0.75557, time : 10.225531339645386 lr : 0.20027702685748935\n",
      "epoch : 160 [5/23] Train loss: 0.47624,Valid loss: 0.72675, time : 10.639801979064941 lr : 0.20027702685748935\n",
      "epoch : 160 [6/23] Train loss: 0.47023,Valid loss: 0.76086, time : 10.628748416900635 lr : 0.20027702685748935\n",
      "epoch : 160 [7/23] Train loss: 0.48945,Valid loss: 0.73315, time : 10.43325400352478 lr : 0.20027702685748935\n",
      "epoch : 160 [8/23] Train loss: 0.47416,Valid loss: 0.73731, time : 10.47783875465393 lr : 0.20027702685748935\n",
      "epoch : 160 [9/23] Train loss: 0.47994,Valid loss: 0.71824, time : 10.574120044708252 lr : 0.20027702685748935\n",
      "epoch : 160 [10/23] Train loss: 0.46543,Valid loss: 0.73985, time : 10.308261394500732 lr : 0.20027702685748935\n",
      "epoch : 160 [11/23] Train loss: 0.47102,Valid loss: 0.86001, time : 10.367283582687378 lr : 0.20027702685748935\n",
      "epoch : 160 [12/23] Train loss: 0.54609,Valid loss: 0.78661, time : 10.572642803192139 lr : 0.20027702685748935\n",
      "epoch : 160 [13/23] Train loss: 0.50583,Valid loss: 0.79704, time : 10.739533424377441 lr : 0.20027702685748935\n",
      "epoch : 160 [14/23] Train loss: 0.48686,Valid loss: 0.74243, time : 10.63076376914978 lr : 0.20027702685748935\n",
      "epoch : 160 [15/23] Train loss: 0.48149,Valid loss: 0.78726, time : 10.124062538146973 lr : 0.20027702685748935\n",
      "epoch : 160 [16/23] Train loss: 0.51236,Valid loss: 0.75281, time : 10.442624568939209 lr : 0.20027702685748935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 160 [17/23] Train loss: 0.48769,Valid loss: 0.73268, time : 9.86405348777771 lr : 0.20027702685748935\n",
      "epoch : 160 [18/23] Train loss: 0.49137,Valid loss: 0.79531, time : 10.347489356994629 lr : 0.20027702685748935\n",
      "epoch : 160 [19/23] Train loss: 0.50648,Valid loss: 0.77419, time : 10.529381036758423 lr : 0.20027702685748935\n",
      "epoch : 160 [20/23] Train loss: 0.48449,Valid loss: 0.79989, time : 10.25575304031372 lr : 0.20027702685748935\n",
      "epoch : 160 [21/23] Train loss: 0.49273,Valid loss: 0.74524, time : 9.982693433761597 lr : 0.20027702685748935\n",
      "epoch : 160 [22/23] Train loss: 0.48924,Valid loss: 0.73970, time : 9.606864213943481 lr : 0.20027702685748935\n",
      "epoch : 161 [0/23] Train loss: 0.48763,Valid loss: 0.76776, time : 10.130742311477661 lr : 0.19827425658891445\n",
      "epoch : 161 [1/23] Train loss: 0.46082,Valid loss: 0.78932, time : 10.145240068435669 lr : 0.19827425658891445\n",
      "epoch : 161 [2/23] Train loss: 0.48306,Valid loss: 0.75037, time : 9.857831001281738 lr : 0.19827425658891445\n",
      "epoch : 161 [3/23] Train loss: 0.48443,Valid loss: 0.75940, time : 10.27731990814209 lr : 0.19827425658891445\n",
      "epoch : 161 [4/23] Train loss: 0.48342,Valid loss: 0.73269, time : 9.994266510009766 lr : 0.19827425658891445\n",
      "epoch : 161 [5/23] Train loss: 0.47854,Valid loss: 0.72386, time : 10.151419162750244 lr : 0.19827425658891445\n",
      "epoch : 161 [6/23] Train loss: 0.47752,Valid loss: 0.74256, time : 10.16637110710144 lr : 0.19827425658891445\n",
      "epoch : 161 [7/23] Train loss: 0.47502,Valid loss: 0.77588, time : 10.627422571182251 lr : 0.19827425658891445\n",
      "epoch : 161 [8/23] Train loss: 0.49439,Valid loss: 0.73293, time : 10.02262544631958 lr : 0.19827425658891445\n",
      "epoch : 161 [9/23] Train loss: 0.47986,Valid loss: 0.82691, time : 10.526179313659668 lr : 0.19827425658891445\n",
      "epoch : 161 [10/23] Train loss: 0.49348,Valid loss: 0.81471, time : 10.061525821685791 lr : 0.19827425658891445\n",
      "epoch : 161 [11/23] Train loss: 0.48613,Valid loss: 0.82231, time : 9.803470373153687 lr : 0.19827425658891445\n",
      "epoch : 161 [12/23] Train loss: 0.47666,Valid loss: 0.97221, time : 9.897643089294434 lr : 0.19827425658891445\n",
      "epoch : 161 [13/23] Train loss: 0.47596,Valid loss: 1.06139, time : 10.155232429504395 lr : 0.19827425658891445\n",
      "epoch : 161 [14/23] Train loss: 0.49838,Valid loss: 0.97136, time : 10.598921775817871 lr : 0.19827425658891445\n",
      "epoch : 161 [15/23] Train loss: 0.50110,Valid loss: 0.75065, time : 10.344604969024658 lr : 0.19827425658891445\n",
      "epoch : 161 [16/23] Train loss: 0.49232,Valid loss: 1.64060, time : 10.241904258728027 lr : 0.19827425658891445\n",
      "epoch : 161 [17/23] Train loss: 0.51651,Valid loss: 0.94747, time : 10.28751015663147 lr : 0.19827425658891445\n",
      "epoch : 161 [18/23] Train loss: 0.50793,Valid loss: 0.80556, time : 10.747230291366577 lr : 0.19827425658891445\n",
      "epoch : 161 [19/23] Train loss: 0.50264,Valid loss: 0.79060, time : 10.393895149230957 lr : 0.19827425658891445\n",
      "epoch : 161 [20/23] Train loss: 0.49335,Valid loss: 0.76005, time : 9.903631925582886 lr : 0.19827425658891445\n",
      "epoch : 161 [21/23] Train loss: 0.47874,Valid loss: 0.73521, time : 10.142939567565918 lr : 0.19827425658891445\n",
      "epoch : 161 [22/23] Train loss: 0.47856,Valid loss: 0.72982, time : 9.514017105102539 lr : 0.19827425658891445\n",
      "epoch : 162 [0/23] Train loss: 0.47862,Valid loss: 0.72598, time : 10.595525741577148 lr : 0.1962915140230253\n",
      "epoch : 162 [1/23] Train loss: 0.48130,Valid loss: 0.74260, time : 10.453869342803955 lr : 0.1962915140230253\n",
      "epoch : 162 [2/23] Train loss: 0.46571,Valid loss: 0.74088, time : 10.497777938842773 lr : 0.1962915140230253\n",
      "epoch : 162 [3/23] Train loss: 0.47656,Valid loss: 0.74561, time : 10.527546405792236 lr : 0.1962915140230253\n",
      "epoch : 162 [4/23] Train loss: 0.47150,Valid loss: 0.72558, time : 10.530205011367798 lr : 0.1962915140230253\n",
      "epoch : 162 [5/23] Train loss: 0.47819,Valid loss: 0.73514, time : 10.321674585342407 lr : 0.1962915140230253\n",
      "epoch : 162 [6/23] Train loss: 0.46022,Valid loss: 0.72911, time : 10.119752407073975 lr : 0.1962915140230253\n",
      "epoch : 162 [7/23] Train loss: 0.46149,Valid loss: 0.73653, time : 10.206547021865845 lr : 0.1962915140230253\n",
      "epoch : 162 [8/23] Train loss: 0.46074,Valid loss: 0.73212, time : 9.840945959091187 lr : 0.1962915140230253\n",
      "epoch : 162 [9/23] Train loss: 0.48316,Valid loss: 0.73547, time : 10.086817026138306 lr : 0.1962915140230253\n",
      "epoch : 162 [10/23] Train loss: 0.47518,Valid loss: 0.73756, time : 9.816057920455933 lr : 0.1962915140230253\n",
      "epoch : 162 [11/23] Train loss: 0.46731,Valid loss: 0.73275, time : 10.251956701278687 lr : 0.1962915140230253\n",
      "epoch : 162 [12/23] Train loss: 0.46933,Valid loss: 0.73297, time : 10.410654306411743 lr : 0.1962915140230253\n",
      "epoch : 162 [13/23] Train loss: 0.48060,Valid loss: 0.72671, time : 10.193320751190186 lr : 0.1962915140230253\n",
      "epoch : 162 [14/23] Train loss: 0.47211,Valid loss: 0.72084, time : 10.692536115646362 lr : 0.1962915140230253\n",
      "epoch : 162 [15/23] Train loss: 0.46612,Valid loss: 0.73974, time : 10.24267578125 lr : 0.1962915140230253\n",
      "epoch : 162 [16/23] Train loss: 0.45957,Valid loss: 0.73439, time : 10.277005672454834 lr : 0.1962915140230253\n",
      "epoch : 162 [17/23] Train loss: 0.48477,Valid loss: 0.73028, time : 10.524652004241943 lr : 0.1962915140230253\n",
      "epoch : 162 [18/23] Train loss: 0.46589,Valid loss: 0.72139, time : 10.349123001098633 lr : 0.1962915140230253\n",
      "epoch : 162 [19/23] Train loss: 0.47431,Valid loss: 0.77573, time : 10.395155429840088 lr : 0.1962915140230253\n",
      "epoch : 162 [20/23] Train loss: 0.46777,Valid loss: 0.73506, time : 10.097970962524414 lr : 0.1962915140230253\n",
      "epoch : 162 [21/23] Train loss: 0.47000,Valid loss: 0.72796, time : 10.497384309768677 lr : 0.1962915140230253\n",
      "epoch : 162 [22/23] Train loss: 0.47116,Valid loss: 0.73072, time : 9.637974500656128 lr : 0.1962915140230253\n",
      "epoch : 163 [0/23] Train loss: 0.47597,Valid loss: 0.72485, time : 10.661057472229004 lr : 0.19432859888279505\n",
      "epoch : 163 [1/23] Train loss: 0.45594,Valid loss: 0.72447, time : 10.202666759490967 lr : 0.19432859888279505\n",
      "epoch : 163 [2/23] Train loss: 0.48140,Valid loss: 0.73821, time : 10.051561117172241 lr : 0.19432859888279505\n",
      "epoch : 163 [3/23] Train loss: 0.45083,Valid loss: 0.75522, time : 10.510700702667236 lr : 0.19432859888279505\n",
      "epoch : 163 [4/23] Train loss: 0.45999,Valid loss: 0.72215, time : 10.25154709815979 lr : 0.19432859888279505\n",
      "epoch : 163 [5/23] Train loss: 0.48308,Valid loss: 0.73419, time : 10.149981498718262 lr : 0.19432859888279505\n",
      "epoch : 163 [6/23] Train loss: 0.46605,Valid loss: 0.71963, time : 10.601069211959839 lr : 0.19432859888279505\n",
      "epoch : 163 [7/23] Train loss: 0.46802,Valid loss: 0.73275, time : 10.441316604614258 lr : 0.19432859888279505\n",
      "epoch : 163 [8/23] Train loss: 0.46429,Valid loss: 0.72700, time : 10.123615503311157 lr : 0.19432859888279505\n",
      "epoch : 163 [9/23] Train loss: 0.46883,Valid loss: 0.73699, time : 10.476532936096191 lr : 0.19432859888279505\n",
      "epoch : 163 [10/23] Train loss: 0.46889,Valid loss: 0.72197, time : 10.417869567871094 lr : 0.19432859888279505\n",
      "epoch : 163 [11/23] Train loss: 0.47127,Valid loss: 0.75993, time : 10.437866449356079 lr : 0.19432859888279505\n",
      "epoch : 163 [12/23] Train loss: 0.46678,Valid loss: 0.77055, time : 10.451971769332886 lr : 0.19432859888279505\n",
      "epoch : 163 [13/23] Train loss: 0.44779,Valid loss: 0.75913, time : 10.343256950378418 lr : 0.19432859888279505\n",
      "epoch : 163 [14/23] Train loss: 0.46700,Valid loss: 0.72146, time : 10.402680397033691 lr : 0.19432859888279505\n",
      "epoch : 163 [15/23] Train loss: 0.46074,Valid loss: 0.72772, time : 10.654090166091919 lr : 0.19432859888279505\n",
      "epoch : 163 [16/23] Train loss: 0.46250,Valid loss: 0.71744, time : 10.288294076919556 lr : 0.19432859888279505\n",
      "epoch : 163 [17/23] Train loss: 0.45897,Valid loss: 0.74734, time : 10.550096988677979 lr : 0.19432859888279505\n",
      "epoch : 163 [18/23] Train loss: 0.47660,Valid loss: 0.73893, time : 10.167137622833252 lr : 0.19432859888279505\n",
      "epoch : 163 [19/23] Train loss: 0.47318,Valid loss: 0.72745, time : 10.506233930587769 lr : 0.19432859888279505\n",
      "epoch : 163 [20/23] Train loss: 0.46007,Valid loss: 0.72081, time : 10.271419525146484 lr : 0.19432859888279505\n",
      "epoch : 163 [21/23] Train loss: 0.45693,Valid loss: 0.73166, time : 10.477725267410278 lr : 0.19432859888279505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 163 [22/23] Train loss: 0.48045,Valid loss: 0.74324, time : 9.564132452011108 lr : 0.19432859888279505\n",
      "epoch : 164 [0/23] Train loss: 0.47430,Valid loss: 0.73562, time : 10.349328994750977 lr : 0.1923853128939671\n",
      "epoch : 164 [1/23] Train loss: 0.45935,Valid loss: 0.72958, time : 10.097442865371704 lr : 0.1923853128939671\n",
      "epoch : 164 [2/23] Train loss: 0.44944,Valid loss: 0.71504, time : 10.290255784988403 lr : 0.1923853128939671\n",
      "epoch : 164 [3/23] Train loss: 0.46127,Valid loss: 0.72579, time : 9.812190771102905 lr : 0.1923853128939671\n",
      "epoch : 164 [4/23] Train loss: 0.46385,Valid loss: 0.72412, time : 10.227596759796143 lr : 0.1923853128939671\n",
      "epoch : 164 [5/23] Train loss: 0.45360,Valid loss: 0.71639, time : 10.010518074035645 lr : 0.1923853128939671\n",
      "epoch : 164 [6/23] Train loss: 0.46655,Valid loss: 0.72325, time : 10.045105218887329 lr : 0.1923853128939671\n",
      "epoch : 164 [7/23] Train loss: 0.46232,Valid loss: 0.71580, time : 10.323909997940063 lr : 0.1923853128939671\n",
      "epoch : 164 [8/23] Train loss: 0.46052,Valid loss: 0.73455, time : 10.100043535232544 lr : 0.1923853128939671\n",
      "epoch : 164 [9/23] Train loss: 0.45212,Valid loss: 0.74980, time : 10.38734745979309 lr : 0.1923853128939671\n",
      "epoch : 164 [10/23] Train loss: 0.47931,Valid loss: 0.71727, time : 10.471417903900146 lr : 0.1923853128939671\n",
      "epoch : 164 [11/23] Train loss: 0.46643,Valid loss: 0.72911, time : 10.620849132537842 lr : 0.1923853128939671\n",
      "epoch : 164 [12/23] Train loss: 0.46745,Valid loss: 0.73065, time : 10.45680856704712 lr : 0.1923853128939671\n",
      "epoch : 164 [13/23] Train loss: 0.45482,Valid loss: 0.71033, time : 10.229350328445435 lr : 0.1923853128939671\n",
      "epoch : 164 [14/23] Train loss: 0.45741,Valid loss: 0.71316, time : 10.575562715530396 lr : 0.1923853128939671\n",
      "epoch : 164 [15/23] Train loss: 0.46076,Valid loss: 0.72534, time : 10.6815767288208 lr : 0.1923853128939671\n",
      "epoch : 164 [16/23] Train loss: 0.46598,Valid loss: 0.72469, time : 10.302440166473389 lr : 0.1923853128939671\n",
      "epoch : 164 [17/23] Train loss: 0.46592,Valid loss: 0.71931, time : 10.226699352264404 lr : 0.1923853128939671\n",
      "epoch : 164 [18/23] Train loss: 0.46651,Valid loss: 0.71865, time : 10.049017190933228 lr : 0.1923853128939671\n",
      "epoch : 164 [19/23] Train loss: 0.46554,Valid loss: 0.70375, time : 10.418437242507935 lr : 0.1923853128939671\n",
      "epoch : 164 [20/23] Train loss: 0.45169,Valid loss: 0.72692, time : 10.177400588989258 lr : 0.1923853128939671\n",
      "epoch : 164 [21/23] Train loss: 0.46122,Valid loss: 0.71810, time : 10.399504899978638 lr : 0.1923853128939671\n",
      "epoch : 164 [22/23] Train loss: 0.44985,Valid loss: 0.72524, time : 9.543496370315552 lr : 0.1923853128939671\n",
      "epoch : 165 [0/23] Train loss: 0.47652,Valid loss: 0.72393, time : 10.42531156539917 lr : 0.19046145976502743\n",
      "epoch : 165 [1/23] Train loss: 0.45779,Valid loss: 0.75279, time : 10.0691397190094 lr : 0.19046145976502743\n",
      "epoch : 165 [2/23] Train loss: 0.46314,Valid loss: 0.72614, time : 10.685663938522339 lr : 0.19046145976502743\n",
      "epoch : 165 [3/23] Train loss: 0.45161,Valid loss: 0.77851, time : 10.336938619613647 lr : 0.19046145976502743\n",
      "epoch : 165 [4/23] Train loss: 0.44803,Valid loss: 0.72425, time : 10.56760573387146 lr : 0.19046145976502743\n",
      "epoch : 165 [5/23] Train loss: 0.45640,Valid loss: 0.72162, time : 9.848487138748169 lr : 0.19046145976502743\n",
      "epoch : 165 [6/23] Train loss: 0.45248,Valid loss: 0.70408, time : 10.05537462234497 lr : 0.19046145976502743\n",
      "epoch : 165 [7/23] Train loss: 0.46327,Valid loss: 0.79835, time : 10.3573739528656 lr : 0.19046145976502743\n",
      "epoch : 165 [8/23] Train loss: 0.47483,Valid loss: 0.74060, time : 10.36566686630249 lr : 0.19046145976502743\n",
      "epoch : 165 [9/23] Train loss: 0.51939,Valid loss: 0.75373, time : 10.226126670837402 lr : 0.19046145976502743\n",
      "epoch : 165 [10/23] Train loss: 0.47528,Valid loss: 0.73483, time : 10.035255908966064 lr : 0.19046145976502743\n",
      "epoch : 165 [11/23] Train loss: 0.45691,Valid loss: 0.75357, time : 10.4633948802948 lr : 0.19046145976502743\n",
      "epoch : 165 [12/23] Train loss: 0.45492,Valid loss: 0.73556, time : 10.249855518341064 lr : 0.19046145976502743\n",
      "epoch : 165 [13/23] Train loss: 0.47311,Valid loss: 0.72352, time : 10.202397346496582 lr : 0.19046145976502743\n",
      "epoch : 165 [14/23] Train loss: 0.46408,Valid loss: 0.79237, time : 10.584064722061157 lr : 0.19046145976502743\n",
      "epoch : 165 [15/23] Train loss: 0.46693,Valid loss: 0.73049, time : 10.467036962509155 lr : 0.19046145976502743\n",
      "epoch : 165 [16/23] Train loss: 0.46310,Valid loss: 0.79815, time : 10.482106685638428 lr : 0.19046145976502743\n",
      "epoch : 165 [17/23] Train loss: 0.46732,Valid loss: 0.71619, time : 10.302984476089478 lr : 0.19046145976502743\n",
      "epoch : 165 [18/23] Train loss: 0.45132,Valid loss: 0.71792, time : 10.483874320983887 lr : 0.19046145976502743\n",
      "epoch : 165 [19/23] Train loss: 0.46517,Valid loss: 0.72360, time : 10.080699682235718 lr : 0.19046145976502743\n",
      "epoch : 165 [20/23] Train loss: 0.45866,Valid loss: 0.73280, time : 10.2762770652771 lr : 0.19046145976502743\n",
      "epoch : 165 [21/23] Train loss: 0.44946,Valid loss: 0.71363, time : 10.464215278625488 lr : 0.19046145976502743\n",
      "epoch : 165 [22/23] Train loss: 0.45029,Valid loss: 0.69855, time : 9.538460731506348 lr : 0.19046145976502743\n",
      "epoch : 166 [0/23] Train loss: 0.44955,Valid loss: 0.69930, time : 10.518065690994263 lr : 0.18855684516737714\n",
      "epoch : 166 [1/23] Train loss: 0.44616,Valid loss: 0.70530, time : 10.11553692817688 lr : 0.18855684516737714\n",
      "epoch : 166 [2/23] Train loss: 0.44666,Valid loss: 0.71229, time : 10.166168451309204 lr : 0.18855684516737714\n",
      "epoch : 166 [3/23] Train loss: 0.44783,Valid loss: 0.70495, time : 10.158658266067505 lr : 0.18855684516737714\n",
      "epoch : 166 [4/23] Train loss: 0.45557,Valid loss: 0.74274, time : 9.866527557373047 lr : 0.18855684516737714\n",
      "epoch : 166 [5/23] Train loss: 0.44404,Valid loss: 0.69825, time : 10.11111569404602 lr : 0.18855684516737714\n",
      "epoch : 166 [6/23] Train loss: 0.45272,Valid loss: 0.73414, time : 10.065186262130737 lr : 0.18855684516737714\n",
      "epoch : 166 [7/23] Train loss: 0.45685,Valid loss: 0.71642, time : 10.001740217208862 lr : 0.18855684516737714\n",
      "epoch : 166 [8/23] Train loss: 0.45132,Valid loss: 0.70111, time : 10.32278847694397 lr : 0.18855684516737714\n",
      "epoch : 166 [9/23] Train loss: 0.46463,Valid loss: 0.72161, time : 9.70770525932312 lr : 0.18855684516737714\n",
      "epoch : 166 [10/23] Train loss: 0.45398,Valid loss: 0.71967, time : 10.173453330993652 lr : 0.18855684516737714\n",
      "epoch : 166 [11/23] Train loss: 0.45607,Valid loss: 0.71257, time : 10.066768169403076 lr : 0.18855684516737714\n",
      "epoch : 166 [12/23] Train loss: 0.45946,Valid loss: 0.74955, time : 10.496549844741821 lr : 0.18855684516737714\n",
      "epoch : 166 [13/23] Train loss: 0.45022,Valid loss: 0.78771, time : 10.304865837097168 lr : 0.18855684516737714\n",
      "epoch : 166 [14/23] Train loss: 0.45275,Valid loss: 0.71970, time : 10.761888265609741 lr : 0.18855684516737714\n",
      "epoch : 166 [15/23] Train loss: 0.45197,Valid loss: 0.77741, time : 9.838874816894531 lr : 0.18855684516737714\n",
      "epoch : 166 [16/23] Train loss: 0.45784,Valid loss: 0.71509, time : 10.309225082397461 lr : 0.18855684516737714\n",
      "epoch : 166 [17/23] Train loss: 0.45620,Valid loss: 0.76951, time : 9.975547790527344 lr : 0.18855684516737714\n",
      "epoch : 166 [18/23] Train loss: 0.44515,Valid loss: 0.70089, time : 10.23833155632019 lr : 0.18855684516737714\n",
      "epoch : 166 [19/23] Train loss: 0.46104,Valid loss: 0.73258, time : 10.264289855957031 lr : 0.18855684516737714\n",
      "epoch : 166 [20/23] Train loss: 0.45423,Valid loss: 0.70819, time : 10.081720113754272 lr : 0.18855684516737714\n",
      "epoch : 166 [21/23] Train loss: 0.44785,Valid loss: 0.70674, time : 10.002980709075928 lr : 0.18855684516737714\n",
      "epoch : 166 [22/23] Train loss: 0.43596,Valid loss: 0.72728, time : 9.653417587280273 lr : 0.18855684516737714\n",
      "epoch : 167 [0/23] Train loss: 0.45031,Valid loss: 0.70815, time : 9.807334661483765 lr : 0.18667127671570335\n",
      "epoch : 167 [1/23] Train loss: 0.43295,Valid loss: 0.70605, time : 10.490077495574951 lr : 0.18667127671570335\n",
      "epoch : 167 [2/23] Train loss: 0.44858,Valid loss: 0.72356, time : 10.068290710449219 lr : 0.18667127671570335\n",
      "epoch : 167 [3/23] Train loss: 0.45975,Valid loss: 0.73283, time : 10.393370628356934 lr : 0.18667127671570335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 167 [4/23] Train loss: 0.44560,Valid loss: 0.70195, time : 9.83785343170166 lr : 0.18667127671570335\n",
      "epoch : 167 [5/23] Train loss: 0.44095,Valid loss: 0.71306, time : 10.546287059783936 lr : 0.18667127671570335\n",
      "epoch : 167 [6/23] Train loss: 0.44299,Valid loss: 0.72593, time : 9.817835569381714 lr : 0.18667127671570335\n",
      "epoch : 167 [7/23] Train loss: 0.44016,Valid loss: 0.69968, time : 10.390604257583618 lr : 0.18667127671570335\n",
      "epoch : 167 [8/23] Train loss: 0.43994,Valid loss: 0.70107, time : 9.850811004638672 lr : 0.18667127671570335\n",
      "epoch : 167 [9/23] Train loss: 0.45623,Valid loss: 0.70655, time : 10.251955509185791 lr : 0.18667127671570335\n",
      "epoch : 167 [10/23] Train loss: 0.44871,Valid loss: 0.72834, time : 9.658620119094849 lr : 0.18667127671570335\n",
      "epoch : 167 [11/23] Train loss: 0.47294,Valid loss: 0.74284, time : 10.405202388763428 lr : 0.18667127671570335\n",
      "epoch : 167 [12/23] Train loss: 0.45209,Valid loss: 0.71562, time : 9.903660774230957 lr : 0.18667127671570335\n",
      "epoch : 167 [13/23] Train loss: 0.44878,Valid loss: 0.69926, time : 10.125725746154785 lr : 0.18667127671570335\n",
      "epoch : 167 [14/23] Train loss: 0.43869,Valid loss: 0.75531, time : 10.13809847831726 lr : 0.18667127671570335\n",
      "epoch : 167 [15/23] Train loss: 0.43940,Valid loss: 0.71491, time : 10.083718299865723 lr : 0.18667127671570335\n",
      "epoch : 167 [16/23] Train loss: 0.46079,Valid loss: 0.70480, time : 10.15278697013855 lr : 0.18667127671570335\n",
      "epoch : 167 [17/23] Train loss: 0.45347,Valid loss: 0.70193, time : 10.046889781951904 lr : 0.18667127671570335\n",
      "epoch : 167 [18/23] Train loss: 0.45141,Valid loss: 0.74883, time : 9.975140571594238 lr : 0.18667127671570335\n",
      "epoch : 167 [19/23] Train loss: 0.45276,Valid loss: 0.72844, time : 9.858413457870483 lr : 0.18667127671570335\n",
      "epoch : 167 [20/23] Train loss: 0.45531,Valid loss: 0.69481, time : 10.355354309082031 lr : 0.18667127671570335\n",
      "epoch : 167 [21/23] Train loss: 0.45411,Valid loss: 0.75102, time : 10.350244045257568 lr : 0.18667127671570335\n",
      "epoch : 167 [22/23] Train loss: 0.44834,Valid loss: 0.72765, time : 9.631604194641113 lr : 0.18667127671570335\n",
      "epoch : 168 [0/23] Train loss: 0.45902,Valid loss: 0.75977, time : 10.609736680984497 lr : 0.18480456394854633\n",
      "epoch : 168 [1/23] Train loss: 0.46518,Valid loss: 0.71602, time : 10.100838661193848 lr : 0.18480456394854633\n",
      "epoch : 168 [2/23] Train loss: 0.45592,Valid loss: 0.78918, time : 10.18500566482544 lr : 0.18480456394854633\n",
      "epoch : 168 [3/23] Train loss: 0.44860,Valid loss: 0.69860, time : 10.271164655685425 lr : 0.18480456394854633\n",
      "epoch : 168 [4/23] Train loss: 0.44644,Valid loss: 0.73026, time : 10.53324294090271 lr : 0.18480456394854633\n",
      "epoch : 168 [5/23] Train loss: 0.44538,Valid loss: 0.70848, time : 10.282018661499023 lr : 0.18480456394854633\n",
      "epoch : 168 [6/23] Train loss: 0.45161,Valid loss: 0.75175, time : 10.125867366790771 lr : 0.18480456394854633\n",
      "epoch : 168 [7/23] Train loss: 0.45288,Valid loss: 0.72080, time : 10.290886640548706 lr : 0.18480456394854633\n",
      "epoch : 168 [8/23] Train loss: 0.43902,Valid loss: 0.79422, time : 9.891143321990967 lr : 0.18480456394854633\n",
      "epoch : 168 [9/23] Train loss: 0.45020,Valid loss: 0.70915, time : 10.326615571975708 lr : 0.18480456394854633\n",
      "epoch : 168 [10/23] Train loss: 0.45299,Valid loss: 0.77313, time : 10.317239761352539 lr : 0.18480456394854633\n",
      "epoch : 168 [11/23] Train loss: 0.44747,Valid loss: 0.70692, time : 9.93349003791809 lr : 0.18480456394854633\n",
      "epoch : 168 [12/23] Train loss: 0.44141,Valid loss: 0.72846, time : 9.933047771453857 lr : 0.18480456394854633\n",
      "epoch : 168 [13/23] Train loss: 0.43311,Valid loss: 0.73822, time : 9.902932167053223 lr : 0.18480456394854633\n",
      "epoch : 168 [14/23] Train loss: 0.44614,Valid loss: 0.71966, time : 10.335936307907104 lr : 0.18480456394854633\n",
      "epoch : 168 [15/23] Train loss: 0.45823,Valid loss: 0.76914, time : 10.181422472000122 lr : 0.18480456394854633\n",
      "epoch : 168 [16/23] Train loss: 0.42976,Valid loss: 0.71556, time : 9.90469217300415 lr : 0.18480456394854633\n",
      "epoch : 168 [17/23] Train loss: 0.44968,Valid loss: 0.73046, time : 10.170964002609253 lr : 0.18480456394854633\n",
      "epoch : 168 [18/23] Train loss: 0.44515,Valid loss: 0.70398, time : 10.526421308517456 lr : 0.18480456394854633\n",
      "epoch : 168 [19/23] Train loss: 0.44939,Valid loss: 0.70530, time : 10.641732215881348 lr : 0.18480456394854633\n",
      "epoch : 168 [20/23] Train loss: 0.44198,Valid loss: 0.71164, time : 10.219498872756958 lr : 0.18480456394854633\n",
      "epoch : 168 [21/23] Train loss: 0.44646,Valid loss: 0.76203, time : 10.33805251121521 lr : 0.18480456394854633\n",
      "epoch : 168 [22/23] Train loss: 0.46243,Valid loss: 0.74062, time : 9.517709255218506 lr : 0.18480456394854633\n",
      "epoch : 169 [0/23] Train loss: 0.47389,Valid loss: 0.71431, time : 10.431886434555054 lr : 0.18295651830906087\n",
      "epoch : 169 [1/23] Train loss: 0.45764,Valid loss: 1.00374, time : 10.239574432373047 lr : 0.18295651830906087\n",
      "epoch : 169 [2/23] Train loss: 0.47358,Valid loss: 0.76004, time : 10.55093765258789 lr : 0.18295651830906087\n",
      "epoch : 169 [3/23] Train loss: 0.48392,Valid loss: 0.75088, time : 10.265368700027466 lr : 0.18295651830906087\n",
      "epoch : 169 [4/23] Train loss: 0.49262,Valid loss: 0.74206, time : 10.514477491378784 lr : 0.18295651830906087\n",
      "epoch : 169 [5/23] Train loss: 0.47629,Valid loss: 0.79055, time : 10.68842887878418 lr : 0.18295651830906087\n",
      "epoch : 169 [6/23] Train loss: 0.49329,Valid loss: 0.80293, time : 10.610908269882202 lr : 0.18295651830906087\n",
      "epoch : 169 [7/23] Train loss: 0.48720,Valid loss: 0.75953, time : 10.51205587387085 lr : 0.18295651830906087\n",
      "epoch : 169 [8/23] Train loss: 0.47087,Valid loss: 0.77907, time : 10.733459234237671 lr : 0.18295651830906087\n",
      "epoch : 169 [9/23] Train loss: 0.52089,Valid loss: 0.80383, time : 10.5188627243042 lr : 0.18295651830906087\n",
      "epoch : 169 [10/23] Train loss: 0.49730,Valid loss: 0.79795, time : 10.673383951187134 lr : 0.18295651830906087\n",
      "epoch : 169 [11/23] Train loss: 0.50100,Valid loss: 0.75395, time : 10.502949953079224 lr : 0.18295651830906087\n",
      "epoch : 169 [12/23] Train loss: 0.48612,Valid loss: 0.74020, time : 10.199789762496948 lr : 0.18295651830906087\n",
      "epoch : 169 [13/23] Train loss: 0.47502,Valid loss: 0.73652, time : 10.359543561935425 lr : 0.18295651830906087\n",
      "epoch : 169 [14/23] Train loss: 0.46465,Valid loss: 0.73845, time : 10.424365282058716 lr : 0.18295651830906087\n",
      "epoch : 169 [15/23] Train loss: 0.47847,Valid loss: 0.73587, time : 10.47541618347168 lr : 0.18295651830906087\n",
      "epoch : 169 [16/23] Train loss: 0.46684,Valid loss: 0.71863, time : 10.510077714920044 lr : 0.18295651830906087\n",
      "epoch : 169 [17/23] Train loss: 0.46166,Valid loss: 0.72302, time : 9.963075637817383 lr : 0.18295651830906087\n",
      "epoch : 169 [18/23] Train loss: 0.46160,Valid loss: 0.70701, time : 10.384764671325684 lr : 0.18295651830906087\n",
      "epoch : 169 [19/23] Train loss: 0.46201,Valid loss: 0.72247, time : 10.447059631347656 lr : 0.18295651830906087\n",
      "epoch : 169 [20/23] Train loss: 0.46164,Valid loss: 0.70227, time : 10.414380550384521 lr : 0.18295651830906087\n",
      "epoch : 169 [21/23] Train loss: 0.46278,Valid loss: 0.70845, time : 10.485073804855347 lr : 0.18295651830906087\n",
      "epoch : 169 [22/23] Train loss: 0.45223,Valid loss: 0.80670, time : 9.790283679962158 lr : 0.18295651830906087\n",
      "epoch : 170 [0/23] Train loss: 0.46684,Valid loss: 0.79162, time : 10.526313781738281 lr : 0.18112695312597027\n",
      "epoch : 170 [1/23] Train loss: 0.46231,Valid loss: 0.69734, time : 10.36754822731018 lr : 0.18112695312597027\n",
      "epoch : 170 [2/23] Train loss: 0.46610,Valid loss: 0.75837, time : 10.407287359237671 lr : 0.18112695312597027\n",
      "epoch : 170 [3/23] Train loss: 0.46914,Valid loss: 0.78472, time : 10.309545278549194 lr : 0.18112695312597027\n",
      "epoch : 170 [4/23] Train loss: 0.45445,Valid loss: 0.71249, time : 9.859421253204346 lr : 0.18112695312597027\n",
      "epoch : 170 [5/23] Train loss: 0.45841,Valid loss: 0.72270, time : 10.36199688911438 lr : 0.18112695312597027\n",
      "epoch : 170 [6/23] Train loss: 0.44395,Valid loss: 0.70582, time : 10.675903081893921 lr : 0.18112695312597027\n",
      "epoch : 170 [7/23] Train loss: 0.44753,Valid loss: 0.75077, time : 10.198025941848755 lr : 0.18112695312597027\n",
      "epoch : 170 [8/23] Train loss: 0.44044,Valid loss: 0.72767, time : 10.130130290985107 lr : 0.18112695312597027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 170 [9/23] Train loss: 0.45781,Valid loss: 0.71668, time : 10.622238874435425 lr : 0.18112695312597027\n",
      "epoch : 170 [10/23] Train loss: 0.45902,Valid loss: 0.72708, time : 10.705397367477417 lr : 0.18112695312597027\n",
      "epoch : 170 [11/23] Train loss: 0.44372,Valid loss: 0.73489, time : 10.329131364822388 lr : 0.18112695312597027\n",
      "epoch : 170 [12/23] Train loss: 0.45604,Valid loss: 0.82909, time : 10.436952352523804 lr : 0.18112695312597027\n",
      "epoch : 170 [13/23] Train loss: 0.44893,Valid loss: 0.72925, time : 10.147207498550415 lr : 0.18112695312597027\n",
      "epoch : 170 [14/23] Train loss: 0.45208,Valid loss: 0.72349, time : 10.305127143859863 lr : 0.18112695312597027\n",
      "epoch : 170 [15/23] Train loss: 0.45222,Valid loss: 0.73625, time : 10.61043095588684 lr : 0.18112695312597027\n",
      "epoch : 170 [16/23] Train loss: 0.45070,Valid loss: 0.72859, time : 10.461921453475952 lr : 0.18112695312597027\n",
      "epoch : 170 [17/23] Train loss: 0.44636,Valid loss: 0.74714, time : 10.191143989562988 lr : 0.18112695312597027\n",
      "epoch : 170 [18/23] Train loss: 0.46501,Valid loss: 0.78308, time : 10.328864097595215 lr : 0.18112695312597027\n",
      "epoch : 170 [19/23] Train loss: 0.45178,Valid loss: 0.72752, time : 10.327006340026855 lr : 0.18112695312597027\n",
      "epoch : 170 [20/23] Train loss: 0.45907,Valid loss: 0.68201, time : 10.325719594955444 lr : 0.18112695312597027\n",
      "epoch : 170 [21/23] Train loss: 0.45032,Valid loss: 0.70355, time : 10.571779012680054 lr : 0.18112695312597027\n",
      "epoch : 170 [22/23] Train loss: 0.44851,Valid loss: 0.69663, time : 10.05089807510376 lr : 0.18112695312597027\n",
      "epoch : 171 [0/23] Train loss: 0.45500,Valid loss: 0.72544, time : 10.37816047668457 lr : 0.17931568359471056\n",
      "epoch : 171 [1/23] Train loss: 0.45916,Valid loss: 0.69936, time : 10.672102689743042 lr : 0.17931568359471056\n",
      "epoch : 171 [2/23] Train loss: 0.45318,Valid loss: 0.69284, time : 10.014056921005249 lr : 0.17931568359471056\n",
      "epoch : 171 [3/23] Train loss: 0.45699,Valid loss: 0.72956, time : 10.419507265090942 lr : 0.17931568359471056\n",
      "epoch : 171 [4/23] Train loss: 0.44115,Valid loss: 0.69634, time : 10.368646621704102 lr : 0.17931568359471056\n",
      "epoch : 171 [5/23] Train loss: 0.45021,Valid loss: 0.70267, time : 10.167517185211182 lr : 0.17931568359471056\n",
      "epoch : 171 [6/23] Train loss: 0.45121,Valid loss: 0.74973, time : 10.5107421875 lr : 0.17931568359471056\n",
      "epoch : 171 [7/23] Train loss: 0.44516,Valid loss: 0.72178, time : 9.969230890274048 lr : 0.17931568359471056\n",
      "epoch : 171 [8/23] Train loss: 0.44927,Valid loss: 0.74262, time : 10.22012734413147 lr : 0.17931568359471056\n",
      "epoch : 171 [9/23] Train loss: 0.45923,Valid loss: 0.70891, time : 10.265947103500366 lr : 0.17931568359471056\n",
      "epoch : 171 [10/23] Train loss: 0.44763,Valid loss: 0.69630, time : 9.778928518295288 lr : 0.17931568359471056\n",
      "epoch : 171 [11/23] Train loss: 0.44236,Valid loss: 0.71198, time : 10.084840059280396 lr : 0.17931568359471056\n",
      "epoch : 171 [12/23] Train loss: 0.44107,Valid loss: 0.74666, time : 10.382272481918335 lr : 0.17931568359471056\n",
      "epoch : 171 [13/23] Train loss: 0.44939,Valid loss: 0.73044, time : 10.088773250579834 lr : 0.17931568359471056\n",
      "epoch : 171 [14/23] Train loss: 0.44703,Valid loss: 0.71151, time : 10.14607286453247 lr : 0.17931568359471056\n",
      "epoch : 171 [15/23] Train loss: 0.44082,Valid loss: 0.70418, time : 9.849543333053589 lr : 0.17931568359471056\n",
      "epoch : 171 [16/23] Train loss: 0.44133,Valid loss: 0.73934, time : 10.251091957092285 lr : 0.17931568359471056\n",
      "epoch : 171 [17/23] Train loss: 0.43669,Valid loss: 0.74844, time : 10.250511884689331 lr : 0.17931568359471056\n",
      "epoch : 171 [18/23] Train loss: 0.44398,Valid loss: 0.69747, time : 9.729758024215698 lr : 0.17931568359471056\n",
      "epoch : 171 [19/23] Train loss: 0.43637,Valid loss: 0.70626, time : 10.365366697311401 lr : 0.17931568359471056\n",
      "epoch : 171 [20/23] Train loss: 0.44849,Valid loss: 0.70105, time : 10.116502046585083 lr : 0.17931568359471056\n",
      "epoch : 171 [21/23] Train loss: 0.44410,Valid loss: 0.73562, time : 10.581722021102905 lr : 0.17931568359471056\n",
      "epoch : 171 [22/23] Train loss: 0.46322,Valid loss: 0.70683, time : 9.404365539550781 lr : 0.17931568359471056\n",
      "epoch : 172 [0/23] Train loss: 0.48397,Valid loss: 0.76506, time : 10.399133920669556 lr : 0.17752252675876345\n",
      "epoch : 172 [1/23] Train loss: 0.46185,Valid loss: 0.76708, time : 10.995502471923828 lr : 0.17752252675876345\n",
      "epoch : 172 [2/23] Train loss: 0.48645,Valid loss: 0.80413, time : 10.332149267196655 lr : 0.17752252675876345\n",
      "epoch : 172 [3/23] Train loss: 0.48768,Valid loss: 0.73619, time : 10.209593296051025 lr : 0.17752252675876345\n",
      "epoch : 172 [4/23] Train loss: 0.45862,Valid loss: 0.73171, time : 10.290242910385132 lr : 0.17752252675876345\n",
      "epoch : 172 [5/23] Train loss: 0.44917,Valid loss: 0.76065, time : 10.38323163986206 lr : 0.17752252675876345\n",
      "epoch : 172 [6/23] Train loss: 0.44805,Valid loss: 0.71585, time : 10.180688381195068 lr : 0.17752252675876345\n",
      "epoch : 172 [7/23] Train loss: 0.45486,Valid loss: 0.68908, time : 10.405096054077148 lr : 0.17752252675876345\n",
      "epoch : 172 [8/23] Train loss: 0.44141,Valid loss: 0.70608, time : 10.104979276657104 lr : 0.17752252675876345\n",
      "epoch : 172 [9/23] Train loss: 0.45952,Valid loss: 0.72645, time : 9.961653232574463 lr : 0.17752252675876345\n",
      "epoch : 172 [10/23] Train loss: 0.44059,Valid loss: 0.72683, time : 10.16316294670105 lr : 0.17752252675876345\n",
      "epoch : 172 [11/23] Train loss: 0.45706,Valid loss: 0.70509, time : 10.480707168579102 lr : 0.17752252675876345\n",
      "epoch : 172 [12/23] Train loss: 0.45585,Valid loss: 0.73306, time : 10.320457696914673 lr : 0.17752252675876345\n",
      "epoch : 172 [13/23] Train loss: 0.44055,Valid loss: 0.70430, time : 10.291948556900024 lr : 0.17752252675876345\n",
      "epoch : 172 [14/23] Train loss: 0.43866,Valid loss: 0.70004, time : 10.393963813781738 lr : 0.17752252675876345\n",
      "epoch : 172 [15/23] Train loss: 0.44322,Valid loss: 0.73911, time : 10.575509786605835 lr : 0.17752252675876345\n",
      "epoch : 172 [16/23] Train loss: 0.45061,Valid loss: 0.74025, time : 10.23742938041687 lr : 0.17752252675876345\n",
      "epoch : 172 [17/23] Train loss: 0.44184,Valid loss: 0.69685, time : 10.507261514663696 lr : 0.17752252675876345\n",
      "epoch : 172 [18/23] Train loss: 0.44709,Valid loss: 0.74485, time : 10.551992416381836 lr : 0.17752252675876345\n",
      "epoch : 172 [19/23] Train loss: 0.43658,Valid loss: 0.72749, time : 10.598022222518921 lr : 0.17752252675876345\n",
      "epoch : 172 [20/23] Train loss: 0.45200,Valid loss: 0.72142, time : 10.29844069480896 lr : 0.17752252675876345\n",
      "epoch : 172 [21/23] Train loss: 0.45121,Valid loss: 0.70306, time : 10.349750518798828 lr : 0.17752252675876345\n",
      "epoch : 172 [22/23] Train loss: 0.45411,Valid loss: 0.71222, time : 9.646958351135254 lr : 0.17752252675876345\n",
      "epoch : 173 [0/23] Train loss: 0.44721,Valid loss: 0.68720, time : 10.23051142692566 lr : 0.17574730149117582\n",
      "epoch : 173 [1/23] Train loss: 0.45331,Valid loss: 0.70135, time : 10.27086353302002 lr : 0.17574730149117582\n",
      "epoch : 173 [2/23] Train loss: 0.44803,Valid loss: 0.71901, time : 9.715469121932983 lr : 0.17574730149117582\n",
      "epoch : 173 [3/23] Train loss: 0.43219,Valid loss: 0.76073, time : 10.279374837875366 lr : 0.17574730149117582\n",
      "epoch : 173 [4/23] Train loss: 0.45609,Valid loss: 0.72954, time : 10.420743942260742 lr : 0.17574730149117582\n",
      "epoch : 173 [5/23] Train loss: 0.44272,Valid loss: 0.71458, time : 10.18838095664978 lr : 0.17574730149117582\n",
      "epoch : 173 [6/23] Train loss: 0.44565,Valid loss: 0.70186, time : 9.66523027420044 lr : 0.17574730149117582\n",
      "epoch : 173 [7/23] Train loss: 0.43753,Valid loss: 0.69404, time : 9.766871452331543 lr : 0.17574730149117582\n",
      "epoch : 173 [8/23] Train loss: 0.43890,Valid loss: 0.71552, time : 10.031432151794434 lr : 0.17574730149117582\n",
      "epoch : 173 [9/23] Train loss: 0.43818,Valid loss: 0.70950, time : 9.828251123428345 lr : 0.17574730149117582\n",
      "epoch : 173 [10/23] Train loss: 0.44102,Valid loss: 0.71077, time : 10.05141830444336 lr : 0.17574730149117582\n",
      "epoch : 173 [11/23] Train loss: 0.44144,Valid loss: 0.69567, time : 10.062765121459961 lr : 0.17574730149117582\n",
      "epoch : 173 [12/23] Train loss: 0.43478,Valid loss: 0.68538, time : 10.044175386428833 lr : 0.17574730149117582\n",
      "epoch : 173 [13/23] Train loss: 0.42998,Valid loss: 0.73849, time : 10.110184669494629 lr : 0.17574730149117582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 173 [14/23] Train loss: 0.42747,Valid loss: 0.71371, time : 10.101303339004517 lr : 0.17574730149117582\n",
      "epoch : 173 [15/23] Train loss: 0.43782,Valid loss: 0.71449, time : 10.12087345123291 lr : 0.17574730149117582\n",
      "epoch : 173 [16/23] Train loss: 0.43937,Valid loss: 0.69987, time : 10.399014949798584 lr : 0.17574730149117582\n",
      "epoch : 173 [17/23] Train loss: 0.44303,Valid loss: 0.71026, time : 10.40844988822937 lr : 0.17574730149117582\n",
      "epoch : 173 [18/23] Train loss: 0.45093,Valid loss: 0.70428, time : 9.978711605072021 lr : 0.17574730149117582\n",
      "epoch : 173 [19/23] Train loss: 0.44776,Valid loss: 0.71229, time : 10.182198524475098 lr : 0.17574730149117582\n",
      "epoch : 173 [20/23] Train loss: 0.44035,Valid loss: 0.69958, time : 10.641466617584229 lr : 0.17574730149117582\n",
      "epoch : 173 [21/23] Train loss: 0.43100,Valid loss: 0.71228, time : 10.149277448654175 lr : 0.17574730149117582\n",
      "epoch : 173 [22/23] Train loss: 0.43342,Valid loss: 0.74579, time : 9.52888035774231 lr : 0.17574730149117582\n",
      "epoch : 174 [0/23] Train loss: 0.42931,Valid loss: 0.77988, time : 10.379963159561157 lr : 0.17398982847626407\n",
      "epoch : 174 [1/23] Train loss: 0.43582,Valid loss: 0.70325, time : 10.595219612121582 lr : 0.17398982847626407\n",
      "epoch : 174 [2/23] Train loss: 0.44341,Valid loss: 0.69401, time : 10.42948055267334 lr : 0.17398982847626407\n",
      "epoch : 174 [3/23] Train loss: 0.43290,Valid loss: 0.69362, time : 10.213027954101562 lr : 0.17398982847626407\n",
      "epoch : 174 [4/23] Train loss: 0.42071,Valid loss: 0.76049, time : 10.39755892753601 lr : 0.17398982847626407\n",
      "epoch : 174 [5/23] Train loss: 0.44159,Valid loss: 0.74851, time : 10.02551555633545 lr : 0.17398982847626407\n",
      "epoch : 174 [6/23] Train loss: 0.44098,Valid loss: 0.70827, time : 10.060632467269897 lr : 0.17398982847626407\n",
      "epoch : 174 [7/23] Train loss: 0.43235,Valid loss: 0.78166, time : 9.86255669593811 lr : 0.17398982847626407\n",
      "epoch : 174 [8/23] Train loss: 0.43597,Valid loss: 0.69671, time : 9.69204306602478 lr : 0.17398982847626407\n",
      "epoch : 174 [9/23] Train loss: 0.43481,Valid loss: 0.68716, time : 10.290228366851807 lr : 0.17398982847626407\n",
      "epoch : 174 [10/23] Train loss: 0.44001,Valid loss: 0.69913, time : 10.28745698928833 lr : 0.17398982847626407\n",
      "epoch : 174 [11/23] Train loss: 0.43342,Valid loss: 0.70981, time : 10.095930099487305 lr : 0.17398982847626407\n",
      "epoch : 174 [12/23] Train loss: 0.43256,Valid loss: 0.69007, time : 10.320188283920288 lr : 0.17398982847626407\n",
      "epoch : 174 [13/23] Train loss: 0.43876,Valid loss: 0.68811, time : 9.683573722839355 lr : 0.17398982847626407\n",
      "epoch : 174 [14/23] Train loss: 0.44759,Valid loss: 0.68536, time : 10.266025304794312 lr : 0.17398982847626407\n",
      "epoch : 174 [15/23] Train loss: 0.44407,Valid loss: 0.70680, time : 9.9554922580719 lr : 0.17398982847626407\n",
      "epoch : 174 [16/23] Train loss: 0.43772,Valid loss: 0.69960, time : 9.916037559509277 lr : 0.17398982847626407\n",
      "epoch : 174 [17/23] Train loss: 0.42805,Valid loss: 0.77898, time : 10.054362058639526 lr : 0.17398982847626407\n",
      "epoch : 174 [18/23] Train loss: 0.43677,Valid loss: 0.68958, time : 10.322502851486206 lr : 0.17398982847626407\n",
      "epoch : 174 [19/23] Train loss: 0.42104,Valid loss: 0.74737, time : 9.924776554107666 lr : 0.17398982847626407\n",
      "epoch : 174 [20/23] Train loss: 0.44009,Valid loss: 0.69179, time : 10.166965246200562 lr : 0.17398982847626407\n",
      "epoch : 174 [21/23] Train loss: 0.43888,Valid loss: 0.69715, time : 10.27054214477539 lr : 0.17398982847626407\n",
      "epoch : 174 [22/23] Train loss: 0.43001,Valid loss: 0.69868, time : 9.563430786132812 lr : 0.17398982847626407\n",
      "epoch : 175 [0/23] Train loss: 0.42846,Valid loss: 0.74556, time : 10.351073026657104 lr : 0.17224993019150142\n",
      "epoch : 175 [1/23] Train loss: 0.42817,Valid loss: 0.69993, time : 10.210277557373047 lr : 0.17224993019150142\n",
      "epoch : 175 [2/23] Train loss: 0.42901,Valid loss: 0.73019, time : 10.169355154037476 lr : 0.17224993019150142\n",
      "epoch : 175 [3/23] Train loss: 0.43428,Valid loss: 0.74154, time : 10.317955493927002 lr : 0.17224993019150142\n",
      "epoch : 175 [4/23] Train loss: 0.41385,Valid loss: 0.69665, time : 10.208046197891235 lr : 0.17224993019150142\n",
      "epoch : 175 [5/23] Train loss: 0.41912,Valid loss: 0.68979, time : 10.075406312942505 lr : 0.17224993019150142\n",
      "epoch : 175 [6/23] Train loss: 0.42408,Valid loss: 0.68619, time : 10.584918737411499 lr : 0.17224993019150142\n",
      "epoch : 175 [7/23] Train loss: 0.43731,Valid loss: 0.69340, time : 10.089712619781494 lr : 0.17224993019150142\n",
      "epoch : 175 [8/23] Train loss: 0.42533,Valid loss: 0.70745, time : 9.79826831817627 lr : 0.17224993019150142\n",
      "epoch : 175 [9/23] Train loss: 0.41780,Valid loss: 0.70241, time : 9.847573280334473 lr : 0.17224993019150142\n",
      "epoch : 175 [10/23] Train loss: 0.43171,Valid loss: 0.72987, time : 10.239362239837646 lr : 0.17224993019150142\n",
      "epoch : 175 [11/23] Train loss: 0.42661,Valid loss: 0.75809, time : 10.199939727783203 lr : 0.17224993019150142\n",
      "epoch : 175 [12/23] Train loss: 0.42900,Valid loss: 0.70066, time : 10.383579015731812 lr : 0.17224993019150142\n",
      "epoch : 175 [13/23] Train loss: 0.44103,Valid loss: 0.69807, time : 10.134183645248413 lr : 0.17224993019150142\n",
      "epoch : 175 [14/23] Train loss: 0.44073,Valid loss: 0.68155, time : 10.180227756500244 lr : 0.17224993019150142\n",
      "epoch : 175 [15/23] Train loss: 0.43025,Valid loss: 0.70006, time : 10.331006050109863 lr : 0.17224993019150142\n",
      "epoch : 175 [16/23] Train loss: 0.42605,Valid loss: 0.71089, time : 10.205984354019165 lr : 0.17224993019150142\n",
      "epoch : 175 [17/23] Train loss: 0.42911,Valid loss: 0.68309, time : 10.068806648254395 lr : 0.17224993019150142\n",
      "epoch : 175 [18/23] Train loss: 0.43547,Valid loss: 0.67872, time : 10.063451290130615 lr : 0.17224993019150142\n",
      "epoch : 175 [19/23] Train loss: 0.41932,Valid loss: 0.68363, time : 10.05920672416687 lr : 0.17224993019150142\n",
      "epoch : 175 [20/23] Train loss: 0.42158,Valid loss: 0.68479, time : 10.176007270812988 lr : 0.17224993019150142\n",
      "epoch : 175 [21/23] Train loss: 0.43192,Valid loss: 0.69713, time : 10.147398233413696 lr : 0.17224993019150142\n",
      "epoch : 175 [22/23] Train loss: 0.43879,Valid loss: 0.69376, time : 9.667269229888916 lr : 0.17224993019150142\n",
      "epoch : 176 [0/23] Train loss: 0.42289,Valid loss: 0.70274, time : 10.518348217010498 lr : 0.1705274308895864\n",
      "epoch : 176 [1/23] Train loss: 0.42133,Valid loss: 0.68379, time : 10.042271137237549 lr : 0.1705274308895864\n",
      "epoch : 176 [2/23] Train loss: 0.42004,Valid loss: 0.70814, time : 10.37028431892395 lr : 0.1705274308895864\n",
      "epoch : 176 [3/23] Train loss: 0.41723,Valid loss: 0.75810, time : 10.37734580039978 lr : 0.1705274308895864\n",
      "epoch : 176 [4/23] Train loss: 0.43369,Valid loss: 0.69577, time : 10.162872552871704 lr : 0.1705274308895864\n",
      "epoch : 176 [5/23] Train loss: 0.42658,Valid loss: 0.67670, time : 10.178934097290039 lr : 0.1705274308895864\n",
      "epoch : 176 [6/23] Train loss: 0.43027,Valid loss: 0.67306, time : 10.258228302001953 lr : 0.1705274308895864\n",
      "epoch : 176 [7/23] Train loss: 0.42652,Valid loss: 0.67392, time : 9.713165998458862 lr : 0.1705274308895864\n",
      "epoch : 176 [8/23] Train loss: 0.42192,Valid loss: 0.68685, time : 10.212908267974854 lr : 0.1705274308895864\n",
      "epoch : 176 [9/23] Train loss: 0.42663,Valid loss: 0.69441, time : 9.995821952819824 lr : 0.1705274308895864\n",
      "epoch : 176 [10/23] Train loss: 0.42440,Valid loss: 0.68609, time : 10.406983852386475 lr : 0.1705274308895864\n",
      "epoch : 176 [11/23] Train loss: 0.42332,Valid loss: 0.70174, time : 10.081829309463501 lr : 0.1705274308895864\n",
      "epoch : 176 [12/23] Train loss: 0.41664,Valid loss: 0.68845, time : 10.12637734413147 lr : 0.1705274308895864\n",
      "epoch : 176 [13/23] Train loss: 0.42246,Valid loss: 0.75559, time : 10.26461386680603 lr : 0.1705274308895864\n",
      "epoch : 176 [14/23] Train loss: 0.42626,Valid loss: 0.71183, time : 10.12228512763977 lr : 0.1705274308895864\n",
      "epoch : 176 [15/23] Train loss: 0.42853,Valid loss: 0.73008, time : 10.467502355575562 lr : 0.1705274308895864\n",
      "epoch : 176 [16/23] Train loss: 0.43560,Valid loss: 0.74320, time : 10.24744987487793 lr : 0.1705274308895864\n",
      "epoch : 176 [17/23] Train loss: 0.45424,Valid loss: 0.70040, time : 10.242210388183594 lr : 0.1705274308895864\n",
      "epoch : 176 [18/23] Train loss: 0.44077,Valid loss: 0.71138, time : 10.252768278121948 lr : 0.1705274308895864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 176 [19/23] Train loss: 0.43434,Valid loss: 0.69847, time : 10.20805048942566 lr : 0.1705274308895864\n",
      "epoch : 176 [20/23] Train loss: 0.41533,Valid loss: 0.68492, time : 10.242765665054321 lr : 0.1705274308895864\n",
      "epoch : 176 [21/23] Train loss: 0.42190,Valid loss: 0.70647, time : 10.30904769897461 lr : 0.1705274308895864\n",
      "epoch : 176 [22/23] Train loss: 0.42488,Valid loss: 0.70459, time : 9.507354021072388 lr : 0.1705274308895864\n",
      "epoch : 177 [0/23] Train loss: 0.43226,Valid loss: 0.71635, time : 11.002762794494629 lr : 0.16882215658069055\n",
      "epoch : 177 [1/23] Train loss: 0.41964,Valid loss: 0.69453, time : 10.25276517868042 lr : 0.16882215658069055\n",
      "epoch : 177 [2/23] Train loss: 0.42746,Valid loss: 0.71111, time : 10.625645399093628 lr : 0.16882215658069055\n",
      "epoch : 177 [3/23] Train loss: 0.42938,Valid loss: 0.71471, time : 10.529056310653687 lr : 0.16882215658069055\n",
      "epoch : 177 [4/23] Train loss: 0.43494,Valid loss: 0.72902, time : 10.628902912139893 lr : 0.16882215658069055\n",
      "epoch : 177 [5/23] Train loss: 0.42285,Valid loss: 0.72865, time : 10.50494122505188 lr : 0.16882215658069055\n",
      "epoch : 177 [6/23] Train loss: 0.43702,Valid loss: 0.68656, time : 10.326261520385742 lr : 0.16882215658069055\n",
      "epoch : 177 [7/23] Train loss: 0.42001,Valid loss: 0.67902, time : 10.388828039169312 lr : 0.16882215658069055\n",
      "epoch : 177 [8/23] Train loss: 0.43035,Valid loss: 0.67792, time : 10.656422138214111 lr : 0.16882215658069055\n",
      "epoch : 177 [9/23] Train loss: 0.42433,Valid loss: 0.75122, time : 10.442672967910767 lr : 0.16882215658069055\n",
      "epoch : 177 [10/23] Train loss: 0.42419,Valid loss: 0.70258, time : 10.32480764389038 lr : 0.16882215658069055\n",
      "epoch : 177 [11/23] Train loss: 0.41815,Valid loss: 0.71283, time : 10.518501996994019 lr : 0.16882215658069055\n",
      "epoch : 177 [12/23] Train loss: 0.41543,Valid loss: 0.68574, time : 10.469290971755981 lr : 0.16882215658069055\n",
      "epoch : 177 [13/23] Train loss: 0.42001,Valid loss: 0.78401, time : 10.629140615463257 lr : 0.16882215658069055\n",
      "epoch : 177 [14/23] Train loss: 0.42188,Valid loss: 0.66931, time : 10.276986837387085 lr : 0.16882215658069055\n",
      "epoch : 177 [15/23] Train loss: 0.41175,Valid loss: 0.80159, time : 10.376640558242798 lr : 0.16882215658069055\n",
      "epoch : 177 [16/23] Train loss: 0.42434,Valid loss: 0.82196, time : 10.282988548278809 lr : 0.16882215658069055\n",
      "epoch : 177 [17/23] Train loss: 0.46194,Valid loss: 0.94326, time : 10.444253206253052 lr : 0.16882215658069055\n",
      "epoch : 177 [18/23] Train loss: 0.44049,Valid loss: 0.74251, time : 10.323755741119385 lr : 0.16882215658069055\n",
      "epoch : 177 [19/23] Train loss: 0.44214,Valid loss: 0.68796, time : 10.537575960159302 lr : 0.16882215658069055\n",
      "epoch : 177 [20/23] Train loss: 0.43107,Valid loss: 0.69898, time : 10.595535278320312 lr : 0.16882215658069055\n",
      "epoch : 177 [21/23] Train loss: 0.42767,Valid loss: 0.68194, time : 10.47797441482544 lr : 0.16882215658069055\n",
      "epoch : 177 [22/23] Train loss: 0.41188,Valid loss: 0.70255, time : 9.669171571731567 lr : 0.16882215658069055\n",
      "epoch : 178 [0/23] Train loss: 0.41220,Valid loss: 0.68809, time : 10.370620489120483 lr : 0.16713393501488363\n",
      "epoch : 178 [1/23] Train loss: 0.41911,Valid loss: 0.74726, time : 10.209600448608398 lr : 0.16713393501488363\n",
      "epoch : 178 [2/23] Train loss: 0.45500,Valid loss: 0.75949, time : 10.33632493019104 lr : 0.16713393501488363\n",
      "epoch : 178 [3/23] Train loss: 0.48627,Valid loss: 0.73600, time : 10.1685791015625 lr : 0.16713393501488363\n",
      "epoch : 178 [4/23] Train loss: 0.45084,Valid loss: 0.72701, time : 10.313464879989624 lr : 0.16713393501488363\n",
      "epoch : 178 [5/23] Train loss: 0.43732,Valid loss: 0.70741, time : 10.881896018981934 lr : 0.16713393501488363\n",
      "epoch : 178 [6/23] Train loss: 0.42034,Valid loss: 0.70784, time : 10.585834503173828 lr : 0.16713393501488363\n",
      "epoch : 178 [7/23] Train loss: 0.43535,Valid loss: 0.72048, time : 10.132764101028442 lr : 0.16713393501488363\n",
      "epoch : 178 [8/23] Train loss: 0.41768,Valid loss: 0.67801, time : 10.230844736099243 lr : 0.16713393501488363\n",
      "epoch : 178 [9/23] Train loss: 0.41548,Valid loss: 0.69614, time : 10.090847253799438 lr : 0.16713393501488363\n",
      "epoch : 178 [10/23] Train loss: 0.41564,Valid loss: 0.70383, time : 10.04427194595337 lr : 0.16713393501488363\n",
      "epoch : 178 [11/23] Train loss: 0.41657,Valid loss: 0.74818, time : 10.397841930389404 lr : 0.16713393501488363\n",
      "epoch : 178 [12/23] Train loss: 0.43129,Valid loss: 0.69843, time : 9.783249139785767 lr : 0.16713393501488363\n",
      "epoch : 178 [13/23] Train loss: 0.42452,Valid loss: 0.73850, time : 10.029240608215332 lr : 0.16713393501488363\n",
      "epoch : 178 [14/23] Train loss: 0.44024,Valid loss: 0.69212, time : 10.387077808380127 lr : 0.16713393501488363\n",
      "epoch : 178 [15/23] Train loss: 0.42062,Valid loss: 0.69506, time : 9.962346315383911 lr : 0.16713393501488363\n",
      "epoch : 178 [16/23] Train loss: 0.42936,Valid loss: 0.68970, time : 10.103013038635254 lr : 0.16713393501488363\n",
      "epoch : 178 [17/23] Train loss: 0.43422,Valid loss: 0.75532, time : 9.835307121276855 lr : 0.16713393501488363\n",
      "epoch : 178 [18/23] Train loss: 0.42415,Valid loss: 0.72633, time : 10.041588544845581 lr : 0.16713393501488363\n",
      "epoch : 178 [19/23] Train loss: 0.42733,Valid loss: 0.71506, time : 10.069339275360107 lr : 0.16713393501488363\n",
      "epoch : 178 [20/23] Train loss: 0.43040,Valid loss: 0.67538, time : 10.129626750946045 lr : 0.16713393501488363\n",
      "epoch : 178 [21/23] Train loss: 0.43422,Valid loss: 0.67930, time : 9.850280284881592 lr : 0.16713393501488363\n",
      "epoch : 178 [22/23] Train loss: 0.43760,Valid loss: 0.69574, time : 9.44180178642273 lr : 0.16713393501488363\n",
      "epoch : 179 [0/23] Train loss: 0.43263,Valid loss: 0.71238, time : 10.028284549713135 lr : 0.16546259566473479\n",
      "epoch : 179 [1/23] Train loss: 0.45514,Valid loss: 0.71142, time : 10.345202922821045 lr : 0.16546259566473479\n",
      "epoch : 179 [2/23] Train loss: 0.41498,Valid loss: 0.81262, time : 10.122498989105225 lr : 0.16546259566473479\n",
      "epoch : 179 [3/23] Train loss: 0.42523,Valid loss: 0.71720, time : 9.754247903823853 lr : 0.16546259566473479\n",
      "epoch : 179 [4/23] Train loss: 0.43309,Valid loss: 0.68889, time : 10.147608280181885 lr : 0.16546259566473479\n",
      "epoch : 179 [5/23] Train loss: 0.43167,Valid loss: 0.79427, time : 10.256876945495605 lr : 0.16546259566473479\n",
      "epoch : 179 [6/23] Train loss: 0.42851,Valid loss: 0.67487, time : 10.10547137260437 lr : 0.16546259566473479\n",
      "epoch : 179 [7/23] Train loss: 0.42690,Valid loss: 0.67099, time : 9.939284563064575 lr : 0.16546259566473479\n",
      "epoch : 179 [8/23] Train loss: 0.41559,Valid loss: 0.67883, time : 10.213921070098877 lr : 0.16546259566473479\n",
      "epoch : 179 [9/23] Train loss: 0.42061,Valid loss: 0.70606, time : 10.175191879272461 lr : 0.16546259566473479\n",
      "epoch : 179 [10/23] Train loss: 0.41591,Valid loss: 0.67164, time : 10.495213031768799 lr : 0.16546259566473479\n",
      "epoch : 179 [11/23] Train loss: 0.42322,Valid loss: 0.70188, time : 10.243760347366333 lr : 0.16546259566473479\n",
      "epoch : 179 [12/23] Train loss: 0.41746,Valid loss: 0.67841, time : 10.362673997879028 lr : 0.16546259566473479\n",
      "epoch : 179 [13/23] Train loss: 0.41937,Valid loss: 0.67598, time : 10.63863229751587 lr : 0.16546259566473479\n",
      "epoch : 179 [14/23] Train loss: 0.42747,Valid loss: 0.76637, time : 10.560433387756348 lr : 0.16546259566473479\n",
      "epoch : 179 [15/23] Train loss: 0.41157,Valid loss: 0.78926, time : 10.038042783737183 lr : 0.16546259566473479\n",
      "epoch : 179 [16/23] Train loss: 0.42582,Valid loss: 0.68566, time : 10.904194116592407 lr : 0.16546259566473479\n",
      "epoch : 179 [17/23] Train loss: 0.40691,Valid loss: 0.68292, time : 10.482429504394531 lr : 0.16546259566473479\n",
      "epoch : 179 [18/23] Train loss: 0.42228,Valid loss: 0.67545, time : 10.558073997497559 lr : 0.16546259566473479\n",
      "epoch : 179 [19/23] Train loss: 0.41780,Valid loss: 0.75330, time : 9.782644748687744 lr : 0.16546259566473479\n",
      "epoch : 179 [20/23] Train loss: 0.40866,Valid loss: 0.69572, time : 10.076285362243652 lr : 0.16546259566473479\n",
      "epoch : 179 [21/23] Train loss: 0.41909,Valid loss: 0.72136, time : 10.06013035774231 lr : 0.16546259566473479\n",
      "epoch : 179 [22/23] Train loss: 0.42808,Valid loss: 0.70759, time : 9.583914518356323 lr : 0.16546259566473479\n",
      "epoch : 180 [0/23] Train loss: 0.40723,Valid loss: 0.78133, time : 10.505850553512573 lr : 0.16380796970808745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 180 [1/23] Train loss: 0.41574,Valid loss: 0.68391, time : 10.887434959411621 lr : 0.16380796970808745\n",
      "epoch : 180 [2/23] Train loss: 0.42833,Valid loss: 0.76841, time : 10.504286050796509 lr : 0.16380796970808745\n",
      "epoch : 180 [3/23] Train loss: 0.40455,Valid loss: 0.72526, time : 10.773672103881836 lr : 0.16380796970808745\n",
      "epoch : 180 [4/23] Train loss: 0.40626,Valid loss: 0.71777, time : 10.342365741729736 lr : 0.16380796970808745\n",
      "epoch : 180 [5/23] Train loss: 0.41653,Valid loss: 0.78471, time : 10.622946500778198 lr : 0.16380796970808745\n",
      "epoch : 180 [6/23] Train loss: 0.41072,Valid loss: 0.68302, time : 10.224623441696167 lr : 0.16380796970808745\n",
      "epoch : 180 [7/23] Train loss: 0.41867,Valid loss: 0.67277, time : 10.3739013671875 lr : 0.16380796970808745\n",
      "epoch : 180 [8/23] Train loss: 0.40299,Valid loss: 0.68334, time : 10.487203598022461 lr : 0.16380796970808745\n",
      "epoch : 180 [9/23] Train loss: 0.41587,Valid loss: 0.76746, time : 10.473037719726562 lr : 0.16380796970808745\n",
      "epoch : 180 [10/23] Train loss: 0.42674,Valid loss: 0.72267, time : 10.094667911529541 lr : 0.16380796970808745\n",
      "epoch : 180 [11/23] Train loss: 0.41284,Valid loss: 0.69248, time : 10.538280248641968 lr : 0.16380796970808745\n",
      "epoch : 180 [12/23] Train loss: 0.41267,Valid loss: 0.75117, time : 10.235788106918335 lr : 0.16380796970808745\n",
      "epoch : 180 [13/23] Train loss: 0.41120,Valid loss: 0.70941, time : 10.430053472518921 lr : 0.16380796970808745\n",
      "epoch : 180 [14/23] Train loss: 0.40992,Valid loss: 0.74056, time : 10.414801359176636 lr : 0.16380796970808745\n",
      "epoch : 180 [15/23] Train loss: 0.41191,Valid loss: 0.68014, time : 10.193580150604248 lr : 0.16380796970808745\n",
      "epoch : 180 [16/23] Train loss: 0.42095,Valid loss: 0.79670, time : 10.348143577575684 lr : 0.16380796970808745\n",
      "epoch : 180 [17/23] Train loss: 0.41240,Valid loss: 0.68262, time : 10.560583114624023 lr : 0.16380796970808745\n",
      "epoch : 180 [18/23] Train loss: 0.41007,Valid loss: 0.66631, time : 10.211331605911255 lr : 0.16380796970808745\n",
      "epoch : 180 [19/23] Train loss: 0.40487,Valid loss: 0.66680, time : 10.423274278640747 lr : 0.16380796970808745\n",
      "epoch : 180 [20/23] Train loss: 0.41368,Valid loss: 0.77412, time : 10.486374855041504 lr : 0.16380796970808745\n",
      "epoch : 180 [21/23] Train loss: 0.43561,Valid loss: 0.78269, time : 10.574584245681763 lr : 0.16380796970808745\n",
      "epoch : 180 [22/23] Train loss: 0.39884,Valid loss: 0.68633, time : 9.662986278533936 lr : 0.16380796970808745\n",
      "epoch : 181 [0/23] Train loss: 0.40839,Valid loss: 0.69414, time : 10.708641767501831 lr : 0.16216989001100657\n",
      "epoch : 181 [1/23] Train loss: 0.41033,Valid loss: 0.74094, time : 10.296374082565308 lr : 0.16216989001100657\n",
      "epoch : 181 [2/23] Train loss: 0.41469,Valid loss: 0.67960, time : 10.13826847076416 lr : 0.16216989001100657\n",
      "epoch : 181 [3/23] Train loss: 0.39658,Valid loss: 0.78702, time : 10.352462768554688 lr : 0.16216989001100657\n",
      "epoch : 181 [4/23] Train loss: 0.42360,Valid loss: 0.66331, time : 10.399022102355957 lr : 0.16216989001100657\n",
      "epoch : 181 [5/23] Train loss: 0.40803,Valid loss: 0.71708, time : 10.701411247253418 lr : 0.16216989001100657\n",
      "epoch : 181 [6/23] Train loss: 0.41461,Valid loss: 0.65501, time : 10.724569320678711 lr : 0.16216989001100657\n",
      "epoch : 181 [7/23] Train loss: 0.41415,Valid loss: 0.66744, time : 10.514144897460938 lr : 0.16216989001100657\n",
      "epoch : 181 [8/23] Train loss: 0.41354,Valid loss: 0.66358, time : 10.777254104614258 lr : 0.16216989001100657\n",
      "epoch : 181 [9/23] Train loss: 0.42120,Valid loss: 0.68022, time : 10.37284803390503 lr : 0.16216989001100657\n",
      "epoch : 181 [10/23] Train loss: 0.40000,Valid loss: 0.70649, time : 10.59485387802124 lr : 0.16216989001100657\n",
      "epoch : 181 [11/23] Train loss: 0.42039,Valid loss: 0.70596, time : 10.336334228515625 lr : 0.16216989001100657\n",
      "epoch : 181 [12/23] Train loss: 0.39832,Valid loss: 0.72722, time : 10.472787380218506 lr : 0.16216989001100657\n",
      "epoch : 181 [13/23] Train loss: 0.41099,Valid loss: 0.70069, time : 10.52208137512207 lr : 0.16216989001100657\n",
      "epoch : 181 [14/23] Train loss: 0.40321,Valid loss: 0.69228, time : 10.758723735809326 lr : 0.16216989001100657\n",
      "epoch : 181 [15/23] Train loss: 0.41074,Valid loss: 0.74062, time : 10.552966594696045 lr : 0.16216989001100657\n",
      "epoch : 181 [16/23] Train loss: 0.41180,Valid loss: 0.72855, time : 10.73725414276123 lr : 0.16216989001100657\n",
      "epoch : 181 [17/23] Train loss: 0.42650,Valid loss: 0.70691, time : 10.657999515533447 lr : 0.16216989001100657\n",
      "epoch : 181 [18/23] Train loss: 0.41234,Valid loss: 0.68382, time : 10.648596286773682 lr : 0.16216989001100657\n",
      "epoch : 181 [19/23] Train loss: 0.41898,Valid loss: 0.68936, time : 10.808179378509521 lr : 0.16216989001100657\n",
      "epoch : 181 [20/23] Train loss: 0.40824,Valid loss: 0.68146, time : 10.345531940460205 lr : 0.16216989001100657\n",
      "epoch : 181 [21/23] Train loss: 0.41613,Valid loss: 0.72549, time : 10.334076404571533 lr : 0.16216989001100657\n",
      "epoch : 181 [22/23] Train loss: 0.40145,Valid loss: 0.75833, time : 9.656255006790161 lr : 0.16216989001100657\n",
      "epoch : 182 [0/23] Train loss: 0.40782,Valid loss: 0.67326, time : 10.764558553695679 lr : 0.1605481911108965\n",
      "epoch : 182 [1/23] Train loss: 0.40896,Valid loss: 0.75956, time : 10.38969612121582 lr : 0.1605481911108965\n",
      "epoch : 182 [2/23] Train loss: 0.41893,Valid loss: 0.71475, time : 10.567669153213501 lr : 0.1605481911108965\n",
      "epoch : 182 [3/23] Train loss: 0.39350,Valid loss: 0.73639, time : 10.487629413604736 lr : 0.1605481911108965\n",
      "epoch : 182 [4/23] Train loss: 0.41227,Valid loss: 0.73911, time : 10.520570755004883 lr : 0.1605481911108965\n",
      "epoch : 182 [5/23] Train loss: 0.40973,Valid loss: 0.69583, time : 10.317373275756836 lr : 0.1605481911108965\n",
      "epoch : 182 [6/23] Train loss: 0.40643,Valid loss: 0.77584, time : 10.486819505691528 lr : 0.1605481911108965\n",
      "epoch : 182 [7/23] Train loss: 0.42518,Valid loss: 0.67175, time : 10.444434642791748 lr : 0.1605481911108965\n",
      "epoch : 182 [8/23] Train loss: 0.41097,Valid loss: 0.72725, time : 10.22748064994812 lr : 0.1605481911108965\n",
      "epoch : 182 [9/23] Train loss: 0.40950,Valid loss: 0.66997, time : 10.570773363113403 lr : 0.1605481911108965\n",
      "epoch : 182 [10/23] Train loss: 0.39830,Valid loss: 0.73653, time : 10.038724660873413 lr : 0.1605481911108965\n",
      "epoch : 182 [11/23] Train loss: 0.40851,Valid loss: 0.66100, time : 10.471281290054321 lr : 0.1605481911108965\n",
      "epoch : 182 [12/23] Train loss: 0.40627,Valid loss: 0.73124, time : 10.705480813980103 lr : 0.1605481911108965\n",
      "epoch : 182 [13/23] Train loss: 0.41703,Valid loss: 0.65872, time : 10.686147451400757 lr : 0.1605481911108965\n",
      "epoch : 182 [14/23] Train loss: 0.39498,Valid loss: 0.72329, time : 10.829387426376343 lr : 0.1605481911108965\n",
      "epoch : 182 [15/23] Train loss: 0.41150,Valid loss: 0.67547, time : 10.624410390853882 lr : 0.1605481911108965\n",
      "epoch : 182 [16/23] Train loss: 0.40680,Valid loss: 0.71371, time : 10.297735691070557 lr : 0.1605481911108965\n",
      "epoch : 182 [17/23] Train loss: 0.41021,Valid loss: 0.66962, time : 10.422257900238037 lr : 0.1605481911108965\n",
      "epoch : 182 [18/23] Train loss: 0.40306,Valid loss: 0.69310, time : 10.208517789840698 lr : 0.1605481911108965\n",
      "epoch : 182 [19/23] Train loss: 0.40611,Valid loss: 0.83575, time : 10.239771604537964 lr : 0.1605481911108965\n",
      "epoch : 182 [20/23] Train loss: 0.41010,Valid loss: 0.67534, time : 10.432252883911133 lr : 0.1605481911108965\n",
      "epoch : 182 [21/23] Train loss: 0.40090,Valid loss: 0.74404, time : 10.549875020980835 lr : 0.1605481911108965\n",
      "epoch : 182 [22/23] Train loss: 0.41023,Valid loss: 0.66555, time : 9.60299277305603 lr : 0.1605481911108965\n",
      "epoch : 183 [0/23] Train loss: 0.41339,Valid loss: 0.65969, time : 10.61388111114502 lr : 0.15894270919978754\n",
      "epoch : 183 [1/23] Train loss: 0.42200,Valid loss: 0.65978, time : 9.963246822357178 lr : 0.15894270919978754\n",
      "epoch : 183 [2/23] Train loss: 0.39158,Valid loss: 0.68543, time : 10.196076154708862 lr : 0.15894270919978754\n",
      "epoch : 183 [3/23] Train loss: 0.40385,Valid loss: 0.67719, time : 10.270101547241211 lr : 0.15894270919978754\n",
      "epoch : 183 [4/23] Train loss: 0.41155,Valid loss: 0.70670, time : 10.305555820465088 lr : 0.15894270919978754\n",
      "epoch : 183 [5/23] Train loss: 0.39348,Valid loss: 0.66858, time : 10.172996759414673 lr : 0.15894270919978754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 183 [6/23] Train loss: 0.41688,Valid loss: 0.66628, time : 10.888648748397827 lr : 0.15894270919978754\n",
      "epoch : 183 [7/23] Train loss: 0.39231,Valid loss: 0.69643, time : 10.474421262741089 lr : 0.15894270919978754\n",
      "epoch : 183 [8/23] Train loss: 0.40368,Valid loss: 0.74171, time : 10.335909843444824 lr : 0.15894270919978754\n",
      "epoch : 183 [9/23] Train loss: 0.40234,Valid loss: 0.68979, time : 10.161404848098755 lr : 0.15894270919978754\n",
      "epoch : 183 [10/23] Train loss: 0.40543,Valid loss: 0.67416, time : 10.186517238616943 lr : 0.15894270919978754\n",
      "epoch : 183 [11/23] Train loss: 0.40542,Valid loss: 0.70986, time : 10.17620038986206 lr : 0.15894270919978754\n",
      "epoch : 183 [12/23] Train loss: 0.41600,Valid loss: 0.72948, time : 10.19420576095581 lr : 0.15894270919978754\n",
      "epoch : 183 [13/23] Train loss: 0.38874,Valid loss: 0.75837, time : 10.411412715911865 lr : 0.15894270919978754\n",
      "epoch : 183 [14/23] Train loss: 0.41431,Valid loss: 0.67306, time : 10.13067626953125 lr : 0.15894270919978754\n",
      "epoch : 183 [15/23] Train loss: 0.40792,Valid loss: 0.70464, time : 10.094485759735107 lr : 0.15894270919978754\n",
      "epoch : 183 [16/23] Train loss: 0.40380,Valid loss: 0.66287, time : 10.080827951431274 lr : 0.15894270919978754\n",
      "epoch : 183 [17/23] Train loss: 0.40449,Valid loss: 0.68136, time : 9.90286135673523 lr : 0.15894270919978754\n",
      "epoch : 183 [18/23] Train loss: 0.40066,Valid loss: 0.66188, time : 10.34750485420227 lr : 0.15894270919978754\n",
      "epoch : 183 [19/23] Train loss: 0.40964,Valid loss: 0.70697, time : 10.39543080329895 lr : 0.15894270919978754\n",
      "epoch : 183 [20/23] Train loss: 0.40242,Valid loss: 0.69038, time : 10.61271333694458 lr : 0.15894270919978754\n",
      "epoch : 183 [21/23] Train loss: 0.40999,Valid loss: 0.66313, time : 10.341652154922485 lr : 0.15894270919978754\n",
      "epoch : 183 [22/23] Train loss: 0.39317,Valid loss: 0.67519, time : 9.593173027038574 lr : 0.15894270919978754\n",
      "epoch : 184 [0/23] Train loss: 0.40377,Valid loss: 0.69080, time : 10.196259260177612 lr : 0.15735328210778965\n",
      "epoch : 184 [1/23] Train loss: 0.39405,Valid loss: 0.71179, time : 10.781683683395386 lr : 0.15735328210778965\n",
      "epoch : 184 [2/23] Train loss: 0.40542,Valid loss: 0.68142, time : 10.1412193775177 lr : 0.15735328210778965\n",
      "epoch : 184 [3/23] Train loss: 0.39656,Valid loss: 0.66392, time : 10.492023706436157 lr : 0.15735328210778965\n",
      "epoch : 184 [4/23] Train loss: 0.40527,Valid loss: 0.72886, time : 10.106722831726074 lr : 0.15735328210778965\n",
      "epoch : 184 [5/23] Train loss: 0.40603,Valid loss: 0.68507, time : 10.112797021865845 lr : 0.15735328210778965\n",
      "epoch : 184 [6/23] Train loss: 0.39513,Valid loss: 0.74856, time : 9.952724695205688 lr : 0.15735328210778965\n",
      "epoch : 184 [7/23] Train loss: 0.39866,Valid loss: 0.70623, time : 10.7065269947052 lr : 0.15735328210778965\n",
      "epoch : 184 [8/23] Train loss: 0.39409,Valid loss: 0.67959, time : 10.188730239868164 lr : 0.15735328210778965\n",
      "epoch : 184 [9/23] Train loss: 0.40780,Valid loss: 0.66546, time : 10.077996015548706 lr : 0.15735328210778965\n",
      "epoch : 184 [10/23] Train loss: 0.40268,Valid loss: 0.67771, time : 10.417152404785156 lr : 0.15735328210778965\n",
      "epoch : 184 [11/23] Train loss: 0.40891,Valid loss: 0.71403, time : 10.332816362380981 lr : 0.15735328210778965\n",
      "epoch : 184 [12/23] Train loss: 0.40849,Valid loss: 0.68703, time : 9.990989208221436 lr : 0.15735328210778965\n",
      "epoch : 184 [13/23] Train loss: 0.39825,Valid loss: 0.66933, time : 9.960032939910889 lr : 0.15735328210778965\n",
      "epoch : 184 [14/23] Train loss: 0.41157,Valid loss: 0.71002, time : 9.859147787094116 lr : 0.15735328210778965\n",
      "epoch : 184 [15/23] Train loss: 0.40618,Valid loss: 0.73731, time : 10.23891019821167 lr : 0.15735328210778965\n",
      "epoch : 184 [16/23] Train loss: 0.41447,Valid loss: 0.67548, time : 9.976729393005371 lr : 0.15735328210778965\n",
      "epoch : 184 [17/23] Train loss: 0.41115,Valid loss: 0.68139, time : 9.829735517501831 lr : 0.15735328210778965\n",
      "epoch : 184 [18/23] Train loss: 0.40370,Valid loss: 0.66923, time : 10.01519775390625 lr : 0.15735328210778965\n",
      "epoch : 184 [19/23] Train loss: 0.38835,Valid loss: 0.69745, time : 10.164173603057861 lr : 0.15735328210778965\n",
      "epoch : 184 [20/23] Train loss: 0.39463,Valid loss: 0.68936, time : 10.206558465957642 lr : 0.15735328210778965\n",
      "epoch : 184 [21/23] Train loss: 0.38288,Valid loss: 0.67864, time : 9.83333969116211 lr : 0.15735328210778965\n",
      "epoch : 184 [22/23] Train loss: 0.39303,Valid loss: 0.67570, time : 9.513822793960571 lr : 0.15735328210778965\n",
      "epoch : 185 [0/23] Train loss: 0.38404,Valid loss: 0.70595, time : 10.303206205368042 lr : 0.15577974928671176\n",
      "epoch : 185 [1/23] Train loss: 0.42020,Valid loss: 0.68693, time : 10.158461809158325 lr : 0.15577974928671176\n",
      "epoch : 185 [2/23] Train loss: 0.40761,Valid loss: 0.66331, time : 10.145291090011597 lr : 0.15577974928671176\n",
      "epoch : 185 [3/23] Train loss: 0.40073,Valid loss: 0.66890, time : 10.364434719085693 lr : 0.15577974928671176\n",
      "epoch : 185 [4/23] Train loss: 0.40050,Valid loss: 0.69181, time : 10.161864280700684 lr : 0.15577974928671176\n",
      "epoch : 185 [5/23] Train loss: 0.39778,Valid loss: 0.67485, time : 10.460773229598999 lr : 0.15577974928671176\n",
      "epoch : 185 [6/23] Train loss: 0.40541,Valid loss: 0.70719, time : 10.294213056564331 lr : 0.15577974928671176\n",
      "epoch : 185 [7/23] Train loss: 0.40974,Valid loss: 0.70597, time : 10.198860883712769 lr : 0.15577974928671176\n",
      "epoch : 185 [8/23] Train loss: 0.39896,Valid loss: 0.74603, time : 10.584714889526367 lr : 0.15577974928671176\n",
      "epoch : 185 [9/23] Train loss: 0.41494,Valid loss: 0.75364, time : 10.729906558990479 lr : 0.15577974928671176\n",
      "epoch : 185 [10/23] Train loss: 0.41037,Valid loss: 0.67814, time : 10.708873271942139 lr : 0.15577974928671176\n",
      "epoch : 185 [11/23] Train loss: 0.39876,Valid loss: 0.67317, time : 10.354782581329346 lr : 0.15577974928671176\n",
      "epoch : 185 [12/23] Train loss: 0.39850,Valid loss: 0.69155, time : 10.15886926651001 lr : 0.15577974928671176\n",
      "epoch : 185 [13/23] Train loss: 0.40261,Valid loss: 0.68009, time : 10.589046001434326 lr : 0.15577974928671176\n",
      "epoch : 185 [14/23] Train loss: 0.39885,Valid loss: 0.68891, time : 10.459438800811768 lr : 0.15577974928671176\n",
      "epoch : 185 [15/23] Train loss: 0.39065,Valid loss: 0.66678, time : 10.061147928237915 lr : 0.15577974928671176\n",
      "epoch : 185 [16/23] Train loss: 0.39619,Valid loss: 0.66139, time : 10.115396976470947 lr : 0.15577974928671176\n",
      "epoch : 185 [17/23] Train loss: 0.41570,Valid loss: 0.65015, time : 10.56525206565857 lr : 0.15577974928671176\n",
      "epoch : 185 [18/23] Train loss: 0.39527,Valid loss: 0.66215, time : 10.57688307762146 lr : 0.15577974928671176\n",
      "epoch : 185 [19/23] Train loss: 0.39432,Valid loss: 0.66782, time : 10.334943056106567 lr : 0.15577974928671176\n",
      "epoch : 185 [20/23] Train loss: 0.40133,Valid loss: 0.67197, time : 10.378562211990356 lr : 0.15577974928671176\n",
      "epoch : 185 [21/23] Train loss: 0.39661,Valid loss: 0.67868, time : 10.763557434082031 lr : 0.15577974928671176\n",
      "epoch : 185 [22/23] Train loss: 0.38621,Valid loss: 0.66887, time : 9.705442428588867 lr : 0.15577974928671176\n",
      "epoch : 186 [0/23] Train loss: 0.40469,Valid loss: 0.71346, time : 10.350191831588745 lr : 0.15422195179384465\n",
      "epoch : 186 [1/23] Train loss: 0.40476,Valid loss: 0.65730, time : 10.611802101135254 lr : 0.15422195179384465\n",
      "epoch : 186 [2/23] Train loss: 0.40301,Valid loss: 0.65613, time : 9.959006309509277 lr : 0.15422195179384465\n",
      "epoch : 186 [3/23] Train loss: 0.40189,Valid loss: 0.65027, time : 10.340255975723267 lr : 0.15422195179384465\n",
      "epoch : 186 [4/23] Train loss: 0.38564,Valid loss: 0.70963, time : 10.510066509246826 lr : 0.15422195179384465\n",
      "epoch : 186 [5/23] Train loss: 0.37700,Valid loss: 0.69958, time : 10.338829517364502 lr : 0.15422195179384465\n",
      "epoch : 186 [6/23] Train loss: 0.39928,Valid loss: 0.65480, time : 10.018762350082397 lr : 0.15422195179384465\n",
      "epoch : 186 [7/23] Train loss: 0.39601,Valid loss: 0.69044, time : 10.378297805786133 lr : 0.15422195179384465\n",
      "epoch : 186 [8/23] Train loss: 0.39761,Valid loss: 0.69176, time : 9.848793029785156 lr : 0.15422195179384465\n",
      "epoch : 186 [9/23] Train loss: 0.42390,Valid loss: 0.68477, time : 10.483418941497803 lr : 0.15422195179384465\n",
      "epoch : 186 [10/23] Train loss: 0.42291,Valid loss: 0.70624, time : 9.983150243759155 lr : 0.15422195179384465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 186 [11/23] Train loss: 0.42779,Valid loss: 0.68957, time : 10.486016035079956 lr : 0.15422195179384465\n",
      "epoch : 186 [12/23] Train loss: 0.41279,Valid loss: 0.71633, time : 10.00347900390625 lr : 0.15422195179384465\n",
      "epoch : 186 [13/23] Train loss: 0.41486,Valid loss: 0.70510, time : 10.30036735534668 lr : 0.15422195179384465\n",
      "epoch : 186 [14/23] Train loss: 0.38458,Valid loss: 0.71725, time : 9.978706121444702 lr : 0.15422195179384465\n",
      "epoch : 186 [15/23] Train loss: 0.39599,Valid loss: 0.67387, time : 10.19411301612854 lr : 0.15422195179384465\n",
      "epoch : 186 [16/23] Train loss: 0.39576,Valid loss: 0.70397, time : 9.816165924072266 lr : 0.15422195179384465\n",
      "epoch : 186 [17/23] Train loss: 0.42847,Valid loss: 0.69922, time : 10.3257155418396 lr : 0.15422195179384465\n",
      "epoch : 186 [18/23] Train loss: 0.44238,Valid loss: 0.69246, time : 9.841853380203247 lr : 0.15422195179384465\n",
      "epoch : 186 [19/23] Train loss: 0.46183,Valid loss: 0.69687, time : 10.281055927276611 lr : 0.15422195179384465\n",
      "epoch : 186 [20/23] Train loss: 0.43443,Valid loss: 0.71346, time : 9.99630355834961 lr : 0.15422195179384465\n",
      "epoch : 186 [21/23] Train loss: 0.43053,Valid loss: 0.69077, time : 9.989417791366577 lr : 0.15422195179384465\n",
      "epoch : 186 [22/23] Train loss: 0.44007,Valid loss: 0.69603, time : 9.683857440948486 lr : 0.15422195179384465\n",
      "epoch : 187 [0/23] Train loss: 0.45548,Valid loss: 0.75418, time : 10.603753089904785 lr : 0.1526797322759062\n",
      "epoch : 187 [1/23] Train loss: 0.44267,Valid loss: 0.71241, time : 10.241410255432129 lr : 0.1526797322759062\n",
      "epoch : 187 [2/23] Train loss: 0.44453,Valid loss: 0.75721, time : 9.847217082977295 lr : 0.1526797322759062\n",
      "epoch : 187 [3/23] Train loss: 0.43104,Valid loss: 0.68171, time : 10.000194311141968 lr : 0.1526797322759062\n",
      "epoch : 187 [4/23] Train loss: 0.43443,Valid loss: 0.67832, time : 9.817760705947876 lr : 0.1526797322759062\n",
      "epoch : 187 [5/23] Train loss: 0.41892,Valid loss: 0.69117, time : 10.077330827713013 lr : 0.1526797322759062\n",
      "epoch : 187 [6/23] Train loss: 0.40750,Valid loss: 0.68408, time : 9.904550790786743 lr : 0.1526797322759062\n",
      "epoch : 187 [7/23] Train loss: 0.42354,Valid loss: 0.74870, time : 10.019083976745605 lr : 0.1526797322759062\n",
      "epoch : 187 [8/23] Train loss: 0.45383,Valid loss: 0.70638, time : 10.50205945968628 lr : 0.1526797322759062\n",
      "epoch : 187 [9/23] Train loss: 0.43420,Valid loss: 0.70646, time : 10.760533809661865 lr : 0.1526797322759062\n",
      "epoch : 187 [10/23] Train loss: 0.41542,Valid loss: 0.70425, time : 10.342482566833496 lr : 0.1526797322759062\n",
      "epoch : 187 [11/23] Train loss: 0.42681,Valid loss: 0.71621, time : 9.955873012542725 lr : 0.1526797322759062\n",
      "epoch : 187 [12/23] Train loss: 0.41604,Valid loss: 0.70069, time : 10.637914419174194 lr : 0.1526797322759062\n",
      "epoch : 187 [13/23] Train loss: 0.42194,Valid loss: 0.77057, time : 9.907270193099976 lr : 0.1526797322759062\n",
      "epoch : 187 [14/23] Train loss: 0.45713,Valid loss: 0.68220, time : 10.000462055206299 lr : 0.1526797322759062\n",
      "epoch : 187 [15/23] Train loss: 0.43385,Valid loss: 0.68781, time : 9.962637424468994 lr : 0.1526797322759062\n",
      "epoch : 187 [16/23] Train loss: 0.41544,Valid loss: 0.70463, time : 9.865883827209473 lr : 0.1526797322759062\n",
      "epoch : 187 [17/23] Train loss: 0.42072,Valid loss: 0.73004, time : 10.002666234970093 lr : 0.1526797322759062\n",
      "epoch : 187 [18/23] Train loss: 0.40668,Valid loss: 0.66834, time : 10.859487056732178 lr : 0.1526797322759062\n",
      "epoch : 187 [19/23] Train loss: 0.40959,Valid loss: 0.71717, time : 9.828916549682617 lr : 0.1526797322759062\n",
      "epoch : 187 [20/23] Train loss: 0.41165,Valid loss: 0.71588, time : 9.83056092262268 lr : 0.1526797322759062\n",
      "epoch : 187 [21/23] Train loss: 0.43200,Valid loss: 0.73041, time : 10.386079549789429 lr : 0.1526797322759062\n",
      "epoch : 187 [22/23] Train loss: 0.40553,Valid loss: 0.81044, time : 9.611096143722534 lr : 0.1526797322759062\n",
      "epoch : 188 [0/23] Train loss: 0.43835,Valid loss: 0.70433, time : 10.35804271697998 lr : 0.15115293495314713\n",
      "epoch : 188 [1/23] Train loss: 0.41886,Valid loss: 0.69614, time : 10.012746810913086 lr : 0.15115293495314713\n",
      "epoch : 188 [2/23] Train loss: 0.42785,Valid loss: 0.71452, time : 10.450498580932617 lr : 0.15115293495314713\n",
      "epoch : 188 [3/23] Train loss: 0.43598,Valid loss: 0.71942, time : 10.648300647735596 lr : 0.15115293495314713\n",
      "epoch : 188 [4/23] Train loss: 0.40552,Valid loss: 0.70695, time : 9.92719841003418 lr : 0.15115293495314713\n",
      "epoch : 188 [5/23] Train loss: 0.42595,Valid loss: 0.72363, time : 10.150355339050293 lr : 0.15115293495314713\n",
      "epoch : 188 [6/23] Train loss: 0.43581,Valid loss: 0.68481, time : 10.154076337814331 lr : 0.15115293495314713\n",
      "epoch : 188 [7/23] Train loss: 0.42630,Valid loss: 0.64985, time : 10.178882598876953 lr : 0.15115293495314713\n",
      "epoch : 188 [8/23] Train loss: 0.40952,Valid loss: 0.74812, time : 10.051071882247925 lr : 0.15115293495314713\n",
      "epoch : 188 [9/23] Train loss: 0.42833,Valid loss: 0.69479, time : 10.270636081695557 lr : 0.15115293495314713\n",
      "epoch : 188 [10/23] Train loss: 0.41415,Valid loss: 0.66765, time : 9.937991857528687 lr : 0.15115293495314713\n",
      "epoch : 188 [11/23] Train loss: 0.39965,Valid loss: 0.65843, time : 10.24306869506836 lr : 0.15115293495314713\n",
      "epoch : 188 [12/23] Train loss: 0.40164,Valid loss: 0.72445, time : 9.922596454620361 lr : 0.15115293495314713\n",
      "epoch : 188 [13/23] Train loss: 0.40919,Valid loss: 0.71264, time : 10.29493236541748 lr : 0.15115293495314713\n",
      "epoch : 188 [14/23] Train loss: 0.41291,Valid loss: 0.70050, time : 10.211185693740845 lr : 0.15115293495314713\n",
      "epoch : 188 [15/23] Train loss: 0.40383,Valid loss: 0.71645, time : 10.331552267074585 lr : 0.15115293495314713\n",
      "epoch : 188 [16/23] Train loss: 0.42385,Valid loss: 0.65830, time : 9.851870059967041 lr : 0.15115293495314713\n",
      "epoch : 188 [17/23] Train loss: 0.41423,Valid loss: 0.70194, time : 10.121558666229248 lr : 0.15115293495314713\n",
      "epoch : 188 [18/23] Train loss: 0.39806,Valid loss: 0.66491, time : 10.281857013702393 lr : 0.15115293495314713\n",
      "epoch : 188 [19/23] Train loss: 0.41029,Valid loss: 0.67078, time : 10.715679407119751 lr : 0.15115293495314713\n",
      "epoch : 188 [20/23] Train loss: 0.41667,Valid loss: 0.66369, time : 9.930279731750488 lr : 0.15115293495314713\n",
      "epoch : 188 [21/23] Train loss: 0.43165,Valid loss: 0.67239, time : 10.156330108642578 lr : 0.15115293495314713\n",
      "epoch : 188 [22/23] Train loss: 0.43852,Valid loss: 0.65311, time : 9.668443441390991 lr : 0.15115293495314713\n",
      "epoch : 189 [0/23] Train loss: 0.42930,Valid loss: 0.69674, time : 10.872471332550049 lr : 0.14964140560361566\n",
      "epoch : 189 [1/23] Train loss: 0.41215,Valid loss: 0.70790, time : 10.32927680015564 lr : 0.14964140560361566\n",
      "epoch : 189 [2/23] Train loss: 0.41120,Valid loss: 0.65399, time : 10.354358434677124 lr : 0.14964140560361566\n",
      "epoch : 189 [3/23] Train loss: 0.40953,Valid loss: 0.73165, time : 10.347016096115112 lr : 0.14964140560361566\n",
      "epoch : 189 [4/23] Train loss: 0.41084,Valid loss: 0.66725, time : 10.303982973098755 lr : 0.14964140560361566\n",
      "epoch : 189 [5/23] Train loss: 0.40569,Valid loss: 0.67029, time : 10.134020566940308 lr : 0.14964140560361566\n",
      "epoch : 189 [6/23] Train loss: 0.41622,Valid loss: 0.68050, time : 10.709878921508789 lr : 0.14964140560361566\n",
      "epoch : 189 [7/23] Train loss: 0.41093,Valid loss: 0.65221, time : 10.009718179702759 lr : 0.14964140560361566\n",
      "epoch : 189 [8/23] Train loss: 0.40031,Valid loss: 0.66246, time : 10.381999254226685 lr : 0.14964140560361566\n",
      "epoch : 189 [9/23] Train loss: 0.41419,Valid loss: 0.67378, time : 10.355698347091675 lr : 0.14964140560361566\n",
      "epoch : 189 [10/23] Train loss: 0.39984,Valid loss: 0.72435, time : 10.560311317443848 lr : 0.14964140560361566\n",
      "epoch : 189 [11/23] Train loss: 0.39824,Valid loss: 0.69935, time : 10.379277467727661 lr : 0.14964140560361566\n",
      "epoch : 189 [12/23] Train loss: 0.42585,Valid loss: 0.66362, time : 10.357338428497314 lr : 0.14964140560361566\n",
      "epoch : 189 [13/23] Train loss: 0.39696,Valid loss: 0.66180, time : 10.399715185165405 lr : 0.14964140560361566\n",
      "epoch : 189 [14/23] Train loss: 0.41124,Valid loss: 0.65425, time : 10.580046653747559 lr : 0.14964140560361566\n",
      "epoch : 189 [15/23] Train loss: 0.39713,Valid loss: 0.64596, time : 10.47036337852478 lr : 0.14964140560361566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 189 [16/23] Train loss: 0.40173,Valid loss: 0.65654, time : 10.238240003585815 lr : 0.14964140560361566\n",
      "epoch : 189 [17/23] Train loss: 0.40802,Valid loss: 0.65266, time : 10.113366842269897 lr : 0.14964140560361566\n",
      "epoch : 189 [18/23] Train loss: 0.41309,Valid loss: 0.66719, time : 9.828767538070679 lr : 0.14964140560361566\n",
      "epoch : 189 [19/23] Train loss: 0.39956,Valid loss: 0.68073, time : 10.01204514503479 lr : 0.14964140560361566\n",
      "epoch : 189 [20/23] Train loss: 0.39246,Valid loss: 0.65626, time : 10.125365018844604 lr : 0.14964140560361566\n",
      "epoch : 189 [21/23] Train loss: 0.40517,Valid loss: 0.64898, time : 9.879107475280762 lr : 0.14964140560361566\n",
      "epoch : 189 [22/23] Train loss: 0.41545,Valid loss: 0.64493, time : 9.663488626480103 lr : 0.14964140560361566\n",
      "epoch : 190 [0/23] Train loss: 0.40682,Valid loss: 0.64670, time : 10.309879064559937 lr : 0.1481449915475795\n",
      "epoch : 190 [1/23] Train loss: 0.39067,Valid loss: 0.66721, time : 10.299124956130981 lr : 0.1481449915475795\n",
      "epoch : 190 [2/23] Train loss: 0.39796,Valid loss: 0.67258, time : 10.287508964538574 lr : 0.1481449915475795\n",
      "epoch : 190 [3/23] Train loss: 0.40904,Valid loss: 0.67445, time : 10.312063694000244 lr : 0.1481449915475795\n",
      "epoch : 190 [4/23] Train loss: 0.39340,Valid loss: 0.67940, time : 10.390406608581543 lr : 0.1481449915475795\n",
      "epoch : 190 [5/23] Train loss: 0.39591,Valid loss: 0.67402, time : 10.363032102584839 lr : 0.1481449915475795\n",
      "epoch : 190 [6/23] Train loss: 0.39600,Valid loss: 0.66399, time : 10.064091205596924 lr : 0.1481449915475795\n",
      "epoch : 190 [7/23] Train loss: 0.39130,Valid loss: 0.67729, time : 10.092551946640015 lr : 0.1481449915475795\n",
      "epoch : 190 [8/23] Train loss: 0.39915,Valid loss: 0.67309, time : 10.080169916152954 lr : 0.1481449915475795\n",
      "epoch : 190 [9/23] Train loss: 0.40177,Valid loss: 0.65546, time : 10.39814829826355 lr : 0.1481449915475795\n",
      "epoch : 190 [10/23] Train loss: 0.38628,Valid loss: 0.68457, time : 10.410387754440308 lr : 0.1481449915475795\n",
      "epoch : 190 [11/23] Train loss: 0.41157,Valid loss: 0.65843, time : 10.419582605361938 lr : 0.1481449915475795\n",
      "epoch : 190 [12/23] Train loss: 0.38615,Valid loss: 0.71022, time : 10.740004301071167 lr : 0.1481449915475795\n",
      "epoch : 190 [13/23] Train loss: 0.39999,Valid loss: 0.66557, time : 10.513577699661255 lr : 0.1481449915475795\n",
      "epoch : 190 [14/23] Train loss: 0.39049,Valid loss: 0.67600, time : 10.406884670257568 lr : 0.1481449915475795\n",
      "epoch : 190 [15/23] Train loss: 0.39842,Valid loss: 0.67420, time : 10.51314401626587 lr : 0.1481449915475795\n",
      "epoch : 190 [16/23] Train loss: 0.39472,Valid loss: 0.67193, time : 10.485125303268433 lr : 0.1481449915475795\n",
      "epoch : 190 [17/23] Train loss: 0.40194,Valid loss: 0.67290, time : 10.460577487945557 lr : 0.1481449915475795\n",
      "epoch : 190 [18/23] Train loss: 0.40184,Valid loss: 0.65238, time : 10.308715343475342 lr : 0.1481449915475795\n",
      "epoch : 190 [19/23] Train loss: 0.39775,Valid loss: 0.68497, time : 10.673493146896362 lr : 0.1481449915475795\n",
      "epoch : 190 [20/23] Train loss: 0.39562,Valid loss: 0.66867, time : 9.979402303695679 lr : 0.1481449915475795\n",
      "epoch : 190 [21/23] Train loss: 0.39291,Valid loss: 0.66191, time : 10.665491819381714 lr : 0.1481449915475795\n",
      "epoch : 190 [22/23] Train loss: 0.41016,Valid loss: 0.69642, time : 9.568447828292847 lr : 0.1481449915475795\n",
      "epoch : 191 [0/23] Train loss: 0.39038,Valid loss: 0.67098, time : 9.753153562545776 lr : 0.1466635416321037\n",
      "epoch : 191 [1/23] Train loss: 0.38732,Valid loss: 0.66228, time : 10.059216260910034 lr : 0.1466635416321037\n",
      "epoch : 191 [2/23] Train loss: 0.39210,Valid loss: 0.68319, time : 9.637067317962646 lr : 0.1466635416321037\n",
      "epoch : 191 [3/23] Train loss: 0.38802,Valid loss: 0.66906, time : 10.245600938796997 lr : 0.1466635416321037\n",
      "epoch : 191 [4/23] Train loss: 0.39664,Valid loss: 0.67697, time : 9.704189777374268 lr : 0.1466635416321037\n",
      "epoch : 191 [5/23] Train loss: 0.38140,Valid loss: 0.65499, time : 10.057896375656128 lr : 0.1466635416321037\n",
      "epoch : 191 [6/23] Train loss: 0.39526,Valid loss: 0.67045, time : 9.622020721435547 lr : 0.1466635416321037\n",
      "epoch : 191 [7/23] Train loss: 0.39390,Valid loss: 0.67716, time : 10.139755010604858 lr : 0.1466635416321037\n",
      "epoch : 191 [8/23] Train loss: 0.39332,Valid loss: 0.66371, time : 10.09593415260315 lr : 0.1466635416321037\n",
      "epoch : 191 [9/23] Train loss: 0.37512,Valid loss: 0.68456, time : 10.291189193725586 lr : 0.1466635416321037\n",
      "epoch : 191 [10/23] Train loss: 0.40038,Valid loss: 0.67807, time : 9.992194652557373 lr : 0.1466635416321037\n",
      "epoch : 191 [11/23] Train loss: 0.40675,Valid loss: 0.66162, time : 10.71279001235962 lr : 0.1466635416321037\n",
      "epoch : 191 [12/23] Train loss: 0.38801,Valid loss: 0.65986, time : 10.212414026260376 lr : 0.1466635416321037\n",
      "epoch : 191 [13/23] Train loss: 0.38022,Valid loss: 0.68094, time : 10.327673196792603 lr : 0.1466635416321037\n",
      "epoch : 191 [14/23] Train loss: 0.39144,Valid loss: 0.70492, time : 9.831332683563232 lr : 0.1466635416321037\n",
      "epoch : 191 [15/23] Train loss: 0.39226,Valid loss: 0.65937, time : 9.690501689910889 lr : 0.1466635416321037\n",
      "epoch : 191 [16/23] Train loss: 0.38945,Valid loss: 0.68700, time : 9.514992952346802 lr : 0.1466635416321037\n",
      "epoch : 191 [17/23] Train loss: 0.39151,Valid loss: 0.68901, time : 9.634325504302979 lr : 0.1466635416321037\n",
      "epoch : 191 [18/23] Train loss: 0.38689,Valid loss: 0.68950, time : 9.64784574508667 lr : 0.1466635416321037\n",
      "epoch : 191 [19/23] Train loss: 0.37978,Valid loss: 0.67006, time : 9.627639293670654 lr : 0.1466635416321037\n",
      "epoch : 191 [20/23] Train loss: 0.39016,Valid loss: 0.66462, time : 9.665592193603516 lr : 0.1466635416321037\n",
      "epoch : 191 [21/23] Train loss: 0.37744,Valid loss: 0.67905, time : 9.626642942428589 lr : 0.1466635416321037\n",
      "epoch : 191 [22/23] Train loss: 0.38220,Valid loss: 0.66910, time : 9.743251323699951 lr : 0.1466635416321037\n",
      "epoch : 192 [0/23] Train loss: 0.38894,Valid loss: 0.67320, time : 10.564125776290894 lr : 0.14519690621578268\n",
      "epoch : 192 [1/23] Train loss: 0.38624,Valid loss: 0.68089, time : 10.171259880065918 lr : 0.14519690621578268\n",
      "epoch : 192 [2/23] Train loss: 0.38512,Valid loss: 0.71657, time : 10.331524133682251 lr : 0.14519690621578268\n",
      "epoch : 192 [3/23] Train loss: 0.38952,Valid loss: 0.67564, time : 9.912011861801147 lr : 0.14519690621578268\n",
      "epoch : 192 [4/23] Train loss: 0.38819,Valid loss: 0.66530, time : 10.252493143081665 lr : 0.14519690621578268\n",
      "epoch : 192 [5/23] Train loss: 0.38596,Valid loss: 0.65975, time : 9.986167907714844 lr : 0.14519690621578268\n",
      "epoch : 192 [6/23] Train loss: 0.39231,Valid loss: 0.68382, time : 10.499805927276611 lr : 0.14519690621578268\n",
      "epoch : 192 [7/23] Train loss: 0.39620,Valid loss: 0.68298, time : 10.221137523651123 lr : 0.14519690621578268\n",
      "epoch : 192 [8/23] Train loss: 0.37550,Valid loss: 0.68040, time : 10.318878173828125 lr : 0.14519690621578268\n",
      "epoch : 192 [9/23] Train loss: 0.39120,Valid loss: 0.66742, time : 9.745872735977173 lr : 0.14519690621578268\n",
      "epoch : 192 [10/23] Train loss: 0.38769,Valid loss: 0.70183, time : 10.378774404525757 lr : 0.14519690621578268\n",
      "epoch : 192 [11/23] Train loss: 0.36889,Valid loss: 0.70700, time : 10.342839479446411 lr : 0.14519690621578268\n",
      "epoch : 192 [12/23] Train loss: 0.38122,Valid loss: 0.67820, time : 10.581625938415527 lr : 0.14519690621578268\n",
      "epoch : 192 [13/23] Train loss: 0.38964,Valid loss: 0.66941, time : 10.789881944656372 lr : 0.14519690621578268\n",
      "epoch : 192 [14/23] Train loss: 0.38967,Valid loss: 0.66520, time : 10.166946649551392 lr : 0.14519690621578268\n",
      "epoch : 192 [15/23] Train loss: 0.39445,Valid loss: 0.65818, time : 10.032318115234375 lr : 0.14519690621578268\n",
      "epoch : 192 [16/23] Train loss: 0.40281,Valid loss: 0.70190, time : 10.345222234725952 lr : 0.14519690621578268\n",
      "epoch : 192 [17/23] Train loss: 0.39049,Valid loss: 0.66540, time : 10.072568416595459 lr : 0.14519690621578268\n",
      "epoch : 192 [18/23] Train loss: 0.38066,Valid loss: 0.75280, time : 10.328486204147339 lr : 0.14519690621578268\n",
      "epoch : 192 [19/23] Train loss: 0.37566,Valid loss: 0.67947, time : 9.845903635025024 lr : 0.14519690621578268\n",
      "epoch : 192 [20/23] Train loss: 0.38428,Valid loss: 0.69586, time : 10.036595582962036 lr : 0.14519690621578268\n",
      "epoch : 192 [21/23] Train loss: 0.38685,Valid loss: 0.63331, time : 10.359374761581421 lr : 0.14519690621578268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 192 [22/23] Train loss: 0.38819,Valid loss: 0.64726, time : 9.430664777755737 lr : 0.14519690621578268\n",
      "epoch : 193 [0/23] Train loss: 0.38517,Valid loss: 0.68770, time : 10.082364559173584 lr : 0.14374493715362485\n",
      "epoch : 193 [1/23] Train loss: 0.38414,Valid loss: 0.67970, time : 10.157824754714966 lr : 0.14374493715362485\n",
      "epoch : 193 [2/23] Train loss: 0.37499,Valid loss: 0.67160, time : 10.538201093673706 lr : 0.14374493715362485\n",
      "epoch : 193 [3/23] Train loss: 0.38065,Valid loss: 0.69057, time : 10.486601829528809 lr : 0.14374493715362485\n",
      "epoch : 193 [4/23] Train loss: 0.37438,Valid loss: 0.69364, time : 10.35647177696228 lr : 0.14374493715362485\n",
      "epoch : 193 [5/23] Train loss: 0.38988,Valid loss: 0.64793, time : 10.477089881896973 lr : 0.14374493715362485\n",
      "epoch : 193 [6/23] Train loss: 0.37826,Valid loss: 0.63550, time : 9.966640710830688 lr : 0.14374493715362485\n",
      "epoch : 193 [7/23] Train loss: 0.38930,Valid loss: 0.67008, time : 10.44506311416626 lr : 0.14374493715362485\n",
      "epoch : 193 [8/23] Train loss: 0.38201,Valid loss: 0.69697, time : 9.91126012802124 lr : 0.14374493715362485\n",
      "epoch : 193 [9/23] Train loss: 0.39113,Valid loss: 0.72573, time : 10.203011751174927 lr : 0.14374493715362485\n",
      "epoch : 193 [10/23] Train loss: 0.39161,Valid loss: 0.69712, time : 9.868119478225708 lr : 0.14374493715362485\n",
      "epoch : 193 [11/23] Train loss: 0.39561,Valid loss: 0.70846, time : 10.149622440338135 lr : 0.14374493715362485\n",
      "epoch : 193 [12/23] Train loss: 0.38481,Valid loss: 0.68894, time : 9.85739016532898 lr : 0.14374493715362485\n",
      "epoch : 193 [13/23] Train loss: 0.38462,Valid loss: 0.68102, time : 10.025950193405151 lr : 0.14374493715362485\n",
      "epoch : 193 [14/23] Train loss: 0.38579,Valid loss: 0.71008, time : 9.923691272735596 lr : 0.14374493715362485\n",
      "epoch : 193 [15/23] Train loss: 0.39508,Valid loss: 0.63052, time : 10.434280633926392 lr : 0.14374493715362485\n",
      "epoch : 193 [16/23] Train loss: 0.38990,Valid loss: 0.69032, time : 9.824913501739502 lr : 0.14374493715362485\n",
      "epoch : 193 [17/23] Train loss: 0.37784,Valid loss: 0.70589, time : 10.256392002105713 lr : 0.14374493715362485\n",
      "epoch : 193 [18/23] Train loss: 0.39194,Valid loss: 0.67007, time : 9.69839596748352 lr : 0.14374493715362485\n",
      "epoch : 193 [19/23] Train loss: 0.40246,Valid loss: 0.66870, time : 10.705037832260132 lr : 0.14374493715362485\n",
      "epoch : 193 [20/23] Train loss: 0.40062,Valid loss: 0.65195, time : 9.957905054092407 lr : 0.14374493715362485\n",
      "epoch : 193 [21/23] Train loss: 0.39492,Valid loss: 0.66510, time : 10.203095436096191 lr : 0.14374493715362485\n",
      "epoch : 193 [22/23] Train loss: 0.38651,Valid loss: 0.64712, time : 9.522804975509644 lr : 0.14374493715362485\n",
      "epoch : 194 [0/23] Train loss: 0.38219,Valid loss: 0.67850, time : 10.398139715194702 lr : 0.1423074877820886\n",
      "epoch : 194 [1/23] Train loss: 0.37696,Valid loss: 0.67031, time : 10.31689453125 lr : 0.1423074877820886\n",
      "epoch : 194 [2/23] Train loss: 0.37841,Valid loss: 0.67478, time : 10.092563152313232 lr : 0.1423074877820886\n",
      "epoch : 194 [3/23] Train loss: 0.39854,Valid loss: 0.70862, time : 10.525980234146118 lr : 0.1423074877820886\n",
      "epoch : 194 [4/23] Train loss: 0.37878,Valid loss: 0.70697, time : 10.199802875518799 lr : 0.1423074877820886\n",
      "epoch : 194 [5/23] Train loss: 0.38112,Valid loss: 0.66163, time : 10.39470887184143 lr : 0.1423074877820886\n",
      "epoch : 194 [6/23] Train loss: 0.38412,Valid loss: 0.68608, time : 10.53147578239441 lr : 0.1423074877820886\n",
      "epoch : 194 [7/23] Train loss: 0.39865,Valid loss: 0.72230, time : 10.15604829788208 lr : 0.1423074877820886\n",
      "epoch : 194 [8/23] Train loss: 0.38067,Valid loss: 0.66639, time : 9.991285800933838 lr : 0.1423074877820886\n",
      "epoch : 194 [9/23] Train loss: 0.37813,Valid loss: 0.69187, time : 9.744754314422607 lr : 0.1423074877820886\n",
      "epoch : 194 [10/23] Train loss: 0.37956,Valid loss: 0.71307, time : 10.211393594741821 lr : 0.1423074877820886\n",
      "epoch : 194 [11/23] Train loss: 0.38305,Valid loss: 0.67635, time : 10.178634643554688 lr : 0.1423074877820886\n",
      "epoch : 194 [12/23] Train loss: 0.37620,Valid loss: 0.66052, time : 10.224135160446167 lr : 0.1423074877820886\n",
      "epoch : 194 [13/23] Train loss: 0.38034,Valid loss: 0.72544, time : 10.244310140609741 lr : 0.1423074877820886\n",
      "epoch : 194 [14/23] Train loss: 0.39451,Valid loss: 0.68637, time : 9.784847497940063 lr : 0.1423074877820886\n",
      "epoch : 194 [15/23] Train loss: 0.39633,Valid loss: 0.63238, time : 9.82229208946228 lr : 0.1423074877820886\n",
      "epoch : 194 [16/23] Train loss: 0.38036,Valid loss: 0.65525, time : 10.037462949752808 lr : 0.1423074877820886\n",
      "epoch : 194 [17/23] Train loss: 0.38509,Valid loss: 0.72855, time : 9.753853797912598 lr : 0.1423074877820886\n",
      "epoch : 194 [18/23] Train loss: 0.40390,Valid loss: 0.77050, time : 10.715231657028198 lr : 0.1423074877820886\n",
      "epoch : 194 [19/23] Train loss: 0.38760,Valid loss: 0.67276, time : 9.705002546310425 lr : 0.1423074877820886\n",
      "epoch : 194 [20/23] Train loss: 0.39856,Valid loss: 0.71415, time : 10.105740785598755 lr : 0.1423074877820886\n",
      "epoch : 194 [21/23] Train loss: 0.40674,Valid loss: 0.69207, time : 10.0800039768219 lr : 0.1423074877820886\n",
      "epoch : 194 [22/23] Train loss: 0.40994,Valid loss: 0.69577, time : 9.45648455619812 lr : 0.1423074877820886\n",
      "epoch : 195 [0/23] Train loss: 0.38311,Valid loss: 0.66382, time : 10.300294637680054 lr : 0.1408844129042677\n",
      "epoch : 195 [1/23] Train loss: 0.39461,Valid loss: 0.68272, time : 10.24079442024231 lr : 0.1408844129042677\n",
      "epoch : 195 [2/23] Train loss: 0.39340,Valid loss: 0.65103, time : 10.04441213607788 lr : 0.1408844129042677\n",
      "epoch : 195 [3/23] Train loss: 0.39105,Valid loss: 0.72991, time : 9.896867990493774 lr : 0.1408844129042677\n",
      "epoch : 195 [4/23] Train loss: 0.38954,Valid loss: 0.71566, time : 10.26471209526062 lr : 0.1408844129042677\n",
      "epoch : 195 [5/23] Train loss: 0.37461,Valid loss: 0.69983, time : 9.90110445022583 lr : 0.1408844129042677\n",
      "epoch : 195 [6/23] Train loss: 0.38968,Valid loss: 0.69934, time : 10.226703643798828 lr : 0.1408844129042677\n",
      "epoch : 195 [7/23] Train loss: 0.37327,Valid loss: 0.71279, time : 9.955950498580933 lr : 0.1408844129042677\n",
      "epoch : 195 [8/23] Train loss: 0.38294,Valid loss: 0.67360, time : 10.23673701286316 lr : 0.1408844129042677\n",
      "epoch : 195 [9/23] Train loss: 0.39100,Valid loss: 0.75393, time : 10.159182786941528 lr : 0.1408844129042677\n",
      "epoch : 195 [10/23] Train loss: 0.38075,Valid loss: 0.73081, time : 10.25609302520752 lr : 0.1408844129042677\n",
      "epoch : 195 [11/23] Train loss: 0.38084,Valid loss: 0.78533, time : 10.038542747497559 lr : 0.1408844129042677\n",
      "epoch : 195 [12/23] Train loss: 0.38791,Valid loss: 0.66906, time : 10.283167600631714 lr : 0.1408844129042677\n",
      "epoch : 195 [13/23] Train loss: 0.38247,Valid loss: 0.69937, time : 10.424994468688965 lr : 0.1408844129042677\n",
      "epoch : 195 [14/23] Train loss: 0.37962,Valid loss: 0.73441, time : 10.511581182479858 lr : 0.1408844129042677\n",
      "epoch : 195 [15/23] Train loss: 0.37388,Valid loss: 0.73942, time : 10.495420217514038 lr : 0.1408844129042677\n",
      "epoch : 195 [16/23] Train loss: 0.37885,Valid loss: 0.63951, time : 10.233376502990723 lr : 0.1408844129042677\n",
      "epoch : 195 [17/23] Train loss: 0.38360,Valid loss: 0.73690, time : 10.28457522392273 lr : 0.1408844129042677\n",
      "epoch : 195 [18/23] Train loss: 0.37814,Valid loss: 0.62609, time : 10.30958080291748 lr : 0.1408844129042677\n",
      "epoch : 195 [19/23] Train loss: 0.37674,Valid loss: 0.69291, time : 10.258646249771118 lr : 0.1408844129042677\n",
      "epoch : 195 [20/23] Train loss: 0.37978,Valid loss: 0.64126, time : 10.296711683273315 lr : 0.1408844129042677\n",
      "epoch : 195 [21/23] Train loss: 0.38038,Valid loss: 0.66989, time : 10.461585998535156 lr : 0.1408844129042677\n",
      "epoch : 195 [22/23] Train loss: 0.38733,Valid loss: 0.64100, time : 9.656570196151733 lr : 0.1408844129042677\n",
      "epoch : 196 [0/23] Train loss: 0.38212,Valid loss: 0.73692, time : 10.573055744171143 lr : 0.13947556877522502\n",
      "epoch : 196 [1/23] Train loss: 0.37872,Valid loss: 0.71057, time : 10.064347982406616 lr : 0.13947556877522502\n",
      "epoch : 196 [2/23] Train loss: 0.37185,Valid loss: 0.71178, time : 10.272235870361328 lr : 0.13947556877522502\n",
      "epoch : 196 [3/23] Train loss: 0.38656,Valid loss: 0.64524, time : 10.037608861923218 lr : 0.13947556877522502\n",
      "epoch : 196 [4/23] Train loss: 0.36884,Valid loss: 0.65343, time : 10.435365676879883 lr : 0.13947556877522502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 196 [5/23] Train loss: 0.37989,Valid loss: 0.68411, time : 10.390401363372803 lr : 0.13947556877522502\n",
      "epoch : 196 [6/23] Train loss: 0.37734,Valid loss: 0.63414, time : 10.160623788833618 lr : 0.13947556877522502\n",
      "epoch : 196 [7/23] Train loss: 0.37994,Valid loss: 0.67781, time : 10.519018650054932 lr : 0.13947556877522502\n",
      "epoch : 196 [8/23] Train loss: 0.37496,Valid loss: 0.65911, time : 10.421286582946777 lr : 0.13947556877522502\n",
      "epoch : 196 [9/23] Train loss: 0.37438,Valid loss: 0.64069, time : 10.427922487258911 lr : 0.13947556877522502\n",
      "epoch : 196 [10/23] Train loss: 0.38605,Valid loss: 0.72300, time : 10.41837739944458 lr : 0.13947556877522502\n",
      "epoch : 196 [11/23] Train loss: 0.38836,Valid loss: 0.68633, time : 10.567928075790405 lr : 0.13947556877522502\n",
      "epoch : 196 [12/23] Train loss: 0.37698,Valid loss: 0.66005, time : 10.427763223648071 lr : 0.13947556877522502\n",
      "epoch : 196 [13/23] Train loss: 0.38346,Valid loss: 0.62642, time : 10.828396081924438 lr : 0.13947556877522502\n",
      "epoch : 196 [14/23] Train loss: 0.38045,Valid loss: 0.72216, time : 10.217256546020508 lr : 0.13947556877522502\n",
      "epoch : 196 [15/23] Train loss: 0.36244,Valid loss: 0.66750, time : 10.344719409942627 lr : 0.13947556877522502\n",
      "epoch : 196 [16/23] Train loss: 0.36520,Valid loss: 0.71661, time : 10.133414506912231 lr : 0.13947556877522502\n",
      "epoch : 196 [17/23] Train loss: 0.37318,Valid loss: 0.64474, time : 10.552438974380493 lr : 0.13947556877522502\n",
      "epoch : 196 [18/23] Train loss: 0.37969,Valid loss: 0.65831, time : 10.600953817367554 lr : 0.13947556877522502\n",
      "epoch : 196 [19/23] Train loss: 0.38989,Valid loss: 0.67861, time : 10.316195011138916 lr : 0.13947556877522502\n",
      "epoch : 196 [20/23] Train loss: 0.37371,Valid loss: 0.65809, time : 10.115166187286377 lr : 0.13947556877522502\n",
      "epoch : 196 [21/23] Train loss: 0.38638,Valid loss: 0.67864, time : 10.7186758518219 lr : 0.13947556877522502\n",
      "epoch : 196 [22/23] Train loss: 0.37714,Valid loss: 0.66707, time : 9.57669734954834 lr : 0.13947556877522502\n",
      "epoch : 197 [0/23] Train loss: 0.37963,Valid loss: 0.66101, time : 10.224111557006836 lr : 0.13808081308747278\n",
      "epoch : 197 [1/23] Train loss: 0.37081,Valid loss: 0.65130, time : 10.227668285369873 lr : 0.13808081308747278\n",
      "epoch : 197 [2/23] Train loss: 0.37271,Valid loss: 0.64779, time : 10.068854331970215 lr : 0.13808081308747278\n",
      "epoch : 197 [3/23] Train loss: 0.38546,Valid loss: 0.69274, time : 10.218735218048096 lr : 0.13808081308747278\n",
      "epoch : 197 [4/23] Train loss: 0.37360,Valid loss: 0.62983, time : 10.634761810302734 lr : 0.13808081308747278\n",
      "epoch : 197 [5/23] Train loss: 0.36529,Valid loss: 0.66325, time : 10.352035284042358 lr : 0.13808081308747278\n",
      "epoch : 197 [6/23] Train loss: 0.36946,Valid loss: 0.73961, time : 10.5306236743927 lr : 0.13808081308747278\n",
      "epoch : 197 [7/23] Train loss: 0.38905,Valid loss: 0.66808, time : 10.302329301834106 lr : 0.13808081308747278\n",
      "epoch : 197 [8/23] Train loss: 0.39547,Valid loss: 0.65646, time : 10.295185565948486 lr : 0.13808081308747278\n",
      "epoch : 197 [9/23] Train loss: 0.38076,Valid loss: 0.68123, time : 10.45232605934143 lr : 0.13808081308747278\n",
      "epoch : 197 [10/23] Train loss: 0.38043,Valid loss: 0.66424, time : 10.265882015228271 lr : 0.13808081308747278\n",
      "epoch : 197 [11/23] Train loss: 0.38294,Valid loss: 0.73633, time : 10.355967044830322 lr : 0.13808081308747278\n",
      "epoch : 197 [12/23] Train loss: 0.39463,Valid loss: 0.68109, time : 10.399082899093628 lr : 0.13808081308747278\n",
      "epoch : 197 [13/23] Train loss: 0.39887,Valid loss: 0.69455, time : 10.338716506958008 lr : 0.13808081308747278\n",
      "epoch : 197 [14/23] Train loss: 0.39247,Valid loss: 0.68000, time : 10.380086421966553 lr : 0.13808081308747278\n",
      "epoch : 197 [15/23] Train loss: 0.39099,Valid loss: 0.67102, time : 10.584625959396362 lr : 0.13808081308747278\n",
      "epoch : 197 [16/23] Train loss: 0.38604,Valid loss: 0.67094, time : 10.568901538848877 lr : 0.13808081308747278\n",
      "epoch : 197 [17/23] Train loss: 0.39171,Valid loss: 0.66701, time : 10.477360725402832 lr : 0.13808081308747278\n",
      "epoch : 197 [18/23] Train loss: 0.39222,Valid loss: 0.63860, time : 10.351913452148438 lr : 0.13808081308747278\n",
      "epoch : 197 [19/23] Train loss: 0.37989,Valid loss: 0.65288, time : 10.618712902069092 lr : 0.13808081308747278\n",
      "epoch : 197 [20/23] Train loss: 0.38725,Valid loss: 0.65400, time : 10.956528425216675 lr : 0.13808081308747278\n",
      "epoch : 197 [21/23] Train loss: 0.39333,Valid loss: 0.65374, time : 10.566038608551025 lr : 0.13808081308747278\n",
      "epoch : 197 [22/23] Train loss: 0.38879,Valid loss: 0.66238, time : 9.781101942062378 lr : 0.13808081308747278\n",
      "epoch : 198 [0/23] Train loss: 0.38268,Valid loss: 0.65502, time : 10.561095714569092 lr : 0.13670000495659804\n",
      "epoch : 198 [1/23] Train loss: 0.37783,Valid loss: 0.67611, time : 10.71097207069397 lr : 0.13670000495659804\n",
      "epoch : 198 [2/23] Train loss: 0.37109,Valid loss: 0.67353, time : 10.326888799667358 lr : 0.13670000495659804\n",
      "epoch : 198 [3/23] Train loss: 0.36567,Valid loss: 0.70233, time : 10.428546667098999 lr : 0.13670000495659804\n",
      "epoch : 198 [4/23] Train loss: 0.37534,Valid loss: 0.64171, time : 10.544243812561035 lr : 0.13670000495659804\n",
      "epoch : 198 [5/23] Train loss: 0.38278,Valid loss: 0.67003, time : 10.52953577041626 lr : 0.13670000495659804\n",
      "epoch : 198 [6/23] Train loss: 0.38087,Valid loss: 0.64372, time : 10.410930633544922 lr : 0.13670000495659804\n",
      "epoch : 198 [7/23] Train loss: 0.37749,Valid loss: 0.66660, time : 10.350216150283813 lr : 0.13670000495659804\n",
      "epoch : 198 [8/23] Train loss: 0.39056,Valid loss: 0.64392, time : 10.458333015441895 lr : 0.13670000495659804\n",
      "epoch : 198 [9/23] Train loss: 0.36981,Valid loss: 0.65482, time : 10.377406597137451 lr : 0.13670000495659804\n",
      "epoch : 198 [10/23] Train loss: 0.37637,Valid loss: 0.72433, time : 10.464455604553223 lr : 0.13670000495659804\n",
      "epoch : 198 [11/23] Train loss: 0.37809,Valid loss: 0.63051, time : 10.314943075180054 lr : 0.13670000495659804\n",
      "epoch : 198 [12/23] Train loss: 0.37037,Valid loss: 0.64621, time : 10.160025358200073 lr : 0.13670000495659804\n",
      "epoch : 198 [13/23] Train loss: 0.37214,Valid loss: 0.68725, time : 10.571876764297485 lr : 0.13670000495659804\n",
      "epoch : 198 [14/23] Train loss: 0.37744,Valid loss: 0.65129, time : 10.012516736984253 lr : 0.13670000495659804\n",
      "epoch : 198 [15/23] Train loss: 0.37410,Valid loss: 0.61683, time : 9.972545623779297 lr : 0.13670000495659804\n",
      "epoch : 198 [16/23] Train loss: 0.37398,Valid loss: 0.69666, time : 10.26434326171875 lr : 0.13670000495659804\n",
      "epoch : 198 [17/23] Train loss: 0.37233,Valid loss: 0.66881, time : 10.203911304473877 lr : 0.13670000495659804\n",
      "epoch : 198 [18/23] Train loss: 0.39131,Valid loss: 0.71885, time : 10.386686086654663 lr : 0.13670000495659804\n",
      "epoch : 198 [19/23] Train loss: 0.38665,Valid loss: 0.72748, time : 10.5363028049469 lr : 0.13670000495659804\n",
      "epoch : 198 [20/23] Train loss: 0.38618,Valid loss: 0.72856, time : 10.214901208877563 lr : 0.13670000495659804\n",
      "epoch : 198 [21/23] Train loss: 0.38721,Valid loss: 0.71728, time : 10.398698329925537 lr : 0.13670000495659804\n",
      "epoch : 198 [22/23] Train loss: 0.38064,Valid loss: 0.64524, time : 9.69340467453003 lr : 0.13670000495659804\n",
      "epoch : 199 [0/23] Train loss: 0.39460,Valid loss: 0.68293, time : 9.796925067901611 lr : 0.13533300490703207\n",
      "epoch : 199 [1/23] Train loss: 0.37313,Valid loss: 0.64752, time : 10.278130531311035 lr : 0.13533300490703207\n",
      "epoch : 199 [2/23] Train loss: 0.37416,Valid loss: 0.72136, time : 9.665823936462402 lr : 0.13533300490703207\n",
      "epoch : 199 [3/23] Train loss: 0.36097,Valid loss: 0.62891, time : 10.29537296295166 lr : 0.13533300490703207\n",
      "epoch : 199 [4/23] Train loss: 0.36656,Valid loss: 0.66302, time : 9.77711296081543 lr : 0.13533300490703207\n",
      "epoch : 199 [5/23] Train loss: 0.36494,Valid loss: 0.65400, time : 10.25603199005127 lr : 0.13533300490703207\n",
      "epoch : 199 [6/23] Train loss: 0.37047,Valid loss: 0.63833, time : 9.84337306022644 lr : 0.13533300490703207\n",
      "epoch : 199 [7/23] Train loss: 0.37272,Valid loss: 0.66276, time : 9.892662763595581 lr : 0.13533300490703207\n",
      "epoch : 199 [8/23] Train loss: 0.37724,Valid loss: 0.66653, time : 9.640459299087524 lr : 0.13533300490703207\n",
      "epoch : 199 [9/23] Train loss: 0.37788,Valid loss: 0.63435, time : 10.30199670791626 lr : 0.13533300490703207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 199 [10/23] Train loss: 0.38301,Valid loss: 0.61917, time : 9.935047626495361 lr : 0.13533300490703207\n",
      "epoch : 199 [11/23] Train loss: 0.36738,Valid loss: 0.74175, time : 10.263950109481812 lr : 0.13533300490703207\n",
      "epoch : 199 [12/23] Train loss: 0.37390,Valid loss: 0.62422, time : 9.391799211502075 lr : 0.13533300490703207\n",
      "epoch : 199 [13/23] Train loss: 0.37906,Valid loss: 0.66366, time : 9.965162992477417 lr : 0.13533300490703207\n",
      "epoch : 199 [14/23] Train loss: 0.36988,Valid loss: 0.62022, time : 9.616625308990479 lr : 0.13533300490703207\n",
      "epoch : 199 [15/23] Train loss: 0.37200,Valid loss: 0.67400, time : 10.059659004211426 lr : 0.13533300490703207\n",
      "epoch : 199 [16/23] Train loss: 0.38023,Valid loss: 0.66175, time : 9.689576625823975 lr : 0.13533300490703207\n",
      "epoch : 199 [17/23] Train loss: 0.37151,Valid loss: 0.64186, time : 10.227409362792969 lr : 0.13533300490703207\n",
      "epoch : 199 [18/23] Train loss: 0.37077,Valid loss: 0.68576, time : 9.582544088363647 lr : 0.13533300490703207\n",
      "epoch : 199 [19/23] Train loss: 0.37311,Valid loss: 0.67277, time : 10.159334659576416 lr : 0.13533300490703207\n",
      "epoch : 199 [20/23] Train loss: 0.37747,Valid loss: 0.61961, time : 9.541709899902344 lr : 0.13533300490703207\n",
      "epoch : 199 [21/23] Train loss: 0.36511,Valid loss: 0.61842, time : 10.010976552963257 lr : 0.13533300490703207\n",
      "epoch : 199 [22/23] Train loss: 0.38050,Valid loss: 0.65796, time : 9.440556526184082 lr : 0.13533300490703207\n",
      "epoch : 200 [0/23] Train loss: 0.38695,Valid loss: 0.67152, time : 10.240691423416138 lr : 0.13397967485796175\n",
      "epoch : 200 [1/23] Train loss: 0.36378,Valid loss: 0.65018, time : 9.683391571044922 lr : 0.13397967485796175\n",
      "epoch : 200 [2/23] Train loss: 0.35529,Valid loss: 0.65859, time : 10.217679500579834 lr : 0.13397967485796175\n",
      "epoch : 200 [3/23] Train loss: 0.37298,Valid loss: 0.67364, time : 10.206441879272461 lr : 0.13397967485796175\n",
      "epoch : 200 [4/23] Train loss: 0.37347,Valid loss: 0.65168, time : 10.077526569366455 lr : 0.13397967485796175\n",
      "epoch : 200 [5/23] Train loss: 0.37113,Valid loss: 0.64136, time : 9.83439588546753 lr : 0.13397967485796175\n",
      "epoch : 200 [6/23] Train loss: 0.36656,Valid loss: 0.70189, time : 10.18234372138977 lr : 0.13397967485796175\n",
      "epoch : 200 [7/23] Train loss: 0.36295,Valid loss: 0.65295, time : 9.917256116867065 lr : 0.13397967485796175\n",
      "epoch : 200 [8/23] Train loss: 0.36629,Valid loss: 0.65927, time : 10.484711647033691 lr : 0.13397967485796175\n",
      "epoch : 200 [9/23] Train loss: 0.36912,Valid loss: 0.65837, time : 10.157654523849487 lr : 0.13397967485796175\n",
      "epoch : 200 [10/23] Train loss: 0.37169,Valid loss: 0.63802, time : 10.578002452850342 lr : 0.13397967485796175\n",
      "epoch : 200 [11/23] Train loss: 0.37497,Valid loss: 0.65412, time : 10.357110738754272 lr : 0.13397967485796175\n",
      "epoch : 200 [12/23] Train loss: 0.36680,Valid loss: 0.70824, time : 9.6077880859375 lr : 0.13397967485796175\n",
      "epoch : 200 [13/23] Train loss: 0.36119,Valid loss: 0.63561, time : 10.00985050201416 lr : 0.13397967485796175\n",
      "epoch : 200 [14/23] Train loss: 0.37130,Valid loss: 0.68624, time : 9.89046835899353 lr : 0.13397967485796175\n",
      "epoch : 200 [15/23] Train loss: 0.37082,Valid loss: 0.63306, time : 10.15208625793457 lr : 0.13397967485796175\n",
      "epoch : 200 [16/23] Train loss: 0.36898,Valid loss: 0.65435, time : 10.444580316543579 lr : 0.13397967485796175\n",
      "epoch : 200 [17/23] Train loss: 0.37044,Valid loss: 0.62961, time : 10.014276027679443 lr : 0.13397967485796175\n",
      "epoch : 200 [18/23] Train loss: 0.37057,Valid loss: 0.64750, time : 9.850782632827759 lr : 0.13397967485796175\n",
      "epoch : 200 [19/23] Train loss: 0.36737,Valid loss: 0.62408, time : 9.856616020202637 lr : 0.13397967485796175\n",
      "epoch : 200 [20/23] Train loss: 0.37122,Valid loss: 0.63433, time : 10.675223350524902 lr : 0.13397967485796175\n",
      "epoch : 200 [21/23] Train loss: 0.37140,Valid loss: 0.63011, time : 10.486525297164917 lr : 0.13397967485796175\n",
      "epoch : 200 [22/23] Train loss: 0.37488,Valid loss: 0.62485, time : 9.527433633804321 lr : 0.13397967485796175\n",
      "epoch : 201 [0/23] Train loss: 0.37681,Valid loss: 0.62631, time : 10.08554458618164 lr : 0.13263987810938213\n",
      "epoch : 201 [1/23] Train loss: 0.36797,Valid loss: 0.71761, time : 10.051672458648682 lr : 0.13263987810938213\n",
      "epoch : 201 [2/23] Train loss: 0.36704,Valid loss: 0.63311, time : 9.939514398574829 lr : 0.13263987810938213\n",
      "epoch : 201 [3/23] Train loss: 0.37260,Valid loss: 0.63758, time : 10.170459270477295 lr : 0.13263987810938213\n",
      "epoch : 201 [4/23] Train loss: 0.36891,Valid loss: 0.64429, time : 10.57985258102417 lr : 0.13263987810938213\n",
      "epoch : 201 [5/23] Train loss: 0.36624,Valid loss: 0.74172, time : 10.665619850158691 lr : 0.13263987810938213\n",
      "epoch : 201 [6/23] Train loss: 0.37001,Valid loss: 0.63187, time : 10.22084355354309 lr : 0.13263987810938213\n",
      "epoch : 201 [7/23] Train loss: 0.36354,Valid loss: 0.64464, time : 9.904399156570435 lr : 0.13263987810938213\n",
      "epoch : 201 [8/23] Train loss: 0.36971,Valid loss: 0.63210, time : 10.160637140274048 lr : 0.13263987810938213\n",
      "epoch : 201 [9/23] Train loss: 0.36461,Valid loss: 0.65225, time : 10.170070171356201 lr : 0.13263987810938213\n",
      "epoch : 201 [10/23] Train loss: 0.36869,Valid loss: 0.69150, time : 10.043205738067627 lr : 0.13263987810938213\n",
      "epoch : 201 [11/23] Train loss: 0.37101,Valid loss: 0.66435, time : 10.55190634727478 lr : 0.13263987810938213\n",
      "epoch : 201 [12/23] Train loss: 0.39062,Valid loss: 0.63548, time : 10.29510760307312 lr : 0.13263987810938213\n",
      "epoch : 201 [13/23] Train loss: 0.38304,Valid loss: 0.66289, time : 10.17503547668457 lr : 0.13263987810938213\n",
      "epoch : 201 [14/23] Train loss: 0.37026,Valid loss: 0.75210, time : 10.391578197479248 lr : 0.13263987810938213\n",
      "epoch : 201 [15/23] Train loss: 0.36405,Valid loss: 0.73766, time : 10.193804025650024 lr : 0.13263987810938213\n",
      "epoch : 201 [16/23] Train loss: 0.37281,Valid loss: 0.63886, time : 10.023984670639038 lr : 0.13263987810938213\n",
      "epoch : 201 [17/23] Train loss: 0.37863,Valid loss: 0.64909, time : 10.261272192001343 lr : 0.13263987810938213\n",
      "epoch : 201 [18/23] Train loss: 0.37323,Valid loss: 0.61468, time : 10.335877895355225 lr : 0.13263987810938213\n",
      "epoch : 201 [19/23] Train loss: 0.36877,Valid loss: 0.66746, time : 10.648356676101685 lr : 0.13263987810938213\n",
      "epoch : 201 [20/23] Train loss: 0.37024,Valid loss: 0.65738, time : 10.599486827850342 lr : 0.13263987810938213\n",
      "epoch : 201 [21/23] Train loss: 0.36173,Valid loss: 0.63586, time : 10.506150722503662 lr : 0.13263987810938213\n",
      "epoch : 201 [22/23] Train loss: 0.36940,Valid loss: 0.68155, time : 9.766714572906494 lr : 0.13263987810938213\n",
      "epoch : 202 [0/23] Train loss: 0.36802,Valid loss: 0.64985, time : 11.018179178237915 lr : 0.1313134793282883\n",
      "epoch : 202 [1/23] Train loss: 0.36283,Valid loss: 0.65706, time : 10.403462648391724 lr : 0.1313134793282883\n",
      "epoch : 202 [2/23] Train loss: 0.36804,Valid loss: 0.65494, time : 10.657735109329224 lr : 0.1313134793282883\n",
      "epoch : 202 [3/23] Train loss: 0.37146,Valid loss: 0.68050, time : 10.207214593887329 lr : 0.1313134793282883\n",
      "epoch : 202 [4/23] Train loss: 0.36376,Valid loss: 0.73838, time : 10.471285343170166 lr : 0.1313134793282883\n",
      "epoch : 202 [5/23] Train loss: 0.37450,Valid loss: 0.64224, time : 10.380931377410889 lr : 0.1313134793282883\n",
      "epoch : 202 [6/23] Train loss: 0.37345,Valid loss: 0.70226, time : 10.608775854110718 lr : 0.1313134793282883\n",
      "epoch : 202 [7/23] Train loss: 0.37334,Valid loss: 0.62602, time : 10.01337718963623 lr : 0.1313134793282883\n",
      "epoch : 202 [8/23] Train loss: 0.35936,Valid loss: 0.67295, time : 10.299378395080566 lr : 0.1313134793282883\n",
      "epoch : 202 [9/23] Train loss: 0.36151,Valid loss: 0.65781, time : 10.27077341079712 lr : 0.1313134793282883\n",
      "epoch : 202 [10/23] Train loss: 0.36837,Valid loss: 0.66410, time : 10.439797401428223 lr : 0.1313134793282883\n",
      "epoch : 202 [11/23] Train loss: 0.36651,Valid loss: 0.64325, time : 10.634257555007935 lr : 0.1313134793282883\n",
      "epoch : 202 [12/23] Train loss: 0.35161,Valid loss: 0.66839, time : 10.581723690032959 lr : 0.1313134793282883\n",
      "epoch : 202 [13/23] Train loss: 0.36137,Valid loss: 0.62807, time : 10.533441305160522 lr : 0.1313134793282883\n",
      "epoch : 202 [14/23] Train loss: 0.36360,Valid loss: 0.77071, time : 10.20346474647522 lr : 0.1313134793282883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 202 [15/23] Train loss: 0.37434,Valid loss: 0.64346, time : 10.326871395111084 lr : 0.1313134793282883\n",
      "epoch : 202 [16/23] Train loss: 0.36611,Valid loss: 0.75860, time : 10.376873970031738 lr : 0.1313134793282883\n",
      "epoch : 202 [17/23] Train loss: 0.35975,Valid loss: 0.64351, time : 10.021437168121338 lr : 0.1313134793282883\n",
      "epoch : 202 [18/23] Train loss: 0.36870,Valid loss: 0.75959, time : 10.393604040145874 lr : 0.1313134793282883\n",
      "epoch : 202 [19/23] Train loss: 0.36734,Valid loss: 0.62785, time : 10.043883323669434 lr : 0.1313134793282883\n",
      "epoch : 202 [20/23] Train loss: 0.35839,Valid loss: 0.66586, time : 10.273078918457031 lr : 0.1313134793282883\n",
      "epoch : 202 [21/23] Train loss: 0.37039,Valid loss: 0.62571, time : 10.369704484939575 lr : 0.1313134793282883\n",
      "epoch : 202 [22/23] Train loss: 0.36036,Valid loss: 0.62059, time : 9.73147201538086 lr : 0.1313134793282883\n",
      "epoch : 203 [0/23] Train loss: 0.36589,Valid loss: 0.75550, time : 10.44003701210022 lr : 0.13000034453500542\n",
      "epoch : 203 [1/23] Train loss: 0.35956,Valid loss: 0.61449, time : 10.334788084030151 lr : 0.13000034453500542\n",
      "epoch : 203 [2/23] Train loss: 0.36473,Valid loss: 0.78535, time : 10.29102897644043 lr : 0.13000034453500542\n",
      "epoch : 203 [3/23] Train loss: 0.35617,Valid loss: 0.66364, time : 10.583779096603394 lr : 0.13000034453500542\n",
      "epoch : 203 [4/23] Train loss: 0.35440,Valid loss: 0.77696, time : 10.404536008834839 lr : 0.13000034453500542\n",
      "epoch : 203 [5/23] Train loss: 0.36497,Valid loss: 0.74437, time : 10.370044708251953 lr : 0.13000034453500542\n",
      "epoch : 203 [6/23] Train loss: 0.34949,Valid loss: 0.63925, time : 10.442096710205078 lr : 0.13000034453500542\n",
      "epoch : 203 [7/23] Train loss: 0.35466,Valid loss: 0.78211, time : 10.28393816947937 lr : 0.13000034453500542\n",
      "epoch : 203 [8/23] Train loss: 0.35882,Valid loss: 0.66143, time : 10.499662399291992 lr : 0.13000034453500542\n",
      "epoch : 203 [9/23] Train loss: 0.36532,Valid loss: 0.75946, time : 10.086557865142822 lr : 0.13000034453500542\n",
      "epoch : 203 [10/23] Train loss: 0.38222,Valid loss: 0.63556, time : 10.191505193710327 lr : 0.13000034453500542\n",
      "epoch : 203 [11/23] Train loss: 0.36694,Valid loss: 0.64021, time : 10.143954992294312 lr : 0.13000034453500542\n",
      "epoch : 203 [12/23] Train loss: 0.34852,Valid loss: 0.65795, time : 10.386931657791138 lr : 0.13000034453500542\n",
      "epoch : 203 [13/23] Train loss: 0.36663,Valid loss: 0.66272, time : 10.228039503097534 lr : 0.13000034453500542\n",
      "epoch : 203 [14/23] Train loss: 0.36919,Valid loss: 0.71643, time : 10.407041072845459 lr : 0.13000034453500542\n",
      "epoch : 203 [15/23] Train loss: 0.35918,Valid loss: 0.62196, time : 10.206810235977173 lr : 0.13000034453500542\n",
      "epoch : 203 [16/23] Train loss: 0.35683,Valid loss: 0.65587, time : 10.224937677383423 lr : 0.13000034453500542\n",
      "epoch : 203 [17/23] Train loss: 0.35020,Valid loss: 0.64682, time : 10.363957643508911 lr : 0.13000034453500542\n",
      "epoch : 203 [18/23] Train loss: 0.37009,Valid loss: 0.67041, time : 10.041966676712036 lr : 0.13000034453500542\n",
      "epoch : 203 [19/23] Train loss: 0.36222,Valid loss: 0.71604, time : 10.237450361251831 lr : 0.13000034453500542\n",
      "epoch : 203 [20/23] Train loss: 0.36897,Valid loss: 0.65571, time : 10.047285795211792 lr : 0.13000034453500542\n",
      "epoch : 203 [21/23] Train loss: 0.36565,Valid loss: 0.69849, time : 10.176560640335083 lr : 0.13000034453500542\n",
      "epoch : 203 [22/23] Train loss: 0.36205,Valid loss: 0.68384, time : 9.42443299293518 lr : 0.13000034453500542\n",
      "epoch : 204 [0/23] Train loss: 0.36070,Valid loss: 0.69599, time : 10.414443969726562 lr : 0.12870034108965536\n",
      "epoch : 204 [1/23] Train loss: 0.35540,Valid loss: 0.65901, time : 10.767838716506958 lr : 0.12870034108965536\n",
      "epoch : 204 [2/23] Train loss: 0.35521,Valid loss: 0.69718, time : 10.341202735900879 lr : 0.12870034108965536\n",
      "epoch : 204 [3/23] Train loss: 0.37021,Valid loss: 0.65695, time : 10.519547462463379 lr : 0.12870034108965536\n",
      "epoch : 204 [4/23] Train loss: 0.36229,Valid loss: 0.65964, time : 11.026217460632324 lr : 0.12870034108965536\n",
      "epoch : 204 [5/23] Train loss: 0.35442,Valid loss: 0.65075, time : 10.032279014587402 lr : 0.12870034108965536\n",
      "epoch : 204 [6/23] Train loss: 0.36488,Valid loss: 0.68054, time : 10.342526912689209 lr : 0.12870034108965536\n",
      "epoch : 204 [7/23] Train loss: 0.38023,Valid loss: 0.77350, time : 10.528521537780762 lr : 0.12870034108965536\n",
      "epoch : 204 [8/23] Train loss: 0.39017,Valid loss: 0.65929, time : 10.150179386138916 lr : 0.12870034108965536\n",
      "epoch : 204 [9/23] Train loss: 0.38402,Valid loss: 0.66514, time : 10.017025470733643 lr : 0.12870034108965536\n",
      "epoch : 204 [10/23] Train loss: 0.36779,Valid loss: 0.61953, time : 9.97618317604065 lr : 0.12870034108965536\n",
      "epoch : 204 [11/23] Train loss: 0.36599,Valid loss: 0.67421, time : 10.090120553970337 lr : 0.12870034108965536\n",
      "epoch : 204 [12/23] Train loss: 0.35829,Valid loss: 0.70927, time : 10.276464700698853 lr : 0.12870034108965536\n",
      "epoch : 204 [13/23] Train loss: 0.36416,Valid loss: 0.63643, time : 10.212599039077759 lr : 0.12870034108965536\n",
      "epoch : 204 [14/23] Train loss: 0.38097,Valid loss: 0.66751, time : 9.956326246261597 lr : 0.12870034108965536\n",
      "epoch : 204 [15/23] Train loss: 0.38841,Valid loss: 0.66743, time : 9.757206678390503 lr : 0.12870034108965536\n",
      "epoch : 204 [16/23] Train loss: 0.37622,Valid loss: 0.69127, time : 9.857317447662354 lr : 0.12870034108965536\n",
      "epoch : 204 [17/23] Train loss: 0.38248,Valid loss: 0.72166, time : 10.409384489059448 lr : 0.12870034108965536\n",
      "epoch : 204 [18/23] Train loss: 0.39824,Valid loss: 0.69783, time : 10.186613321304321 lr : 0.12870034108965536\n",
      "epoch : 204 [19/23] Train loss: 0.39441,Valid loss: 0.64242, time : 10.422084093093872 lr : 0.12870034108965536\n",
      "epoch : 204 [20/23] Train loss: 0.39397,Valid loss: 0.68309, time : 10.436038494110107 lr : 0.12870034108965536\n",
      "epoch : 204 [21/23] Train loss: 0.40175,Valid loss: 0.68196, time : 10.4999361038208 lr : 0.12870034108965536\n",
      "epoch : 204 [22/23] Train loss: 0.39544,Valid loss: 0.65671, time : 9.818225383758545 lr : 0.12870034108965536\n",
      "epoch : 205 [0/23] Train loss: 0.39582,Valid loss: 0.64940, time : 10.683531522750854 lr : 0.12741333767875881\n",
      "epoch : 205 [1/23] Train loss: 0.38987,Valid loss: 0.69280, time : 9.883349895477295 lr : 0.12741333767875881\n",
      "epoch : 205 [2/23] Train loss: 0.38654,Valid loss: 0.63573, time : 10.233985424041748 lr : 0.12741333767875881\n",
      "epoch : 205 [3/23] Train loss: 0.39269,Valid loss: 0.67879, time : 9.968483448028564 lr : 0.12741333767875881\n",
      "epoch : 205 [4/23] Train loss: 0.39375,Valid loss: 0.65831, time : 9.96145510673523 lr : 0.12741333767875881\n",
      "epoch : 205 [5/23] Train loss: 0.39447,Valid loss: 0.69956, time : 10.140162467956543 lr : 0.12741333767875881\n",
      "epoch : 205 [6/23] Train loss: 0.38135,Valid loss: 0.65429, time : 10.104556560516357 lr : 0.12741333767875881\n",
      "epoch : 205 [7/23] Train loss: 0.37261,Valid loss: 0.68111, time : 9.991318225860596 lr : 0.12741333767875881\n",
      "epoch : 205 [8/23] Train loss: 0.37314,Valid loss: 0.65309, time : 10.291514873504639 lr : 0.12741333767875881\n",
      "epoch : 205 [9/23] Train loss: 0.37761,Valid loss: 0.67242, time : 10.036955833435059 lr : 0.12741333767875881\n",
      "epoch : 205 [10/23] Train loss: 0.38690,Valid loss: 0.65571, time : 9.985296249389648 lr : 0.12741333767875881\n",
      "epoch : 205 [11/23] Train loss: 0.37057,Valid loss: 0.69501, time : 10.26648235321045 lr : 0.12741333767875881\n",
      "epoch : 205 [12/23] Train loss: 0.37349,Valid loss: 0.67097, time : 9.70937466621399 lr : 0.12741333767875881\n",
      "epoch : 205 [13/23] Train loss: 0.35850,Valid loss: 0.69755, time : 10.184357166290283 lr : 0.12741333767875881\n",
      "epoch : 205 [14/23] Train loss: 0.37487,Valid loss: 0.61878, time : 10.00443172454834 lr : 0.12741333767875881\n",
      "epoch : 205 [15/23] Train loss: 0.37542,Valid loss: 0.66330, time : 9.784071683883667 lr : 0.12741333767875881\n",
      "epoch : 205 [16/23] Train loss: 0.37623,Valid loss: 0.62051, time : 10.206791877746582 lr : 0.12741333767875881\n",
      "epoch : 205 [17/23] Train loss: 0.37965,Valid loss: 0.65586, time : 9.878605127334595 lr : 0.12741333767875881\n",
      "epoch : 205 [18/23] Train loss: 0.37104,Valid loss: 0.67708, time : 9.898961544036865 lr : 0.12741333767875881\n",
      "epoch : 205 [19/23] Train loss: 0.37142,Valid loss: 0.65155, time : 10.421151161193848 lr : 0.12741333767875881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 205 [20/23] Train loss: 0.38679,Valid loss: 0.70573, time : 10.253148317337036 lr : 0.12741333767875881\n",
      "epoch : 205 [21/23] Train loss: 0.38958,Valid loss: 0.70058, time : 10.240981817245483 lr : 0.12741333767875881\n",
      "epoch : 205 [22/23] Train loss: 0.36489,Valid loss: 0.62488, time : 9.496915102005005 lr : 0.12741333767875881\n",
      "epoch : 206 [0/23] Train loss: 0.36879,Valid loss: 0.69039, time : 10.22732400894165 lr : 0.12613920430197123\n",
      "epoch : 206 [1/23] Train loss: 0.36797,Valid loss: 0.73476, time : 9.984890460968018 lr : 0.12613920430197123\n",
      "epoch : 206 [2/23] Train loss: 0.37880,Valid loss: 0.69736, time : 10.495838165283203 lr : 0.12613920430197123\n",
      "epoch : 206 [3/23] Train loss: 0.36821,Valid loss: 0.63528, time : 10.222827434539795 lr : 0.12613920430197123\n",
      "epoch : 206 [4/23] Train loss: 0.35824,Valid loss: 0.65587, time : 10.328975677490234 lr : 0.12613920430197123\n",
      "epoch : 206 [5/23] Train loss: 0.37264,Valid loss: 0.65322, time : 10.167648077011108 lr : 0.12613920430197123\n",
      "epoch : 206 [6/23] Train loss: 0.37367,Valid loss: 0.69844, time : 10.659273862838745 lr : 0.12613920430197123\n",
      "epoch : 206 [7/23] Train loss: 0.40716,Valid loss: 0.65279, time : 10.177456378936768 lr : 0.12613920430197123\n",
      "epoch : 206 [8/23] Train loss: 0.38181,Valid loss: 0.70098, time : 10.28152346611023 lr : 0.12613920430197123\n",
      "epoch : 206 [9/23] Train loss: 0.37913,Valid loss: 0.64543, time : 9.95948076248169 lr : 0.12613920430197123\n",
      "epoch : 206 [10/23] Train loss: 0.37417,Valid loss: 0.65027, time : 10.557740926742554 lr : 0.12613920430197123\n",
      "epoch : 206 [11/23] Train loss: 0.36811,Valid loss: 0.69097, time : 10.220308780670166 lr : 0.12613920430197123\n",
      "epoch : 206 [12/23] Train loss: 0.36184,Valid loss: 0.63209, time : 9.590105056762695 lr : 0.12613920430197123\n",
      "epoch : 206 [13/23] Train loss: 0.37425,Valid loss: 0.67551, time : 10.119024753570557 lr : 0.12613920430197123\n",
      "epoch : 206 [14/23] Train loss: 0.37477,Valid loss: 0.62394, time : 9.89939284324646 lr : 0.12613920430197123\n",
      "epoch : 206 [15/23] Train loss: 0.38010,Valid loss: 0.64860, time : 10.160893678665161 lr : 0.12613920430197123\n",
      "epoch : 206 [16/23] Train loss: 0.36211,Valid loss: 0.69058, time : 10.329488277435303 lr : 0.12613920430197123\n",
      "epoch : 206 [17/23] Train loss: 0.36936,Valid loss: 0.66591, time : 10.32259225845337 lr : 0.12613920430197123\n",
      "epoch : 206 [18/23] Train loss: 0.36955,Valid loss: 0.63630, time : 9.965713500976562 lr : 0.12613920430197123\n",
      "epoch : 206 [19/23] Train loss: 0.38150,Valid loss: 0.65772, time : 10.270291566848755 lr : 0.12613920430197123\n",
      "epoch : 206 [20/23] Train loss: 0.37513,Valid loss: 0.68192, time : 9.757656574249268 lr : 0.12613920430197123\n",
      "epoch : 206 [21/23] Train loss: 0.35920,Valid loss: 0.65706, time : 9.950170755386353 lr : 0.12613920430197123\n",
      "epoch : 206 [22/23] Train loss: 0.37284,Valid loss: 0.67420, time : 9.441755533218384 lr : 0.12613920430197123\n",
      "epoch : 207 [0/23] Train loss: 0.36932,Valid loss: 0.65981, time : 10.280430316925049 lr : 0.12487781225895152\n",
      "epoch : 207 [1/23] Train loss: 0.36369,Valid loss: 0.67885, time : 9.792646408081055 lr : 0.12487781225895152\n",
      "epoch : 207 [2/23] Train loss: 0.35260,Valid loss: 0.68595, time : 10.310367107391357 lr : 0.12487781225895152\n",
      "epoch : 207 [3/23] Train loss: 0.36905,Valid loss: 0.67297, time : 9.775722026824951 lr : 0.12487781225895152\n",
      "epoch : 207 [4/23] Train loss: 0.37727,Valid loss: 0.66027, time : 10.532948970794678 lr : 0.12487781225895152\n",
      "epoch : 207 [5/23] Train loss: 0.38397,Valid loss: 0.69855, time : 10.026185989379883 lr : 0.12487781225895152\n",
      "epoch : 207 [6/23] Train loss: 0.38917,Valid loss: 0.68016, time : 10.246358156204224 lr : 0.12487781225895152\n",
      "epoch : 207 [7/23] Train loss: 0.39093,Valid loss: 0.67709, time : 9.866319179534912 lr : 0.12487781225895152\n",
      "epoch : 207 [8/23] Train loss: 0.37833,Valid loss: 0.62831, time : 10.273917436599731 lr : 0.12487781225895152\n",
      "epoch : 207 [9/23] Train loss: 0.36658,Valid loss: 0.61637, time : 10.166754007339478 lr : 0.12487781225895152\n",
      "epoch : 207 [10/23] Train loss: 0.36281,Valid loss: 0.62511, time : 10.293644905090332 lr : 0.12487781225895152\n",
      "epoch : 207 [11/23] Train loss: 0.36434,Valid loss: 0.64016, time : 9.876311779022217 lr : 0.12487781225895152\n",
      "epoch : 207 [12/23] Train loss: 0.36902,Valid loss: 0.62479, time : 10.205172300338745 lr : 0.12487781225895152\n",
      "epoch : 207 [13/23] Train loss: 0.36681,Valid loss: 0.64786, time : 9.906262397766113 lr : 0.12487781225895152\n",
      "epoch : 207 [14/23] Train loss: 0.35350,Valid loss: 0.63153, time : 9.893624782562256 lr : 0.12487781225895152\n",
      "epoch : 207 [15/23] Train loss: 0.36485,Valid loss: 0.68887, time : 9.844532489776611 lr : 0.12487781225895152\n",
      "epoch : 207 [16/23] Train loss: 0.35769,Valid loss: 0.66208, time : 9.910044193267822 lr : 0.12487781225895152\n",
      "epoch : 207 [17/23] Train loss: 0.35231,Valid loss: 0.68235, time : 10.175628185272217 lr : 0.12487781225895152\n",
      "epoch : 207 [18/23] Train loss: 0.36070,Valid loss: 0.63998, time : 10.153180837631226 lr : 0.12487781225895152\n",
      "epoch : 207 [19/23] Train loss: 0.36505,Valid loss: 0.69950, time : 9.994090795516968 lr : 0.12487781225895152\n",
      "epoch : 207 [20/23] Train loss: 0.36775,Valid loss: 0.63783, time : 10.066591024398804 lr : 0.12487781225895152\n",
      "epoch : 207 [21/23] Train loss: 0.36244,Valid loss: 0.67791, time : 9.726243734359741 lr : 0.12487781225895152\n",
      "epoch : 207 [22/23] Train loss: 0.36820,Valid loss: 0.62055, time : 9.291362047195435 lr : 0.12487781225895152\n",
      "epoch : 208 [0/23] Train loss: 0.36594,Valid loss: 0.63725, time : 10.203991651535034 lr : 0.123629034136362\n",
      "epoch : 208 [1/23] Train loss: 0.35860,Valid loss: 0.63209, time : 10.02650761604309 lr : 0.123629034136362\n",
      "epoch : 208 [2/23] Train loss: 0.35365,Valid loss: 0.69997, time : 10.440812349319458 lr : 0.123629034136362\n",
      "epoch : 208 [3/23] Train loss: 0.35831,Valid loss: 0.63417, time : 10.021339893341064 lr : 0.123629034136362\n",
      "epoch : 208 [4/23] Train loss: 0.35598,Valid loss: 0.70021, time : 10.372176885604858 lr : 0.123629034136362\n",
      "epoch : 208 [5/23] Train loss: 0.37206,Valid loss: 0.63923, time : 9.582725048065186 lr : 0.123629034136362\n",
      "epoch : 208 [6/23] Train loss: 0.34773,Valid loss: 0.64238, time : 10.104941844940186 lr : 0.123629034136362\n",
      "epoch : 208 [7/23] Train loss: 0.36310,Valid loss: 0.73545, time : 9.659386396408081 lr : 0.123629034136362\n",
      "epoch : 208 [8/23] Train loss: 0.36407,Valid loss: 0.66542, time : 10.172409057617188 lr : 0.123629034136362\n",
      "epoch : 208 [9/23] Train loss: 0.36801,Valid loss: 0.65396, time : 9.996294975280762 lr : 0.123629034136362\n",
      "epoch : 208 [10/23] Train loss: 0.36295,Valid loss: 0.63337, time : 9.924926996231079 lr : 0.123629034136362\n",
      "epoch : 208 [11/23] Train loss: 0.36055,Valid loss: 0.71343, time : 10.08739447593689 lr : 0.123629034136362\n",
      "epoch : 208 [12/23] Train loss: 0.36769,Valid loss: 0.62516, time : 10.092971563339233 lr : 0.123629034136362\n",
      "epoch : 208 [13/23] Train loss: 0.35292,Valid loss: 0.69415, time : 9.599096775054932 lr : 0.123629034136362\n",
      "epoch : 208 [14/23] Train loss: 0.36226,Valid loss: 0.67527, time : 10.020164728164673 lr : 0.123629034136362\n",
      "epoch : 208 [15/23] Train loss: 0.35534,Valid loss: 0.67488, time : 9.93626880645752 lr : 0.123629034136362\n",
      "epoch : 208 [16/23] Train loss: 0.35603,Valid loss: 0.67184, time : 10.081824779510498 lr : 0.123629034136362\n",
      "epoch : 208 [17/23] Train loss: 0.36532,Valid loss: 0.65336, time : 10.328146696090698 lr : 0.123629034136362\n",
      "epoch : 208 [18/23] Train loss: 0.35851,Valid loss: 0.69681, time : 10.018900871276855 lr : 0.123629034136362\n",
      "epoch : 208 [19/23] Train loss: 0.36297,Valid loss: 0.66736, time : 10.040362358093262 lr : 0.123629034136362\n",
      "epoch : 208 [20/23] Train loss: 0.34890,Valid loss: 0.67659, time : 10.292337417602539 lr : 0.123629034136362\n",
      "epoch : 208 [21/23] Train loss: 0.35537,Valid loss: 0.66635, time : 9.717773914337158 lr : 0.123629034136362\n",
      "epoch : 208 [22/23] Train loss: 0.35604,Valid loss: 0.68834, time : 9.569330215454102 lr : 0.123629034136362\n",
      "epoch : 209 [0/23] Train loss: 0.37181,Valid loss: 0.63182, time : 10.334380388259888 lr : 0.12239274379499838\n",
      "epoch : 209 [1/23] Train loss: 0.34965,Valid loss: 0.65269, time : 10.087891578674316 lr : 0.12239274379499838\n",
      "epoch : 209 [2/23] Train loss: 0.35946,Valid loss: 0.67835, time : 10.185902833938599 lr : 0.12239274379499838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 209 [3/23] Train loss: 0.37521,Valid loss: 0.66790, time : 9.98613977432251 lr : 0.12239274379499838\n",
      "epoch : 209 [4/23] Train loss: 0.34907,Valid loss: 0.65080, time : 10.022173404693604 lr : 0.12239274379499838\n",
      "epoch : 209 [5/23] Train loss: 0.36540,Valid loss: 0.67266, time : 10.265156745910645 lr : 0.12239274379499838\n",
      "epoch : 209 [6/23] Train loss: 0.36914,Valid loss: 0.65352, time : 10.090291738510132 lr : 0.12239274379499838\n",
      "epoch : 209 [7/23] Train loss: 0.35609,Valid loss: 0.65151, time : 10.002230882644653 lr : 0.12239274379499838\n",
      "epoch : 209 [8/23] Train loss: 0.35623,Valid loss: 0.72351, time : 10.035676956176758 lr : 0.12239274379499838\n",
      "epoch : 209 [9/23] Train loss: 0.35845,Valid loss: 0.69174, time : 10.341641664505005 lr : 0.12239274379499838\n",
      "epoch : 209 [10/23] Train loss: 0.35101,Valid loss: 0.72084, time : 10.244266986846924 lr : 0.12239274379499838\n",
      "epoch : 209 [11/23] Train loss: 0.35762,Valid loss: 0.67484, time : 10.320972442626953 lr : 0.12239274379499838\n",
      "epoch : 209 [12/23] Train loss: 0.37034,Valid loss: 0.64544, time : 10.22748589515686 lr : 0.12239274379499838\n",
      "epoch : 209 [13/23] Train loss: 0.36096,Valid loss: 0.71456, time : 10.18037486076355 lr : 0.12239274379499838\n",
      "epoch : 209 [14/23] Train loss: 0.35115,Valid loss: 0.70836, time : 9.826569080352783 lr : 0.12239274379499838\n",
      "epoch : 209 [15/23] Train loss: 0.35825,Valid loss: 0.64296, time : 10.406646490097046 lr : 0.12239274379499838\n",
      "epoch : 209 [16/23] Train loss: 0.35942,Valid loss: 0.70361, time : 10.650892496109009 lr : 0.12239274379499838\n",
      "epoch : 209 [17/23] Train loss: 0.35762,Valid loss: 0.72163, time : 10.70688772201538 lr : 0.12239274379499838\n",
      "epoch : 209 [18/23] Train loss: 0.36513,Valid loss: 0.61952, time : 10.262753009796143 lr : 0.12239274379499838\n",
      "epoch : 209 [19/23] Train loss: 0.36624,Valid loss: 0.66498, time : 10.640850305557251 lr : 0.12239274379499838\n",
      "epoch : 209 [20/23] Train loss: 0.35614,Valid loss: 0.66649, time : 10.61430025100708 lr : 0.12239274379499838\n",
      "epoch : 209 [21/23] Train loss: 0.36235,Valid loss: 0.65907, time : 10.742493391036987 lr : 0.12239274379499838\n",
      "epoch : 209 [22/23] Train loss: 0.36415,Valid loss: 0.65881, time : 9.593897819519043 lr : 0.12239274379499838\n",
      "epoch : 210 [0/23] Train loss: 0.34863,Valid loss: 0.66124, time : 10.531448602676392 lr : 0.1211688163570484\n",
      "epoch : 210 [1/23] Train loss: 0.35754,Valid loss: 0.67063, time : 10.259567499160767 lr : 0.1211688163570484\n",
      "epoch : 210 [2/23] Train loss: 0.35295,Valid loss: 0.64608, time : 10.677847385406494 lr : 0.1211688163570484\n",
      "epoch : 210 [3/23] Train loss: 0.33698,Valid loss: 0.67920, time : 10.306945562362671 lr : 0.1211688163570484\n",
      "epoch : 210 [4/23] Train loss: 0.35578,Valid loss: 0.65217, time : 10.369324922561646 lr : 0.1211688163570484\n",
      "epoch : 210 [5/23] Train loss: 0.35271,Valid loss: 0.65702, time : 10.15425419807434 lr : 0.1211688163570484\n",
      "epoch : 210 [6/23] Train loss: 0.35316,Valid loss: 0.63191, time : 10.197756052017212 lr : 0.1211688163570484\n",
      "epoch : 210 [7/23] Train loss: 0.36352,Valid loss: 0.64986, time : 10.41437315940857 lr : 0.1211688163570484\n",
      "epoch : 210 [8/23] Train loss: 0.35822,Valid loss: 0.64441, time : 10.271953821182251 lr : 0.1211688163570484\n",
      "epoch : 210 [9/23] Train loss: 0.35675,Valid loss: 0.64343, time : 10.40281891822815 lr : 0.1211688163570484\n",
      "epoch : 210 [10/23] Train loss: 0.35457,Valid loss: 0.62503, time : 10.332736730575562 lr : 0.1211688163570484\n",
      "epoch : 210 [11/23] Train loss: 0.36049,Valid loss: 0.66814, time : 9.70117712020874 lr : 0.1211688163570484\n",
      "epoch : 210 [12/23] Train loss: 0.35362,Valid loss: 0.63768, time : 10.294388771057129 lr : 0.1211688163570484\n",
      "epoch : 210 [13/23] Train loss: 0.34837,Valid loss: 0.71928, time : 10.409858703613281 lr : 0.1211688163570484\n",
      "epoch : 210 [14/23] Train loss: 0.35745,Valid loss: 0.62460, time : 10.051117897033691 lr : 0.1211688163570484\n",
      "epoch : 210 [15/23] Train loss: 0.35330,Valid loss: 0.68729, time : 10.360377550125122 lr : 0.1211688163570484\n",
      "epoch : 210 [16/23] Train loss: 0.35079,Valid loss: 0.68009, time : 10.399658203125 lr : 0.1211688163570484\n",
      "epoch : 210 [17/23] Train loss: 0.36462,Valid loss: 0.64597, time : 10.242685794830322 lr : 0.1211688163570484\n",
      "epoch : 210 [18/23] Train loss: 0.36620,Valid loss: 0.66287, time : 10.278942823410034 lr : 0.1211688163570484\n",
      "epoch : 210 [19/23] Train loss: 0.35823,Valid loss: 0.65048, time : 10.482775449752808 lr : 0.1211688163570484\n",
      "epoch : 210 [20/23] Train loss: 0.34505,Valid loss: 0.66987, time : 10.326488494873047 lr : 0.1211688163570484\n",
      "epoch : 210 [21/23] Train loss: 0.34947,Valid loss: 0.65075, time : 10.360060214996338 lr : 0.1211688163570484\n",
      "epoch : 210 [22/23] Train loss: 0.35094,Valid loss: 0.66829, time : 9.479909658432007 lr : 0.1211688163570484\n",
      "epoch : 211 [0/23] Train loss: 0.35737,Valid loss: 0.64190, time : 10.48050832748413 lr : 0.11995712819347792\n",
      "epoch : 211 [1/23] Train loss: 0.35089,Valid loss: 0.65404, time : 9.990584373474121 lr : 0.11995712819347792\n",
      "epoch : 211 [2/23] Train loss: 0.36383,Valid loss: 0.63556, time : 10.233224391937256 lr : 0.11995712819347792\n",
      "epoch : 211 [3/23] Train loss: 0.36194,Valid loss: 0.66917, time : 10.30358600616455 lr : 0.11995712819347792\n",
      "epoch : 211 [4/23] Train loss: 0.36177,Valid loss: 0.61400, time : 9.951003551483154 lr : 0.11995712819347792\n",
      "epoch : 211 [5/23] Train loss: 0.35068,Valid loss: 0.63032, time : 10.154242753982544 lr : 0.11995712819347792\n",
      "epoch : 211 [6/23] Train loss: 0.35199,Valid loss: 0.63222, time : 10.368476867675781 lr : 0.11995712819347792\n",
      "epoch : 211 [7/23] Train loss: 0.33607,Valid loss: 0.66960, time : 10.01431679725647 lr : 0.11995712819347792\n",
      "epoch : 211 [8/23] Train loss: 0.35524,Valid loss: 0.62394, time : 10.138765573501587 lr : 0.11995712819347792\n",
      "epoch : 211 [9/23] Train loss: 0.35131,Valid loss: 0.63470, time : 9.758761167526245 lr : 0.11995712819347792\n",
      "epoch : 211 [10/23] Train loss: 0.34356,Valid loss: 0.63620, time : 10.4359290599823 lr : 0.11995712819347792\n",
      "epoch : 211 [11/23] Train loss: 0.34466,Valid loss: 0.68071, time : 10.071282148361206 lr : 0.11995712819347792\n",
      "epoch : 211 [12/23] Train loss: 0.35300,Valid loss: 0.65032, time : 10.18932294845581 lr : 0.11995712819347792\n",
      "epoch : 211 [13/23] Train loss: 0.36037,Valid loss: 0.68711, time : 10.353452682495117 lr : 0.11995712819347792\n",
      "epoch : 211 [14/23] Train loss: 0.35730,Valid loss: 0.62876, time : 10.432405948638916 lr : 0.11995712819347792\n",
      "epoch : 211 [15/23] Train loss: 0.34438,Valid loss: 0.63919, time : 10.086549043655396 lr : 0.11995712819347792\n",
      "epoch : 211 [16/23] Train loss: 0.34296,Valid loss: 0.64494, time : 10.429925441741943 lr : 0.11995712819347792\n",
      "epoch : 211 [17/23] Train loss: 0.35635,Valid loss: 0.69087, time : 10.079038858413696 lr : 0.11995712819347792\n",
      "epoch : 211 [18/23] Train loss: 0.35983,Valid loss: 0.65050, time : 10.361859321594238 lr : 0.11995712819347792\n",
      "epoch : 211 [19/23] Train loss: 0.35156,Valid loss: 0.63682, time : 10.314201831817627 lr : 0.11995712819347792\n",
      "epoch : 211 [20/23] Train loss: 0.36278,Valid loss: 0.67073, time : 10.285845756530762 lr : 0.11995712819347792\n",
      "epoch : 211 [21/23] Train loss: 0.34714,Valid loss: 0.66672, time : 10.325824737548828 lr : 0.11995712819347792\n",
      "epoch : 211 [22/23] Train loss: 0.37019,Valid loss: 0.64329, time : 9.508518695831299 lr : 0.11995712819347792\n",
      "epoch : 212 [0/23] Train loss: 0.35067,Valid loss: 0.64597, time : 10.519329309463501 lr : 0.11875755691154315\n",
      "epoch : 212 [1/23] Train loss: 0.35464,Valid loss: 0.63382, time : 10.189964294433594 lr : 0.11875755691154315\n",
      "epoch : 212 [2/23] Train loss: 0.36280,Valid loss: 0.66766, time : 10.76314401626587 lr : 0.11875755691154315\n",
      "epoch : 212 [3/23] Train loss: 0.35766,Valid loss: 0.66406, time : 10.069078922271729 lr : 0.11875755691154315\n",
      "epoch : 212 [4/23] Train loss: 0.35350,Valid loss: 0.72002, time : 10.42889142036438 lr : 0.11875755691154315\n",
      "epoch : 212 [5/23] Train loss: 0.36302,Valid loss: 0.64941, time : 10.393697023391724 lr : 0.11875755691154315\n",
      "epoch : 212 [6/23] Train loss: 0.35321,Valid loss: 0.73785, time : 9.88922119140625 lr : 0.11875755691154315\n",
      "epoch : 212 [7/23] Train loss: 0.34833,Valid loss: 0.66990, time : 9.99563193321228 lr : 0.11875755691154315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 212 [8/23] Train loss: 0.35204,Valid loss: 0.67680, time : 9.896427392959595 lr : 0.11875755691154315\n",
      "epoch : 212 [9/23] Train loss: 0.34114,Valid loss: 0.66408, time : 9.873799324035645 lr : 0.11875755691154315\n",
      "epoch : 212 [10/23] Train loss: 0.34892,Valid loss: 0.70415, time : 10.009455442428589 lr : 0.11875755691154315\n",
      "epoch : 212 [11/23] Train loss: 0.34182,Valid loss: 0.69606, time : 10.140281438827515 lr : 0.11875755691154315\n",
      "epoch : 212 [12/23] Train loss: 0.36509,Valid loss: 0.66421, time : 9.684810638427734 lr : 0.11875755691154315\n",
      "epoch : 212 [13/23] Train loss: 0.34922,Valid loss: 0.69023, time : 9.798600196838379 lr : 0.11875755691154315\n",
      "epoch : 212 [14/23] Train loss: 0.34342,Valid loss: 0.65477, time : 9.9451904296875 lr : 0.11875755691154315\n",
      "epoch : 212 [15/23] Train loss: 0.36351,Valid loss: 0.66892, time : 9.992972373962402 lr : 0.11875755691154315\n",
      "epoch : 212 [16/23] Train loss: 0.34759,Valid loss: 0.69519, time : 9.994160413742065 lr : 0.11875755691154315\n",
      "epoch : 212 [17/23] Train loss: 0.34996,Valid loss: 0.70077, time : 9.995830297470093 lr : 0.11875755691154315\n",
      "epoch : 212 [18/23] Train loss: 0.35133,Valid loss: 0.66746, time : 9.897812366485596 lr : 0.11875755691154315\n",
      "epoch : 212 [19/23] Train loss: 0.35053,Valid loss: 0.66330, time : 10.120180606842041 lr : 0.11875755691154315\n",
      "epoch : 212 [20/23] Train loss: 0.35171,Valid loss: 0.71233, time : 9.920409679412842 lr : 0.11875755691154315\n",
      "epoch : 212 [21/23] Train loss: 0.35339,Valid loss: 0.67181, time : 9.511969089508057 lr : 0.11875755691154315\n",
      "epoch : 212 [22/23] Train loss: 0.33725,Valid loss: 0.68273, time : 9.239699363708496 lr : 0.11875755691154315\n",
      "epoch : 213 [0/23] Train loss: 0.34732,Valid loss: 0.67413, time : 10.410692691802979 lr : 0.11756998134242772\n",
      "epoch : 213 [1/23] Train loss: 0.34727,Valid loss: 0.66481, time : 10.25880742073059 lr : 0.11756998134242772\n",
      "epoch : 213 [2/23] Train loss: 0.35010,Valid loss: 0.66158, time : 9.787201404571533 lr : 0.11756998134242772\n",
      "epoch : 213 [3/23] Train loss: 0.34262,Valid loss: 0.67583, time : 9.943895816802979 lr : 0.11756998134242772\n",
      "epoch : 213 [4/23] Train loss: 0.34484,Valid loss: 0.63922, time : 10.080814123153687 lr : 0.11756998134242772\n",
      "epoch : 213 [5/23] Train loss: 0.33781,Valid loss: 0.67020, time : 10.476421117782593 lr : 0.11756998134242772\n",
      "epoch : 213 [6/23] Train loss: 0.34896,Valid loss: 0.63260, time : 10.020406484603882 lr : 0.11756998134242772\n",
      "epoch : 213 [7/23] Train loss: 0.35037,Valid loss: 0.71146, time : 10.057968139648438 lr : 0.11756998134242772\n",
      "epoch : 213 [8/23] Train loss: 0.35926,Valid loss: 0.71298, time : 10.09093713760376 lr : 0.11756998134242772\n",
      "epoch : 213 [9/23] Train loss: 0.34878,Valid loss: 0.69072, time : 10.066492319107056 lr : 0.11756998134242772\n",
      "epoch : 213 [10/23] Train loss: 0.35358,Valid loss: 0.65873, time : 10.248876333236694 lr : 0.11756998134242772\n",
      "epoch : 213 [11/23] Train loss: 0.35103,Valid loss: 0.63844, time : 10.274250507354736 lr : 0.11756998134242772\n",
      "epoch : 213 [12/23] Train loss: 0.35143,Valid loss: 0.68408, time : 10.352086305618286 lr : 0.11756998134242772\n",
      "epoch : 213 [13/23] Train loss: 0.35174,Valid loss: 0.63403, time : 10.526874780654907 lr : 0.11756998134242772\n",
      "epoch : 213 [14/23] Train loss: 0.34610,Valid loss: 0.64824, time : 10.290313959121704 lr : 0.11756998134242772\n",
      "epoch : 213 [15/23] Train loss: 0.35585,Valid loss: 0.70292, time : 10.273310422897339 lr : 0.11756998134242772\n",
      "epoch : 213 [16/23] Train loss: 0.33977,Valid loss: 0.63682, time : 10.07608938217163 lr : 0.11756998134242772\n",
      "epoch : 213 [17/23] Train loss: 0.34171,Valid loss: 0.64311, time : 10.067272901535034 lr : 0.11756998134242772\n",
      "epoch : 213 [18/23] Train loss: 0.35417,Valid loss: 0.63703, time : 9.692162990570068 lr : 0.11756998134242772\n",
      "epoch : 213 [19/23] Train loss: 0.34140,Valid loss: 0.70075, time : 10.14552640914917 lr : 0.11756998134242772\n",
      "epoch : 213 [20/23] Train loss: 0.34498,Valid loss: 0.64982, time : 10.064312219619751 lr : 0.11756998134242772\n",
      "epoch : 213 [21/23] Train loss: 0.33872,Valid loss: 0.70291, time : 10.379648447036743 lr : 0.11756998134242772\n",
      "epoch : 213 [22/23] Train loss: 0.34940,Valid loss: 0.60547, time : 9.856301307678223 lr : 0.11756998134242772\n",
      "epoch : 214 [0/23] Train loss: 0.34471,Valid loss: 0.67212, time : 10.150205850601196 lr : 0.11639428152900344\n",
      "epoch : 214 [1/23] Train loss: 0.34089,Valid loss: 0.69287, time : 10.93690299987793 lr : 0.11639428152900344\n",
      "epoch : 214 [2/23] Train loss: 0.35167,Valid loss: 0.63835, time : 10.393810272216797 lr : 0.11639428152900344\n",
      "epoch : 214 [3/23] Train loss: 0.35141,Valid loss: 0.67697, time : 10.077499151229858 lr : 0.11639428152900344\n",
      "epoch : 214 [4/23] Train loss: 0.35126,Valid loss: 0.63461, time : 10.129169225692749 lr : 0.11639428152900344\n",
      "epoch : 214 [5/23] Train loss: 0.35484,Valid loss: 0.67915, time : 10.162168025970459 lr : 0.11639428152900344\n",
      "epoch : 214 [6/23] Train loss: 0.34486,Valid loss: 0.60964, time : 9.595103979110718 lr : 0.11639428152900344\n",
      "epoch : 214 [7/23] Train loss: 0.35382,Valid loss: 0.63387, time : 11.046803712844849 lr : 0.11639428152900344\n",
      "epoch : 214 [8/23] Train loss: 0.34108,Valid loss: 0.63786, time : 10.164684534072876 lr : 0.11639428152900344\n",
      "epoch : 214 [9/23] Train loss: 0.35346,Valid loss: 0.61030, time : 9.751632690429688 lr : 0.11639428152900344\n",
      "epoch : 214 [10/23] Train loss: 0.35301,Valid loss: 0.66722, time : 10.15628170967102 lr : 0.11639428152900344\n",
      "epoch : 214 [11/23] Train loss: 0.35211,Valid loss: 0.63185, time : 10.450314998626709 lr : 0.11639428152900344\n",
      "epoch : 214 [12/23] Train loss: 0.34600,Valid loss: 0.69230, time : 10.459689378738403 lr : 0.11639428152900344\n",
      "epoch : 214 [13/23] Train loss: 0.35187,Valid loss: 0.67049, time : 10.351706981658936 lr : 0.11639428152900344\n",
      "epoch : 214 [14/23] Train loss: 0.34576,Valid loss: 0.63727, time : 10.48503828048706 lr : 0.11639428152900344\n",
      "epoch : 214 [15/23] Train loss: 0.35920,Valid loss: 0.66127, time : 10.30136513710022 lr : 0.11639428152900344\n",
      "epoch : 214 [16/23] Train loss: 0.34512,Valid loss: 0.63062, time : 10.068841695785522 lr : 0.11639428152900344\n",
      "epoch : 214 [17/23] Train loss: 0.34927,Valid loss: 0.71919, time : 9.987417459487915 lr : 0.11639428152900344\n",
      "epoch : 214 [18/23] Train loss: 0.35373,Valid loss: 0.65886, time : 10.254760503768921 lr : 0.11639428152900344\n",
      "epoch : 214 [19/23] Train loss: 0.35394,Valid loss: 0.62125, time : 10.385540962219238 lr : 0.11639428152900344\n",
      "epoch : 214 [20/23] Train loss: 0.34694,Valid loss: 0.64448, time : 9.772078037261963 lr : 0.11639428152900344\n",
      "epoch : 214 [21/23] Train loss: 0.34986,Valid loss: 0.65632, time : 10.258346557617188 lr : 0.11639428152900344\n",
      "epoch : 214 [22/23] Train loss: 0.33954,Valid loss: 0.72496, time : 9.425639867782593 lr : 0.11639428152900344\n",
      "epoch : 215 [0/23] Train loss: 0.34030,Valid loss: 0.62797, time : 10.452468633651733 lr : 0.11523033871371341\n",
      "epoch : 215 [1/23] Train loss: 0.35000,Valid loss: 0.71274, time : 10.084080219268799 lr : 0.11523033871371341\n",
      "epoch : 215 [2/23] Train loss: 0.35150,Valid loss: 0.66962, time : 10.39387321472168 lr : 0.11523033871371341\n",
      "epoch : 215 [3/23] Train loss: 0.35666,Valid loss: 0.61941, time : 10.450048208236694 lr : 0.11523033871371341\n",
      "epoch : 215 [4/23] Train loss: 0.33399,Valid loss: 0.67684, time : 10.230865001678467 lr : 0.11523033871371341\n",
      "epoch : 215 [5/23] Train loss: 0.35332,Valid loss: 0.62532, time : 10.420624017715454 lr : 0.11523033871371341\n",
      "epoch : 215 [6/23] Train loss: 0.34544,Valid loss: 0.71359, time : 11.142851829528809 lr : 0.11523033871371341\n",
      "epoch : 215 [7/23] Train loss: 0.34824,Valid loss: 0.62958, time : 10.3902428150177 lr : 0.11523033871371341\n",
      "epoch : 215 [8/23] Train loss: 0.35442,Valid loss: 0.68921, time : 10.24532961845398 lr : 0.11523033871371341\n",
      "epoch : 215 [9/23] Train loss: 0.33925,Valid loss: 0.64001, time : 10.277026653289795 lr : 0.11523033871371341\n",
      "epoch : 215 [10/23] Train loss: 0.34927,Valid loss: 0.65561, time : 10.36417031288147 lr : 0.11523033871371341\n",
      "epoch : 215 [11/23] Train loss: 0.34441,Valid loss: 0.61114, time : 10.788442373275757 lr : 0.11523033871371341\n",
      "epoch : 215 [12/23] Train loss: 0.34591,Valid loss: 0.65991, time : 10.475233316421509 lr : 0.11523033871371341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 215 [13/23] Train loss: 0.34358,Valid loss: 0.66486, time : 10.146835803985596 lr : 0.11523033871371341\n",
      "epoch : 215 [14/23] Train loss: 0.34772,Valid loss: 0.65415, time : 10.583563089370728 lr : 0.11523033871371341\n",
      "epoch : 215 [15/23] Train loss: 0.34713,Valid loss: 0.69189, time : 10.48623251914978 lr : 0.11523033871371341\n",
      "epoch : 215 [16/23] Train loss: 0.34412,Valid loss: 0.68420, time : 9.864075660705566 lr : 0.11523033871371341\n",
      "epoch : 215 [17/23] Train loss: 0.33315,Valid loss: 0.64658, time : 9.890689134597778 lr : 0.11523033871371341\n",
      "epoch : 215 [18/23] Train loss: 0.32938,Valid loss: 0.68147, time : 10.118838787078857 lr : 0.11523033871371341\n",
      "epoch : 215 [19/23] Train loss: 0.35184,Valid loss: 0.62922, time : 10.331168174743652 lr : 0.11523033871371341\n",
      "epoch : 215 [20/23] Train loss: 0.34349,Valid loss: 0.68254, time : 10.370851039886475 lr : 0.11523033871371341\n",
      "epoch : 215 [21/23] Train loss: 0.35047,Valid loss: 0.65218, time : 10.197679281234741 lr : 0.11523033871371341\n",
      "epoch : 215 [22/23] Train loss: 0.34217,Valid loss: 0.63725, time : 9.534043550491333 lr : 0.11523033871371341\n",
      "epoch : 216 [0/23] Train loss: 0.33496,Valid loss: 0.67094, time : 10.367761611938477 lr : 0.11407803532657627\n",
      "epoch : 216 [1/23] Train loss: 0.34735,Valid loss: 0.64096, time : 10.191176652908325 lr : 0.11407803532657627\n",
      "epoch : 216 [2/23] Train loss: 0.34969,Valid loss: 0.66497, time : 10.38080358505249 lr : 0.11407803532657627\n",
      "epoch : 216 [3/23] Train loss: 0.33852,Valid loss: 0.66066, time : 10.25316071510315 lr : 0.11407803532657627\n",
      "epoch : 216 [4/23] Train loss: 0.35094,Valid loss: 0.66793, time : 10.371142625808716 lr : 0.11407803532657627\n",
      "epoch : 216 [5/23] Train loss: 0.35841,Valid loss: 0.64066, time : 10.252218961715698 lr : 0.11407803532657627\n",
      "epoch : 216 [6/23] Train loss: 0.33857,Valid loss: 0.64363, time : 9.650166273117065 lr : 0.11407803532657627\n",
      "epoch : 216 [7/23] Train loss: 0.34296,Valid loss: 0.64225, time : 10.078838348388672 lr : 0.11407803532657627\n",
      "epoch : 216 [8/23] Train loss: 0.35377,Valid loss: 0.64692, time : 9.66258716583252 lr : 0.11407803532657627\n",
      "epoch : 216 [9/23] Train loss: 0.36029,Valid loss: 0.69900, time : 10.276870965957642 lr : 0.11407803532657627\n",
      "epoch : 216 [10/23] Train loss: 0.34036,Valid loss: 0.68606, time : 9.758458852767944 lr : 0.11407803532657627\n",
      "epoch : 216 [11/23] Train loss: 0.35035,Valid loss: 0.65921, time : 10.077762842178345 lr : 0.11407803532657627\n",
      "epoch : 216 [12/23] Train loss: 0.33502,Valid loss: 0.68574, time : 9.734430074691772 lr : 0.11407803532657627\n",
      "epoch : 216 [13/23] Train loss: 0.35164,Valid loss: 0.63863, time : 10.276262998580933 lr : 0.11407803532657627\n",
      "epoch : 216 [14/23] Train loss: 0.33971,Valid loss: 0.67520, time : 9.724544048309326 lr : 0.11407803532657627\n",
      "epoch : 216 [15/23] Train loss: 0.34298,Valid loss: 0.69355, time : 10.704048156738281 lr : 0.11407803532657627\n",
      "epoch : 216 [16/23] Train loss: 0.34544,Valid loss: 0.64077, time : 9.861793279647827 lr : 0.11407803532657627\n",
      "epoch : 216 [17/23] Train loss: 0.34292,Valid loss: 0.64711, time : 10.022187948226929 lr : 0.11407803532657627\n",
      "epoch : 216 [18/23] Train loss: 0.34618,Valid loss: 0.63819, time : 10.122281074523926 lr : 0.11407803532657627\n",
      "epoch : 216 [19/23] Train loss: 0.33890,Valid loss: 0.63367, time : 10.039108753204346 lr : 0.11407803532657627\n",
      "epoch : 216 [20/23] Train loss: 0.33550,Valid loss: 0.68808, time : 9.92901062965393 lr : 0.11407803532657627\n",
      "epoch : 216 [21/23] Train loss: 0.33892,Valid loss: 0.63468, time : 10.097336530685425 lr : 0.11407803532657627\n",
      "epoch : 216 [22/23] Train loss: 0.35177,Valid loss: 0.64435, time : 9.632318496704102 lr : 0.11407803532657627\n",
      "epoch : 217 [0/23] Train loss: 0.33723,Valid loss: 0.64604, time : 10.482442140579224 lr : 0.11293725497331052\n",
      "epoch : 217 [1/23] Train loss: 0.34134,Valid loss: 0.65123, time : 10.049809694290161 lr : 0.11293725497331052\n",
      "epoch : 217 [2/23] Train loss: 0.34370,Valid loss: 0.68356, time : 10.179404497146606 lr : 0.11293725497331052\n",
      "epoch : 217 [3/23] Train loss: 0.35426,Valid loss: 0.63663, time : 9.81413722038269 lr : 0.11293725497331052\n",
      "epoch : 217 [4/23] Train loss: 0.34354,Valid loss: 0.66494, time : 10.018454790115356 lr : 0.11293725497331052\n",
      "epoch : 217 [5/23] Train loss: 0.35665,Valid loss: 0.69254, time : 9.617699146270752 lr : 0.11293725497331052\n",
      "epoch : 217 [6/23] Train loss: 0.33292,Valid loss: 0.63215, time : 10.174522638320923 lr : 0.11293725497331052\n",
      "epoch : 217 [7/23] Train loss: 0.34491,Valid loss: 0.69700, time : 9.607897520065308 lr : 0.11293725497331052\n",
      "epoch : 217 [8/23] Train loss: 0.34811,Valid loss: 0.66611, time : 10.256500244140625 lr : 0.11293725497331052\n",
      "epoch : 217 [9/23] Train loss: 0.34353,Valid loss: 0.68834, time : 9.963058948516846 lr : 0.11293725497331052\n",
      "epoch : 217 [10/23] Train loss: 0.34773,Valid loss: 0.64397, time : 10.293514728546143 lr : 0.11293725497331052\n",
      "epoch : 217 [11/23] Train loss: 0.34286,Valid loss: 0.69340, time : 9.724932432174683 lr : 0.11293725497331052\n",
      "epoch : 217 [12/23] Train loss: 0.33797,Valid loss: 0.61734, time : 10.36768126487732 lr : 0.11293725497331052\n",
      "epoch : 217 [13/23] Train loss: 0.34673,Valid loss: 0.71075, time : 10.454280853271484 lr : 0.11293725497331052\n",
      "epoch : 217 [14/23] Train loss: 0.33059,Valid loss: 0.66419, time : 10.12813663482666 lr : 0.11293725497331052\n",
      "epoch : 217 [15/23] Train loss: 0.33335,Valid loss: 0.68299, time : 10.274575233459473 lr : 0.11293725497331052\n",
      "epoch : 217 [16/23] Train loss: 0.34856,Valid loss: 0.64796, time : 10.649111032485962 lr : 0.11293725497331052\n",
      "epoch : 217 [17/23] Train loss: 0.34175,Valid loss: 0.64180, time : 10.43253755569458 lr : 0.11293725497331052\n",
      "epoch : 217 [18/23] Train loss: 0.34570,Valid loss: 0.63121, time : 10.136589288711548 lr : 0.11293725497331052\n",
      "epoch : 217 [19/23] Train loss: 0.33887,Valid loss: 0.61807, time : 10.523330211639404 lr : 0.11293725497331052\n",
      "epoch : 217 [20/23] Train loss: 0.33422,Valid loss: 0.62490, time : 10.389490127563477 lr : 0.11293725497331052\n",
      "epoch : 217 [21/23] Train loss: 0.34127,Valid loss: 0.63870, time : 10.59658432006836 lr : 0.11293725497331052\n",
      "epoch : 217 [22/23] Train loss: 0.33349,Valid loss: 0.64711, time : 9.453636646270752 lr : 0.11293725497331052\n",
      "epoch : 218 [0/23] Train loss: 0.35109,Valid loss: 0.70369, time : 10.377295732498169 lr : 0.1118078824235774\n",
      "epoch : 218 [1/23] Train loss: 0.33633,Valid loss: 0.64456, time : 10.400646448135376 lr : 0.1118078824235774\n",
      "epoch : 218 [2/23] Train loss: 0.33861,Valid loss: 0.64723, time : 10.090851783752441 lr : 0.1118078824235774\n",
      "epoch : 218 [3/23] Train loss: 0.34690,Valid loss: 0.65498, time : 10.366918802261353 lr : 0.1118078824235774\n",
      "epoch : 218 [4/23] Train loss: 0.34060,Valid loss: 0.64083, time : 10.155208826065063 lr : 0.1118078824235774\n",
      "epoch : 218 [5/23] Train loss: 0.33922,Valid loss: 0.65950, time : 10.367736577987671 lr : 0.1118078824235774\n",
      "epoch : 218 [6/23] Train loss: 0.33382,Valid loss: 0.69091, time : 10.252946615219116 lr : 0.1118078824235774\n",
      "epoch : 218 [7/23] Train loss: 0.34075,Valid loss: 0.67235, time : 10.342822313308716 lr : 0.1118078824235774\n",
      "epoch : 218 [8/23] Train loss: 0.33354,Valid loss: 0.63880, time : 10.216094732284546 lr : 0.1118078824235774\n",
      "epoch : 218 [9/23] Train loss: 0.33472,Valid loss: 0.65592, time : 10.387837171554565 lr : 0.1118078824235774\n",
      "epoch : 218 [10/23] Train loss: 0.32615,Valid loss: 0.70983, time : 10.365679264068604 lr : 0.1118078824235774\n",
      "epoch : 218 [11/23] Train loss: 0.33516,Valid loss: 0.66027, time : 10.392394065856934 lr : 0.1118078824235774\n",
      "epoch : 218 [12/23] Train loss: 0.34368,Valid loss: 0.68542, time : 10.067477464675903 lr : 0.1118078824235774\n",
      "epoch : 218 [13/23] Train loss: 0.35872,Valid loss: 0.67482, time : 10.104990720748901 lr : 0.1118078824235774\n",
      "epoch : 218 [14/23] Train loss: 0.34117,Valid loss: 0.62578, time : 9.718677282333374 lr : 0.1118078824235774\n",
      "epoch : 218 [15/23] Train loss: 0.34071,Valid loss: 0.63618, time : 9.970312356948853 lr : 0.1118078824235774\n",
      "epoch : 218 [16/23] Train loss: 0.33430,Valid loss: 0.62670, time : 9.800556182861328 lr : 0.1118078824235774\n",
      "epoch : 218 [17/23] Train loss: 0.33745,Valid loss: 0.66121, time : 10.162644863128662 lr : 0.1118078824235774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 218 [18/23] Train loss: 0.35605,Valid loss: 0.64410, time : 9.690471649169922 lr : 0.1118078824235774\n",
      "epoch : 218 [19/23] Train loss: 0.33531,Valid loss: 0.69396, time : 9.997239112854004 lr : 0.1118078824235774\n",
      "epoch : 218 [20/23] Train loss: 0.33355,Valid loss: 0.63834, time : 9.846463680267334 lr : 0.1118078824235774\n",
      "epoch : 218 [21/23] Train loss: 0.33585,Valid loss: 0.67178, time : 10.142813205718994 lr : 0.1118078824235774\n",
      "epoch : 218 [22/23] Train loss: 0.33314,Valid loss: 0.63751, time : 9.450905799865723 lr : 0.1118078824235774\n",
      "epoch : 219 [0/23] Train loss: 0.34024,Valid loss: 0.68173, time : 10.383176803588867 lr : 0.11068980359934164\n",
      "epoch : 219 [1/23] Train loss: 0.33066,Valid loss: 0.66873, time : 10.033437728881836 lr : 0.11068980359934164\n",
      "epoch : 219 [2/23] Train loss: 0.33482,Valid loss: 0.66670, time : 10.224961042404175 lr : 0.11068980359934164\n",
      "epoch : 219 [3/23] Train loss: 0.33839,Valid loss: 0.62997, time : 9.919971704483032 lr : 0.11068980359934164\n",
      "epoch : 219 [4/23] Train loss: 0.33676,Valid loss: 0.67469, time : 10.290437698364258 lr : 0.11068980359934164\n",
      "epoch : 219 [5/23] Train loss: 0.34229,Valid loss: 0.64262, time : 10.132539987564087 lr : 0.11068980359934164\n",
      "epoch : 219 [6/23] Train loss: 0.34934,Valid loss: 0.65599, time : 10.476101875305176 lr : 0.11068980359934164\n",
      "epoch : 219 [7/23] Train loss: 0.34092,Valid loss: 0.68286, time : 10.294720649719238 lr : 0.11068980359934164\n",
      "epoch : 219 [8/23] Train loss: 0.36204,Valid loss: 0.63846, time : 9.982170581817627 lr : 0.11068980359934164\n",
      "epoch : 219 [9/23] Train loss: 0.34994,Valid loss: 0.65172, time : 10.22584867477417 lr : 0.11068980359934164\n",
      "epoch : 219 [10/23] Train loss: 0.35497,Valid loss: 0.66941, time : 9.900157690048218 lr : 0.11068980359934164\n",
      "epoch : 219 [11/23] Train loss: 0.34738,Valid loss: 0.66284, time : 10.433231115341187 lr : 0.11068980359934164\n",
      "epoch : 219 [12/23] Train loss: 0.34864,Valid loss: 0.65873, time : 10.212258577346802 lr : 0.11068980359934164\n",
      "epoch : 219 [13/23] Train loss: 0.34206,Valid loss: 0.68092, time : 10.553253412246704 lr : 0.11068980359934164\n",
      "epoch : 219 [14/23] Train loss: 0.33693,Valid loss: 0.68421, time : 10.378457307815552 lr : 0.11068980359934164\n",
      "epoch : 219 [15/23] Train loss: 0.33826,Valid loss: 0.70108, time : 10.960188865661621 lr : 0.11068980359934164\n",
      "epoch : 219 [16/23] Train loss: 0.35059,Valid loss: 0.65429, time : 10.38230276107788 lr : 0.11068980359934164\n",
      "epoch : 219 [17/23] Train loss: 0.35995,Valid loss: 0.68561, time : 10.426594972610474 lr : 0.11068980359934164\n",
      "epoch : 219 [18/23] Train loss: 0.34882,Valid loss: 0.69813, time : 10.112497091293335 lr : 0.11068980359934164\n",
      "epoch : 219 [19/23] Train loss: 0.36050,Valid loss: 0.68201, time : 10.278242349624634 lr : 0.11068980359934164\n",
      "epoch : 219 [20/23] Train loss: 0.35880,Valid loss: 0.65187, time : 10.146416664123535 lr : 0.11068980359934164\n",
      "epoch : 219 [21/23] Train loss: 0.34171,Valid loss: 0.67656, time : 10.28232216835022 lr : 0.11068980359934164\n",
      "epoch : 219 [22/23] Train loss: 0.34361,Valid loss: 0.66389, time : 9.433192014694214 lr : 0.11068980359934164\n",
      "epoch : 220 [0/23] Train loss: 0.35056,Valid loss: 0.68470, time : 10.819453716278076 lr : 0.10958290556334822\n",
      "epoch : 220 [1/23] Train loss: 0.34104,Valid loss: 0.68287, time : 10.026814222335815 lr : 0.10958290556334822\n",
      "epoch : 220 [2/23] Train loss: 0.35019,Valid loss: 0.70274, time : 10.16721510887146 lr : 0.10958290556334822\n",
      "epoch : 220 [3/23] Train loss: 0.32944,Valid loss: 0.67403, time : 9.907258987426758 lr : 0.10958290556334822\n",
      "epoch : 220 [4/23] Train loss: 0.33529,Valid loss: 0.69813, time : 10.143558263778687 lr : 0.10958290556334822\n",
      "epoch : 220 [5/23] Train loss: 0.33670,Valid loss: 0.70808, time : 9.580991506576538 lr : 0.10958290556334822\n",
      "epoch : 220 [6/23] Train loss: 0.34072,Valid loss: 0.68889, time : 10.254027843475342 lr : 0.10958290556334822\n",
      "epoch : 220 [7/23] Train loss: 0.33458,Valid loss: 0.67101, time : 9.627734661102295 lr : 0.10958290556334822\n",
      "epoch : 220 [8/23] Train loss: 0.34161,Valid loss: 0.70239, time : 10.324094295501709 lr : 0.10958290556334822\n",
      "epoch : 220 [9/23] Train loss: 0.33526,Valid loss: 0.70088, time : 9.582072257995605 lr : 0.10958290556334822\n",
      "epoch : 220 [10/23] Train loss: 0.34127,Valid loss: 0.71833, time : 10.18732476234436 lr : 0.10958290556334822\n",
      "epoch : 220 [11/23] Train loss: 0.33794,Valid loss: 0.72007, time : 9.550448656082153 lr : 0.10958290556334822\n",
      "epoch : 220 [12/23] Train loss: 0.34087,Valid loss: 0.64464, time : 9.967851161956787 lr : 0.10958290556334822\n",
      "epoch : 220 [13/23] Train loss: 0.33193,Valid loss: 0.70021, time : 9.83443021774292 lr : 0.10958290556334822\n",
      "epoch : 220 [14/23] Train loss: 0.33327,Valid loss: 0.71479, time : 10.085957765579224 lr : 0.10958290556334822\n",
      "epoch : 220 [15/23] Train loss: 0.34044,Valid loss: 0.67583, time : 9.761751413345337 lr : 0.10958290556334822\n",
      "epoch : 220 [16/23] Train loss: 0.35060,Valid loss: 0.63633, time : 10.204872131347656 lr : 0.10958290556334822\n",
      "epoch : 220 [17/23] Train loss: 0.32868,Valid loss: 0.68581, time : 9.961283445358276 lr : 0.10958290556334822\n",
      "epoch : 220 [18/23] Train loss: 0.33945,Valid loss: 0.72143, time : 10.093441247940063 lr : 0.10958290556334822\n",
      "epoch : 220 [19/23] Train loss: 0.34200,Valid loss: 0.66215, time : 10.149924993515015 lr : 0.10958290556334822\n",
      "epoch : 220 [20/23] Train loss: 0.35054,Valid loss: 0.66076, time : 10.359229564666748 lr : 0.10958290556334822\n",
      "epoch : 220 [21/23] Train loss: 0.34331,Valid loss: 0.70267, time : 10.052641868591309 lr : 0.10958290556334822\n",
      "epoch : 220 [22/23] Train loss: 0.32888,Valid loss: 0.67233, time : 9.42837119102478 lr : 0.10958290556334822\n",
      "epoch : 221 [0/23] Train loss: 0.33145,Valid loss: 0.65910, time : 10.341339588165283 lr : 0.10848707650771475\n",
      "epoch : 221 [1/23] Train loss: 0.34771,Valid loss: 0.69672, time : 10.327094793319702 lr : 0.10848707650771475\n",
      "epoch : 221 [2/23] Train loss: 0.32671,Valid loss: 0.66931, time : 10.326841354370117 lr : 0.10848707650771475\n",
      "epoch : 221 [3/23] Train loss: 0.33820,Valid loss: 0.65764, time : 10.163807153701782 lr : 0.10848707650771475\n",
      "epoch : 221 [4/23] Train loss: 0.33430,Valid loss: 0.66420, time : 10.519670724868774 lr : 0.10848707650771475\n",
      "epoch : 221 [5/23] Train loss: 0.33352,Valid loss: 0.69673, time : 10.67849087715149 lr : 0.10848707650771475\n",
      "epoch : 221 [6/23] Train loss: 0.32442,Valid loss: 0.68011, time : 10.885801315307617 lr : 0.10848707650771475\n",
      "epoch : 221 [7/23] Train loss: 0.33761,Valid loss: 0.66007, time : 10.669503688812256 lr : 0.10848707650771475\n",
      "epoch : 221 [8/23] Train loss: 0.33179,Valid loss: 0.69942, time : 10.432757377624512 lr : 0.10848707650771475\n",
      "epoch : 221 [9/23] Train loss: 0.33165,Valid loss: 0.69182, time : 10.542927026748657 lr : 0.10848707650771475\n",
      "epoch : 221 [10/23] Train loss: 0.33177,Valid loss: 0.69408, time : 10.333602666854858 lr : 0.10848707650771475\n",
      "epoch : 221 [11/23] Train loss: 0.33405,Valid loss: 0.67824, time : 10.421662330627441 lr : 0.10848707650771475\n",
      "epoch : 221 [12/23] Train loss: 0.33277,Valid loss: 0.67918, time : 10.532110691070557 lr : 0.10848707650771475\n",
      "epoch : 221 [13/23] Train loss: 0.34793,Valid loss: 0.71357, time : 10.55862283706665 lr : 0.10848707650771475\n",
      "epoch : 221 [14/23] Train loss: 0.33085,Valid loss: 0.68082, time : 10.904569625854492 lr : 0.10848707650771475\n",
      "epoch : 221 [15/23] Train loss: 0.34498,Valid loss: 0.70808, time : 10.914070844650269 lr : 0.10848707650771475\n",
      "epoch : 221 [16/23] Train loss: 0.34200,Valid loss: 0.64070, time : 10.725464344024658 lr : 0.10848707650771475\n",
      "epoch : 221 [17/23] Train loss: 0.34392,Valid loss: 0.66399, time : 10.27088713645935 lr : 0.10848707650771475\n",
      "epoch : 221 [18/23] Train loss: 0.34291,Valid loss: 0.68011, time : 10.383153200149536 lr : 0.10848707650771475\n",
      "epoch : 221 [19/23] Train loss: 0.33487,Valid loss: 0.65538, time : 10.08273434638977 lr : 0.10848707650771475\n",
      "epoch : 221 [20/23] Train loss: 0.33664,Valid loss: 0.69581, time : 10.280516624450684 lr : 0.10848707650771475\n",
      "epoch : 221 [21/23] Train loss: 0.33441,Valid loss: 0.69872, time : 10.603920221328735 lr : 0.10848707650771475\n",
      "epoch : 221 [22/23] Train loss: 0.34578,Valid loss: 0.69166, time : 9.459419012069702 lr : 0.10848707650771475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 222 [0/23] Train loss: 0.33822,Valid loss: 0.70565, time : 10.279680252075195 lr : 0.1074022057426376\n",
      "epoch : 222 [1/23] Train loss: 0.32442,Valid loss: 0.67563, time : 10.342589378356934 lr : 0.1074022057426376\n",
      "epoch : 222 [2/23] Train loss: 0.32330,Valid loss: 0.69114, time : 10.283799648284912 lr : 0.1074022057426376\n",
      "epoch : 222 [3/23] Train loss: 0.32514,Valid loss: 0.64880, time : 10.299498796463013 lr : 0.1074022057426376\n",
      "epoch : 222 [4/23] Train loss: 0.32804,Valid loss: 0.66995, time : 9.973788976669312 lr : 0.1074022057426376\n",
      "epoch : 222 [5/23] Train loss: 0.33909,Valid loss: 0.66464, time : 10.28283977508545 lr : 0.1074022057426376\n",
      "epoch : 222 [6/23] Train loss: 0.33862,Valid loss: 0.69375, time : 9.630872011184692 lr : 0.1074022057426376\n",
      "epoch : 222 [7/23] Train loss: 0.33255,Valid loss: 0.64169, time : 10.119873046875 lr : 0.1074022057426376\n",
      "epoch : 222 [8/23] Train loss: 0.34001,Valid loss: 0.67762, time : 9.533503293991089 lr : 0.1074022057426376\n",
      "epoch : 222 [9/23] Train loss: 0.34037,Valid loss: 0.69237, time : 10.058384656906128 lr : 0.1074022057426376\n",
      "epoch : 222 [10/23] Train loss: 0.33686,Valid loss: 0.67991, time : 9.910057067871094 lr : 0.1074022057426376\n",
      "epoch : 222 [11/23] Train loss: 0.32830,Valid loss: 0.65511, time : 10.0390625 lr : 0.1074022057426376\n",
      "epoch : 222 [12/23] Train loss: 0.33476,Valid loss: 0.68774, time : 9.554335355758667 lr : 0.1074022057426376\n",
      "epoch : 222 [13/23] Train loss: 0.34232,Valid loss: 0.68371, time : 9.994004487991333 lr : 0.1074022057426376\n",
      "epoch : 222 [14/23] Train loss: 0.32917,Valid loss: 0.67534, time : 9.948586702346802 lr : 0.1074022057426376\n",
      "epoch : 222 [15/23] Train loss: 0.33287,Valid loss: 0.65322, time : 10.222594738006592 lr : 0.1074022057426376\n",
      "epoch : 222 [16/23] Train loss: 0.35012,Valid loss: 0.69817, time : 10.205113172531128 lr : 0.1074022057426376\n",
      "epoch : 222 [17/23] Train loss: 0.33194,Valid loss: 0.66808, time : 10.212344884872437 lr : 0.1074022057426376\n",
      "epoch : 222 [18/23] Train loss: 0.34658,Valid loss: 0.67263, time : 10.245279788970947 lr : 0.1074022057426376\n",
      "epoch : 222 [19/23] Train loss: 0.32537,Valid loss: 0.68667, time : 10.20189380645752 lr : 0.1074022057426376\n",
      "epoch : 222 [20/23] Train loss: 0.32953,Valid loss: 0.69767, time : 10.248317003250122 lr : 0.1074022057426376\n",
      "epoch : 222 [21/23] Train loss: 0.33566,Valid loss: 0.67185, time : 10.223289012908936 lr : 0.1074022057426376\n",
      "epoch : 222 [22/23] Train loss: 0.33575,Valid loss: 0.69058, time : 9.431272983551025 lr : 0.1074022057426376\n",
      "epoch : 223 [0/23] Train loss: 0.33146,Valid loss: 0.67695, time : 10.425363540649414 lr : 0.10632818368521123\n",
      "epoch : 223 [1/23] Train loss: 0.32986,Valid loss: 0.69300, time : 10.095276594161987 lr : 0.10632818368521123\n",
      "epoch : 223 [2/23] Train loss: 0.33264,Valid loss: 0.68199, time : 10.103148460388184 lr : 0.10632818368521123\n",
      "epoch : 223 [3/23] Train loss: 0.33470,Valid loss: 0.69144, time : 9.860365629196167 lr : 0.10632818368521123\n",
      "epoch : 223 [4/23] Train loss: 0.32421,Valid loss: 0.67588, time : 10.460504293441772 lr : 0.10632818368521123\n",
      "epoch : 223 [5/23] Train loss: 0.32745,Valid loss: 0.66404, time : 10.436546087265015 lr : 0.10632818368521123\n",
      "epoch : 223 [6/23] Train loss: 0.33551,Valid loss: 0.64994, time : 10.515841245651245 lr : 0.10632818368521123\n",
      "epoch : 223 [7/23] Train loss: 0.33321,Valid loss: 0.63631, time : 10.007543563842773 lr : 0.10632818368521123\n",
      "epoch : 223 [8/23] Train loss: 0.33297,Valid loss: 0.71010, time : 10.329132080078125 lr : 0.10632818368521123\n",
      "epoch : 223 [9/23] Train loss: 0.34384,Valid loss: 0.63391, time : 10.03215742111206 lr : 0.10632818368521123\n",
      "epoch : 223 [10/23] Train loss: 0.33408,Valid loss: 0.64293, time : 10.441404581069946 lr : 0.10632818368521123\n",
      "epoch : 223 [11/23] Train loss: 0.32404,Valid loss: 0.63743, time : 10.270933389663696 lr : 0.10632818368521123\n",
      "epoch : 223 [12/23] Train loss: 0.33534,Valid loss: 0.65057, time : 10.36310601234436 lr : 0.10632818368521123\n",
      "epoch : 223 [13/23] Train loss: 0.32861,Valid loss: 0.63377, time : 9.951430320739746 lr : 0.10632818368521123\n",
      "epoch : 223 [14/23] Train loss: 0.33252,Valid loss: 0.65600, time : 10.204575777053833 lr : 0.10632818368521123\n",
      "epoch : 223 [15/23] Train loss: 0.34081,Valid loss: 0.71238, time : 10.008085489273071 lr : 0.10632818368521123\n",
      "epoch : 223 [16/23] Train loss: 0.33731,Valid loss: 0.67289, time : 10.652954578399658 lr : 0.10632818368521123\n",
      "epoch : 223 [17/23] Train loss: 0.33235,Valid loss: 0.69676, time : 9.815598011016846 lr : 0.10632818368521123\n",
      "epoch : 223 [18/23] Train loss: 0.33578,Valid loss: 0.66388, time : 10.280718088150024 lr : 0.10632818368521123\n",
      "epoch : 223 [19/23] Train loss: 0.32815,Valid loss: 0.67592, time : 10.196645498275757 lr : 0.10632818368521123\n",
      "epoch : 223 [20/23] Train loss: 0.33665,Valid loss: 0.70791, time : 10.102242469787598 lr : 0.10632818368521123\n",
      "epoch : 223 [21/23] Train loss: 0.33874,Valid loss: 0.69350, time : 10.236888885498047 lr : 0.10632818368521123\n",
      "epoch : 223 [22/23] Train loss: 0.33425,Valid loss: 0.67639, time : 9.484607219696045 lr : 0.10632818368521123\n",
      "epoch : 224 [0/23] Train loss: 0.32169,Valid loss: 0.63302, time : 10.582192420959473 lr : 0.10526490184835911\n",
      "epoch : 224 [1/23] Train loss: 0.32834,Valid loss: 0.67821, time : 10.283830165863037 lr : 0.10526490184835911\n",
      "epoch : 224 [2/23] Train loss: 0.34128,Valid loss: 0.66665, time : 10.58788800239563 lr : 0.10526490184835911\n",
      "epoch : 224 [3/23] Train loss: 0.34263,Valid loss: 0.68787, time : 10.630447387695312 lr : 0.10526490184835911\n",
      "epoch : 224 [4/23] Train loss: 0.32489,Valid loss: 0.62392, time : 9.748499631881714 lr : 0.10526490184835911\n",
      "epoch : 224 [5/23] Train loss: 0.33422,Valid loss: 0.60956, time : 10.284828901290894 lr : 0.10526490184835911\n",
      "epoch : 224 [6/23] Train loss: 0.32328,Valid loss: 0.68782, time : 10.52132534980774 lr : 0.10526490184835911\n",
      "epoch : 224 [7/23] Train loss: 0.32833,Valid loss: 0.67209, time : 10.984833240509033 lr : 0.10526490184835911\n",
      "epoch : 224 [8/23] Train loss: 0.33955,Valid loss: 0.61067, time : 10.345170736312866 lr : 0.10526490184835911\n",
      "epoch : 224 [9/23] Train loss: 0.33566,Valid loss: 0.64888, time : 10.298203229904175 lr : 0.10526490184835911\n",
      "epoch : 224 [10/23] Train loss: 0.32124,Valid loss: 0.68023, time : 10.275834083557129 lr : 0.10526490184835911\n",
      "epoch : 224 [11/23] Train loss: 0.33535,Valid loss: 0.66099, time : 10.335660219192505 lr : 0.10526490184835911\n",
      "epoch : 224 [12/23] Train loss: 0.33756,Valid loss: 0.67991, time : 10.31704568862915 lr : 0.10526490184835911\n",
      "epoch : 224 [13/23] Train loss: 0.32111,Valid loss: 0.67385, time : 10.425041198730469 lr : 0.10526490184835911\n",
      "epoch : 224 [14/23] Train loss: 0.32722,Valid loss: 0.67282, time : 10.151203393936157 lr : 0.10526490184835911\n",
      "epoch : 224 [15/23] Train loss: 0.32997,Valid loss: 0.67751, time : 10.399368524551392 lr : 0.10526490184835911\n",
      "epoch : 224 [16/23] Train loss: 0.32952,Valid loss: 0.62239, time : 10.296081304550171 lr : 0.10526490184835911\n",
      "epoch : 224 [17/23] Train loss: 0.33282,Valid loss: 0.65882, time : 10.53876280784607 lr : 0.10526490184835911\n",
      "epoch : 224 [18/23] Train loss: 0.33753,Valid loss: 0.67308, time : 10.039002895355225 lr : 0.10526490184835911\n",
      "epoch : 224 [19/23] Train loss: 0.33518,Valid loss: 0.68052, time : 10.604321241378784 lr : 0.10526490184835911\n",
      "epoch : 224 [20/23] Train loss: 0.32399,Valid loss: 0.69500, time : 10.027106761932373 lr : 0.10526490184835911\n",
      "epoch : 224 [21/23] Train loss: 0.32478,Valid loss: 0.60169, time : 10.367589712142944 lr : 0.10526490184835911\n",
      "epoch : 224 [22/23] Train loss: 0.31648,Valid loss: 0.68712, time : 9.353395700454712 lr : 0.10526490184835911\n",
      "epoch : 225 [0/23] Train loss: 0.33457,Valid loss: 0.66950, time : 10.221227407455444 lr : 0.10421225282987552\n",
      "epoch : 225 [1/23] Train loss: 0.33888,Valid loss: 0.64245, time : 10.228018760681152 lr : 0.10421225282987552\n",
      "epoch : 225 [2/23] Train loss: 0.32474,Valid loss: 0.65299, time : 10.387564659118652 lr : 0.10421225282987552\n",
      "epoch : 225 [3/23] Train loss: 0.33641,Valid loss: 0.71631, time : 10.116972923278809 lr : 0.10421225282987552\n",
      "epoch : 225 [4/23] Train loss: 0.33111,Valid loss: 0.60936, time : 10.070251941680908 lr : 0.10421225282987552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 225 [5/23] Train loss: 0.32816,Valid loss: 0.66396, time : 10.14214015007019 lr : 0.10421225282987552\n",
      "epoch : 225 [6/23] Train loss: 0.30877,Valid loss: 0.59392, time : 10.19585132598877 lr : 0.10421225282987552\n",
      "epoch : 225 [7/23] Train loss: 0.32927,Valid loss: 0.73709, time : 10.317341089248657 lr : 0.10421225282987552\n",
      "epoch : 225 [8/23] Train loss: 0.32049,Valid loss: 0.59767, time : 10.399869441986084 lr : 0.10421225282987552\n",
      "epoch : 225 [9/23] Train loss: 0.32647,Valid loss: 0.69784, time : 10.196529626846313 lr : 0.10421225282987552\n",
      "epoch : 225 [10/23] Train loss: 0.33113,Valid loss: 0.66754, time : 10.074493169784546 lr : 0.10421225282987552\n",
      "epoch : 225 [11/23] Train loss: 0.32510,Valid loss: 0.69714, time : 10.474784135818481 lr : 0.10421225282987552\n",
      "epoch : 225 [12/23] Train loss: 0.33804,Valid loss: 0.69604, time : 10.389843702316284 lr : 0.10421225282987552\n",
      "epoch : 225 [13/23] Train loss: 0.33263,Valid loss: 0.66419, time : 10.13646936416626 lr : 0.10421225282987552\n",
      "epoch : 225 [14/23] Train loss: 0.33118,Valid loss: 0.71705, time : 10.15363883972168 lr : 0.10421225282987552\n",
      "epoch : 225 [15/23] Train loss: 0.32251,Valid loss: 0.64542, time : 10.165952205657959 lr : 0.10421225282987552\n",
      "epoch : 225 [16/23] Train loss: 0.33612,Valid loss: 0.65100, time : 10.292502641677856 lr : 0.10421225282987552\n",
      "epoch : 225 [17/23] Train loss: 0.32576,Valid loss: 0.68803, time : 10.63198971748352 lr : 0.10421225282987552\n",
      "epoch : 225 [18/23] Train loss: 0.32885,Valid loss: 0.66017, time : 10.61390995979309 lr : 0.10421225282987552\n",
      "epoch : 225 [19/23] Train loss: 0.32970,Valid loss: 0.65734, time : 10.516642570495605 lr : 0.10421225282987552\n",
      "epoch : 225 [20/23] Train loss: 0.31824,Valid loss: 0.70794, time : 10.687144041061401 lr : 0.10421225282987552\n",
      "epoch : 225 [21/23] Train loss: 0.32922,Valid loss: 0.69931, time : 10.570273160934448 lr : 0.10421225282987552\n",
      "epoch : 225 [22/23] Train loss: 0.32928,Valid loss: 0.64861, time : 9.65164852142334 lr : 0.10421225282987552\n",
      "epoch : 226 [0/23] Train loss: 0.32095,Valid loss: 0.67435, time : 10.492527961730957 lr : 0.10317013030157676\n",
      "epoch : 226 [1/23] Train loss: 0.32260,Valid loss: 0.67550, time : 10.113229036331177 lr : 0.10317013030157676\n",
      "epoch : 226 [2/23] Train loss: 0.32802,Valid loss: 0.67126, time : 10.431768894195557 lr : 0.10317013030157676\n",
      "epoch : 226 [3/23] Train loss: 0.32874,Valid loss: 0.68421, time : 10.164622783660889 lr : 0.10317013030157676\n",
      "epoch : 226 [4/23] Train loss: 0.32598,Valid loss: 0.65321, time : 10.350484609603882 lr : 0.10317013030157676\n",
      "epoch : 226 [5/23] Train loss: 0.32593,Valid loss: 0.68803, time : 10.020389795303345 lr : 0.10317013030157676\n",
      "epoch : 226 [6/23] Train loss: 0.33362,Valid loss: 0.64186, time : 10.268624544143677 lr : 0.10317013030157676\n",
      "epoch : 226 [7/23] Train loss: 0.33026,Valid loss: 0.67234, time : 10.303356885910034 lr : 0.10317013030157676\n",
      "epoch : 226 [8/23] Train loss: 0.33182,Valid loss: 0.66224, time : 10.344221353530884 lr : 0.10317013030157676\n",
      "epoch : 226 [9/23] Train loss: 0.33138,Valid loss: 0.67481, time : 10.213395833969116 lr : 0.10317013030157676\n",
      "epoch : 226 [10/23] Train loss: 0.32724,Valid loss: 0.62447, time : 9.716100692749023 lr : 0.10317013030157676\n",
      "epoch : 226 [11/23] Train loss: 0.32335,Valid loss: 0.69631, time : 9.96468710899353 lr : 0.10317013030157676\n",
      "epoch : 226 [12/23] Train loss: 0.32742,Valid loss: 0.62481, time : 9.56806993484497 lr : 0.10317013030157676\n",
      "epoch : 226 [13/23] Train loss: 0.33079,Valid loss: 0.64145, time : 10.20429253578186 lr : 0.10317013030157676\n",
      "epoch : 226 [14/23] Train loss: 0.33752,Valid loss: 0.62672, time : 10.06427812576294 lr : 0.10317013030157676\n",
      "epoch : 226 [15/23] Train loss: 0.32198,Valid loss: 0.61537, time : 10.675653457641602 lr : 0.10317013030157676\n",
      "epoch : 226 [16/23] Train loss: 0.32507,Valid loss: 0.62620, time : 10.21931529045105 lr : 0.10317013030157676\n",
      "epoch : 226 [17/23] Train loss: 0.33360,Valid loss: 0.64979, time : 10.2932870388031 lr : 0.10317013030157676\n",
      "epoch : 226 [18/23] Train loss: 0.33095,Valid loss: 0.64030, time : 10.470786809921265 lr : 0.10317013030157676\n",
      "epoch : 226 [19/23] Train loss: 0.33731,Valid loss: 0.65766, time : 10.529646873474121 lr : 0.10317013030157676\n",
      "epoch : 226 [20/23] Train loss: 0.32740,Valid loss: 0.67004, time : 10.474714994430542 lr : 0.10317013030157676\n",
      "epoch : 226 [21/23] Train loss: 0.31870,Valid loss: 0.69956, time : 10.761234521865845 lr : 0.10317013030157676\n",
      "epoch : 226 [22/23] Train loss: 0.32049,Valid loss: 0.68002, time : 9.658372402191162 lr : 0.10317013030157676\n",
      "epoch : 227 [0/23] Train loss: 0.32600,Valid loss: 0.69396, time : 10.165580749511719 lr : 0.10213842899856099\n",
      "epoch : 227 [1/23] Train loss: 0.32540,Valid loss: 0.63497, time : 10.15580940246582 lr : 0.10213842899856099\n",
      "epoch : 227 [2/23] Train loss: 0.32473,Valid loss: 0.63342, time : 10.44489049911499 lr : 0.10213842899856099\n",
      "epoch : 227 [3/23] Train loss: 0.31243,Valid loss: 0.66837, time : 10.416746139526367 lr : 0.10213842899856099\n",
      "epoch : 227 [4/23] Train loss: 0.33034,Valid loss: 0.66261, time : 10.298534631729126 lr : 0.10213842899856099\n",
      "epoch : 227 [5/23] Train loss: 0.31940,Valid loss: 0.69556, time : 10.062151432037354 lr : 0.10213842899856099\n",
      "epoch : 227 [6/23] Train loss: 0.33099,Valid loss: 0.67316, time : 10.30221962928772 lr : 0.10213842899856099\n",
      "epoch : 227 [7/23] Train loss: 0.32101,Valid loss: 0.67226, time : 10.347151517868042 lr : 0.10213842899856099\n",
      "epoch : 227 [8/23] Train loss: 0.31710,Valid loss: 0.65798, time : 10.423909425735474 lr : 0.10213842899856099\n",
      "epoch : 227 [9/23] Train loss: 0.31899,Valid loss: 0.65135, time : 10.253244161605835 lr : 0.10213842899856099\n",
      "epoch : 227 [10/23] Train loss: 0.32875,Valid loss: 0.64161, time : 10.212798118591309 lr : 0.10213842899856099\n",
      "epoch : 227 [11/23] Train loss: 0.31834,Valid loss: 0.63623, time : 10.45655083656311 lr : 0.10213842899856099\n",
      "epoch : 227 [12/23] Train loss: 0.32876,Valid loss: 0.69179, time : 10.400423049926758 lr : 0.10213842899856099\n",
      "epoch : 227 [13/23] Train loss: 0.31731,Valid loss: 0.66363, time : 10.164372444152832 lr : 0.10213842899856099\n",
      "epoch : 227 [14/23] Train loss: 0.32566,Valid loss: 0.64521, time : 10.281768560409546 lr : 0.10213842899856099\n",
      "epoch : 227 [15/23] Train loss: 0.33256,Valid loss: 0.67593, time : 10.468534708023071 lr : 0.10213842899856099\n",
      "epoch : 227 [16/23] Train loss: 0.32168,Valid loss: 0.64249, time : 10.292608737945557 lr : 0.10213842899856099\n",
      "epoch : 227 [17/23] Train loss: 0.32645,Valid loss: 0.63038, time : 10.151077032089233 lr : 0.10213842899856099\n",
      "epoch : 227 [18/23] Train loss: 0.32265,Valid loss: 0.68600, time : 10.116590976715088 lr : 0.10213842899856099\n",
      "epoch : 227 [19/23] Train loss: 0.32389,Valid loss: 0.68158, time : 10.508295774459839 lr : 0.10213842899856099\n",
      "epoch : 227 [20/23] Train loss: 0.32744,Valid loss: 0.63495, time : 10.563903093338013 lr : 0.10213842899856099\n",
      "epoch : 227 [21/23] Train loss: 0.32390,Valid loss: 0.63385, time : 10.666356563568115 lr : 0.10213842899856099\n",
      "epoch : 227 [22/23] Train loss: 0.33003,Valid loss: 0.63041, time : 9.460912942886353 lr : 0.10213842899856099\n",
      "epoch : 228 [0/23] Train loss: 0.31236,Valid loss: 0.67399, time : 10.647408723831177 lr : 0.10111704470857538\n",
      "epoch : 228 [1/23] Train loss: 0.31887,Valid loss: 0.68930, time : 10.277998208999634 lr : 0.10111704470857538\n",
      "epoch : 228 [2/23] Train loss: 0.32983,Valid loss: 0.65095, time : 10.056641340255737 lr : 0.10111704470857538\n",
      "epoch : 228 [3/23] Train loss: 0.32424,Valid loss: 0.63579, time : 10.30077314376831 lr : 0.10111704470857538\n",
      "epoch : 228 [4/23] Train loss: 0.32629,Valid loss: 0.67600, time : 10.46690034866333 lr : 0.10111704470857538\n",
      "epoch : 228 [5/23] Train loss: 0.32451,Valid loss: 0.63919, time : 10.538519620895386 lr : 0.10111704470857538\n",
      "epoch : 228 [6/23] Train loss: 0.32705,Valid loss: 0.72321, time : 10.135754585266113 lr : 0.10111704470857538\n",
      "epoch : 228 [7/23] Train loss: 0.32636,Valid loss: 0.62335, time : 10.448387622833252 lr : 0.10111704470857538\n",
      "epoch : 228 [8/23] Train loss: 0.33842,Valid loss: 0.73712, time : 9.604088068008423 lr : 0.10111704470857538\n",
      "epoch : 228 [9/23] Train loss: 0.31925,Valid loss: 0.60492, time : 10.11722731590271 lr : 0.10111704470857538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 228 [10/23] Train loss: 0.31975,Valid loss: 0.69281, time : 9.497523307800293 lr : 0.10111704470857538\n",
      "epoch : 228 [11/23] Train loss: 0.33759,Valid loss: 0.58584, time : 10.168634176254272 lr : 0.10111704470857538\n",
      "epoch : 228 [12/23] Train loss: 0.33712,Valid loss: 0.67175, time : 10.135812520980835 lr : 0.10111704470857538\n",
      "epoch : 228 [13/23] Train loss: 0.33150,Valid loss: 0.60253, time : 10.239715576171875 lr : 0.10111704470857538\n",
      "epoch : 228 [14/23] Train loss: 0.31962,Valid loss: 0.64308, time : 10.020817756652832 lr : 0.10111704470857538\n",
      "epoch : 228 [15/23] Train loss: 0.32785,Valid loss: 0.63912, time : 10.37723422050476 lr : 0.10111704470857538\n",
      "epoch : 228 [16/23] Train loss: 0.32287,Valid loss: 0.67214, time : 10.005056381225586 lr : 0.10111704470857538\n",
      "epoch : 228 [17/23] Train loss: 0.33064,Valid loss: 0.65359, time : 10.137171983718872 lr : 0.10111704470857538\n",
      "epoch : 228 [18/23] Train loss: 0.31319,Valid loss: 0.67312, time : 9.808954238891602 lr : 0.10111704470857538\n",
      "epoch : 228 [19/23] Train loss: 0.31884,Valid loss: 0.73884, time : 10.240957736968994 lr : 0.10111704470857538\n",
      "epoch : 228 [20/23] Train loss: 0.32169,Valid loss: 0.67152, time : 10.44164252281189 lr : 0.10111704470857538\n",
      "epoch : 228 [21/23] Train loss: 0.32489,Valid loss: 0.77181, time : 9.701500415802002 lr : 0.10111704470857538\n",
      "epoch : 228 [22/23] Train loss: 0.32291,Valid loss: 0.68229, time : 9.580155849456787 lr : 0.10111704470857538\n",
      "epoch : 229 [0/23] Train loss: 0.32390,Valid loss: 0.66293, time : 10.393003463745117 lr : 0.10010587426148963\n",
      "epoch : 229 [1/23] Train loss: 0.32636,Valid loss: 0.67056, time : 10.6407470703125 lr : 0.10010587426148963\n",
      "epoch : 229 [2/23] Train loss: 0.31617,Valid loss: 0.77175, time : 10.807143449783325 lr : 0.10010587426148963\n",
      "epoch : 229 [3/23] Train loss: 0.32341,Valid loss: 0.67372, time : 10.381418228149414 lr : 0.10010587426148963\n",
      "epoch : 229 [4/23] Train loss: 0.31734,Valid loss: 0.63214, time : 10.182699203491211 lr : 0.10010587426148963\n",
      "epoch : 229 [5/23] Train loss: 0.32316,Valid loss: 0.65978, time : 10.074059963226318 lr : 0.10010587426148963\n",
      "epoch : 229 [6/23] Train loss: 0.32239,Valid loss: 0.70315, time : 10.650499820709229 lr : 0.10010587426148963\n",
      "epoch : 229 [7/23] Train loss: 0.33373,Valid loss: 0.62829, time : 10.641080379486084 lr : 0.10010587426148963\n",
      "epoch : 229 [8/23] Train loss: 0.32023,Valid loss: 0.65643, time : 10.865328788757324 lr : 0.10010587426148963\n",
      "epoch : 229 [9/23] Train loss: 0.32457,Valid loss: 0.62581, time : 10.636102199554443 lr : 0.10010587426148963\n",
      "epoch : 229 [10/23] Train loss: 0.32681,Valid loss: 0.65843, time : 10.221481800079346 lr : 0.10010587426148963\n",
      "epoch : 229 [11/23] Train loss: 0.33609,Valid loss: 0.67313, time : 10.06598687171936 lr : 0.10010587426148963\n",
      "epoch : 229 [12/23] Train loss: 0.32620,Valid loss: 0.62420, time : 10.179583311080933 lr : 0.10010587426148963\n",
      "epoch : 229 [13/23] Train loss: 0.33511,Valid loss: 0.67991, time : 10.02382779121399 lr : 0.10010587426148963\n",
      "epoch : 229 [14/23] Train loss: 0.32625,Valid loss: 0.65145, time : 10.997058153152466 lr : 0.10010587426148963\n",
      "epoch : 229 [15/23] Train loss: 0.31842,Valid loss: 0.67925, time : 10.664859533309937 lr : 0.10010587426148963\n",
      "epoch : 229 [16/23] Train loss: 0.32964,Valid loss: 0.66931, time : 10.595992803573608 lr : 0.10010587426148963\n",
      "epoch : 229 [17/23] Train loss: 0.32728,Valid loss: 0.70247, time : 10.551158905029297 lr : 0.10010587426148963\n",
      "epoch : 229 [18/23] Train loss: 0.32843,Valid loss: 0.67062, time : 10.584323406219482 lr : 0.10010587426148963\n",
      "epoch : 229 [19/23] Train loss: 0.32582,Valid loss: 0.60875, time : 10.532683610916138 lr : 0.10010587426148963\n",
      "epoch : 229 [20/23] Train loss: 0.32507,Valid loss: 0.70717, time : 10.33733606338501 lr : 0.10010587426148963\n",
      "epoch : 229 [21/23] Train loss: 0.32520,Valid loss: 0.64103, time : 10.211503267288208 lr : 0.10010587426148963\n",
      "epoch : 229 [22/23] Train loss: 0.31914,Valid loss: 0.65018, time : 9.627514600753784 lr : 0.10010587426148963\n",
      "epoch : 230 [0/23] Train loss: 0.32067,Valid loss: 0.65121, time : 10.516937971115112 lr : 0.09910481551887473\n",
      "epoch : 230 [1/23] Train loss: 0.33380,Valid loss: 0.63607, time : 10.416881799697876 lr : 0.09910481551887473\n",
      "epoch : 230 [2/23] Train loss: 0.31760,Valid loss: 0.66594, time : 10.582871198654175 lr : 0.09910481551887473\n",
      "epoch : 230 [3/23] Train loss: 0.32233,Valid loss: 0.66024, time : 10.426483631134033 lr : 0.09910481551887473\n",
      "epoch : 230 [4/23] Train loss: 0.33205,Valid loss: 0.72876, time : 10.739102602005005 lr : 0.09910481551887473\n",
      "epoch : 230 [5/23] Train loss: 0.32385,Valid loss: 0.65405, time : 10.567025423049927 lr : 0.09910481551887473\n",
      "epoch : 230 [6/23] Train loss: 0.32661,Valid loss: 0.68088, time : 10.021872282028198 lr : 0.09910481551887473\n",
      "epoch : 230 [7/23] Train loss: 0.33404,Valid loss: 0.58273, time : 10.235054731369019 lr : 0.09910481551887473\n",
      "epoch : 230 [8/23] Train loss: 0.32343,Valid loss: 0.66954, time : 9.813566446304321 lr : 0.09910481551887473\n",
      "epoch : 230 [9/23] Train loss: 0.32288,Valid loss: 0.59876, time : 10.43493127822876 lr : 0.09910481551887473\n",
      "epoch : 230 [10/23] Train loss: 0.32757,Valid loss: 0.67124, time : 10.005460977554321 lr : 0.09910481551887473\n",
      "epoch : 230 [11/23] Train loss: 0.32325,Valid loss: 0.65370, time : 10.218832015991211 lr : 0.09910481551887473\n",
      "epoch : 230 [12/23] Train loss: 0.32370,Valid loss: 0.67725, time : 10.068654775619507 lr : 0.09910481551887473\n",
      "epoch : 230 [13/23] Train loss: 0.31122,Valid loss: 0.60585, time : 10.279530048370361 lr : 0.09910481551887473\n",
      "epoch : 230 [14/23] Train loss: 0.32541,Valid loss: 0.69553, time : 10.271406173706055 lr : 0.09910481551887473\n",
      "epoch : 230 [15/23] Train loss: 0.31636,Valid loss: 0.62765, time : 9.891898155212402 lr : 0.09910481551887473\n",
      "epoch : 230 [16/23] Train loss: 0.31701,Valid loss: 0.63174, time : 10.738034725189209 lr : 0.09910481551887473\n",
      "epoch : 230 [17/23] Train loss: 0.32952,Valid loss: 0.69267, time : 10.045352458953857 lr : 0.09910481551887473\n",
      "epoch : 230 [18/23] Train loss: 0.32419,Valid loss: 0.65834, time : 10.303312540054321 lr : 0.09910481551887473\n",
      "epoch : 230 [19/23] Train loss: 0.32471,Valid loss: 0.65092, time : 10.309423446655273 lr : 0.09910481551887473\n",
      "epoch : 230 [20/23] Train loss: 0.32593,Valid loss: 0.60589, time : 10.34757399559021 lr : 0.09910481551887473\n",
      "epoch : 230 [21/23] Train loss: 0.31629,Valid loss: 0.62940, time : 10.299715042114258 lr : 0.09910481551887473\n",
      "epoch : 230 [22/23] Train loss: 0.33750,Valid loss: 0.65681, time : 9.623926639556885 lr : 0.09910481551887473\n",
      "epoch : 231 [0/23] Train loss: 0.32103,Valid loss: 0.65444, time : 10.263958930969238 lr : 0.09811376736368599\n",
      "epoch : 231 [1/23] Train loss: 0.32851,Valid loss: 0.64723, time : 9.835456132888794 lr : 0.09811376736368599\n",
      "epoch : 231 [2/23] Train loss: 0.32003,Valid loss: 0.66485, time : 9.824866533279419 lr : 0.09811376736368599\n",
      "epoch : 231 [3/23] Train loss: 0.32172,Valid loss: 0.66463, time : 10.45576286315918 lr : 0.09811376736368599\n",
      "epoch : 231 [4/23] Train loss: 0.32245,Valid loss: 0.65957, time : 10.57585883140564 lr : 0.09811376736368599\n",
      "epoch : 231 [5/23] Train loss: 0.31700,Valid loss: 0.63122, time : 10.327642679214478 lr : 0.09811376736368599\n",
      "epoch : 231 [6/23] Train loss: 0.32739,Valid loss: 0.62386, time : 10.419668197631836 lr : 0.09811376736368599\n",
      "epoch : 231 [7/23] Train loss: 0.32763,Valid loss: 0.67065, time : 10.177994966506958 lr : 0.09811376736368599\n",
      "epoch : 231 [8/23] Train loss: 0.31012,Valid loss: 0.66679, time : 10.216707706451416 lr : 0.09811376736368599\n",
      "epoch : 231 [9/23] Train loss: 0.32264,Valid loss: 0.63566, time : 9.947519540786743 lr : 0.09811376736368599\n",
      "epoch : 231 [10/23] Train loss: 0.32247,Valid loss: 0.68719, time : 10.235713005065918 lr : 0.09811376736368599\n",
      "epoch : 231 [11/23] Train loss: 0.31500,Valid loss: 0.60309, time : 10.03046464920044 lr : 0.09811376736368599\n",
      "epoch : 231 [12/23] Train loss: 0.31540,Valid loss: 0.67348, time : 10.057800769805908 lr : 0.09811376736368599\n",
      "epoch : 231 [13/23] Train loss: 0.31673,Valid loss: 0.59570, time : 10.142443418502808 lr : 0.09811376736368599\n",
      "epoch : 231 [14/23] Train loss: 0.32501,Valid loss: 0.70062, time : 10.274517059326172 lr : 0.09811376736368599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 231 [15/23] Train loss: 0.33137,Valid loss: 0.64419, time : 10.200363159179688 lr : 0.09811376736368599\n",
      "epoch : 231 [16/23] Train loss: 0.32494,Valid loss: 0.69017, time : 10.151366949081421 lr : 0.09811376736368599\n",
      "epoch : 231 [17/23] Train loss: 0.31987,Valid loss: 0.66604, time : 10.121946573257446 lr : 0.09811376736368599\n",
      "epoch : 231 [18/23] Train loss: 0.32169,Valid loss: 0.63290, time : 10.198494911193848 lr : 0.09811376736368599\n",
      "epoch : 231 [19/23] Train loss: 0.32105,Valid loss: 0.69187, time : 10.395252704620361 lr : 0.09811376736368599\n",
      "epoch : 231 [20/23] Train loss: 0.31221,Valid loss: 0.60578, time : 10.173397779464722 lr : 0.09811376736368599\n",
      "epoch : 231 [21/23] Train loss: 0.31919,Valid loss: 0.68203, time : 10.220113277435303 lr : 0.09811376736368599\n",
      "epoch : 231 [22/23] Train loss: 0.31895,Valid loss: 0.60107, time : 9.63490629196167 lr : 0.09811376736368599\n",
      "epoch : 232 [0/23] Train loss: 0.32147,Valid loss: 0.64375, time : 10.63764476776123 lr : 0.09713262969004913\n",
      "epoch : 232 [1/23] Train loss: 0.32353,Valid loss: 0.65524, time : 10.480180740356445 lr : 0.09713262969004913\n",
      "epoch : 232 [2/23] Train loss: 0.31420,Valid loss: 0.71678, time : 10.455317258834839 lr : 0.09713262969004913\n",
      "epoch : 232 [3/23] Train loss: 0.30598,Valid loss: 0.66754, time : 10.62040901184082 lr : 0.09713262969004913\n",
      "epoch : 232 [4/23] Train loss: 0.32433,Valid loss: 0.61568, time : 10.58721375465393 lr : 0.09713262969004913\n",
      "epoch : 232 [5/23] Train loss: 0.32492,Valid loss: 0.61233, time : 9.900083303451538 lr : 0.09713262969004913\n",
      "epoch : 232 [6/23] Train loss: 0.31769,Valid loss: 0.64001, time : 10.534477233886719 lr : 0.09713262969004913\n",
      "epoch : 232 [7/23] Train loss: 0.32224,Valid loss: 0.62097, time : 10.139444351196289 lr : 0.09713262969004913\n",
      "epoch : 232 [8/23] Train loss: 0.32242,Valid loss: 0.68741, time : 10.641896724700928 lr : 0.09713262969004913\n",
      "epoch : 232 [9/23] Train loss: 0.32978,Valid loss: 0.65087, time : 10.279850244522095 lr : 0.09713262969004913\n",
      "epoch : 232 [10/23] Train loss: 0.32047,Valid loss: 0.68579, time : 9.911971807479858 lr : 0.09713262969004913\n",
      "epoch : 232 [11/23] Train loss: 0.32195,Valid loss: 0.64935, time : 10.317776918411255 lr : 0.09713262969004913\n",
      "epoch : 232 [12/23] Train loss: 0.32571,Valid loss: 0.63726, time : 9.955549955368042 lr : 0.09713262969004913\n",
      "epoch : 232 [13/23] Train loss: 0.32459,Valid loss: 0.61553, time : 9.929355382919312 lr : 0.09713262969004913\n",
      "epoch : 232 [14/23] Train loss: 0.31697,Valid loss: 0.62356, time : 10.275746583938599 lr : 0.09713262969004913\n",
      "epoch : 232 [15/23] Train loss: 0.31687,Valid loss: 0.70846, time : 10.676745414733887 lr : 0.09713262969004913\n",
      "epoch : 232 [16/23] Train loss: 0.32469,Valid loss: 0.63591, time : 10.47762942314148 lr : 0.09713262969004913\n",
      "epoch : 232 [17/23] Train loss: 0.31906,Valid loss: 0.70396, time : 10.383140802383423 lr : 0.09713262969004913\n",
      "epoch : 232 [18/23] Train loss: 0.32744,Valid loss: 0.63649, time : 10.228675603866577 lr : 0.09713262969004913\n",
      "epoch : 232 [19/23] Train loss: 0.31896,Valid loss: 0.68441, time : 9.809682846069336 lr : 0.09713262969004913\n",
      "epoch : 232 [20/23] Train loss: 0.30832,Valid loss: 0.69739, time : 10.514544486999512 lr : 0.09713262969004913\n",
      "epoch : 232 [21/23] Train loss: 0.31391,Valid loss: 0.69030, time : 9.907931804656982 lr : 0.09713262969004913\n",
      "epoch : 232 [22/23] Train loss: 0.32564,Valid loss: 0.62863, time : 9.815072298049927 lr : 0.09713262969004913\n",
      "epoch : 233 [0/23] Train loss: 0.31781,Valid loss: 0.70358, time : 10.63155484199524 lr : 0.09616130339314863\n",
      "epoch : 233 [1/23] Train loss: 0.32323,Valid loss: 0.62186, time : 10.488561391830444 lr : 0.09616130339314863\n",
      "epoch : 233 [2/23] Train loss: 0.31226,Valid loss: 0.70394, time : 10.707847356796265 lr : 0.09616130339314863\n",
      "epoch : 233 [3/23] Train loss: 0.31791,Valid loss: 0.61375, time : 10.661609172821045 lr : 0.09616130339314863\n",
      "epoch : 233 [4/23] Train loss: 0.31912,Valid loss: 0.65791, time : 10.367653608322144 lr : 0.09616130339314863\n",
      "epoch : 233 [5/23] Train loss: 0.31146,Valid loss: 0.67149, time : 10.451499462127686 lr : 0.09616130339314863\n",
      "epoch : 233 [6/23] Train loss: 0.31882,Valid loss: 0.62846, time : 10.530242919921875 lr : 0.09616130339314863\n",
      "epoch : 233 [7/23] Train loss: 0.32093,Valid loss: 0.71384, time : 10.477114200592041 lr : 0.09616130339314863\n",
      "epoch : 233 [8/23] Train loss: 0.31063,Valid loss: 0.63824, time : 10.560832738876343 lr : 0.09616130339314863\n",
      "epoch : 233 [9/23] Train loss: 0.31981,Valid loss: 0.68652, time : 10.800983428955078 lr : 0.09616130339314863\n",
      "epoch : 233 [10/23] Train loss: 0.32378,Valid loss: 0.71020, time : 11.107154846191406 lr : 0.09616130339314863\n",
      "epoch : 233 [11/23] Train loss: 0.31189,Valid loss: 0.64747, time : 10.752350807189941 lr : 0.09616130339314863\n",
      "epoch : 233 [12/23] Train loss: 0.31719,Valid loss: 0.61898, time : 10.53772759437561 lr : 0.09616130339314863\n",
      "epoch : 233 [13/23] Train loss: 0.32132,Valid loss: 0.68296, time : 10.623733520507812 lr : 0.09616130339314863\n",
      "epoch : 233 [14/23] Train loss: 0.31156,Valid loss: 0.61933, time : 10.711162328720093 lr : 0.09616130339314863\n",
      "epoch : 233 [15/23] Train loss: 0.31321,Valid loss: 0.70846, time : 10.496389389038086 lr : 0.09616130339314863\n",
      "epoch : 233 [16/23] Train loss: 0.31297,Valid loss: 0.70227, time : 10.568944692611694 lr : 0.09616130339314863\n",
      "epoch : 233 [17/23] Train loss: 0.31576,Valid loss: 0.68257, time : 10.577792406082153 lr : 0.09616130339314863\n",
      "epoch : 233 [18/23] Train loss: 0.31401,Valid loss: 0.70830, time : 10.621445417404175 lr : 0.09616130339314863\n",
      "epoch : 233 [19/23] Train loss: 0.32277,Valid loss: 0.70314, time : 10.887064695358276 lr : 0.09616130339314863\n",
      "epoch : 233 [20/23] Train loss: 0.31446,Valid loss: 0.65697, time : 10.78837513923645 lr : 0.09616130339314863\n",
      "epoch : 233 [21/23] Train loss: 0.31961,Valid loss: 0.65958, time : 10.713921546936035 lr : 0.09616130339314863\n",
      "epoch : 233 [22/23] Train loss: 0.31365,Valid loss: 0.61535, time : 9.768604755401611 lr : 0.09616130339314863\n",
      "epoch : 234 [0/23] Train loss: 0.31570,Valid loss: 0.67100, time : 10.608975172042847 lr : 0.09519969035921715\n",
      "epoch : 234 [1/23] Train loss: 0.32885,Valid loss: 0.68014, time : 10.530499458312988 lr : 0.09519969035921715\n",
      "epoch : 234 [2/23] Train loss: 0.31299,Valid loss: 0.59268, time : 10.297085762023926 lr : 0.09519969035921715\n",
      "epoch : 234 [3/23] Train loss: 0.32952,Valid loss: 0.66337, time : 10.360075235366821 lr : 0.09519969035921715\n",
      "epoch : 234 [4/23] Train loss: 0.31009,Valid loss: 0.62212, time : 10.316827774047852 lr : 0.09519969035921715\n",
      "epoch : 234 [5/23] Train loss: 0.31975,Valid loss: 0.62856, time : 10.367352962493896 lr : 0.09519969035921715\n",
      "epoch : 234 [6/23] Train loss: 0.31365,Valid loss: 0.66805, time : 10.207389831542969 lr : 0.09519969035921715\n",
      "epoch : 234 [7/23] Train loss: 0.30153,Valid loss: 0.66536, time : 10.347737073898315 lr : 0.09519969035921715\n",
      "epoch : 234 [8/23] Train loss: 0.32207,Valid loss: 0.66209, time : 11.044289827346802 lr : 0.09519969035921715\n",
      "epoch : 234 [9/23] Train loss: 0.31819,Valid loss: 0.62783, time : 10.389140367507935 lr : 0.09519969035921715\n",
      "epoch : 234 [10/23] Train loss: 0.33141,Valid loss: 0.67834, time : 10.541579484939575 lr : 0.09519969035921715\n",
      "epoch : 234 [11/23] Train loss: 0.32061,Valid loss: 0.62795, time : 10.133825302124023 lr : 0.09519969035921715\n",
      "epoch : 234 [12/23] Train loss: 0.32243,Valid loss: 0.63752, time : 10.313030242919922 lr : 0.09519969035921715\n",
      "epoch : 234 [13/23] Train loss: 0.31089,Valid loss: 0.64757, time : 9.833645582199097 lr : 0.09519969035921715\n",
      "epoch : 234 [14/23] Train loss: 0.31364,Valid loss: 0.68672, time : 10.263538837432861 lr : 0.09519969035921715\n",
      "epoch : 234 [15/23] Train loss: 0.30497,Valid loss: 0.65681, time : 10.191641330718994 lr : 0.09519969035921715\n",
      "epoch : 234 [16/23] Train loss: 0.31726,Valid loss: 0.70016, time : 10.674554824829102 lr : 0.09519969035921715\n",
      "epoch : 234 [17/23] Train loss: 0.31136,Valid loss: 0.60135, time : 10.40081524848938 lr : 0.09519969035921715\n",
      "epoch : 234 [18/23] Train loss: 0.32185,Valid loss: 0.66382, time : 10.67034387588501 lr : 0.09519969035921715\n",
      "epoch : 234 [19/23] Train loss: 0.31917,Valid loss: 0.57886, time : 10.743818044662476 lr : 0.09519969035921715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 234 [20/23] Train loss: 0.32725,Valid loss: 0.67448, time : 10.28244400024414 lr : 0.09519969035921715\n",
      "epoch : 234 [21/23] Train loss: 0.32139,Valid loss: 0.66600, time : 10.194291114807129 lr : 0.09519969035921715\n",
      "epoch : 234 [22/23] Train loss: 0.31008,Valid loss: 0.60969, time : 9.556376457214355 lr : 0.09519969035921715\n",
      "epoch : 235 [0/23] Train loss: 0.31457,Valid loss: 0.66677, time : 10.050629377365112 lr : 0.09424769345562498\n",
      "epoch : 235 [1/23] Train loss: 0.31052,Valid loss: 0.61817, time : 9.83250117301941 lr : 0.09424769345562498\n",
      "epoch : 235 [2/23] Train loss: 0.32014,Valid loss: 0.66804, time : 9.886990547180176 lr : 0.09424769345562498\n",
      "epoch : 235 [3/23] Train loss: 0.30954,Valid loss: 0.66301, time : 9.965056896209717 lr : 0.09424769345562498\n",
      "epoch : 235 [4/23] Train loss: 0.33132,Valid loss: 0.67180, time : 9.582244634628296 lr : 0.09424769345562498\n",
      "epoch : 235 [5/23] Train loss: 0.32134,Valid loss: 0.68630, time : 9.922916412353516 lr : 0.09424769345562498\n",
      "epoch : 235 [6/23] Train loss: 0.32138,Valid loss: 0.63054, time : 9.666748523712158 lr : 0.09424769345562498\n",
      "epoch : 235 [7/23] Train loss: 0.32103,Valid loss: 0.67664, time : 9.791586637496948 lr : 0.09424769345562498\n",
      "epoch : 235 [8/23] Train loss: 0.31587,Valid loss: 0.74177, time : 9.771784543991089 lr : 0.09424769345562498\n",
      "epoch : 235 [9/23] Train loss: 0.31017,Valid loss: 0.66566, time : 10.269137144088745 lr : 0.09424769345562498\n",
      "epoch : 235 [10/23] Train loss: 0.31420,Valid loss: 0.65955, time : 9.624773502349854 lr : 0.09424769345562498\n",
      "epoch : 235 [11/23] Train loss: 0.30782,Valid loss: 0.65745, time : 9.958347797393799 lr : 0.09424769345562498\n",
      "epoch : 235 [12/23] Train loss: 0.31001,Valid loss: 0.65256, time : 10.247620820999146 lr : 0.09424769345562498\n",
      "epoch : 235 [13/23] Train loss: 0.30698,Valid loss: 0.66335, time : 10.320664167404175 lr : 0.09424769345562498\n",
      "epoch : 235 [14/23] Train loss: 0.31223,Valid loss: 0.66019, time : 10.364417791366577 lr : 0.09424769345562498\n",
      "epoch : 235 [15/23] Train loss: 0.32458,Valid loss: 0.68208, time : 10.162630319595337 lr : 0.09424769345562498\n",
      "epoch : 235 [16/23] Train loss: 0.31675,Valid loss: 0.63965, time : 10.285667657852173 lr : 0.09424769345562498\n",
      "epoch : 235 [17/23] Train loss: 0.32183,Valid loss: 0.66248, time : 10.19336748123169 lr : 0.09424769345562498\n",
      "epoch : 235 [18/23] Train loss: 0.31903,Valid loss: 0.66689, time : 10.047436714172363 lr : 0.09424769345562498\n",
      "epoch : 235 [19/23] Train loss: 0.32082,Valid loss: 0.72360, time : 10.17630410194397 lr : 0.09424769345562498\n",
      "epoch : 235 [20/23] Train loss: 0.31831,Valid loss: 0.64938, time : 10.45520544052124 lr : 0.09424769345562498\n",
      "epoch : 235 [21/23] Train loss: 0.31251,Valid loss: 0.64907, time : 10.21842074394226 lr : 0.09424769345562498\n",
      "epoch : 235 [22/23] Train loss: 0.32391,Valid loss: 0.65125, time : 9.517937660217285 lr : 0.09424769345562498\n",
      "epoch : 236 [0/23] Train loss: 0.31216,Valid loss: 0.64921, time : 9.858215093612671 lr : 0.09330521652106873\n",
      "epoch : 236 [1/23] Train loss: 0.30956,Valid loss: 0.68451, time : 10.299142122268677 lr : 0.09330521652106873\n",
      "epoch : 236 [2/23] Train loss: 0.31155,Valid loss: 0.65131, time : 9.70594835281372 lr : 0.09330521652106873\n",
      "epoch : 236 [3/23] Train loss: 0.32092,Valid loss: 0.64715, time : 10.30147647857666 lr : 0.09330521652106873\n",
      "epoch : 236 [4/23] Train loss: 0.30805,Valid loss: 0.67923, time : 9.993582963943481 lr : 0.09330521652106873\n",
      "epoch : 236 [5/23] Train loss: 0.31993,Valid loss: 0.65678, time : 10.017400026321411 lr : 0.09330521652106873\n",
      "epoch : 236 [6/23] Train loss: 0.31435,Valid loss: 0.67696, time : 10.202651500701904 lr : 0.09330521652106873\n",
      "epoch : 236 [7/23] Train loss: 0.32901,Valid loss: 0.67344, time : 10.261529445648193 lr : 0.09330521652106873\n",
      "epoch : 236 [8/23] Train loss: 0.31332,Valid loss: 0.64671, time : 10.388913869857788 lr : 0.09330521652106873\n",
      "epoch : 236 [9/23] Train loss: 0.31594,Valid loss: 0.68769, time : 10.62354588508606 lr : 0.09330521652106873\n",
      "epoch : 236 [10/23] Train loss: 0.31512,Valid loss: 0.67896, time : 10.142471075057983 lr : 0.09330521652106873\n",
      "epoch : 236 [11/23] Train loss: 0.31661,Valid loss: 0.67880, time : 10.59146237373352 lr : 0.09330521652106873\n",
      "epoch : 236 [12/23] Train loss: 0.32361,Valid loss: 0.67709, time : 10.181665658950806 lr : 0.09330521652106873\n",
      "epoch : 236 [13/23] Train loss: 0.32442,Valid loss: 0.68645, time : 10.295841693878174 lr : 0.09330521652106873\n",
      "epoch : 236 [14/23] Train loss: 0.32328,Valid loss: 0.67965, time : 10.509905099868774 lr : 0.09330521652106873\n",
      "epoch : 236 [15/23] Train loss: 0.31242,Valid loss: 0.63613, time : 10.446044921875 lr : 0.09330521652106873\n",
      "epoch : 236 [16/23] Train loss: 0.31015,Valid loss: 0.76016, time : 9.963356018066406 lr : 0.09330521652106873\n",
      "epoch : 236 [17/23] Train loss: 0.30712,Valid loss: 0.65543, time : 10.364691972732544 lr : 0.09330521652106873\n",
      "epoch : 236 [18/23] Train loss: 0.31485,Valid loss: 0.66297, time : 9.909808874130249 lr : 0.09330521652106873\n",
      "epoch : 236 [19/23] Train loss: 0.31163,Valid loss: 0.65871, time : 10.330627918243408 lr : 0.09330521652106873\n",
      "epoch : 236 [20/23] Train loss: 0.31747,Valid loss: 0.66339, time : 10.5325927734375 lr : 0.09330521652106873\n",
      "epoch : 236 [21/23] Train loss: 0.32677,Valid loss: 0.63844, time : 10.19739556312561 lr : 0.09330521652106873\n",
      "epoch : 236 [22/23] Train loss: 0.31534,Valid loss: 0.66486, time : 9.644225597381592 lr : 0.09330521652106873\n",
      "epoch : 237 [0/23] Train loss: 0.30829,Valid loss: 0.66490, time : 10.681614637374878 lr : 0.09237216435585804\n",
      "epoch : 237 [1/23] Train loss: 0.31289,Valid loss: 0.73487, time : 10.07991623878479 lr : 0.09237216435585804\n",
      "epoch : 237 [2/23] Train loss: 0.31507,Valid loss: 0.65573, time : 10.698818683624268 lr : 0.09237216435585804\n",
      "epoch : 237 [3/23] Train loss: 0.32164,Valid loss: 0.68701, time : 10.161282062530518 lr : 0.09237216435585804\n",
      "epoch : 237 [4/23] Train loss: 0.31669,Valid loss: 0.71229, time : 10.552982807159424 lr : 0.09237216435585804\n",
      "epoch : 237 [5/23] Train loss: 0.31790,Valid loss: 0.59305, time : 11.280061960220337 lr : 0.09237216435585804\n",
      "epoch : 237 [6/23] Train loss: 0.31230,Valid loss: 0.68166, time : 10.392218351364136 lr : 0.09237216435585804\n",
      "epoch : 237 [7/23] Train loss: 0.31410,Valid loss: 0.69927, time : 10.240747451782227 lr : 0.09237216435585804\n",
      "epoch : 237 [8/23] Train loss: 0.30988,Valid loss: 0.71930, time : 10.65644097328186 lr : 0.09237216435585804\n",
      "epoch : 237 [9/23] Train loss: 0.31559,Valid loss: 0.68452, time : 10.366590738296509 lr : 0.09237216435585804\n",
      "epoch : 237 [10/23] Train loss: 0.31579,Valid loss: 0.65268, time : 10.268823862075806 lr : 0.09237216435585804\n",
      "epoch : 237 [11/23] Train loss: 0.30178,Valid loss: 0.70372, time : 10.349504232406616 lr : 0.09237216435585804\n",
      "epoch : 237 [12/23] Train loss: 0.31421,Valid loss: 0.58357, time : 10.58017611503601 lr : 0.09237216435585804\n",
      "epoch : 237 [13/23] Train loss: 0.30987,Valid loss: 0.66868, time : 10.544652938842773 lr : 0.09237216435585804\n",
      "epoch : 237 [14/23] Train loss: 0.31617,Valid loss: 0.65941, time : 10.249930620193481 lr : 0.09237216435585804\n",
      "epoch : 237 [15/23] Train loss: 0.32881,Valid loss: 0.66504, time : 10.107130527496338 lr : 0.09237216435585804\n",
      "epoch : 237 [16/23] Train loss: 0.31789,Valid loss: 0.57834, time : 10.67832350730896 lr : 0.09237216435585804\n",
      "epoch : 237 [17/23] Train loss: 0.31804,Valid loss: 0.67473, time : 10.270780563354492 lr : 0.09237216435585804\n",
      "epoch : 237 [18/23] Train loss: 0.31700,Valid loss: 0.66704, time : 10.255185842514038 lr : 0.09237216435585804\n",
      "epoch : 237 [19/23] Train loss: 0.30419,Valid loss: 0.66497, time : 10.045350313186646 lr : 0.09237216435585804\n",
      "epoch : 237 [20/23] Train loss: 0.32189,Valid loss: 0.64082, time : 10.209639310836792 lr : 0.09237216435585804\n",
      "epoch : 237 [21/23] Train loss: 0.30848,Valid loss: 0.65299, time : 9.844521522521973 lr : 0.09237216435585804\n",
      "epoch : 237 [22/23] Train loss: 0.31528,Valid loss: 0.67301, time : 9.597180604934692 lr : 0.09237216435585804\n",
      "epoch : 238 [0/23] Train loss: 0.31183,Valid loss: 0.74472, time : 10.626177549362183 lr : 0.09144844271229946\n",
      "epoch : 238 [1/23] Train loss: 0.30411,Valid loss: 0.65542, time : 11.115596771240234 lr : 0.09144844271229946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 238 [2/23] Train loss: 0.31520,Valid loss: 0.67186, time : 10.865370750427246 lr : 0.09144844271229946\n",
      "epoch : 238 [3/23] Train loss: 0.31339,Valid loss: 0.59761, time : 10.564958333969116 lr : 0.09144844271229946\n",
      "epoch : 238 [4/23] Train loss: 0.31158,Valid loss: 0.64815, time : 10.578856468200684 lr : 0.09144844271229946\n",
      "epoch : 238 [5/23] Train loss: 0.30421,Valid loss: 0.66703, time : 10.93789029121399 lr : 0.09144844271229946\n",
      "epoch : 238 [6/23] Train loss: 0.30560,Valid loss: 0.67608, time : 10.913760900497437 lr : 0.09144844271229946\n",
      "epoch : 238 [7/23] Train loss: 0.30619,Valid loss: 0.64328, time : 10.88705825805664 lr : 0.09144844271229946\n",
      "epoch : 238 [8/23] Train loss: 0.30766,Valid loss: 0.72709, time : 10.202300310134888 lr : 0.09144844271229946\n",
      "epoch : 238 [9/23] Train loss: 0.30056,Valid loss: 0.64982, time : 10.279485702514648 lr : 0.09144844271229946\n",
      "epoch : 238 [10/23] Train loss: 0.31339,Valid loss: 0.69539, time : 10.43004322052002 lr : 0.09144844271229946\n",
      "epoch : 238 [11/23] Train loss: 0.31906,Valid loss: 0.62837, time : 10.471997022628784 lr : 0.09144844271229946\n",
      "epoch : 238 [12/23] Train loss: 0.31883,Valid loss: 0.65818, time : 10.434383869171143 lr : 0.09144844271229946\n",
      "epoch : 238 [13/23] Train loss: 0.30945,Valid loss: 0.64658, time : 10.503751754760742 lr : 0.09144844271229946\n",
      "epoch : 238 [14/23] Train loss: 0.31977,Valid loss: 0.72299, time : 10.450281858444214 lr : 0.09144844271229946\n",
      "epoch : 238 [15/23] Train loss: 0.32499,Valid loss: 0.61931, time : 10.312162399291992 lr : 0.09144844271229946\n",
      "epoch : 238 [16/23] Train loss: 0.31072,Valid loss: 0.67628, time : 10.082045555114746 lr : 0.09144844271229946\n",
      "epoch : 238 [17/23] Train loss: 0.31717,Valid loss: 0.66946, time : 10.026091575622559 lr : 0.09144844271229946\n",
      "epoch : 238 [18/23] Train loss: 0.32813,Valid loss: 0.72735, time : 10.426954984664917 lr : 0.09144844271229946\n",
      "epoch : 238 [19/23] Train loss: 0.31138,Valid loss: 0.75495, time : 10.619168758392334 lr : 0.09144844271229946\n",
      "epoch : 238 [20/23] Train loss: 0.32309,Valid loss: 0.69962, time : 10.450255870819092 lr : 0.09144844271229946\n",
      "epoch : 238 [21/23] Train loss: 0.31253,Valid loss: 0.65457, time : 10.317899465560913 lr : 0.09144844271229946\n",
      "epoch : 238 [22/23] Train loss: 0.30968,Valid loss: 0.69869, time : 9.537127017974854 lr : 0.09144844271229946\n",
      "epoch : 239 [0/23] Train loss: 0.31859,Valid loss: 0.68326, time : 10.335923194885254 lr : 0.09053395828517646\n",
      "epoch : 239 [1/23] Train loss: 0.30924,Valid loss: 0.65232, time : 10.281524419784546 lr : 0.09053395828517646\n",
      "epoch : 239 [2/23] Train loss: 0.31059,Valid loss: 0.65263, time : 10.421458959579468 lr : 0.09053395828517646\n",
      "epoch : 239 [3/23] Train loss: 0.30724,Valid loss: 0.69434, time : 10.386154174804688 lr : 0.09053395828517646\n",
      "epoch : 239 [4/23] Train loss: 0.30187,Valid loss: 0.64874, time : 10.06499719619751 lr : 0.09053395828517646\n",
      "epoch : 239 [5/23] Train loss: 0.32145,Valid loss: 0.67722, time : 10.440763473510742 lr : 0.09053395828517646\n",
      "epoch : 239 [6/23] Train loss: 0.31057,Valid loss: 0.65503, time : 10.356494426727295 lr : 0.09053395828517646\n",
      "epoch : 239 [7/23] Train loss: 0.30581,Valid loss: 0.73703, time : 10.36439299583435 lr : 0.09053395828517646\n",
      "epoch : 239 [8/23] Train loss: 0.31183,Valid loss: 0.65796, time : 10.240377187728882 lr : 0.09053395828517646\n",
      "epoch : 239 [9/23] Train loss: 0.31384,Valid loss: 0.75811, time : 10.412162780761719 lr : 0.09053395828517646\n",
      "epoch : 239 [10/23] Train loss: 0.30753,Valid loss: 0.75645, time : 10.136337041854858 lr : 0.09053395828517646\n",
      "epoch : 239 [11/23] Train loss: 0.30740,Valid loss: 0.63828, time : 10.348185539245605 lr : 0.09053395828517646\n",
      "epoch : 239 [12/23] Train loss: 0.29428,Valid loss: 0.69464, time : 10.042012929916382 lr : 0.09053395828517646\n",
      "epoch : 239 [13/23] Train loss: 0.31559,Valid loss: 0.64707, time : 10.519159317016602 lr : 0.09053395828517646\n",
      "epoch : 239 [14/23] Train loss: 0.30531,Valid loss: 0.65853, time : 10.259050130844116 lr : 0.09053395828517646\n",
      "epoch : 239 [15/23] Train loss: 0.31852,Valid loss: 0.58852, time : 10.320878982543945 lr : 0.09053395828517646\n",
      "epoch : 239 [16/23] Train loss: 0.32061,Valid loss: 0.58770, time : 10.33339786529541 lr : 0.09053395828517646\n",
      "epoch : 239 [17/23] Train loss: 0.31073,Valid loss: 0.65174, time : 10.184662580490112 lr : 0.09053395828517646\n",
      "epoch : 239 [18/23] Train loss: 0.32511,Valid loss: 0.67606, time : 10.370779752731323 lr : 0.09053395828517646\n",
      "epoch : 239 [19/23] Train loss: 0.31816,Valid loss: 0.59459, time : 9.95480728149414 lr : 0.09053395828517646\n",
      "epoch : 239 [20/23] Train loss: 0.30820,Valid loss: 0.69816, time : 10.29040241241455 lr : 0.09053395828517646\n",
      "epoch : 239 [21/23] Train loss: 0.31640,Valid loss: 0.61379, time : 10.121604681015015 lr : 0.09053395828517646\n",
      "epoch : 239 [22/23] Train loss: 0.31311,Valid loss: 0.74899, time : 9.700128078460693 lr : 0.09053395828517646\n",
      "epoch : 240 [0/23] Train loss: 0.31324,Valid loss: 0.62364, time : 10.574355602264404 lr : 0.08962861870232469\n",
      "epoch : 240 [1/23] Train loss: 0.31129,Valid loss: 0.67349, time : 9.959411144256592 lr : 0.08962861870232469\n",
      "epoch : 240 [2/23] Train loss: 0.31696,Valid loss: 0.60337, time : 10.239001035690308 lr : 0.08962861870232469\n",
      "epoch : 240 [3/23] Train loss: 0.31032,Valid loss: 0.72054, time : 10.0951247215271 lr : 0.08962861870232469\n",
      "epoch : 240 [4/23] Train loss: 0.31159,Valid loss: 0.62497, time : 10.499882936477661 lr : 0.08962861870232469\n",
      "epoch : 240 [5/23] Train loss: 0.32653,Valid loss: 0.63969, time : 10.359567165374756 lr : 0.08962861870232469\n",
      "epoch : 240 [6/23] Train loss: 0.31130,Valid loss: 0.65388, time : 10.429198980331421 lr : 0.08962861870232469\n",
      "epoch : 240 [7/23] Train loss: 0.30653,Valid loss: 0.66074, time : 10.02174711227417 lr : 0.08962861870232469\n",
      "epoch : 240 [8/23] Train loss: 0.31902,Valid loss: 0.58702, time : 10.040047407150269 lr : 0.08962861870232469\n",
      "epoch : 240 [9/23] Train loss: 0.31048,Valid loss: 0.69200, time : 10.378224611282349 lr : 0.08962861870232469\n",
      "epoch : 240 [10/23] Train loss: 0.31509,Valid loss: 0.58044, time : 10.07764744758606 lr : 0.08962861870232469\n",
      "epoch : 240 [11/23] Train loss: 0.31178,Valid loss: 0.69927, time : 10.323979139328003 lr : 0.08962861870232469\n",
      "epoch : 240 [12/23] Train loss: 0.31549,Valid loss: 0.66760, time : 10.120777130126953 lr : 0.08962861870232469\n",
      "epoch : 240 [13/23] Train loss: 0.32439,Valid loss: 0.66084, time : 9.993756294250488 lr : 0.08962861870232469\n",
      "epoch : 240 [14/23] Train loss: 0.30855,Valid loss: 0.65902, time : 9.785784244537354 lr : 0.08962861870232469\n",
      "epoch : 240 [15/23] Train loss: 0.31088,Valid loss: 0.67916, time : 10.472256422042847 lr : 0.08962861870232469\n",
      "epoch : 240 [16/23] Train loss: 0.31713,Valid loss: 0.65129, time : 10.127758502960205 lr : 0.08962861870232469\n",
      "epoch : 240 [17/23] Train loss: 0.30662,Valid loss: 0.66889, time : 10.417157411575317 lr : 0.08962861870232469\n",
      "epoch : 240 [18/23] Train loss: 0.31625,Valid loss: 0.65333, time : 10.096757650375366 lr : 0.08962861870232469\n",
      "epoch : 240 [19/23] Train loss: 0.31408,Valid loss: 0.66663, time : 10.297377586364746 lr : 0.08962861870232469\n",
      "epoch : 240 [20/23] Train loss: 0.30232,Valid loss: 0.65367, time : 9.988877296447754 lr : 0.08962861870232469\n",
      "epoch : 240 [21/23] Train loss: 0.31227,Valid loss: 0.69815, time : 9.991324186325073 lr : 0.08962861870232469\n",
      "epoch : 240 [22/23] Train loss: 0.30125,Valid loss: 0.65958, time : 9.484193563461304 lr : 0.08962861870232469\n",
      "epoch : 241 [0/23] Train loss: 0.30897,Valid loss: 0.66508, time : 9.78812837600708 lr : 0.08873233251530144\n",
      "epoch : 241 [1/23] Train loss: 0.31220,Valid loss: 0.73707, time : 10.079373121261597 lr : 0.08873233251530144\n",
      "epoch : 241 [2/23] Train loss: 0.30789,Valid loss: 0.67061, time : 10.222906351089478 lr : 0.08873233251530144\n",
      "epoch : 241 [3/23] Train loss: 0.30053,Valid loss: 0.71063, time : 10.317739486694336 lr : 0.08873233251530144\n",
      "epoch : 241 [4/23] Train loss: 0.30269,Valid loss: 0.72995, time : 10.180969715118408 lr : 0.08873233251530144\n",
      "epoch : 241 [5/23] Train loss: 0.31319,Valid loss: 0.66886, time : 9.956958055496216 lr : 0.08873233251530144\n",
      "epoch : 241 [6/23] Train loss: 0.31330,Valid loss: 0.74865, time : 9.817699909210205 lr : 0.08873233251530144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 241 [7/23] Train loss: 0.30899,Valid loss: 0.64968, time : 9.963287591934204 lr : 0.08873233251530144\n",
      "epoch : 241 [8/23] Train loss: 0.29817,Valid loss: 0.66476, time : 9.9103422164917 lr : 0.08873233251530144\n",
      "epoch : 241 [9/23] Train loss: 0.31862,Valid loss: 0.64116, time : 9.748414993286133 lr : 0.08873233251530144\n",
      "epoch : 241 [10/23] Train loss: 0.31370,Valid loss: 0.66541, time : 9.663614749908447 lr : 0.08873233251530144\n",
      "epoch : 241 [11/23] Train loss: 0.31291,Valid loss: 0.65427, time : 9.919350624084473 lr : 0.08873233251530144\n",
      "epoch : 241 [12/23] Train loss: 0.30356,Valid loss: 0.67072, time : 10.136249303817749 lr : 0.08873233251530144\n",
      "epoch : 241 [13/23] Train loss: 0.29968,Valid loss: 0.70186, time : 9.684762239456177 lr : 0.08873233251530144\n",
      "epoch : 241 [14/23] Train loss: 0.31124,Valid loss: 0.59031, time : 10.026947259902954 lr : 0.08873233251530144\n",
      "epoch : 241 [15/23] Train loss: 0.31848,Valid loss: 0.66598, time : 9.979333639144897 lr : 0.08873233251530144\n",
      "epoch : 241 [16/23] Train loss: 0.32045,Valid loss: 0.67133, time : 10.232685804367065 lr : 0.08873233251530144\n",
      "epoch : 241 [17/23] Train loss: 0.31774,Valid loss: 0.75586, time : 10.118553876876831 lr : 0.08873233251530144\n",
      "epoch : 241 [18/23] Train loss: 0.30292,Valid loss: 0.58905, time : 10.420300006866455 lr : 0.08873233251530144\n",
      "epoch : 241 [19/23] Train loss: 0.31003,Valid loss: 0.69106, time : 10.277706384658813 lr : 0.08873233251530144\n",
      "epoch : 241 [20/23] Train loss: 0.31417,Valid loss: 0.57694, time : 10.116751194000244 lr : 0.08873233251530144\n",
      "epoch : 241 [21/23] Train loss: 0.31341,Valid loss: 0.65511, time : 9.94274616241455 lr : 0.08873233251530144\n",
      "epoch : 241 [22/23] Train loss: 0.30476,Valid loss: 0.64665, time : 9.464317560195923 lr : 0.08873233251530144\n",
      "epoch : 242 [0/23] Train loss: 0.30834,Valid loss: 0.67681, time : 10.124224185943604 lr : 0.08784500919014843\n",
      "epoch : 242 [1/23] Train loss: 0.30750,Valid loss: 0.73705, time : 9.825599670410156 lr : 0.08784500919014843\n",
      "epoch : 242 [2/23] Train loss: 0.31578,Valid loss: 0.72309, time : 10.371619939804077 lr : 0.08784500919014843\n",
      "epoch : 242 [3/23] Train loss: 0.31736,Valid loss: 0.70702, time : 10.249860525131226 lr : 0.08784500919014843\n",
      "epoch : 242 [4/23] Train loss: 0.32015,Valid loss: 0.73583, time : 10.199890375137329 lr : 0.08784500919014843\n",
      "epoch : 242 [5/23] Train loss: 0.30737,Valid loss: 0.70917, time : 10.060102462768555 lr : 0.08784500919014843\n",
      "epoch : 242 [6/23] Train loss: 0.31917,Valid loss: 0.69640, time : 10.159076452255249 lr : 0.08784500919014843\n",
      "epoch : 242 [7/23] Train loss: 0.30774,Valid loss: 0.68423, time : 10.249315738677979 lr : 0.08784500919014843\n",
      "epoch : 242 [8/23] Train loss: 0.30485,Valid loss: 0.70130, time : 10.162356853485107 lr : 0.08784500919014843\n",
      "epoch : 242 [9/23] Train loss: 0.30660,Valid loss: 0.66517, time : 9.995927810668945 lr : 0.08784500919014843\n",
      "epoch : 242 [10/23] Train loss: 0.30409,Valid loss: 0.68740, time : 10.48878788948059 lr : 0.08784500919014843\n",
      "epoch : 242 [11/23] Train loss: 0.30268,Valid loss: 0.65747, time : 10.362477540969849 lr : 0.08784500919014843\n",
      "epoch : 242 [12/23] Train loss: 0.32076,Valid loss: 0.70672, time : 10.618235111236572 lr : 0.08784500919014843\n",
      "epoch : 242 [13/23] Train loss: 0.31004,Valid loss: 0.65782, time : 10.120661735534668 lr : 0.08784500919014843\n",
      "epoch : 242 [14/23] Train loss: 0.30004,Valid loss: 0.68245, time : 10.199170589447021 lr : 0.08784500919014843\n",
      "epoch : 242 [15/23] Train loss: 0.29907,Valid loss: 0.65733, time : 9.90152621269226 lr : 0.08784500919014843\n",
      "epoch : 242 [16/23] Train loss: 0.32029,Valid loss: 0.64564, time : 10.161082983016968 lr : 0.08784500919014843\n",
      "epoch : 242 [17/23] Train loss: 0.29835,Valid loss: 0.67991, time : 9.922146081924438 lr : 0.08784500919014843\n",
      "epoch : 242 [18/23] Train loss: 0.31070,Valid loss: 0.67950, time : 10.269028663635254 lr : 0.08784500919014843\n",
      "epoch : 242 [19/23] Train loss: 0.31141,Valid loss: 0.64061, time : 9.999819993972778 lr : 0.08784500919014843\n",
      "epoch : 242 [20/23] Train loss: 0.30604,Valid loss: 0.63880, time : 9.718415260314941 lr : 0.08784500919014843\n",
      "epoch : 242 [21/23] Train loss: 0.31673,Valid loss: 0.61967, time : 10.266342163085938 lr : 0.08784500919014843\n",
      "epoch : 242 [22/23] Train loss: 0.29164,Valid loss: 0.64658, time : 9.553455352783203 lr : 0.08784500919014843\n",
      "epoch : 243 [0/23] Train loss: 0.30931,Valid loss: 0.64423, time : 10.601084470748901 lr : 0.08696655909824694\n",
      "epoch : 243 [1/23] Train loss: 0.30960,Valid loss: 0.65364, time : 9.851630687713623 lr : 0.08696655909824694\n",
      "epoch : 243 [2/23] Train loss: 0.30870,Valid loss: 0.65079, time : 10.107552766799927 lr : 0.08696655909824694\n",
      "epoch : 243 [3/23] Train loss: 0.30474,Valid loss: 0.68446, time : 9.984619140625 lr : 0.08696655909824694\n",
      "epoch : 243 [4/23] Train loss: 0.30446,Valid loss: 0.62823, time : 10.300756931304932 lr : 0.08696655909824694\n",
      "epoch : 243 [5/23] Train loss: 0.31071,Valid loss: 0.67958, time : 10.164217472076416 lr : 0.08696655909824694\n",
      "epoch : 243 [6/23] Train loss: 0.30481,Valid loss: 0.69813, time : 10.384900569915771 lr : 0.08696655909824694\n",
      "epoch : 243 [7/23] Train loss: 0.29575,Valid loss: 0.69702, time : 9.780779600143433 lr : 0.08696655909824694\n",
      "epoch : 243 [8/23] Train loss: 0.30536,Valid loss: 0.69272, time : 10.114055633544922 lr : 0.08696655909824694\n",
      "epoch : 243 [9/23] Train loss: 0.30426,Valid loss: 0.66259, time : 9.863707542419434 lr : 0.08696655909824694\n",
      "epoch : 243 [10/23] Train loss: 0.30937,Valid loss: 0.64465, time : 10.062729597091675 lr : 0.08696655909824694\n",
      "epoch : 243 [11/23] Train loss: 0.29645,Valid loss: 0.64803, time : 9.9518141746521 lr : 0.08696655909824694\n",
      "epoch : 243 [12/23] Train loss: 0.31166,Valid loss: 0.58840, time : 10.232057571411133 lr : 0.08696655909824694\n",
      "epoch : 243 [13/23] Train loss: 0.29999,Valid loss: 0.68634, time : 10.028405904769897 lr : 0.08696655909824694\n",
      "epoch : 243 [14/23] Train loss: 0.30384,Valid loss: 0.67112, time : 10.504462003707886 lr : 0.08696655909824694\n",
      "epoch : 243 [15/23] Train loss: 0.30043,Valid loss: 0.66768, time : 10.001266479492188 lr : 0.08696655909824694\n",
      "epoch : 243 [16/23] Train loss: 0.30940,Valid loss: 0.62144, time : 10.393224239349365 lr : 0.08696655909824694\n",
      "epoch : 243 [17/23] Train loss: 0.31517,Valid loss: 0.64933, time : 9.874329328536987 lr : 0.08696655909824694\n",
      "epoch : 243 [18/23] Train loss: 0.30409,Valid loss: 0.62147, time : 10.219700813293457 lr : 0.08696655909824694\n",
      "epoch : 243 [19/23] Train loss: 0.30813,Valid loss: 0.67233, time : 10.357316493988037 lr : 0.08696655909824694\n",
      "epoch : 243 [20/23] Train loss: 0.31281,Valid loss: 0.66341, time : 10.542107582092285 lr : 0.08696655909824694\n",
      "epoch : 243 [21/23] Train loss: 0.31275,Valid loss: 0.64838, time : 9.926888704299927 lr : 0.08696655909824694\n",
      "epoch : 243 [22/23] Train loss: 0.31664,Valid loss: 0.64996, time : 9.690552949905396 lr : 0.08696655909824694\n",
      "epoch : 244 [0/23] Train loss: 0.30093,Valid loss: 0.64414, time : 10.336836099624634 lr : 0.08609689350726446\n",
      "epoch : 244 [1/23] Train loss: 0.30861,Valid loss: 0.68246, time : 10.240125894546509 lr : 0.08609689350726446\n",
      "epoch : 244 [2/23] Train loss: 0.30381,Valid loss: 0.65585, time : 10.11441159248352 lr : 0.08609689350726446\n",
      "epoch : 244 [3/23] Train loss: 0.30011,Valid loss: 0.66617, time : 9.91750717163086 lr : 0.08609689350726446\n",
      "epoch : 244 [4/23] Train loss: 0.30834,Valid loss: 0.65380, time : 10.0282461643219 lr : 0.08609689350726446\n",
      "epoch : 244 [5/23] Train loss: 0.30400,Valid loss: 0.66027, time : 10.472416639328003 lr : 0.08609689350726446\n",
      "epoch : 244 [6/23] Train loss: 0.31001,Valid loss: 0.66753, time : 10.125010251998901 lr : 0.08609689350726446\n",
      "epoch : 244 [7/23] Train loss: 0.30048,Valid loss: 0.66879, time : 10.405723810195923 lr : 0.08609689350726446\n",
      "epoch : 244 [8/23] Train loss: 0.29986,Valid loss: 0.67501, time : 10.246307373046875 lr : 0.08609689350726446\n",
      "epoch : 244 [9/23] Train loss: 0.31051,Valid loss: 0.67350, time : 10.22511625289917 lr : 0.08609689350726446\n",
      "epoch : 244 [10/23] Train loss: 0.29050,Valid loss: 0.64028, time : 10.285552024841309 lr : 0.08609689350726446\n",
      "epoch : 244 [11/23] Train loss: 0.30765,Valid loss: 0.66783, time : 10.291090726852417 lr : 0.08609689350726446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 244 [12/23] Train loss: 0.30969,Valid loss: 0.64694, time : 10.287831783294678 lr : 0.08609689350726446\n",
      "epoch : 244 [13/23] Train loss: 0.30247,Valid loss: 0.66705, time : 10.584707736968994 lr : 0.08609689350726446\n",
      "epoch : 244 [14/23] Train loss: 0.30237,Valid loss: 0.61340, time : 10.198610782623291 lr : 0.08609689350726446\n",
      "epoch : 244 [15/23] Train loss: 0.30748,Valid loss: 0.68203, time : 10.571160316467285 lr : 0.08609689350726446\n",
      "epoch : 244 [16/23] Train loss: 0.32393,Valid loss: 0.63695, time : 10.711985111236572 lr : 0.08609689350726446\n",
      "epoch : 244 [17/23] Train loss: 0.31941,Valid loss: 0.75963, time : 10.613911151885986 lr : 0.08609689350726446\n",
      "epoch : 244 [18/23] Train loss: 0.32249,Valid loss: 0.70205, time : 10.110294103622437 lr : 0.08609689350726446\n",
      "epoch : 244 [19/23] Train loss: 0.30806,Valid loss: 0.72167, time : 10.333849668502808 lr : 0.08609689350726446\n",
      "epoch : 244 [20/23] Train loss: 0.31616,Valid loss: 0.68812, time : 10.338865518569946 lr : 0.08609689350726446\n",
      "epoch : 244 [21/23] Train loss: 0.31850,Valid loss: 0.63393, time : 10.268848419189453 lr : 0.08609689350726446\n",
      "epoch : 244 [22/23] Train loss: 0.31141,Valid loss: 0.63850, time : 9.593899726867676 lr : 0.08609689350726446\n",
      "epoch : 245 [0/23] Train loss: 0.29825,Valid loss: 0.65384, time : 10.077247142791748 lr : 0.08523592457219181\n",
      "epoch : 245 [1/23] Train loss: 0.30440,Valid loss: 0.64623, time : 10.095794677734375 lr : 0.08523592457219181\n",
      "epoch : 245 [2/23] Train loss: 0.30800,Valid loss: 0.62126, time : 9.851980447769165 lr : 0.08523592457219181\n",
      "epoch : 245 [3/23] Train loss: 0.30780,Valid loss: 0.67822, time : 10.343991994857788 lr : 0.08523592457219181\n",
      "epoch : 245 [4/23] Train loss: 0.31322,Valid loss: 0.66436, time : 10.630403280258179 lr : 0.08523592457219181\n",
      "epoch : 245 [5/23] Train loss: 0.31266,Valid loss: 0.66701, time : 10.590472221374512 lr : 0.08523592457219181\n",
      "epoch : 245 [6/23] Train loss: 0.30391,Valid loss: 0.67272, time : 9.978028297424316 lr : 0.08523592457219181\n",
      "epoch : 245 [7/23] Train loss: 0.29835,Valid loss: 0.67121, time : 10.386963605880737 lr : 0.08523592457219181\n",
      "epoch : 245 [8/23] Train loss: 0.30754,Valid loss: 0.70035, time : 10.10888934135437 lr : 0.08523592457219181\n",
      "epoch : 245 [9/23] Train loss: 0.30339,Valid loss: 0.65490, time : 10.167118072509766 lr : 0.08523592457219181\n",
      "epoch : 245 [10/23] Train loss: 0.29777,Valid loss: 0.66440, time : 10.442498445510864 lr : 0.08523592457219181\n",
      "epoch : 245 [11/23] Train loss: 0.31056,Valid loss: 0.68213, time : 10.145872354507446 lr : 0.08523592457219181\n",
      "epoch : 245 [12/23] Train loss: 0.30561,Valid loss: 0.67234, time : 10.536312580108643 lr : 0.08523592457219181\n",
      "epoch : 245 [13/23] Train loss: 0.30503,Valid loss: 0.72214, time : 10.201147079467773 lr : 0.08523592457219181\n",
      "epoch : 245 [14/23] Train loss: 0.30831,Valid loss: 0.69163, time : 10.517741203308105 lr : 0.08523592457219181\n",
      "epoch : 245 [15/23] Train loss: 0.30891,Valid loss: 0.71621, time : 9.759774446487427 lr : 0.08523592457219181\n",
      "epoch : 245 [16/23] Train loss: 0.31338,Valid loss: 0.64195, time : 10.342026233673096 lr : 0.08523592457219181\n",
      "epoch : 245 [17/23] Train loss: 0.30106,Valid loss: 0.64901, time : 10.082509994506836 lr : 0.08523592457219181\n",
      "epoch : 245 [18/23] Train loss: 0.30535,Valid loss: 0.65197, time : 10.41653323173523 lr : 0.08523592457219181\n",
      "epoch : 245 [19/23] Train loss: 0.30189,Valid loss: 0.68339, time : 10.28965163230896 lr : 0.08523592457219181\n",
      "epoch : 245 [20/23] Train loss: 0.30846,Valid loss: 0.67059, time : 10.354738473892212 lr : 0.08523592457219181\n",
      "epoch : 245 [21/23] Train loss: 0.30054,Valid loss: 0.67289, time : 10.230366706848145 lr : 0.08523592457219181\n",
      "epoch : 245 [22/23] Train loss: 0.30783,Valid loss: 0.65441, time : 9.75314998626709 lr : 0.08523592457219181\n",
      "epoch : 246 [0/23] Train loss: 0.31220,Valid loss: 0.66705, time : 10.487781286239624 lr : 0.0843835653264699\n",
      "epoch : 246 [1/23] Train loss: 0.30060,Valid loss: 0.65484, time : 10.542157411575317 lr : 0.0843835653264699\n",
      "epoch : 246 [2/23] Train loss: 0.31280,Valid loss: 0.65600, time : 10.452575922012329 lr : 0.0843835653264699\n",
      "epoch : 246 [3/23] Train loss: 0.30057,Valid loss: 0.67784, time : 10.314807891845703 lr : 0.0843835653264699\n",
      "epoch : 246 [4/23] Train loss: 0.30990,Valid loss: 0.68244, time : 10.416987180709839 lr : 0.0843835653264699\n",
      "epoch : 246 [5/23] Train loss: 0.29253,Valid loss: 0.68559, time : 10.377260208129883 lr : 0.0843835653264699\n",
      "epoch : 246 [6/23] Train loss: 0.31524,Valid loss: 0.68189, time : 10.653566598892212 lr : 0.0843835653264699\n",
      "epoch : 246 [7/23] Train loss: 0.29595,Valid loss: 0.65192, time : 10.390625715255737 lr : 0.0843835653264699\n",
      "epoch : 246 [8/23] Train loss: 0.30653,Valid loss: 0.67310, time : 10.399654626846313 lr : 0.0843835653264699\n",
      "epoch : 246 [9/23] Train loss: 0.30307,Valid loss: 0.67942, time : 10.622529983520508 lr : 0.0843835653264699\n",
      "epoch : 246 [10/23] Train loss: 0.28867,Valid loss: 0.70138, time : 10.181882858276367 lr : 0.0843835653264699\n",
      "epoch : 246 [11/23] Train loss: 0.29685,Valid loss: 0.68349, time : 10.588757991790771 lr : 0.0843835653264699\n",
      "epoch : 246 [12/23] Train loss: 0.28920,Valid loss: 0.65717, time : 10.408060550689697 lr : 0.0843835653264699\n",
      "epoch : 246 [13/23] Train loss: 0.30409,Valid loss: 0.68714, time : 10.68011212348938 lr : 0.0843835653264699\n",
      "epoch : 246 [14/23] Train loss: 0.30982,Valid loss: 0.68872, time : 10.331371784210205 lr : 0.0843835653264699\n",
      "epoch : 246 [15/23] Train loss: 0.30880,Valid loss: 0.67981, time : 10.296133995056152 lr : 0.0843835653264699\n",
      "epoch : 246 [16/23] Train loss: 0.30158,Valid loss: 0.71501, time : 10.33911919593811 lr : 0.0843835653264699\n",
      "epoch : 246 [17/23] Train loss: 0.30752,Valid loss: 0.65683, time : 10.155669212341309 lr : 0.0843835653264699\n",
      "epoch : 246 [18/23] Train loss: 0.29084,Valid loss: 0.65721, time : 10.728804349899292 lr : 0.0843835653264699\n",
      "epoch : 246 [19/23] Train loss: 0.30373,Valid loss: 0.65733, time : 10.381888389587402 lr : 0.0843835653264699\n",
      "epoch : 246 [20/23] Train loss: 0.30603,Valid loss: 0.65765, time : 10.052810430526733 lr : 0.0843835653264699\n",
      "epoch : 246 [21/23] Train loss: 0.30660,Valid loss: 0.65465, time : 10.520354747772217 lr : 0.0843835653264699\n",
      "epoch : 246 [22/23] Train loss: 0.29884,Valid loss: 0.67289, time : 9.964893102645874 lr : 0.0843835653264699\n",
      "epoch : 247 [0/23] Train loss: 0.29983,Valid loss: 0.68304, time : 11.295187950134277 lr : 0.0835397296732052\n",
      "epoch : 247 [1/23] Train loss: 0.31300,Valid loss: 0.68450, time : 10.235910654067993 lr : 0.0835397296732052\n",
      "epoch : 247 [2/23] Train loss: 0.31090,Valid loss: 0.62836, time : 10.404605627059937 lr : 0.0835397296732052\n",
      "epoch : 247 [3/23] Train loss: 0.30176,Valid loss: 0.72220, time : 10.34852147102356 lr : 0.0835397296732052\n",
      "epoch : 247 [4/23] Train loss: 0.30080,Valid loss: 0.68877, time : 10.023406028747559 lr : 0.0835397296732052\n",
      "epoch : 247 [5/23] Train loss: 0.29572,Valid loss: 0.63782, time : 10.612650632858276 lr : 0.0835397296732052\n",
      "epoch : 247 [6/23] Train loss: 0.30774,Valid loss: 0.66604, time : 10.303620100021362 lr : 0.0835397296732052\n",
      "epoch : 247 [7/23] Train loss: 0.29606,Valid loss: 0.67664, time : 10.13194227218628 lr : 0.0835397296732052\n",
      "epoch : 247 [8/23] Train loss: 0.29899,Valid loss: 0.65484, time : 10.39055871963501 lr : 0.0835397296732052\n",
      "epoch : 247 [9/23] Train loss: 0.29960,Valid loss: 0.67300, time : 10.168340682983398 lr : 0.0835397296732052\n",
      "epoch : 247 [10/23] Train loss: 0.29578,Valid loss: 0.63870, time : 10.552396059036255 lr : 0.0835397296732052\n",
      "epoch : 247 [11/23] Train loss: 0.31210,Valid loss: 0.68767, time : 10.392733335494995 lr : 0.0835397296732052\n",
      "epoch : 247 [12/23] Train loss: 0.29778,Valid loss: 0.67844, time : 10.496821165084839 lr : 0.0835397296732052\n",
      "epoch : 247 [13/23] Train loss: 0.30243,Valid loss: 0.68824, time : 10.353340148925781 lr : 0.0835397296732052\n",
      "epoch : 247 [14/23] Train loss: 0.29920,Valid loss: 0.69856, time : 10.723451137542725 lr : 0.0835397296732052\n",
      "epoch : 247 [15/23] Train loss: 0.29995,Valid loss: 0.67609, time : 10.40884804725647 lr : 0.0835397296732052\n",
      "epoch : 247 [16/23] Train loss: 0.30277,Valid loss: 0.65419, time : 10.096616268157959 lr : 0.0835397296732052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 247 [17/23] Train loss: 0.30242,Valid loss: 0.68021, time : 10.125363826751709 lr : 0.0835397296732052\n",
      "epoch : 247 [18/23] Train loss: 0.30278,Valid loss: 0.73182, time : 10.359941244125366 lr : 0.0835397296732052\n",
      "epoch : 247 [19/23] Train loss: 0.30533,Valid loss: 0.67043, time : 10.483480453491211 lr : 0.0835397296732052\n",
      "epoch : 247 [20/23] Train loss: 0.30363,Valid loss: 0.68355, time : 10.407395601272583 lr : 0.0835397296732052\n",
      "epoch : 247 [21/23] Train loss: 0.30428,Valid loss: 0.69320, time : 10.527174711227417 lr : 0.0835397296732052\n",
      "epoch : 247 [22/23] Train loss: 0.31243,Valid loss: 0.58942, time : 9.874256610870361 lr : 0.0835397296732052\n",
      "epoch : 248 [0/23] Train loss: 0.29809,Valid loss: 0.58486, time : 10.99721622467041 lr : 0.08270433237647315\n",
      "epoch : 248 [1/23] Train loss: 0.30775,Valid loss: 0.63326, time : 10.750900983810425 lr : 0.08270433237647315\n",
      "epoch : 248 [2/23] Train loss: 0.29657,Valid loss: 0.63406, time : 10.491913795471191 lr : 0.08270433237647315\n",
      "epoch : 248 [3/23] Train loss: 0.30488,Valid loss: 0.64650, time : 10.507631063461304 lr : 0.08270433237647315\n",
      "epoch : 248 [4/23] Train loss: 0.30463,Valid loss: 0.63475, time : 10.227149486541748 lr : 0.08270433237647315\n",
      "epoch : 248 [5/23] Train loss: 0.30625,Valid loss: 0.65206, time : 10.211772441864014 lr : 0.08270433237647315\n",
      "epoch : 248 [6/23] Train loss: 0.29201,Valid loss: 0.65705, time : 10.153615236282349 lr : 0.08270433237647315\n",
      "epoch : 248 [7/23] Train loss: 0.30666,Valid loss: 0.66588, time : 10.14764142036438 lr : 0.08270433237647315\n",
      "epoch : 248 [8/23] Train loss: 0.29733,Valid loss: 0.66896, time : 9.994545936584473 lr : 0.08270433237647315\n",
      "epoch : 248 [9/23] Train loss: 0.30731,Valid loss: 0.64490, time : 10.841601610183716 lr : 0.08270433237647315\n",
      "epoch : 248 [10/23] Train loss: 0.31469,Valid loss: 0.67999, time : 10.185268878936768 lr : 0.08270433237647315\n",
      "epoch : 248 [11/23] Train loss: 0.30093,Valid loss: 0.65801, time : 10.257347822189331 lr : 0.08270433237647315\n",
      "epoch : 248 [12/23] Train loss: 0.28570,Valid loss: 0.68411, time : 10.206776142120361 lr : 0.08270433237647315\n",
      "epoch : 248 [13/23] Train loss: 0.29151,Valid loss: 0.65422, time : 10.12253189086914 lr : 0.08270433237647315\n",
      "epoch : 248 [14/23] Train loss: 0.29298,Valid loss: 0.65196, time : 10.482192277908325 lr : 0.08270433237647315\n",
      "epoch : 248 [15/23] Train loss: 0.31510,Valid loss: 0.69441, time : 10.318862676620483 lr : 0.08270433237647315\n",
      "epoch : 248 [16/23] Train loss: 0.29856,Valid loss: 0.65161, time : 10.371185064315796 lr : 0.08270433237647315\n",
      "epoch : 248 [17/23] Train loss: 0.31245,Valid loss: 0.67271, time : 10.383455991744995 lr : 0.08270433237647315\n",
      "epoch : 248 [18/23] Train loss: 0.30512,Valid loss: 0.67611, time : 10.131490468978882 lr : 0.08270433237647315\n",
      "epoch : 248 [19/23] Train loss: 0.30702,Valid loss: 0.65818, time : 10.49486780166626 lr : 0.08270433237647315\n",
      "epoch : 248 [20/23] Train loss: 0.31067,Valid loss: 0.64541, time : 10.241047859191895 lr : 0.08270433237647315\n",
      "epoch : 248 [21/23] Train loss: 0.30618,Valid loss: 0.66852, time : 10.401912212371826 lr : 0.08270433237647315\n",
      "epoch : 248 [22/23] Train loss: 0.30735,Valid loss: 0.66125, time : 9.706585884094238 lr : 0.08270433237647315\n",
      "epoch : 249 [0/23] Train loss: 0.31319,Valid loss: 0.70487, time : 10.496195316314697 lr : 0.08187728905270841\n",
      "epoch : 249 [1/23] Train loss: 0.30302,Valid loss: 0.69665, time : 10.260008573532104 lr : 0.08187728905270841\n",
      "epoch : 249 [2/23] Train loss: 0.29593,Valid loss: 0.69158, time : 10.46429705619812 lr : 0.08187728905270841\n",
      "epoch : 249 [3/23] Train loss: 0.29915,Valid loss: 0.70535, time : 10.290408372879028 lr : 0.08187728905270841\n",
      "epoch : 249 [4/23] Train loss: 0.30606,Valid loss: 0.67506, time : 10.238187074661255 lr : 0.08187728905270841\n",
      "epoch : 249 [5/23] Train loss: 0.30125,Valid loss: 0.65269, time : 10.508980512619019 lr : 0.08187728905270841\n",
      "epoch : 249 [6/23] Train loss: 0.29341,Valid loss: 0.69949, time : 10.754577398300171 lr : 0.08187728905270841\n",
      "epoch : 249 [7/23] Train loss: 0.28808,Valid loss: 0.67281, time : 10.358378887176514 lr : 0.08187728905270841\n",
      "epoch : 249 [8/23] Train loss: 0.30324,Valid loss: 0.65257, time : 10.710071563720703 lr : 0.08187728905270841\n",
      "epoch : 249 [9/23] Train loss: 0.30172,Valid loss: 0.67971, time : 10.682889938354492 lr : 0.08187728905270841\n",
      "epoch : 249 [10/23] Train loss: 0.30233,Valid loss: 0.67983, time : 10.747119426727295 lr : 0.08187728905270841\n",
      "epoch : 249 [11/23] Train loss: 0.29606,Valid loss: 0.67482, time : 10.635030746459961 lr : 0.08187728905270841\n",
      "epoch : 249 [12/23] Train loss: 0.29824,Valid loss: 0.67770, time : 10.492459535598755 lr : 0.08187728905270841\n",
      "epoch : 249 [13/23] Train loss: 0.29800,Valid loss: 0.68377, time : 10.53895354270935 lr : 0.08187728905270841\n",
      "epoch : 249 [14/23] Train loss: 0.30307,Valid loss: 0.67558, time : 10.59397840499878 lr : 0.08187728905270841\n",
      "epoch : 249 [15/23] Train loss: 0.30877,Valid loss: 0.68455, time : 10.21004056930542 lr : 0.08187728905270841\n",
      "epoch : 249 [16/23] Train loss: 0.30673,Valid loss: 0.67788, time : 10.687066316604614 lr : 0.08187728905270841\n",
      "epoch : 249 [17/23] Train loss: 0.29339,Valid loss: 0.68230, time : 10.601627111434937 lr : 0.08187728905270841\n",
      "epoch : 249 [18/23] Train loss: 0.30352,Valid loss: 0.67413, time : 10.709736585617065 lr : 0.08187728905270841\n",
      "epoch : 249 [19/23] Train loss: 0.29639,Valid loss: 0.65120, time : 10.560784339904785 lr : 0.08187728905270841\n",
      "epoch : 249 [20/23] Train loss: 0.30184,Valid loss: 0.67496, time : 10.610707759857178 lr : 0.08187728905270841\n",
      "epoch : 249 [21/23] Train loss: 0.29984,Valid loss: 0.73684, time : 10.307306289672852 lr : 0.08187728905270841\n",
      "epoch : 249 [22/23] Train loss: 0.29550,Valid loss: 0.65489, time : 9.744215488433838 lr : 0.08187728905270841\n",
      "epoch : 250 [0/23] Train loss: 0.31118,Valid loss: 0.65546, time : 10.92434811592102 lr : 0.08105851616218133\n",
      "epoch : 250 [1/23] Train loss: 0.30376,Valid loss: 0.65052, time : 10.329632759094238 lr : 0.08105851616218133\n",
      "epoch : 250 [2/23] Train loss: 0.29352,Valid loss: 0.64864, time : 9.955245971679688 lr : 0.08105851616218133\n",
      "epoch : 250 [3/23] Train loss: 0.29469,Valid loss: 0.65043, time : 10.583925008773804 lr : 0.08105851616218133\n",
      "epoch : 250 [4/23] Train loss: 0.29517,Valid loss: 0.68721, time : 10.59522294998169 lr : 0.08105851616218133\n",
      "epoch : 250 [5/23] Train loss: 0.29421,Valid loss: 0.67147, time : 9.956606388092041 lr : 0.08105851616218133\n",
      "epoch : 250 [6/23] Train loss: 0.29274,Valid loss: 0.64471, time : 10.452354669570923 lr : 0.08105851616218133\n",
      "epoch : 250 [7/23] Train loss: 0.29959,Valid loss: 0.69392, time : 9.950166702270508 lr : 0.08105851616218133\n",
      "epoch : 250 [8/23] Train loss: 0.29860,Valid loss: 0.71898, time : 10.09179949760437 lr : 0.08105851616218133\n",
      "epoch : 250 [9/23] Train loss: 0.30322,Valid loss: 0.64582, time : 9.848050117492676 lr : 0.08105851616218133\n",
      "epoch : 250 [10/23] Train loss: 0.30846,Valid loss: 0.66195, time : 10.501757860183716 lr : 0.08105851616218133\n",
      "epoch : 250 [11/23] Train loss: 0.29960,Valid loss: 0.67234, time : 9.90463662147522 lr : 0.08105851616218133\n",
      "epoch : 250 [12/23] Train loss: 0.29929,Valid loss: 0.62586, time : 10.372952222824097 lr : 0.08105851616218133\n",
      "epoch : 250 [13/23] Train loss: 0.29663,Valid loss: 0.69994, time : 9.800974369049072 lr : 0.08105851616218133\n",
      "epoch : 250 [14/23] Train loss: 0.30239,Valid loss: 0.69704, time : 10.317480087280273 lr : 0.08105851616218133\n",
      "epoch : 250 [15/23] Train loss: 0.29180,Valid loss: 0.67591, time : 10.063980102539062 lr : 0.08105851616218133\n",
      "epoch : 250 [16/23] Train loss: 0.30274,Valid loss: 0.72942, time : 10.335192680358887 lr : 0.08105851616218133\n",
      "epoch : 250 [17/23] Train loss: 0.29700,Valid loss: 0.63844, time : 9.877415657043457 lr : 0.08105851616218133\n",
      "epoch : 250 [18/23] Train loss: 0.29476,Valid loss: 0.71292, time : 10.441959142684937 lr : 0.08105851616218133\n",
      "epoch : 250 [19/23] Train loss: 0.29915,Valid loss: 0.64693, time : 9.947145223617554 lr : 0.08105851616218133\n",
      "epoch : 250 [20/23] Train loss: 0.30303,Valid loss: 0.69922, time : 10.344687461853027 lr : 0.08105851616218133\n",
      "epoch : 250 [21/23] Train loss: 0.29872,Valid loss: 0.62752, time : 10.123972177505493 lr : 0.08105851616218133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 250 [22/23] Train loss: 0.29223,Valid loss: 0.67666, time : 9.603158473968506 lr : 0.08105851616218133\n",
      "epoch : 251 [0/23] Train loss: 0.30643,Valid loss: 0.66781, time : 10.498839616775513 lr : 0.08024793100055952\n",
      "epoch : 251 [1/23] Train loss: 0.28984,Valid loss: 0.65766, time : 10.301860809326172 lr : 0.08024793100055952\n",
      "epoch : 251 [2/23] Train loss: 0.29987,Valid loss: 0.63944, time : 10.442906856536865 lr : 0.08024793100055952\n",
      "epoch : 251 [3/23] Train loss: 0.29453,Valid loss: 0.61329, time : 10.285844087600708 lr : 0.08024793100055952\n",
      "epoch : 251 [4/23] Train loss: 0.30635,Valid loss: 0.62563, time : 10.535605907440186 lr : 0.08024793100055952\n",
      "epoch : 251 [5/23] Train loss: 0.30466,Valid loss: 0.68048, time : 11.029396533966064 lr : 0.08024793100055952\n",
      "epoch : 251 [6/23] Train loss: 0.31173,Valid loss: 0.67584, time : 10.453292846679688 lr : 0.08024793100055952\n",
      "epoch : 251 [7/23] Train loss: 0.30440,Valid loss: 0.61031, time : 10.412618637084961 lr : 0.08024793100055952\n",
      "epoch : 251 [8/23] Train loss: 0.30577,Valid loss: 0.66065, time : 10.600356340408325 lr : 0.08024793100055952\n",
      "epoch : 251 [9/23] Train loss: 0.30814,Valid loss: 0.67065, time : 10.343351602554321 lr : 0.08024793100055952\n",
      "epoch : 251 [10/23] Train loss: 0.30638,Valid loss: 0.62569, time : 10.49350643157959 lr : 0.08024793100055952\n",
      "epoch : 251 [11/23] Train loss: 0.29832,Valid loss: 0.63546, time : 10.258506059646606 lr : 0.08024793100055952\n",
      "epoch : 251 [12/23] Train loss: 0.31122,Valid loss: 0.63603, time : 10.407822847366333 lr : 0.08024793100055952\n",
      "epoch : 251 [13/23] Train loss: 0.30633,Valid loss: 0.59802, time : 10.38521671295166 lr : 0.08024793100055952\n",
      "epoch : 251 [14/23] Train loss: 0.30342,Valid loss: 0.58396, time : 10.270217180252075 lr : 0.08024793100055952\n",
      "epoch : 251 [15/23] Train loss: 0.31630,Valid loss: 0.64425, time : 10.244856119155884 lr : 0.08024793100055952\n",
      "epoch : 251 [16/23] Train loss: 0.29828,Valid loss: 0.61359, time : 10.621336221694946 lr : 0.08024793100055952\n",
      "epoch : 251 [17/23] Train loss: 0.31293,Valid loss: 0.66020, time : 10.641445636749268 lr : 0.08024793100055952\n",
      "epoch : 251 [18/23] Train loss: 0.30420,Valid loss: 0.60522, time : 10.623876810073853 lr : 0.08024793100055952\n",
      "epoch : 251 [19/23] Train loss: 0.30613,Valid loss: 0.66993, time : 10.699271202087402 lr : 0.08024793100055952\n",
      "epoch : 251 [20/23] Train loss: 0.30588,Valid loss: 0.65558, time : 10.684716939926147 lr : 0.08024793100055952\n",
      "epoch : 251 [21/23] Train loss: 0.29650,Valid loss: 0.58502, time : 10.245454788208008 lr : 0.08024793100055952\n",
      "epoch : 251 [22/23] Train loss: 0.30067,Valid loss: 0.63196, time : 9.709592342376709 lr : 0.08024793100055952\n",
      "epoch : 252 [0/23] Train loss: 0.30236,Valid loss: 0.66828, time : 10.312580585479736 lr : 0.07944545169055392\n",
      "epoch : 252 [1/23] Train loss: 0.29688,Valid loss: 0.68743, time : 10.859873533248901 lr : 0.07944545169055392\n",
      "epoch : 252 [2/23] Train loss: 0.30425,Valid loss: 0.66017, time : 10.54488730430603 lr : 0.07944545169055392\n",
      "epoch : 252 [3/23] Train loss: 0.30345,Valid loss: 0.64051, time : 10.2864670753479 lr : 0.07944545169055392\n",
      "epoch : 252 [4/23] Train loss: 0.28744,Valid loss: 0.66914, time : 10.474615573883057 lr : 0.07944545169055392\n",
      "epoch : 252 [5/23] Train loss: 0.30228,Valid loss: 0.68253, time : 10.405137538909912 lr : 0.07944545169055392\n",
      "epoch : 252 [6/23] Train loss: 0.29811,Valid loss: 0.67683, time : 10.439071893692017 lr : 0.07944545169055392\n",
      "epoch : 252 [7/23] Train loss: 0.29640,Valid loss: 0.66560, time : 10.50244688987732 lr : 0.07944545169055392\n",
      "epoch : 252 [8/23] Train loss: 0.29688,Valid loss: 0.64161, time : 10.0162992477417 lr : 0.07944545169055392\n",
      "epoch : 252 [9/23] Train loss: 0.30131,Valid loss: 0.68728, time : 10.28527021408081 lr : 0.07944545169055392\n",
      "epoch : 252 [10/23] Train loss: 0.29776,Valid loss: 0.64889, time : 10.24242901802063 lr : 0.07944545169055392\n",
      "epoch : 252 [11/23] Train loss: 0.29490,Valid loss: 0.69155, time : 10.266543626785278 lr : 0.07944545169055392\n",
      "epoch : 252 [12/23] Train loss: 0.30586,Valid loss: 0.67396, time : 10.114140272140503 lr : 0.07944545169055392\n",
      "epoch : 252 [13/23] Train loss: 0.30079,Valid loss: 0.68315, time : 10.258196592330933 lr : 0.07944545169055392\n",
      "epoch : 252 [14/23] Train loss: 0.29539,Valid loss: 0.70101, time : 10.382100343704224 lr : 0.07944545169055392\n",
      "epoch : 252 [15/23] Train loss: 0.30679,Valid loss: 0.68651, time : 10.557709217071533 lr : 0.07944545169055392\n",
      "epoch : 252 [16/23] Train loss: 0.30130,Valid loss: 0.68099, time : 10.202152013778687 lr : 0.07944545169055392\n",
      "epoch : 252 [17/23] Train loss: 0.30217,Valid loss: 0.64796, time : 10.514238357543945 lr : 0.07944545169055392\n",
      "epoch : 252 [18/23] Train loss: 0.30485,Valid loss: 0.67831, time : 9.952387571334839 lr : 0.07944545169055392\n",
      "epoch : 252 [19/23] Train loss: 0.29502,Valid loss: 0.65280, time : 10.66132640838623 lr : 0.07944545169055392\n",
      "epoch : 252 [20/23] Train loss: 0.30315,Valid loss: 0.66825, time : 9.954610347747803 lr : 0.07944545169055392\n",
      "epoch : 252 [21/23] Train loss: 0.29106,Valid loss: 0.68065, time : 10.615665912628174 lr : 0.07944545169055392\n",
      "epoch : 252 [22/23] Train loss: 0.31073,Valid loss: 0.66174, time : 9.584750413894653 lr : 0.07944545169055392\n",
      "epoch : 253 [0/23] Train loss: 0.30018,Valid loss: 0.66415, time : 10.394886493682861 lr : 0.07865099717364837\n",
      "epoch : 253 [1/23] Train loss: 0.30501,Valid loss: 0.69337, time : 9.946659803390503 lr : 0.07865099717364837\n",
      "epoch : 253 [2/23] Train loss: 0.31770,Valid loss: 0.68342, time : 10.568055868148804 lr : 0.07865099717364837\n",
      "epoch : 253 [3/23] Train loss: 0.29168,Valid loss: 0.68642, time : 9.818222761154175 lr : 0.07865099717364837\n",
      "epoch : 253 [4/23] Train loss: 0.30298,Valid loss: 0.65773, time : 10.526519775390625 lr : 0.07865099717364837\n",
      "epoch : 253 [5/23] Train loss: 0.30581,Valid loss: 0.62514, time : 10.252338171005249 lr : 0.07865099717364837\n",
      "epoch : 253 [6/23] Train loss: 0.30814,Valid loss: 0.68447, time : 10.269397974014282 lr : 0.07865099717364837\n",
      "epoch : 253 [7/23] Train loss: 0.30343,Valid loss: 0.65331, time : 10.326863288879395 lr : 0.07865099717364837\n",
      "epoch : 253 [8/23] Train loss: 0.29154,Valid loss: 0.67516, time : 10.35699987411499 lr : 0.07865099717364837\n",
      "epoch : 253 [9/23] Train loss: 0.29118,Valid loss: 0.67363, time : 10.225356340408325 lr : 0.07865099717364837\n",
      "epoch : 253 [10/23] Train loss: 0.29686,Valid loss: 0.69065, time : 10.328238725662231 lr : 0.07865099717364837\n",
      "epoch : 253 [11/23] Train loss: 0.29348,Valid loss: 0.72876, time : 10.024211406707764 lr : 0.07865099717364837\n",
      "epoch : 253 [12/23] Train loss: 0.29671,Valid loss: 0.67840, time : 10.006212949752808 lr : 0.07865099717364837\n",
      "epoch : 253 [13/23] Train loss: 0.29830,Valid loss: 0.66581, time : 10.053033351898193 lr : 0.07865099717364837\n",
      "epoch : 253 [14/23] Train loss: 0.30927,Valid loss: 0.64576, time : 9.993302345275879 lr : 0.07865099717364837\n",
      "epoch : 253 [15/23] Train loss: 0.29294,Valid loss: 0.69366, time : 10.349811792373657 lr : 0.07865099717364837\n",
      "epoch : 253 [16/23] Train loss: 0.29557,Valid loss: 0.66323, time : 10.299362897872925 lr : 0.07865099717364837\n",
      "epoch : 253 [17/23] Train loss: 0.29903,Valid loss: 0.67323, time : 10.980502605438232 lr : 0.07865099717364837\n",
      "epoch : 253 [18/23] Train loss: 0.30629,Valid loss: 0.65080, time : 10.282047271728516 lr : 0.07865099717364837\n",
      "epoch : 253 [19/23] Train loss: 0.30075,Valid loss: 0.65196, time : 10.295017719268799 lr : 0.07865099717364837\n",
      "epoch : 253 [20/23] Train loss: 0.29632,Valid loss: 0.65193, time : 10.187158823013306 lr : 0.07865099717364837\n",
      "epoch : 253 [21/23] Train loss: 0.30347,Valid loss: 0.66597, time : 10.388768196105957 lr : 0.07865099717364837\n",
      "epoch : 253 [22/23] Train loss: 0.29844,Valid loss: 0.68628, time : 9.800979375839233 lr : 0.07865099717364837\n",
      "epoch : 254 [0/23] Train loss: 0.29474,Valid loss: 0.68904, time : 10.567877054214478 lr : 0.07786448720191189\n",
      "epoch : 254 [1/23] Train loss: 0.29766,Valid loss: 0.71472, time : 10.48451280593872 lr : 0.07786448720191189\n",
      "epoch : 254 [2/23] Train loss: 0.29899,Valid loss: 0.65329, time : 9.876509666442871 lr : 0.07786448720191189\n",
      "epoch : 254 [3/23] Train loss: 0.31160,Valid loss: 0.69251, time : 10.281727313995361 lr : 0.07786448720191189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 254 [4/23] Train loss: 0.29687,Valid loss: 0.66574, time : 10.393468141555786 lr : 0.07786448720191189\n",
      "epoch : 254 [5/23] Train loss: 0.29459,Valid loss: 0.64872, time : 10.392874240875244 lr : 0.07786448720191189\n",
      "epoch : 254 [6/23] Train loss: 0.29107,Valid loss: 0.65981, time : 10.43870735168457 lr : 0.07786448720191189\n",
      "epoch : 254 [7/23] Train loss: 0.29855,Valid loss: 0.64886, time : 10.208095073699951 lr : 0.07786448720191189\n",
      "epoch : 254 [8/23] Train loss: 0.30073,Valid loss: 0.70754, time : 10.23960828781128 lr : 0.07786448720191189\n",
      "epoch : 254 [9/23] Train loss: 0.30133,Valid loss: 0.65913, time : 10.211811542510986 lr : 0.07786448720191189\n",
      "epoch : 254 [10/23] Train loss: 0.29408,Valid loss: 0.68987, time : 10.496088981628418 lr : 0.07786448720191189\n",
      "epoch : 254 [11/23] Train loss: 0.29939,Valid loss: 0.69238, time : 10.224541902542114 lr : 0.07786448720191189\n",
      "epoch : 254 [12/23] Train loss: 0.30340,Valid loss: 0.67692, time : 10.261767148971558 lr : 0.07786448720191189\n",
      "epoch : 254 [13/23] Train loss: 0.29075,Valid loss: 0.68721, time : 10.269786834716797 lr : 0.07786448720191189\n",
      "epoch : 254 [14/23] Train loss: 0.29551,Valid loss: 0.69862, time : 10.628607988357544 lr : 0.07786448720191189\n",
      "epoch : 254 [15/23] Train loss: 0.30843,Valid loss: 0.64111, time : 10.634407758712769 lr : 0.07786448720191189\n",
      "epoch : 254 [16/23] Train loss: 0.30517,Valid loss: 0.64910, time : 10.360198497772217 lr : 0.07786448720191189\n",
      "epoch : 254 [17/23] Train loss: 0.30625,Valid loss: 0.66369, time : 9.817790269851685 lr : 0.07786448720191189\n",
      "epoch : 254 [18/23] Train loss: 0.30160,Valid loss: 0.62110, time : 10.10309886932373 lr : 0.07786448720191189\n",
      "epoch : 254 [19/23] Train loss: 0.29875,Valid loss: 0.67230, time : 10.063449144363403 lr : 0.07786448720191189\n",
      "epoch : 254 [20/23] Train loss: 0.30674,Valid loss: 0.68188, time : 10.128673553466797 lr : 0.07786448720191189\n",
      "epoch : 254 [21/23] Train loss: 0.30628,Valid loss: 0.62611, time : 9.755321502685547 lr : 0.07786448720191189\n",
      "epoch : 254 [22/23] Train loss: 0.29838,Valid loss: 0.68570, time : 9.495129108428955 lr : 0.07786448720191189\n",
      "epoch : 255 [0/23] Train loss: 0.30384,Valid loss: 0.65198, time : 10.236186981201172 lr : 0.07708584232989277\n",
      "epoch : 255 [1/23] Train loss: 0.30329,Valid loss: 0.64871, time : 9.526544332504272 lr : 0.07708584232989277\n",
      "epoch : 255 [2/23] Train loss: 0.31389,Valid loss: 0.59802, time : 9.97855520248413 lr : 0.07708584232989277\n",
      "epoch : 255 [3/23] Train loss: 0.30896,Valid loss: 0.67419, time : 9.71546459197998 lr : 0.07708584232989277\n",
      "epoch : 255 [4/23] Train loss: 0.29113,Valid loss: 0.68872, time : 9.593695640563965 lr : 0.07708584232989277\n",
      "epoch : 255 [5/23] Train loss: 0.31119,Valid loss: 0.65434, time : 10.403898000717163 lr : 0.07708584232989277\n",
      "epoch : 255 [6/23] Train loss: 0.30035,Valid loss: 0.67827, time : 10.350252389907837 lr : 0.07708584232989277\n",
      "epoch : 255 [7/23] Train loss: 0.29914,Valid loss: 0.66850, time : 9.805465459823608 lr : 0.07708584232989277\n",
      "epoch : 255 [8/23] Train loss: 0.30984,Valid loss: 0.67491, time : 9.87186312675476 lr : 0.07708584232989277\n",
      "epoch : 255 [9/23] Train loss: 0.30299,Valid loss: 0.66196, time : 9.923486471176147 lr : 0.07708584232989277\n",
      "epoch : 255 [10/23] Train loss: 0.29600,Valid loss: 0.67006, time : 9.929191827774048 lr : 0.07708584232989277\n",
      "epoch : 255 [11/23] Train loss: 0.31212,Valid loss: 0.67532, time : 9.897600173950195 lr : 0.07708584232989277\n",
      "epoch : 255 [12/23] Train loss: 0.30132,Valid loss: 0.66612, time : 10.047040939331055 lr : 0.07708584232989277\n",
      "epoch : 255 [13/23] Train loss: 0.30087,Valid loss: 0.64877, time : 9.904126644134521 lr : 0.07708584232989277\n",
      "epoch : 255 [14/23] Train loss: 0.31214,Valid loss: 0.66528, time : 10.414773941040039 lr : 0.07708584232989277\n",
      "epoch : 255 [15/23] Train loss: 0.29598,Valid loss: 0.64960, time : 9.786020278930664 lr : 0.07708584232989277\n",
      "epoch : 255 [16/23] Train loss: 0.29819,Valid loss: 0.65918, time : 9.823509454727173 lr : 0.07708584232989277\n",
      "epoch : 255 [17/23] Train loss: 0.28976,Valid loss: 0.66939, time : 10.036027908325195 lr : 0.07708584232989277\n",
      "epoch : 255 [18/23] Train loss: 0.29592,Valid loss: 0.69594, time : 10.452093124389648 lr : 0.07708584232989277\n",
      "epoch : 255 [19/23] Train loss: 0.30019,Valid loss: 0.66590, time : 10.00357460975647 lr : 0.07708584232989277\n",
      "epoch : 255 [20/23] Train loss: 0.30361,Valid loss: 0.67072, time : 10.293585777282715 lr : 0.07708584232989277\n",
      "epoch : 255 [21/23] Train loss: 0.29490,Valid loss: 0.66311, time : 10.389333248138428 lr : 0.07708584232989277\n",
      "epoch : 255 [22/23] Train loss: 0.30404,Valid loss: 0.65166, time : 9.712287187576294 lr : 0.07708584232989277\n",
      "epoch : 256 [0/23] Train loss: 0.29541,Valid loss: 0.67000, time : 10.595843315124512 lr : 0.07631498390659384\n",
      "epoch : 256 [1/23] Train loss: 0.30076,Valid loss: 0.68114, time : 10.60483694076538 lr : 0.07631498390659384\n",
      "epoch : 256 [2/23] Train loss: 0.29237,Valid loss: 0.68064, time : 10.925854206085205 lr : 0.07631498390659384\n",
      "epoch : 256 [3/23] Train loss: 0.30414,Valid loss: 0.67078, time : 10.299619674682617 lr : 0.07631498390659384\n",
      "epoch : 256 [4/23] Train loss: 0.30070,Valid loss: 0.68616, time : 10.245258808135986 lr : 0.07631498390659384\n",
      "epoch : 256 [5/23] Train loss: 0.29121,Valid loss: 0.65288, time : 9.912034034729004 lr : 0.07631498390659384\n",
      "epoch : 256 [6/23] Train loss: 0.29808,Valid loss: 0.68149, time : 10.268984079360962 lr : 0.07631498390659384\n",
      "epoch : 256 [7/23] Train loss: 0.29846,Valid loss: 0.65210, time : 10.088639736175537 lr : 0.07631498390659384\n",
      "epoch : 256 [8/23] Train loss: 0.29502,Valid loss: 0.71496, time : 10.29630160331726 lr : 0.07631498390659384\n",
      "epoch : 256 [9/23] Train loss: 0.30602,Valid loss: 0.70092, time : 10.302552223205566 lr : 0.07631498390659384\n",
      "epoch : 256 [10/23] Train loss: 0.29661,Valid loss: 0.73708, time : 10.913217067718506 lr : 0.07631498390659384\n",
      "epoch : 256 [11/23] Train loss: 0.29252,Valid loss: 0.68327, time : 10.190398693084717 lr : 0.07631498390659384\n",
      "epoch : 256 [12/23] Train loss: 0.29331,Valid loss: 0.67366, time : 10.418951511383057 lr : 0.07631498390659384\n",
      "epoch : 256 [13/23] Train loss: 0.30464,Valid loss: 0.71222, time : 10.231678485870361 lr : 0.07631498390659384\n",
      "epoch : 256 [14/23] Train loss: 0.29496,Valid loss: 0.71287, time : 10.484476804733276 lr : 0.07631498390659384\n",
      "epoch : 256 [15/23] Train loss: 0.30681,Valid loss: 0.71718, time : 10.47051739692688 lr : 0.07631498390659384\n",
      "epoch : 256 [16/23] Train loss: 0.30352,Valid loss: 0.66154, time : 10.637003183364868 lr : 0.07631498390659384\n",
      "epoch : 256 [17/23] Train loss: 0.29462,Valid loss: 0.60186, time : 10.496632099151611 lr : 0.07631498390659384\n",
      "epoch : 256 [18/23] Train loss: 0.29870,Valid loss: 0.65107, time : 10.28860068321228 lr : 0.07631498390659384\n",
      "epoch : 256 [19/23] Train loss: 0.29281,Valid loss: 0.63952, time : 10.049770832061768 lr : 0.07631498390659384\n",
      "epoch : 256 [20/23] Train loss: 0.29396,Valid loss: 0.66543, time : 10.42018437385559 lr : 0.07631498390659384\n",
      "epoch : 256 [21/23] Train loss: 0.30103,Valid loss: 0.67720, time : 10.036282777786255 lr : 0.07631498390659384\n",
      "epoch : 256 [22/23] Train loss: 0.29491,Valid loss: 0.69331, time : 9.766888856887817 lr : 0.07631498390659384\n",
      "epoch : 257 [0/23] Train loss: 0.29464,Valid loss: 0.69110, time : 10.792351484298706 lr : 0.07555183406752791\n",
      "epoch : 257 [1/23] Train loss: 0.29369,Valid loss: 0.69047, time : 10.549351930618286 lr : 0.07555183406752791\n",
      "epoch : 257 [2/23] Train loss: 0.28962,Valid loss: 0.70285, time : 10.433143854141235 lr : 0.07555183406752791\n",
      "epoch : 257 [3/23] Train loss: 0.30031,Valid loss: 0.69045, time : 10.41134524345398 lr : 0.07555183406752791\n",
      "epoch : 257 [4/23] Train loss: 0.30001,Valid loss: 0.65884, time : 10.669656991958618 lr : 0.07555183406752791\n",
      "epoch : 257 [5/23] Train loss: 0.29533,Valid loss: 0.68355, time : 10.597608804702759 lr : 0.07555183406752791\n",
      "epoch : 257 [6/23] Train loss: 0.30651,Valid loss: 0.67464, time : 10.625002384185791 lr : 0.07555183406752791\n",
      "epoch : 257 [7/23] Train loss: 0.29340,Valid loss: 0.67819, time : 10.847973585128784 lr : 0.07555183406752791\n",
      "epoch : 257 [8/23] Train loss: 0.28980,Valid loss: 0.71633, time : 10.66396188735962 lr : 0.07555183406752791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 257 [9/23] Train loss: 0.29526,Valid loss: 0.67821, time : 10.721940279006958 lr : 0.07555183406752791\n",
      "epoch : 257 [10/23] Train loss: 0.29174,Valid loss: 0.71421, time : 10.447471618652344 lr : 0.07555183406752791\n",
      "epoch : 257 [11/23] Train loss: 0.29297,Valid loss: 0.66499, time : 10.677145004272461 lr : 0.07555183406752791\n",
      "epoch : 257 [12/23] Train loss: 0.28563,Valid loss: 0.66462, time : 10.234016180038452 lr : 0.07555183406752791\n",
      "epoch : 257 [13/23] Train loss: 0.30493,Valid loss: 0.65583, time : 10.382839679718018 lr : 0.07555183406752791\n",
      "epoch : 257 [14/23] Train loss: 0.29833,Valid loss: 0.70165, time : 10.23523235321045 lr : 0.07555183406752791\n",
      "epoch : 257 [15/23] Train loss: 0.29238,Valid loss: 0.66758, time : 9.999329328536987 lr : 0.07555183406752791\n",
      "epoch : 257 [16/23] Train loss: 0.31111,Valid loss: 0.69718, time : 10.017167568206787 lr : 0.07555183406752791\n",
      "epoch : 257 [17/23] Train loss: 0.29870,Valid loss: 0.65638, time : 10.262139558792114 lr : 0.07555183406752791\n",
      "epoch : 257 [18/23] Train loss: 0.29521,Valid loss: 0.71569, time : 10.354691743850708 lr : 0.07555183406752791\n",
      "epoch : 257 [19/23] Train loss: 0.28996,Valid loss: 0.71817, time : 10.727970361709595 lr : 0.07555183406752791\n",
      "epoch : 257 [20/23] Train loss: 0.29079,Valid loss: 0.67920, time : 10.79267144203186 lr : 0.07555183406752791\n",
      "epoch : 257 [21/23] Train loss: 0.29996,Valid loss: 0.70264, time : 10.620004892349243 lr : 0.07555183406752791\n",
      "epoch : 257 [22/23] Train loss: 0.29687,Valid loss: 0.68199, time : 9.741976976394653 lr : 0.07555183406752791\n",
      "epoch : 258 [0/23] Train loss: 0.30151,Valid loss: 0.64815, time : 10.01682162284851 lr : 0.07479631572685264\n",
      "epoch : 258 [1/23] Train loss: 0.30015,Valid loss: 0.67470, time : 10.119970560073853 lr : 0.07479631572685264\n",
      "epoch : 258 [2/23] Train loss: 0.29722,Valid loss: 0.69306, time : 10.09686803817749 lr : 0.07479631572685264\n",
      "epoch : 258 [3/23] Train loss: 0.28398,Valid loss: 0.64945, time : 9.964463472366333 lr : 0.07479631572685264\n",
      "epoch : 258 [4/23] Train loss: 0.29376,Valid loss: 0.65107, time : 10.257799625396729 lr : 0.07479631572685264\n",
      "epoch : 258 [5/23] Train loss: 0.29578,Valid loss: 0.68113, time : 10.104402780532837 lr : 0.07479631572685264\n",
      "epoch : 258 [6/23] Train loss: 0.29041,Valid loss: 0.66754, time : 10.696416139602661 lr : 0.07479631572685264\n",
      "epoch : 258 [7/23] Train loss: 0.29633,Valid loss: 0.68138, time : 10.529098510742188 lr : 0.07479631572685264\n",
      "epoch : 258 [8/23] Train loss: 0.29237,Valid loss: 0.69080, time : 10.028322696685791 lr : 0.07479631572685264\n",
      "epoch : 258 [9/23] Train loss: 0.29152,Valid loss: 0.70099, time : 10.209942102432251 lr : 0.07479631572685264\n",
      "epoch : 258 [10/23] Train loss: 0.28733,Valid loss: 0.68850, time : 10.67430830001831 lr : 0.07479631572685264\n",
      "epoch : 258 [11/23] Train loss: 0.29765,Valid loss: 0.63627, time : 9.887327671051025 lr : 0.07479631572685264\n",
      "epoch : 258 [12/23] Train loss: 0.29410,Valid loss: 0.63336, time : 10.145885467529297 lr : 0.07479631572685264\n",
      "epoch : 258 [13/23] Train loss: 0.29425,Valid loss: 0.65305, time : 10.184447526931763 lr : 0.07479631572685264\n",
      "epoch : 258 [14/23] Train loss: 0.29197,Valid loss: 0.64183, time : 10.6398446559906 lr : 0.07479631572685264\n",
      "epoch : 258 [15/23] Train loss: 0.28998,Valid loss: 0.64701, time : 10.385318994522095 lr : 0.07479631572685264\n",
      "epoch : 258 [16/23] Train loss: 0.29323,Valid loss: 0.70824, time : 10.777205467224121 lr : 0.07479631572685264\n",
      "epoch : 258 [17/23] Train loss: 0.28270,Valid loss: 0.71573, time : 10.736309051513672 lr : 0.07479631572685264\n",
      "epoch : 258 [18/23] Train loss: 0.30119,Valid loss: 0.68773, time : 10.68974494934082 lr : 0.07479631572685264\n",
      "epoch : 258 [19/23] Train loss: 0.30839,Valid loss: 0.65951, time : 10.521252632141113 lr : 0.07479631572685264\n",
      "epoch : 258 [20/23] Train loss: 0.28526,Valid loss: 0.70886, time : 10.282301187515259 lr : 0.07479631572685264\n",
      "epoch : 258 [21/23] Train loss: 0.30061,Valid loss: 0.71954, time : 10.500258445739746 lr : 0.07479631572685264\n",
      "epoch : 258 [22/23] Train loss: 0.28566,Valid loss: 0.64682, time : 9.740851163864136 lr : 0.07479631572685264\n",
      "epoch : 259 [0/23] Train loss: 0.28839,Valid loss: 0.72120, time : 10.291441440582275 lr : 0.07404835256958411\n",
      "epoch : 259 [1/23] Train loss: 0.30417,Valid loss: 0.64700, time : 10.520577669143677 lr : 0.07404835256958411\n",
      "epoch : 259 [2/23] Train loss: 0.28808,Valid loss: 0.65874, time : 10.255586385726929 lr : 0.07404835256958411\n",
      "epoch : 259 [3/23] Train loss: 0.28795,Valid loss: 0.68340, time : 10.522156000137329 lr : 0.07404835256958411\n",
      "epoch : 259 [4/23] Train loss: 0.29206,Valid loss: 0.71770, time : 11.342825174331665 lr : 0.07404835256958411\n",
      "epoch : 259 [5/23] Train loss: 0.29758,Valid loss: 0.71917, time : 10.290857791900635 lr : 0.07404835256958411\n",
      "epoch : 259 [6/23] Train loss: 0.30403,Valid loss: 0.64861, time : 10.22884202003479 lr : 0.07404835256958411\n",
      "epoch : 259 [7/23] Train loss: 0.28507,Valid loss: 0.71749, time : 10.35372543334961 lr : 0.07404835256958411\n",
      "epoch : 259 [8/23] Train loss: 0.29528,Valid loss: 0.64924, time : 10.494039058685303 lr : 0.07404835256958411\n",
      "epoch : 259 [9/23] Train loss: 0.29184,Valid loss: 0.69926, time : 10.564318656921387 lr : 0.07404835256958411\n",
      "epoch : 259 [10/23] Train loss: 0.28990,Valid loss: 0.65205, time : 10.431310653686523 lr : 0.07404835256958411\n",
      "epoch : 259 [11/23] Train loss: 0.28418,Valid loss: 0.69934, time : 10.473828554153442 lr : 0.07404835256958411\n",
      "epoch : 259 [12/23] Train loss: 0.29565,Valid loss: 0.67910, time : 10.571853637695312 lr : 0.07404835256958411\n",
      "epoch : 259 [13/23] Train loss: 0.29040,Valid loss: 0.67157, time : 10.561919689178467 lr : 0.07404835256958411\n",
      "epoch : 259 [14/23] Train loss: 0.28952,Valid loss: 0.66207, time : 10.398553609848022 lr : 0.07404835256958411\n",
      "epoch : 259 [15/23] Train loss: 0.29823,Valid loss: 0.65970, time : 10.534243822097778 lr : 0.07404835256958411\n",
      "epoch : 259 [16/23] Train loss: 0.28524,Valid loss: 0.66093, time : 10.7674081325531 lr : 0.07404835256958411\n",
      "epoch : 259 [17/23] Train loss: 0.29726,Valid loss: 0.63855, time : 10.288406133651733 lr : 0.07404835256958411\n",
      "epoch : 259 [18/23] Train loss: 0.29166,Valid loss: 0.64895, time : 10.319368362426758 lr : 0.07404835256958411\n",
      "epoch : 259 [19/23] Train loss: 0.29035,Valid loss: 0.67938, time : 10.67406964302063 lr : 0.07404835256958411\n",
      "epoch : 259 [20/23] Train loss: 0.28900,Valid loss: 0.68483, time : 10.772261381149292 lr : 0.07404835256958411\n",
      "epoch : 259 [21/23] Train loss: 0.29548,Valid loss: 0.65866, time : 10.548993825912476 lr : 0.07404835256958411\n",
      "epoch : 259 [22/23] Train loss: 0.29235,Valid loss: 0.66572, time : 9.844823598861694 lr : 0.07404835256958411\n",
      "epoch : 260 [0/23] Train loss: 0.29354,Valid loss: 0.67374, time : 10.352769374847412 lr : 0.07330786904388827\n",
      "epoch : 260 [1/23] Train loss: 0.29784,Valid loss: 0.70490, time : 10.554688215255737 lr : 0.07330786904388827\n",
      "epoch : 260 [2/23] Train loss: 0.29948,Valid loss: 0.65673, time : 10.532485008239746 lr : 0.07330786904388827\n",
      "epoch : 260 [3/23] Train loss: 0.28485,Valid loss: 0.68401, time : 10.744776725769043 lr : 0.07330786904388827\n",
      "epoch : 260 [4/23] Train loss: 0.29400,Valid loss: 0.64001, time : 10.94352102279663 lr : 0.07330786904388827\n",
      "epoch : 260 [5/23] Train loss: 0.29148,Valid loss: 0.68234, time : 10.692894458770752 lr : 0.07330786904388827\n",
      "epoch : 260 [6/23] Train loss: 0.28933,Valid loss: 0.69032, time : 10.395431280136108 lr : 0.07330786904388827\n",
      "epoch : 260 [7/23] Train loss: 0.29124,Valid loss: 0.64975, time : 10.33522343635559 lr : 0.07330786904388827\n",
      "epoch : 260 [8/23] Train loss: 0.27730,Valid loss: 0.68583, time : 10.634503841400146 lr : 0.07330786904388827\n",
      "epoch : 260 [9/23] Train loss: 0.29558,Valid loss: 0.68141, time : 10.699074745178223 lr : 0.07330786904388827\n",
      "epoch : 260 [10/23] Train loss: 0.29004,Valid loss: 0.69758, time : 10.89211130142212 lr : 0.07330786904388827\n",
      "epoch : 260 [11/23] Train loss: 0.29621,Valid loss: 0.68340, time : 10.552189350128174 lr : 0.07330786904388827\n",
      "epoch : 260 [12/23] Train loss: 0.28938,Valid loss: 0.67903, time : 10.512285470962524 lr : 0.07330786904388827\n",
      "epoch : 260 [13/23] Train loss: 0.28235,Valid loss: 0.68771, time : 10.417277097702026 lr : 0.07330786904388827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 260 [14/23] Train loss: 0.28949,Valid loss: 0.67074, time : 10.887388944625854 lr : 0.07330786904388827\n",
      "epoch : 260 [15/23] Train loss: 0.29593,Valid loss: 0.63953, time : 10.746180057525635 lr : 0.07330786904388827\n",
      "epoch : 260 [16/23] Train loss: 0.29997,Valid loss: 0.69200, time : 10.773640871047974 lr : 0.07330786904388827\n",
      "epoch : 260 [17/23] Train loss: 0.29514,Valid loss: 0.63908, time : 10.489014387130737 lr : 0.07330786904388827\n",
      "epoch : 260 [18/23] Train loss: 0.28094,Valid loss: 0.68346, time : 10.322398900985718 lr : 0.07330786904388827\n",
      "epoch : 260 [19/23] Train loss: 0.29384,Valid loss: 0.61077, time : 10.419479131698608 lr : 0.07330786904388827\n",
      "epoch : 260 [20/23] Train loss: 0.29395,Valid loss: 0.71286, time : 10.30142092704773 lr : 0.07330786904388827\n",
      "epoch : 260 [21/23] Train loss: 0.28981,Valid loss: 0.66574, time : 10.454436302185059 lr : 0.07330786904388827\n",
      "epoch : 260 [22/23] Train loss: 0.28832,Valid loss: 0.68110, time : 9.787559270858765 lr : 0.07330786904388827\n",
      "epoch : 261 [0/23] Train loss: 0.29883,Valid loss: 0.68629, time : 10.184215068817139 lr : 0.07257479035344938\n",
      "epoch : 261 [1/23] Train loss: 0.28166,Valid loss: 0.64251, time : 10.091956615447998 lr : 0.07257479035344938\n",
      "epoch : 261 [2/23] Train loss: 0.28676,Valid loss: 0.66123, time : 10.050512313842773 lr : 0.07257479035344938\n",
      "epoch : 261 [3/23] Train loss: 0.30222,Valid loss: 0.68713, time : 10.096825361251831 lr : 0.07257479035344938\n",
      "epoch : 261 [4/23] Train loss: 0.29336,Valid loss: 0.62892, time : 10.248955011367798 lr : 0.07257479035344938\n",
      "epoch : 261 [5/23] Train loss: 0.29127,Valid loss: 0.66859, time : 10.513108015060425 lr : 0.07257479035344938\n",
      "epoch : 261 [6/23] Train loss: 0.28725,Valid loss: 0.67995, time : 10.282145023345947 lr : 0.07257479035344938\n",
      "epoch : 261 [7/23] Train loss: 0.29106,Valid loss: 0.59408, time : 10.638872861862183 lr : 0.07257479035344938\n",
      "epoch : 261 [8/23] Train loss: 0.29432,Valid loss: 0.69550, time : 10.596020460128784 lr : 0.07257479035344938\n",
      "epoch : 261 [9/23] Train loss: 0.29466,Valid loss: 0.66717, time : 10.428642511367798 lr : 0.07257479035344938\n",
      "epoch : 261 [10/23] Train loss: 0.29520,Valid loss: 0.63941, time : 10.516839027404785 lr : 0.07257479035344938\n",
      "epoch : 261 [11/23] Train loss: 0.28914,Valid loss: 0.65457, time : 10.871930360794067 lr : 0.07257479035344938\n",
      "epoch : 261 [12/23] Train loss: 0.29926,Valid loss: 0.66109, time : 10.477159023284912 lr : 0.07257479035344938\n",
      "epoch : 261 [13/23] Train loss: 0.28480,Valid loss: 0.68517, time : 10.579479217529297 lr : 0.07257479035344938\n",
      "epoch : 261 [14/23] Train loss: 0.28598,Valid loss: 0.67496, time : 10.732179164886475 lr : 0.07257479035344938\n",
      "epoch : 261 [15/23] Train loss: 0.29550,Valid loss: 0.68627, time : 10.243678092956543 lr : 0.07257479035344938\n",
      "epoch : 261 [16/23] Train loss: 0.28586,Valid loss: 0.65515, time : 9.735193252563477 lr : 0.07257479035344938\n",
      "epoch : 261 [17/23] Train loss: 0.29054,Valid loss: 0.67544, time : 10.280395746231079 lr : 0.07257479035344938\n",
      "epoch : 261 [18/23] Train loss: 0.28553,Valid loss: 0.67636, time : 10.27000904083252 lr : 0.07257479035344938\n",
      "epoch : 261 [19/23] Train loss: 0.28232,Valid loss: 0.64136, time : 10.367003202438354 lr : 0.07257479035344938\n",
      "epoch : 261 [20/23] Train loss: 0.29165,Valid loss: 0.68468, time : 10.45263671875 lr : 0.07257479035344938\n",
      "epoch : 261 [21/23] Train loss: 0.28875,Valid loss: 0.67153, time : 10.697002649307251 lr : 0.07257479035344938\n",
      "epoch : 261 [22/23] Train loss: 0.28877,Valid loss: 0.68257, time : 9.77078366279602 lr : 0.07257479035344938\n",
      "epoch : 262 [0/23] Train loss: 0.28705,Valid loss: 0.71334, time : 10.878617525100708 lr : 0.07184904244991488\n",
      "epoch : 262 [1/23] Train loss: 0.28372,Valid loss: 0.68289, time : 10.12307858467102 lr : 0.07184904244991488\n",
      "epoch : 262 [2/23] Train loss: 0.29674,Valid loss: 0.69325, time : 10.309355974197388 lr : 0.07184904244991488\n",
      "epoch : 262 [3/23] Train loss: 0.29634,Valid loss: 0.68628, time : 10.451091051101685 lr : 0.07184904244991488\n",
      "epoch : 262 [4/23] Train loss: 0.29967,Valid loss: 0.67233, time : 10.659391403198242 lr : 0.07184904244991488\n",
      "epoch : 262 [5/23] Train loss: 0.28761,Valid loss: 0.69961, time : 10.245917081832886 lr : 0.07184904244991488\n",
      "epoch : 262 [6/23] Train loss: 0.28879,Valid loss: 0.67315, time : 10.503355503082275 lr : 0.07184904244991488\n",
      "epoch : 262 [7/23] Train loss: 0.28671,Valid loss: 0.65127, time : 10.533001184463501 lr : 0.07184904244991488\n",
      "epoch : 262 [8/23] Train loss: 0.29259,Valid loss: 0.64535, time : 10.581182479858398 lr : 0.07184904244991488\n",
      "epoch : 262 [9/23] Train loss: 0.28990,Valid loss: 0.67758, time : 10.637781381607056 lr : 0.07184904244991488\n",
      "epoch : 262 [10/23] Train loss: 0.29414,Valid loss: 0.72163, time : 10.445573806762695 lr : 0.07184904244991488\n",
      "epoch : 262 [11/23] Train loss: 0.29562,Valid loss: 0.64980, time : 10.189290285110474 lr : 0.07184904244991488\n",
      "epoch : 262 [12/23] Train loss: 0.28376,Valid loss: 0.68672, time : 10.337658643722534 lr : 0.07184904244991488\n",
      "epoch : 262 [13/23] Train loss: 0.29612,Valid loss: 0.65144, time : 10.455345392227173 lr : 0.07184904244991488\n",
      "epoch : 262 [14/23] Train loss: 0.29607,Valid loss: 0.68184, time : 10.399405002593994 lr : 0.07184904244991488\n",
      "epoch : 262 [15/23] Train loss: 0.29760,Valid loss: 0.65705, time : 10.74266266822815 lr : 0.07184904244991488\n",
      "epoch : 262 [16/23] Train loss: 0.28073,Valid loss: 0.64343, time : 10.527660369873047 lr : 0.07184904244991488\n",
      "epoch : 262 [17/23] Train loss: 0.27165,Valid loss: 0.68381, time : 10.612730264663696 lr : 0.07184904244991488\n",
      "epoch : 262 [18/23] Train loss: 0.30049,Valid loss: 0.61424, time : 10.438963890075684 lr : 0.07184904244991488\n",
      "epoch : 262 [19/23] Train loss: 0.28941,Valid loss: 0.64987, time : 10.37657618522644 lr : 0.07184904244991488\n",
      "epoch : 262 [20/23] Train loss: 0.28780,Valid loss: 0.66817, time : 10.383934736251831 lr : 0.07184904244991488\n",
      "epoch : 262 [21/23] Train loss: 0.29555,Valid loss: 0.64374, time : 10.71063494682312 lr : 0.07184904244991488\n",
      "epoch : 262 [22/23] Train loss: 0.28531,Valid loss: 0.63973, time : 9.764461040496826 lr : 0.07184904244991488\n",
      "epoch : 263 [0/23] Train loss: 0.29042,Valid loss: 0.67915, time : 10.402629375457764 lr : 0.07113055202541574\n",
      "epoch : 263 [1/23] Train loss: 0.28620,Valid loss: 0.64688, time : 10.486017227172852 lr : 0.07113055202541574\n",
      "epoch : 263 [2/23] Train loss: 0.28122,Valid loss: 0.63775, time : 10.239497900009155 lr : 0.07113055202541574\n",
      "epoch : 263 [3/23] Train loss: 0.28886,Valid loss: 0.65250, time : 10.525468111038208 lr : 0.07113055202541574\n",
      "epoch : 263 [4/23] Train loss: 0.28974,Valid loss: 0.68849, time : 10.33776068687439 lr : 0.07113055202541574\n",
      "epoch : 263 [5/23] Train loss: 0.30177,Valid loss: 0.68711, time : 10.434338331222534 lr : 0.07113055202541574\n",
      "epoch : 263 [6/23] Train loss: 0.28975,Valid loss: 0.67525, time : 10.55900263786316 lr : 0.07113055202541574\n",
      "epoch : 263 [7/23] Train loss: 0.27899,Valid loss: 0.66157, time : 10.432397365570068 lr : 0.07113055202541574\n",
      "epoch : 263 [8/23] Train loss: 0.28961,Valid loss: 0.64726, time : 10.503234624862671 lr : 0.07113055202541574\n",
      "epoch : 263 [9/23] Train loss: 0.29444,Valid loss: 0.64091, time : 10.744857788085938 lr : 0.07113055202541574\n",
      "epoch : 263 [10/23] Train loss: 0.28276,Valid loss: 0.67943, time : 10.108808994293213 lr : 0.07113055202541574\n",
      "epoch : 263 [11/23] Train loss: 0.29282,Valid loss: 0.64931, time : 10.093510150909424 lr : 0.07113055202541574\n",
      "epoch : 263 [12/23] Train loss: 0.28653,Valid loss: 0.65819, time : 10.054862976074219 lr : 0.07113055202541574\n",
      "epoch : 263 [13/23] Train loss: 0.28737,Valid loss: 0.64576, time : 10.322964668273926 lr : 0.07113055202541574\n",
      "epoch : 263 [14/23] Train loss: 0.29929,Valid loss: 0.64094, time : 10.416564702987671 lr : 0.07113055202541574\n",
      "epoch : 263 [15/23] Train loss: 0.28728,Valid loss: 0.68970, time : 10.460830688476562 lr : 0.07113055202541574\n",
      "epoch : 263 [16/23] Train loss: 0.28951,Valid loss: 0.65632, time : 10.604324579238892 lr : 0.07113055202541574\n",
      "epoch : 263 [17/23] Train loss: 0.29257,Valid loss: 0.70495, time : 10.143946886062622 lr : 0.07113055202541574\n",
      "epoch : 263 [18/23] Train loss: 0.29419,Valid loss: 0.64697, time : 10.41890811920166 lr : 0.07113055202541574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 263 [19/23] Train loss: 0.29305,Valid loss: 0.66714, time : 10.667517900466919 lr : 0.07113055202541574\n",
      "epoch : 263 [20/23] Train loss: 0.28758,Valid loss: 0.64173, time : 10.523414373397827 lr : 0.07113055202541574\n",
      "epoch : 263 [21/23] Train loss: 0.29272,Valid loss: 0.69177, time : 10.626694679260254 lr : 0.07113055202541574\n",
      "epoch : 263 [22/23] Train loss: 0.28164,Valid loss: 0.71400, time : 9.713729858398438 lr : 0.07113055202541574\n",
      "epoch : 264 [0/23] Train loss: 0.29396,Valid loss: 0.71607, time : 10.417718172073364 lr : 0.07041924650516158\n",
      "epoch : 264 [1/23] Train loss: 0.28413,Valid loss: 0.66037, time : 9.880425930023193 lr : 0.07041924650516158\n",
      "epoch : 264 [2/23] Train loss: 0.28774,Valid loss: 0.68584, time : 10.046581745147705 lr : 0.07041924650516158\n",
      "epoch : 264 [3/23] Train loss: 0.29192,Valid loss: 0.63901, time : 10.251303911209106 lr : 0.07041924650516158\n",
      "epoch : 264 [4/23] Train loss: 0.28600,Valid loss: 0.71417, time : 10.325237512588501 lr : 0.07041924650516158\n",
      "epoch : 264 [5/23] Train loss: 0.28639,Valid loss: 0.64109, time : 9.965392589569092 lr : 0.07041924650516158\n",
      "epoch : 264 [6/23] Train loss: 0.28521,Valid loss: 0.70250, time : 9.869184970855713 lr : 0.07041924650516158\n",
      "epoch : 264 [7/23] Train loss: 0.28923,Valid loss: 0.63386, time : 10.053008556365967 lr : 0.07041924650516158\n",
      "epoch : 264 [8/23] Train loss: 0.29668,Valid loss: 0.70499, time : 10.030845403671265 lr : 0.07041924650516158\n",
      "epoch : 264 [9/23] Train loss: 0.28167,Valid loss: 0.65313, time : 10.161196231842041 lr : 0.07041924650516158\n",
      "epoch : 264 [10/23] Train loss: 0.29168,Valid loss: 0.63789, time : 10.435619115829468 lr : 0.07041924650516158\n",
      "epoch : 264 [11/23] Train loss: 0.28581,Valid loss: 0.63810, time : 10.127543449401855 lr : 0.07041924650516158\n",
      "epoch : 264 [12/23] Train loss: 0.28751,Valid loss: 0.67925, time : 10.257797956466675 lr : 0.07041924650516158\n",
      "epoch : 264 [13/23] Train loss: 0.29337,Valid loss: 0.68086, time : 10.065792083740234 lr : 0.07041924650516158\n",
      "epoch : 264 [14/23] Train loss: 0.28542,Valid loss: 0.64093, time : 10.167248725891113 lr : 0.07041924650516158\n",
      "epoch : 264 [15/23] Train loss: 0.30161,Valid loss: 0.70702, time : 10.338874578475952 lr : 0.07041924650516158\n",
      "epoch : 264 [16/23] Train loss: 0.28108,Valid loss: 0.64230, time : 10.108139276504517 lr : 0.07041924650516158\n",
      "epoch : 264 [17/23] Train loss: 0.29139,Valid loss: 0.68297, time : 9.807307720184326 lr : 0.07041924650516158\n",
      "epoch : 264 [18/23] Train loss: 0.28810,Valid loss: 0.66694, time : 9.901819944381714 lr : 0.07041924650516158\n",
      "epoch : 264 [19/23] Train loss: 0.28210,Valid loss: 0.71434, time : 9.723697900772095 lr : 0.07041924650516158\n",
      "epoch : 264 [20/23] Train loss: 0.28956,Valid loss: 0.61934, time : 10.105222463607788 lr : 0.07041924650516158\n",
      "epoch : 264 [21/23] Train loss: 0.29119,Valid loss: 0.68039, time : 9.693049907684326 lr : 0.07041924650516158\n",
      "epoch : 264 [22/23] Train loss: 0.29342,Valid loss: 0.62674, time : 9.259496688842773 lr : 0.07041924650516158\n",
      "epoch : 265 [0/23] Train loss: 0.28691,Valid loss: 0.67862, time : 10.359908819198608 lr : 0.06971505404010997\n",
      "epoch : 265 [1/23] Train loss: 0.29958,Valid loss: 0.64752, time : 10.124763011932373 lr : 0.06971505404010997\n",
      "epoch : 265 [2/23] Train loss: 0.28813,Valid loss: 0.71284, time : 10.530365705490112 lr : 0.06971505404010997\n",
      "epoch : 265 [3/23] Train loss: 0.27846,Valid loss: 0.65491, time : 10.368396997451782 lr : 0.06971505404010997\n",
      "epoch : 265 [4/23] Train loss: 0.28749,Valid loss: 0.66740, time : 10.402472972869873 lr : 0.06971505404010997\n",
      "epoch : 265 [5/23] Train loss: 0.28420,Valid loss: 0.63967, time : 10.146594524383545 lr : 0.06971505404010997\n",
      "epoch : 265 [6/23] Train loss: 0.28565,Valid loss: 0.70087, time : 9.952807426452637 lr : 0.06971505404010997\n",
      "epoch : 265 [7/23] Train loss: 0.28138,Valid loss: 0.63407, time : 10.417061805725098 lr : 0.06971505404010997\n",
      "epoch : 265 [8/23] Train loss: 0.28979,Valid loss: 0.66308, time : 10.139668464660645 lr : 0.06971505404010997\n",
      "epoch : 265 [9/23] Train loss: 0.28277,Valid loss: 0.67665, time : 10.25971007347107 lr : 0.06971505404010997\n",
      "epoch : 265 [10/23] Train loss: 0.28800,Valid loss: 0.64821, time : 9.916281938552856 lr : 0.06971505404010997\n",
      "epoch : 265 [11/23] Train loss: 0.28983,Valid loss: 0.60693, time : 10.486823320388794 lr : 0.06971505404010997\n",
      "epoch : 265 [12/23] Train loss: 0.29529,Valid loss: 0.72476, time : 9.979389667510986 lr : 0.06971505404010997\n",
      "epoch : 265 [13/23] Train loss: 0.28606,Valid loss: 0.62717, time : 10.235637664794922 lr : 0.06971505404010997\n",
      "epoch : 265 [14/23] Train loss: 0.29002,Valid loss: 0.70113, time : 10.58081340789795 lr : 0.06971505404010997\n",
      "epoch : 265 [15/23] Train loss: 0.28617,Valid loss: 0.69893, time : 10.233390808105469 lr : 0.06971505404010997\n",
      "epoch : 265 [16/23] Train loss: 0.28095,Valid loss: 0.66848, time : 10.592576503753662 lr : 0.06971505404010997\n",
      "epoch : 265 [17/23] Train loss: 0.28451,Valid loss: 0.63385, time : 10.21967363357544 lr : 0.06971505404010997\n",
      "epoch : 265 [18/23] Train loss: 0.28502,Valid loss: 0.67316, time : 10.402805089950562 lr : 0.06971505404010997\n",
      "epoch : 265 [19/23] Train loss: 0.28264,Valid loss: 0.62793, time : 10.355157375335693 lr : 0.06971505404010997\n",
      "epoch : 265 [20/23] Train loss: 0.28684,Valid loss: 0.67993, time : 10.371280431747437 lr : 0.06971505404010997\n",
      "epoch : 265 [21/23] Train loss: 0.29442,Valid loss: 0.71665, time : 10.352808952331543 lr : 0.06971505404010997\n",
      "epoch : 265 [22/23] Train loss: 0.28852,Valid loss: 0.63348, time : 9.67671823501587 lr : 0.06971505404010997\n",
      "epoch : 266 [0/23] Train loss: 0.28016,Valid loss: 0.63780, time : 10.137712001800537 lr : 0.06901790349970886\n",
      "epoch : 266 [1/23] Train loss: 0.28874,Valid loss: 0.63679, time : 10.242393016815186 lr : 0.06901790349970886\n",
      "epoch : 266 [2/23] Train loss: 0.28572,Valid loss: 0.64769, time : 10.276428461074829 lr : 0.06901790349970886\n",
      "epoch : 266 [3/23] Train loss: 0.29162,Valid loss: 0.62482, time : 10.054583072662354 lr : 0.06901790349970886\n",
      "epoch : 266 [4/23] Train loss: 0.28603,Valid loss: 0.71148, time : 10.242570161819458 lr : 0.06901790349970886\n",
      "epoch : 266 [5/23] Train loss: 0.28912,Valid loss: 0.70891, time : 10.004252433776855 lr : 0.06901790349970886\n",
      "epoch : 266 [6/23] Train loss: 0.29046,Valid loss: 0.68883, time : 10.411608934402466 lr : 0.06901790349970886\n",
      "epoch : 266 [7/23] Train loss: 0.28780,Valid loss: 0.63920, time : 10.347333908081055 lr : 0.06901790349970886\n",
      "epoch : 266 [8/23] Train loss: 0.29082,Valid loss: 0.63802, time : 10.314835786819458 lr : 0.06901790349970886\n",
      "epoch : 266 [9/23] Train loss: 0.28037,Valid loss: 0.67826, time : 10.367832660675049 lr : 0.06901790349970886\n",
      "epoch : 266 [10/23] Train loss: 0.27808,Valid loss: 0.64844, time : 10.659456014633179 lr : 0.06901790349970886\n",
      "epoch : 266 [11/23] Train loss: 0.28626,Valid loss: 0.63908, time : 10.344629049301147 lr : 0.06901790349970886\n",
      "epoch : 266 [12/23] Train loss: 0.28111,Valid loss: 0.70496, time : 10.45366907119751 lr : 0.06901790349970886\n",
      "epoch : 266 [13/23] Train loss: 0.28670,Valid loss: 0.66796, time : 10.034990549087524 lr : 0.06901790349970886\n",
      "epoch : 266 [14/23] Train loss: 0.29107,Valid loss: 0.69500, time : 10.425713062286377 lr : 0.06901790349970886\n",
      "epoch : 266 [15/23] Train loss: 0.29252,Valid loss: 0.71835, time : 10.347931861877441 lr : 0.06901790349970886\n",
      "epoch : 266 [16/23] Train loss: 0.28804,Valid loss: 0.69312, time : 10.415945768356323 lr : 0.06901790349970886\n",
      "epoch : 266 [17/23] Train loss: 0.28721,Valid loss: 0.68703, time : 10.337219715118408 lr : 0.06901790349970886\n",
      "epoch : 266 [18/23] Train loss: 0.28074,Valid loss: 0.69978, time : 10.301042318344116 lr : 0.06901790349970886\n",
      "epoch : 266 [19/23] Train loss: 0.29649,Valid loss: 0.65037, time : 10.805277585983276 lr : 0.06901790349970886\n",
      "epoch : 266 [20/23] Train loss: 0.28834,Valid loss: 0.69643, time : 10.188537359237671 lr : 0.06901790349970886\n",
      "epoch : 266 [21/23] Train loss: 0.28740,Valid loss: 0.68076, time : 10.148041486740112 lr : 0.06901790349970886\n",
      "epoch : 266 [22/23] Train loss: 0.28651,Valid loss: 0.70955, time : 9.590242624282837 lr : 0.06901790349970886\n",
      "epoch : 267 [0/23] Train loss: 0.29048,Valid loss: 0.65996, time : 10.613913297653198 lr : 0.06832772446471178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 267 [1/23] Train loss: 0.29120,Valid loss: 0.66707, time : 9.7996244430542 lr : 0.06832772446471178\n",
      "epoch : 267 [2/23] Train loss: 0.27805,Valid loss: 0.65398, time : 10.459275960922241 lr : 0.06832772446471178\n",
      "epoch : 267 [3/23] Train loss: 0.28664,Valid loss: 0.68343, time : 10.141367435455322 lr : 0.06832772446471178\n",
      "epoch : 267 [4/23] Train loss: 0.28242,Valid loss: 0.67877, time : 10.450621604919434 lr : 0.06832772446471178\n",
      "epoch : 267 [5/23] Train loss: 0.29098,Valid loss: 0.70884, time : 10.384809732437134 lr : 0.06832772446471178\n",
      "epoch : 267 [6/23] Train loss: 0.28475,Valid loss: 0.63243, time : 10.419901132583618 lr : 0.06832772446471178\n",
      "epoch : 267 [7/23] Train loss: 0.28598,Valid loss: 0.67973, time : 10.291551113128662 lr : 0.06832772446471178\n",
      "epoch : 267 [8/23] Train loss: 0.28170,Valid loss: 0.69926, time : 10.563528060913086 lr : 0.06832772446471178\n",
      "epoch : 267 [9/23] Train loss: 0.27903,Valid loss: 0.70074, time : 10.291297912597656 lr : 0.06832772446471178\n",
      "epoch : 267 [10/23] Train loss: 0.29708,Valid loss: 0.66514, time : 10.469955444335938 lr : 0.06832772446471178\n",
      "epoch : 267 [11/23] Train loss: 0.29861,Valid loss: 0.61849, time : 10.885672092437744 lr : 0.06832772446471178\n",
      "epoch : 267 [12/23] Train loss: 0.30169,Valid loss: 0.61195, time : 10.19063138961792 lr : 0.06832772446471178\n",
      "epoch : 267 [13/23] Train loss: 0.28807,Valid loss: 0.69675, time : 9.884525060653687 lr : 0.06832772446471178\n",
      "epoch : 267 [14/23] Train loss: 0.29765,Valid loss: 0.62676, time : 10.321249723434448 lr : 0.06832772446471178\n",
      "epoch : 267 [15/23] Train loss: 0.29210,Valid loss: 0.63672, time : 9.792821168899536 lr : 0.06832772446471178\n",
      "epoch : 267 [16/23] Train loss: 0.29066,Valid loss: 0.65042, time : 10.463741302490234 lr : 0.06832772446471178\n",
      "epoch : 267 [17/23] Train loss: 0.28450,Valid loss: 0.70128, time : 9.90852952003479 lr : 0.06832772446471178\n",
      "epoch : 267 [18/23] Train loss: 0.28690,Valid loss: 0.66010, time : 10.1889328956604 lr : 0.06832772446471178\n",
      "epoch : 267 [19/23] Train loss: 0.28950,Valid loss: 0.68515, time : 9.906828880310059 lr : 0.06832772446471178\n",
      "epoch : 267 [20/23] Train loss: 0.28619,Valid loss: 0.63715, time : 10.395334482192993 lr : 0.06832772446471178\n",
      "epoch : 267 [21/23] Train loss: 0.28835,Valid loss: 0.67963, time : 9.861424207687378 lr : 0.06832772446471178\n",
      "epoch : 267 [22/23] Train loss: 0.28295,Valid loss: 0.64180, time : 9.820173263549805 lr : 0.06832772446471178\n",
      "epoch : 268 [0/23] Train loss: 0.28786,Valid loss: 0.71839, time : 10.8830726146698 lr : 0.06764444722006466\n",
      "epoch : 268 [1/23] Train loss: 0.28242,Valid loss: 0.69589, time : 10.31748342514038 lr : 0.06764444722006466\n",
      "epoch : 268 [2/23] Train loss: 0.28114,Valid loss: 0.70358, time : 10.413825511932373 lr : 0.06764444722006466\n",
      "epoch : 268 [3/23] Train loss: 0.28674,Valid loss: 0.63767, time : 10.380135774612427 lr : 0.06764444722006466\n",
      "epoch : 268 [4/23] Train loss: 0.28983,Valid loss: 0.68205, time : 10.612612962722778 lr : 0.06764444722006466\n",
      "epoch : 268 [5/23] Train loss: 0.29521,Valid loss: 0.59555, time : 10.545660257339478 lr : 0.06764444722006466\n",
      "epoch : 268 [6/23] Train loss: 0.29222,Valid loss: 0.66852, time : 10.59165334701538 lr : 0.06764444722006466\n",
      "epoch : 268 [7/23] Train loss: 0.28201,Valid loss: 0.61715, time : 10.640528440475464 lr : 0.06764444722006466\n",
      "epoch : 268 [8/23] Train loss: 0.29203,Valid loss: 0.70128, time : 10.73792028427124 lr : 0.06764444722006466\n",
      "epoch : 268 [9/23] Train loss: 0.28500,Valid loss: 0.66546, time : 10.707850217819214 lr : 0.06764444722006466\n",
      "epoch : 268 [10/23] Train loss: 0.28057,Valid loss: 0.62796, time : 10.373429775238037 lr : 0.06764444722006466\n",
      "epoch : 268 [11/23] Train loss: 0.29082,Valid loss: 0.69094, time : 10.298601865768433 lr : 0.06764444722006466\n",
      "epoch : 268 [12/23] Train loss: 0.28505,Valid loss: 0.62013, time : 10.402429342269897 lr : 0.06764444722006466\n",
      "epoch : 268 [13/23] Train loss: 0.28377,Valid loss: 0.69369, time : 10.64545726776123 lr : 0.06764444722006466\n",
      "epoch : 268 [14/23] Train loss: 0.28389,Valid loss: 0.67877, time : 10.283716201782227 lr : 0.06764444722006466\n",
      "epoch : 268 [15/23] Train loss: 0.27810,Valid loss: 0.68406, time : 10.949215650558472 lr : 0.06764444722006466\n",
      "epoch : 268 [16/23] Train loss: 0.28459,Valid loss: 0.70692, time : 10.476150751113892 lr : 0.06764444722006466\n",
      "epoch : 268 [17/23] Train loss: 0.28755,Valid loss: 0.69923, time : 10.710743188858032 lr : 0.06764444722006466\n",
      "epoch : 268 [18/23] Train loss: 0.29317,Valid loss: 0.60089, time : 10.41683053970337 lr : 0.06764444722006466\n",
      "epoch : 268 [19/23] Train loss: 0.28471,Valid loss: 0.70670, time : 10.420108556747437 lr : 0.06764444722006466\n",
      "epoch : 268 [20/23] Train loss: 0.28641,Valid loss: 0.69593, time : 10.67611837387085 lr : 0.06764444722006466\n",
      "epoch : 268 [21/23] Train loss: 0.28898,Valid loss: 0.62156, time : 10.655665874481201 lr : 0.06764444722006466\n",
      "epoch : 268 [22/23] Train loss: 0.29407,Valid loss: 0.71297, time : 9.807458877563477 lr : 0.06764444722006466\n",
      "epoch : 269 [0/23] Train loss: 0.28798,Valid loss: 0.66762, time : 10.765493392944336 lr : 0.066968002747864\n",
      "epoch : 269 [1/23] Train loss: 0.28254,Valid loss: 0.70052, time : 10.630404949188232 lr : 0.066968002747864\n",
      "epoch : 269 [2/23] Train loss: 0.28741,Valid loss: 0.60249, time : 9.918913125991821 lr : 0.066968002747864\n",
      "epoch : 269 [3/23] Train loss: 0.28195,Valid loss: 0.60053, time : 10.563688516616821 lr : 0.066968002747864\n",
      "epoch : 269 [4/23] Train loss: 0.28515,Valid loss: 0.73887, time : 9.957719326019287 lr : 0.066968002747864\n",
      "epoch : 269 [5/23] Train loss: 0.28139,Valid loss: 0.65419, time : 10.01522970199585 lr : 0.066968002747864\n",
      "epoch : 269 [6/23] Train loss: 0.27974,Valid loss: 0.71065, time : 10.391563892364502 lr : 0.066968002747864\n",
      "epoch : 269 [7/23] Train loss: 0.28461,Valid loss: 0.59934, time : 9.931474685668945 lr : 0.066968002747864\n",
      "epoch : 269 [8/23] Train loss: 0.28297,Valid loss: 0.70240, time : 10.244097709655762 lr : 0.066968002747864\n",
      "epoch : 269 [9/23] Train loss: 0.29135,Valid loss: 0.71573, time : 9.96797513961792 lr : 0.066968002747864\n",
      "epoch : 269 [10/23] Train loss: 0.28820,Valid loss: 0.66047, time : 10.092047452926636 lr : 0.066968002747864\n",
      "epoch : 269 [11/23] Train loss: 0.30035,Valid loss: 0.66389, time : 9.810138702392578 lr : 0.066968002747864\n",
      "epoch : 269 [12/23] Train loss: 0.28303,Valid loss: 0.61872, time : 10.063230991363525 lr : 0.066968002747864\n",
      "epoch : 269 [13/23] Train loss: 0.29397,Valid loss: 0.68325, time : 10.645215034484863 lr : 0.066968002747864\n",
      "epoch : 269 [14/23] Train loss: 0.28408,Valid loss: 0.68941, time : 10.390249729156494 lr : 0.066968002747864\n",
      "epoch : 269 [15/23] Train loss: 0.28971,Valid loss: 0.66869, time : 10.202285289764404 lr : 0.066968002747864\n",
      "epoch : 269 [16/23] Train loss: 0.28341,Valid loss: 0.62366, time : 9.9381582736969 lr : 0.066968002747864\n",
      "epoch : 269 [17/23] Train loss: 0.27735,Valid loss: 0.66647, time : 10.120251655578613 lr : 0.066968002747864\n",
      "epoch : 269 [18/23] Train loss: 0.27781,Valid loss: 0.69563, time : 10.173190832138062 lr : 0.066968002747864\n",
      "epoch : 269 [19/23] Train loss: 0.28591,Valid loss: 0.69378, time : 10.260806560516357 lr : 0.066968002747864\n",
      "epoch : 269 [20/23] Train loss: 0.27938,Valid loss: 0.60619, time : 10.436646699905396 lr : 0.066968002747864\n",
      "epoch : 269 [21/23] Train loss: 0.29092,Valid loss: 0.69611, time : 10.477722883224487 lr : 0.066968002747864\n",
      "epoch : 269 [22/23] Train loss: 0.27556,Valid loss: 0.61731, time : 9.930843830108643 lr : 0.066968002747864\n",
      "epoch : 270 [0/23] Train loss: 0.28557,Valid loss: 0.69451, time : 10.827710628509521 lr : 0.06629832272038537\n",
      "epoch : 270 [1/23] Train loss: 0.28142,Valid loss: 0.66860, time : 10.600068092346191 lr : 0.06629832272038537\n",
      "epoch : 270 [2/23] Train loss: 0.27116,Valid loss: 0.68190, time : 10.28249454498291 lr : 0.06629832272038537\n",
      "epoch : 270 [3/23] Train loss: 0.29512,Valid loss: 0.69020, time : 10.225955486297607 lr : 0.06629832272038537\n",
      "epoch : 270 [4/23] Train loss: 0.28980,Valid loss: 0.66922, time : 10.708183526992798 lr : 0.06629832272038537\n",
      "epoch : 270 [5/23] Train loss: 0.28542,Valid loss: 0.62243, time : 10.559700012207031 lr : 0.06629832272038537\n",
      "epoch : 270 [6/23] Train loss: 0.28811,Valid loss: 0.66771, time : 10.63496446609497 lr : 0.06629832272038537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 270 [7/23] Train loss: 0.28071,Valid loss: 0.62155, time : 10.824371814727783 lr : 0.06629832272038537\n",
      "epoch : 270 [8/23] Train loss: 0.27822,Valid loss: 0.62994, time : 10.4996976852417 lr : 0.06629832272038537\n",
      "epoch : 270 [9/23] Train loss: 0.28498,Valid loss: 0.62305, time : 10.270942687988281 lr : 0.06629832272038537\n",
      "epoch : 270 [10/23] Train loss: 0.28193,Valid loss: 0.63927, time : 10.233634948730469 lr : 0.06629832272038537\n",
      "epoch : 270 [11/23] Train loss: 0.28703,Valid loss: 0.61629, time : 10.474944353103638 lr : 0.06629832272038537\n",
      "epoch : 270 [12/23] Train loss: 0.27986,Valid loss: 0.65209, time : 10.006690263748169 lr : 0.06629832272038537\n",
      "epoch : 270 [13/23] Train loss: 0.28093,Valid loss: 0.62046, time : 10.127750873565674 lr : 0.06629832272038537\n",
      "epoch : 270 [14/23] Train loss: 0.27783,Valid loss: 0.66737, time : 10.29829454421997 lr : 0.06629832272038537\n",
      "epoch : 270 [15/23] Train loss: 0.27789,Valid loss: 0.64577, time : 10.518276453018188 lr : 0.06629832272038537\n",
      "epoch : 270 [16/23] Train loss: 0.28193,Valid loss: 0.70138, time : 10.496115446090698 lr : 0.06629832272038537\n",
      "epoch : 270 [17/23] Train loss: 0.28841,Valid loss: 0.66088, time : 10.410954475402832 lr : 0.06629832272038537\n",
      "epoch : 270 [18/23] Train loss: 0.28275,Valid loss: 0.69750, time : 10.344698429107666 lr : 0.06629832272038537\n",
      "epoch : 270 [19/23] Train loss: 0.28785,Valid loss: 0.68806, time : 10.090375661849976 lr : 0.06629832272038537\n",
      "epoch : 270 [20/23] Train loss: 0.27940,Valid loss: 0.68683, time : 10.327311754226685 lr : 0.06629832272038537\n",
      "epoch : 270 [21/23] Train loss: 0.28899,Valid loss: 0.70160, time : 10.485833883285522 lr : 0.06629832272038537\n",
      "epoch : 270 [22/23] Train loss: 0.28747,Valid loss: 0.61624, time : 9.524421453475952 lr : 0.06629832272038537\n",
      "epoch : 271 [0/23] Train loss: 0.27353,Valid loss: 0.63226, time : 10.929966449737549 lr : 0.06563533949318151\n",
      "epoch : 271 [1/23] Train loss: 0.28134,Valid loss: 0.68724, time : 10.455504417419434 lr : 0.06563533949318151\n",
      "epoch : 271 [2/23] Train loss: 0.28457,Valid loss: 0.60561, time : 10.121564388275146 lr : 0.06563533949318151\n",
      "epoch : 271 [3/23] Train loss: 0.27985,Valid loss: 0.62928, time : 10.131392002105713 lr : 0.06563533949318151\n",
      "epoch : 271 [4/23] Train loss: 0.27652,Valid loss: 0.68358, time : 10.105353832244873 lr : 0.06563533949318151\n",
      "epoch : 271 [5/23] Train loss: 0.27009,Valid loss: 0.69139, time : 10.3045015335083 lr : 0.06563533949318151\n",
      "epoch : 271 [6/23] Train loss: 0.28468,Valid loss: 0.60275, time : 10.471302270889282 lr : 0.06563533949318151\n",
      "epoch : 271 [7/23] Train loss: 0.28270,Valid loss: 0.63725, time : 10.348930358886719 lr : 0.06563533949318151\n",
      "epoch : 271 [8/23] Train loss: 0.28905,Valid loss: 0.68694, time : 10.044096231460571 lr : 0.06563533949318151\n",
      "epoch : 271 [9/23] Train loss: 0.29242,Valid loss: 0.63789, time : 10.062963485717773 lr : 0.06563533949318151\n",
      "epoch : 271 [10/23] Train loss: 0.28305,Valid loss: 0.64049, time : 10.475730419158936 lr : 0.06563533949318151\n",
      "epoch : 271 [11/23] Train loss: 0.28408,Valid loss: 0.67663, time : 10.048539876937866 lr : 0.06563533949318151\n",
      "epoch : 271 [12/23] Train loss: 0.28209,Valid loss: 0.65243, time : 10.268832921981812 lr : 0.06563533949318151\n",
      "epoch : 271 [13/23] Train loss: 0.28613,Valid loss: 0.71365, time : 10.085406303405762 lr : 0.06563533949318151\n",
      "epoch : 271 [14/23] Train loss: 0.28301,Valid loss: 0.69869, time : 10.626471519470215 lr : 0.06563533949318151\n",
      "epoch : 271 [15/23] Train loss: 0.27515,Valid loss: 0.63126, time : 10.341552019119263 lr : 0.06563533949318151\n",
      "epoch : 271 [16/23] Train loss: 0.27835,Valid loss: 0.64933, time : 10.443864583969116 lr : 0.06563533949318151\n",
      "epoch : 271 [17/23] Train loss: 0.28885,Valid loss: 0.63837, time : 10.450170755386353 lr : 0.06563533949318151\n",
      "epoch : 271 [18/23] Train loss: 0.28563,Valid loss: 0.64543, time : 10.594799995422363 lr : 0.06563533949318151\n",
      "epoch : 271 [19/23] Train loss: 0.28937,Valid loss: 0.62638, time : 10.56618332862854 lr : 0.06563533949318151\n",
      "epoch : 271 [20/23] Train loss: 0.28739,Valid loss: 0.59734, time : 10.755897283554077 lr : 0.06563533949318151\n",
      "epoch : 271 [21/23] Train loss: 0.28942,Valid loss: 0.57652, time : 10.260704040527344 lr : 0.06563533949318151\n",
      "epoch : 271 [22/23] Train loss: 0.27608,Valid loss: 0.58799, time : 9.652023315429688 lr : 0.06563533949318151\n",
      "epoch : 272 [0/23] Train loss: 0.27239,Valid loss: 0.65247, time : 10.342236042022705 lr : 0.06497898609824969\n",
      "epoch : 272 [1/23] Train loss: 0.28582,Valid loss: 0.67351, time : 10.569713115692139 lr : 0.06497898609824969\n",
      "epoch : 272 [2/23] Train loss: 0.28454,Valid loss: 0.62776, time : 10.369495391845703 lr : 0.06497898609824969\n",
      "epoch : 272 [3/23] Train loss: 0.27318,Valid loss: 0.68544, time : 10.117318630218506 lr : 0.06497898609824969\n",
      "epoch : 272 [4/23] Train loss: 0.28004,Valid loss: 0.60225, time : 9.981383562088013 lr : 0.06497898609824969\n",
      "epoch : 272 [5/23] Train loss: 0.26584,Valid loss: 0.71021, time : 10.417293787002563 lr : 0.06497898609824969\n",
      "epoch : 272 [6/23] Train loss: 0.27775,Valid loss: 0.67765, time : 10.148610353469849 lr : 0.06497898609824969\n",
      "epoch : 272 [7/23] Train loss: 0.28810,Valid loss: 0.71026, time : 9.684171199798584 lr : 0.06497898609824969\n",
      "epoch : 272 [8/23] Train loss: 0.28090,Valid loss: 0.62465, time : 10.109219551086426 lr : 0.06497898609824969\n",
      "epoch : 272 [9/23] Train loss: 0.28145,Valid loss: 0.63557, time : 10.16423511505127 lr : 0.06497898609824969\n",
      "epoch : 272 [10/23] Train loss: 0.28038,Valid loss: 0.64511, time : 10.341194868087769 lr : 0.06497898609824969\n",
      "epoch : 272 [11/23] Train loss: 0.28539,Valid loss: 0.59674, time : 10.341022729873657 lr : 0.06497898609824969\n",
      "epoch : 272 [12/23] Train loss: 0.27732,Valid loss: 0.61661, time : 10.378786325454712 lr : 0.06497898609824969\n",
      "epoch : 272 [13/23] Train loss: 0.28471,Valid loss: 0.61069, time : 10.563671112060547 lr : 0.06497898609824969\n",
      "epoch : 272 [14/23] Train loss: 0.28926,Valid loss: 0.62586, time : 10.20759391784668 lr : 0.06497898609824969\n",
      "epoch : 272 [15/23] Train loss: 0.27766,Valid loss: 0.64635, time : 10.353713274002075 lr : 0.06497898609824969\n",
      "epoch : 272 [16/23] Train loss: 0.28202,Valid loss: 0.60631, time : 10.49081563949585 lr : 0.06497898609824969\n",
      "epoch : 272 [17/23] Train loss: 0.28018,Valid loss: 0.62003, time : 9.838060855865479 lr : 0.06497898609824969\n",
      "epoch : 272 [18/23] Train loss: 0.28166,Valid loss: 0.71735, time : 10.23449158668518 lr : 0.06497898609824969\n",
      "epoch : 272 [19/23] Train loss: 0.27815,Valid loss: 0.72155, time : 10.18684983253479 lr : 0.06497898609824969\n",
      "epoch : 272 [20/23] Train loss: 0.27177,Valid loss: 0.62760, time : 10.453906059265137 lr : 0.06497898609824969\n",
      "epoch : 272 [21/23] Train loss: 0.29614,Valid loss: 0.70721, time : 10.360300779342651 lr : 0.06497898609824969\n",
      "epoch : 272 [22/23] Train loss: 0.28380,Valid loss: 0.62838, time : 9.52788782119751 lr : 0.06497898609824969\n",
      "epoch : 273 [0/23] Train loss: 0.28704,Valid loss: 0.62414, time : 10.109478950500488 lr : 0.0643291962372672\n",
      "epoch : 273 [1/23] Train loss: 0.27662,Valid loss: 0.72018, time : 10.176945686340332 lr : 0.0643291962372672\n",
      "epoch : 273 [2/23] Train loss: 0.28947,Valid loss: 0.70380, time : 10.150771141052246 lr : 0.0643291962372672\n",
      "epoch : 273 [3/23] Train loss: 0.27808,Valid loss: 0.70760, time : 9.953994274139404 lr : 0.0643291962372672\n",
      "epoch : 273 [4/23] Train loss: 0.27876,Valid loss: 0.71826, time : 10.561657428741455 lr : 0.0643291962372672\n",
      "epoch : 273 [5/23] Train loss: 0.28365,Valid loss: 0.71243, time : 10.136168956756592 lr : 0.0643291962372672\n",
      "epoch : 273 [6/23] Train loss: 0.27455,Valid loss: 0.71538, time : 10.068128824234009 lr : 0.0643291962372672\n",
      "epoch : 273 [7/23] Train loss: 0.28036,Valid loss: 0.62130, time : 10.268178701400757 lr : 0.0643291962372672\n",
      "epoch : 273 [8/23] Train loss: 0.28557,Valid loss: 0.72261, time : 10.383076429367065 lr : 0.0643291962372672\n",
      "epoch : 273 [9/23] Train loss: 0.27886,Valid loss: 0.72141, time : 10.301929712295532 lr : 0.0643291962372672\n",
      "epoch : 273 [10/23] Train loss: 0.28320,Valid loss: 0.68481, time : 10.201836824417114 lr : 0.0643291962372672\n",
      "epoch : 273 [11/23] Train loss: 0.28101,Valid loss: 0.62713, time : 10.612595319747925 lr : 0.0643291962372672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 273 [12/23] Train loss: 0.27827,Valid loss: 0.65617, time : 9.857476472854614 lr : 0.0643291962372672\n",
      "epoch : 273 [13/23] Train loss: 0.28411,Valid loss: 0.64459, time : 9.874717950820923 lr : 0.0643291962372672\n",
      "epoch : 273 [14/23] Train loss: 0.29155,Valid loss: 0.63735, time : 10.2353196144104 lr : 0.0643291962372672\n",
      "epoch : 273 [15/23] Train loss: 0.27996,Valid loss: 0.64030, time : 10.113888502120972 lr : 0.0643291962372672\n",
      "epoch : 273 [16/23] Train loss: 0.27496,Valid loss: 0.74947, time : 9.681767702102661 lr : 0.0643291962372672\n",
      "epoch : 273 [17/23] Train loss: 0.28211,Valid loss: 0.72593, time : 10.149143695831299 lr : 0.0643291962372672\n",
      "epoch : 273 [18/23] Train loss: 0.28418,Valid loss: 0.72537, time : 10.27157187461853 lr : 0.0643291962372672\n",
      "epoch : 273 [19/23] Train loss: 0.28031,Valid loss: 0.62216, time : 10.698498725891113 lr : 0.0643291962372672\n",
      "epoch : 273 [20/23] Train loss: 0.28016,Valid loss: 0.63848, time : 10.472503662109375 lr : 0.0643291962372672\n",
      "epoch : 273 [21/23] Train loss: 0.27766,Valid loss: 0.62164, time : 10.467505931854248 lr : 0.0643291962372672\n",
      "epoch : 273 [22/23] Train loss: 0.28147,Valid loss: 0.72231, time : 9.574887752532959 lr : 0.0643291962372672\n",
      "epoch : 274 [0/23] Train loss: 0.28276,Valid loss: 0.62983, time : 10.272101640701294 lr : 0.06368590427489453\n",
      "epoch : 274 [1/23] Train loss: 0.28625,Valid loss: 0.71971, time : 9.980555772781372 lr : 0.06368590427489453\n",
      "epoch : 274 [2/23] Train loss: 0.28158,Valid loss: 0.62648, time : 9.687881708145142 lr : 0.06368590427489453\n",
      "epoch : 274 [3/23] Train loss: 0.27644,Valid loss: 0.71492, time : 10.098891735076904 lr : 0.06368590427489453\n",
      "epoch : 274 [4/23] Train loss: 0.27248,Valid loss: 0.63438, time : 10.259375810623169 lr : 0.06368590427489453\n",
      "epoch : 274 [5/23] Train loss: 0.28579,Valid loss: 0.61831, time : 9.964430570602417 lr : 0.06368590427489453\n",
      "epoch : 274 [6/23] Train loss: 0.28038,Valid loss: 0.71749, time : 10.31165337562561 lr : 0.06368590427489453\n",
      "epoch : 274 [7/23] Train loss: 0.27633,Valid loss: 0.67911, time : 10.002178430557251 lr : 0.06368590427489453\n",
      "epoch : 274 [8/23] Train loss: 0.27769,Valid loss: 0.66865, time : 9.528021097183228 lr : 0.06368590427489453\n",
      "epoch : 274 [9/23] Train loss: 0.28561,Valid loss: 0.72229, time : 10.031601905822754 lr : 0.06368590427489453\n",
      "epoch : 274 [10/23] Train loss: 0.26702,Valid loss: 0.64392, time : 9.621818542480469 lr : 0.06368590427489453\n",
      "epoch : 274 [11/23] Train loss: 0.28705,Valid loss: 0.66574, time : 9.945145606994629 lr : 0.06368590427489453\n",
      "epoch : 274 [12/23] Train loss: 0.27879,Valid loss: 0.60304, time : 9.520527601242065 lr : 0.06368590427489453\n",
      "epoch : 274 [13/23] Train loss: 0.28279,Valid loss: 0.68442, time : 9.82054853439331 lr : 0.06368590427489453\n",
      "epoch : 274 [14/23] Train loss: 0.27549,Valid loss: 0.70118, time : 9.965673208236694 lr : 0.06368590427489453\n",
      "epoch : 274 [15/23] Train loss: 0.28681,Valid loss: 0.62557, time : 9.677834749221802 lr : 0.06368590427489453\n",
      "epoch : 274 [16/23] Train loss: 0.27830,Valid loss: 0.70865, time : 10.145573377609253 lr : 0.06368590427489453\n",
      "epoch : 274 [17/23] Train loss: 0.26437,Valid loss: 0.61930, time : 10.218504905700684 lr : 0.06368590427489453\n",
      "epoch : 274 [18/23] Train loss: 0.27308,Valid loss: 0.66380, time : 9.735792875289917 lr : 0.06368590427489453\n",
      "epoch : 274 [19/23] Train loss: 0.27853,Valid loss: 0.70860, time : 9.949310302734375 lr : 0.06368590427489453\n",
      "epoch : 274 [20/23] Train loss: 0.28613,Valid loss: 0.69894, time : 9.550262212753296 lr : 0.06368590427489453\n",
      "epoch : 274 [21/23] Train loss: 0.28888,Valid loss: 0.70828, time : 9.607567071914673 lr : 0.06368590427489453\n",
      "epoch : 274 [22/23] Train loss: 0.28164,Valid loss: 0.62130, time : 9.689155101776123 lr : 0.06368590427489453\n",
      "epoch : 275 [0/23] Train loss: 0.28175,Valid loss: 0.64768, time : 9.868404626846313 lr : 0.06304904523214558\n",
      "epoch : 275 [1/23] Train loss: 0.27256,Valid loss: 0.68653, time : 9.750787496566772 lr : 0.06304904523214558\n",
      "epoch : 275 [2/23] Train loss: 0.27419,Valid loss: 0.70735, time : 9.772075891494751 lr : 0.06304904523214558\n",
      "epoch : 275 [3/23] Train loss: 0.27986,Valid loss: 0.64121, time : 9.663174629211426 lr : 0.06304904523214558\n",
      "epoch : 275 [4/23] Train loss: 0.28673,Valid loss: 0.62455, time : 9.79452633857727 lr : 0.06304904523214558\n",
      "epoch : 275 [5/23] Train loss: 0.28072,Valid loss: 0.66933, time : 9.972284078598022 lr : 0.06304904523214558\n",
      "epoch : 275 [6/23] Train loss: 0.27907,Valid loss: 0.63033, time : 9.76401424407959 lr : 0.06304904523214558\n",
      "epoch : 275 [7/23] Train loss: 0.27740,Valid loss: 0.66727, time : 9.672776222229004 lr : 0.06304904523214558\n",
      "epoch : 275 [8/23] Train loss: 0.28186,Valid loss: 0.70743, time : 9.923766851425171 lr : 0.06304904523214558\n",
      "epoch : 275 [9/23] Train loss: 0.27207,Valid loss: 0.66488, time : 10.11985158920288 lr : 0.06304904523214558\n",
      "epoch : 275 [10/23] Train loss: 0.28497,Valid loss: 0.62913, time : 9.88470458984375 lr : 0.06304904523214558\n",
      "epoch : 275 [11/23] Train loss: 0.28395,Valid loss: 0.62771, time : 9.498517274856567 lr : 0.06304904523214558\n",
      "epoch : 275 [12/23] Train loss: 0.28068,Valid loss: 0.71117, time : 9.778164148330688 lr : 0.06304904523214558\n",
      "epoch : 275 [13/23] Train loss: 0.27470,Valid loss: 0.69076, time : 9.566646337509155 lr : 0.06304904523214558\n",
      "epoch : 275 [14/23] Train loss: 0.27578,Valid loss: 0.68107, time : 9.871942520141602 lr : 0.06304904523214558\n",
      "epoch : 275 [15/23] Train loss: 0.27669,Valid loss: 0.67827, time : 9.761926889419556 lr : 0.06304904523214558\n",
      "epoch : 275 [16/23] Train loss: 0.27540,Valid loss: 0.71190, time : 9.866433382034302 lr : 0.06304904523214558\n",
      "epoch : 275 [17/23] Train loss: 0.28674,Valid loss: 0.69809, time : 9.702540874481201 lr : 0.06304904523214558\n",
      "epoch : 275 [18/23] Train loss: 0.27436,Valid loss: 0.61125, time : 9.900823831558228 lr : 0.06304904523214558\n",
      "epoch : 275 [19/23] Train loss: 0.27519,Valid loss: 0.67280, time : 9.736890316009521 lr : 0.06304904523214558\n",
      "epoch : 275 [20/23] Train loss: 0.28682,Valid loss: 0.59728, time : 10.277612924575806 lr : 0.06304904523214558\n",
      "epoch : 275 [21/23] Train loss: 0.28787,Valid loss: 0.64711, time : 10.262598752975464 lr : 0.06304904523214558\n",
      "epoch : 275 [22/23] Train loss: 0.27757,Valid loss: 0.68964, time : 9.598268747329712 lr : 0.06304904523214558\n",
      "epoch : 276 [0/23] Train loss: 0.28183,Valid loss: 0.66309, time : 10.651374578475952 lr : 0.06241855477982412\n",
      "epoch : 276 [1/23] Train loss: 0.27802,Valid loss: 0.66018, time : 10.282397747039795 lr : 0.06241855477982412\n",
      "epoch : 276 [2/23] Train loss: 0.27727,Valid loss: 0.62448, time : 10.639717817306519 lr : 0.06241855477982412\n",
      "epoch : 276 [3/23] Train loss: 0.28336,Valid loss: 0.66879, time : 10.343713760375977 lr : 0.06241855477982412\n",
      "epoch : 276 [4/23] Train loss: 0.28462,Valid loss: 0.66292, time : 9.920559883117676 lr : 0.06241855477982412\n",
      "epoch : 276 [5/23] Train loss: 0.27026,Valid loss: 0.68423, time : 10.322583436965942 lr : 0.06241855477982412\n",
      "epoch : 276 [6/23] Train loss: 0.28163,Valid loss: 0.68641, time : 10.436420679092407 lr : 0.06241855477982412\n",
      "epoch : 276 [7/23] Train loss: 0.27635,Valid loss: 0.65405, time : 10.443345308303833 lr : 0.06241855477982412\n",
      "epoch : 276 [8/23] Train loss: 0.27067,Valid loss: 0.69902, time : 10.143836975097656 lr : 0.06241855477982412\n",
      "epoch : 276 [9/23] Train loss: 0.27433,Valid loss: 0.68240, time : 10.167513370513916 lr : 0.06241855477982412\n",
      "epoch : 276 [10/23] Train loss: 0.28757,Valid loss: 0.65149, time : 9.791874647140503 lr : 0.06241855477982412\n",
      "epoch : 276 [11/23] Train loss: 0.28509,Valid loss: 0.60419, time : 10.068300008773804 lr : 0.06241855477982412\n",
      "epoch : 276 [12/23] Train loss: 0.29052,Valid loss: 0.64745, time : 10.026490211486816 lr : 0.06241855477982412\n",
      "epoch : 276 [13/23] Train loss: 0.26703,Valid loss: 0.65998, time : 10.307637929916382 lr : 0.06241855477982412\n",
      "epoch : 276 [14/23] Train loss: 0.27100,Valid loss: 0.63631, time : 10.199970006942749 lr : 0.06241855477982412\n",
      "epoch : 276 [15/23] Train loss: 0.28411,Valid loss: 0.60461, time : 10.348931312561035 lr : 0.06241855477982412\n",
      "epoch : 276 [16/23] Train loss: 0.28154,Valid loss: 0.61026, time : 10.353098630905151 lr : 0.06241855477982412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 276 [17/23] Train loss: 0.28223,Valid loss: 0.61499, time : 10.061864614486694 lr : 0.06241855477982412\n",
      "epoch : 276 [18/23] Train loss: 0.27953,Valid loss: 0.61086, time : 10.331919431686401 lr : 0.06241855477982412\n",
      "epoch : 276 [19/23] Train loss: 0.27374,Valid loss: 0.71286, time : 9.990232467651367 lr : 0.06241855477982412\n",
      "epoch : 276 [20/23] Train loss: 0.28253,Valid loss: 0.71755, time : 10.181441068649292 lr : 0.06241855477982412\n",
      "epoch : 276 [21/23] Train loss: 0.28539,Valid loss: 0.67567, time : 10.359015226364136 lr : 0.06241855477982412\n",
      "epoch : 276 [22/23] Train loss: 0.28095,Valid loss: 0.59999, time : 9.48560357093811 lr : 0.06241855477982412\n",
      "epoch : 277 [0/23] Train loss: 0.27392,Valid loss: 0.67298, time : 10.510305404663086 lr : 0.06179436923202588\n",
      "epoch : 277 [1/23] Train loss: 0.28340,Valid loss: 0.70265, time : 10.205408811569214 lr : 0.06179436923202588\n",
      "epoch : 277 [2/23] Train loss: 0.28070,Valid loss: 0.66820, time : 9.904259443283081 lr : 0.06179436923202588\n",
      "epoch : 277 [3/23] Train loss: 0.28097,Valid loss: 0.67841, time : 10.093393802642822 lr : 0.06179436923202588\n",
      "epoch : 277 [4/23] Train loss: 0.26935,Valid loss: 0.70750, time : 10.16651964187622 lr : 0.06179436923202588\n",
      "epoch : 277 [5/23] Train loss: 0.28399,Valid loss: 0.68820, time : 10.05935788154602 lr : 0.06179436923202588\n",
      "epoch : 277 [6/23] Train loss: 0.27801,Valid loss: 0.62650, time : 9.65320348739624 lr : 0.06179436923202588\n",
      "epoch : 277 [7/23] Train loss: 0.28087,Valid loss: 0.70737, time : 10.113224267959595 lr : 0.06179436923202588\n",
      "epoch : 277 [8/23] Train loss: 0.27510,Valid loss: 0.71110, time : 10.257715702056885 lr : 0.06179436923202588\n",
      "epoch : 277 [9/23] Train loss: 0.26951,Valid loss: 0.62489, time : 9.890889167785645 lr : 0.06179436923202588\n",
      "epoch : 277 [10/23] Train loss: 0.28922,Valid loss: 0.70747, time : 10.010159730911255 lr : 0.06179436923202588\n",
      "epoch : 277 [11/23] Train loss: 0.27704,Valid loss: 0.66298, time : 10.36130428314209 lr : 0.06179436923202588\n",
      "epoch : 277 [12/23] Train loss: 0.27261,Valid loss: 0.59684, time : 10.360422134399414 lr : 0.06179436923202588\n",
      "epoch : 277 [13/23] Train loss: 0.28528,Valid loss: 0.68234, time : 10.469344854354858 lr : 0.06179436923202588\n",
      "epoch : 277 [14/23] Train loss: 0.28157,Valid loss: 0.71308, time : 10.613330841064453 lr : 0.06179436923202588\n",
      "epoch : 277 [15/23] Train loss: 0.28148,Valid loss: 0.62666, time : 10.769980669021606 lr : 0.06179436923202588\n",
      "epoch : 277 [16/23] Train loss: 0.28305,Valid loss: 0.69407, time : 10.530805110931396 lr : 0.06179436923202588\n",
      "epoch : 277 [17/23] Train loss: 0.28277,Valid loss: 0.69950, time : 10.85489797592163 lr : 0.06179436923202588\n",
      "epoch : 277 [18/23] Train loss: 0.28106,Valid loss: 0.71089, time : 10.375361680984497 lr : 0.06179436923202588\n",
      "epoch : 277 [19/23] Train loss: 0.27744,Valid loss: 0.72282, time : 10.515769720077515 lr : 0.06179436923202588\n",
      "epoch : 277 [20/23] Train loss: 0.28416,Valid loss: 0.69929, time : 10.36571455001831 lr : 0.06179436923202588\n",
      "epoch : 277 [21/23] Train loss: 0.26843,Valid loss: 0.71836, time : 10.597185611724854 lr : 0.06179436923202588\n",
      "epoch : 277 [22/23] Train loss: 0.28212,Valid loss: 0.68804, time : 9.609965562820435 lr : 0.06179436923202588\n",
      "epoch : 278 [0/23] Train loss: 0.27572,Valid loss: 0.69444, time : 10.55359435081482 lr : 0.06117642553970562\n",
      "epoch : 278 [1/23] Train loss: 0.27393,Valid loss: 0.63309, time : 10.281700849533081 lr : 0.06117642553970562\n",
      "epoch : 278 [2/23] Train loss: 0.27110,Valid loss: 0.73581, time : 10.302249193191528 lr : 0.06117642553970562\n",
      "epoch : 278 [3/23] Train loss: 0.27462,Valid loss: 0.66105, time : 10.462191820144653 lr : 0.06117642553970562\n",
      "epoch : 278 [4/23] Train loss: 0.28318,Valid loss: 0.72297, time : 10.288868188858032 lr : 0.06117642553970562\n",
      "epoch : 278 [5/23] Train loss: 0.27853,Valid loss: 0.71420, time : 10.332351922988892 lr : 0.06117642553970562\n",
      "epoch : 278 [6/23] Train loss: 0.27793,Valid loss: 0.60824, time : 10.06018614768982 lr : 0.06117642553970562\n",
      "epoch : 278 [7/23] Train loss: 0.27250,Valid loss: 0.62813, time : 10.037657260894775 lr : 0.06117642553970562\n",
      "epoch : 278 [8/23] Train loss: 0.28162,Valid loss: 0.71171, time : 9.743975400924683 lr : 0.06117642553970562\n",
      "epoch : 278 [9/23] Train loss: 0.27738,Valid loss: 0.67445, time : 10.374920129776001 lr : 0.06117642553970562\n",
      "epoch : 278 [10/23] Train loss: 0.26989,Valid loss: 0.70796, time : 9.904624223709106 lr : 0.06117642553970562\n",
      "epoch : 278 [11/23] Train loss: 0.28175,Valid loss: 0.62925, time : 9.952116966247559 lr : 0.06117642553970562\n",
      "epoch : 278 [12/23] Train loss: 0.28203,Valid loss: 0.62665, time : 10.291618824005127 lr : 0.06117642553970562\n",
      "epoch : 278 [13/23] Train loss: 0.27457,Valid loss: 0.71173, time : 10.071592330932617 lr : 0.06117642553970562\n",
      "epoch : 278 [14/23] Train loss: 0.28312,Valid loss: 0.72369, time : 10.105591297149658 lr : 0.06117642553970562\n",
      "epoch : 278 [15/23] Train loss: 0.27708,Valid loss: 0.70667, time : 10.244269847869873 lr : 0.06117642553970562\n",
      "epoch : 278 [16/23] Train loss: 0.28029,Valid loss: 0.70680, time : 9.664465427398682 lr : 0.06117642553970562\n",
      "epoch : 278 [17/23] Train loss: 0.26976,Valid loss: 0.70335, time : 9.737449169158936 lr : 0.06117642553970562\n",
      "epoch : 278 [18/23] Train loss: 0.27674,Valid loss: 0.63247, time : 10.062559127807617 lr : 0.06117642553970562\n",
      "epoch : 278 [19/23] Train loss: 0.28644,Valid loss: 0.65405, time : 9.842802286148071 lr : 0.06117642553970562\n",
      "epoch : 278 [20/23] Train loss: 0.28292,Valid loss: 0.64742, time : 10.029255390167236 lr : 0.06117642553970562\n",
      "epoch : 278 [21/23] Train loss: 0.28547,Valid loss: 0.73230, time : 10.336195945739746 lr : 0.06117642553970562\n",
      "epoch : 278 [22/23] Train loss: 0.28039,Valid loss: 0.61933, time : 9.972221612930298 lr : 0.06117642553970562\n",
      "epoch : 279 [0/23] Train loss: 0.27819,Valid loss: 0.68572, time : 10.507767915725708 lr : 0.06056466128430856\n",
      "epoch : 279 [1/23] Train loss: 0.27884,Valid loss: 0.74155, time : 9.974671840667725 lr : 0.06056466128430856\n",
      "epoch : 279 [2/23] Train loss: 0.27508,Valid loss: 0.69482, time : 10.140339374542236 lr : 0.06056466128430856\n",
      "epoch : 279 [3/23] Train loss: 0.27324,Valid loss: 0.63188, time : 10.38946270942688 lr : 0.06056466128430856\n",
      "epoch : 279 [4/23] Train loss: 0.27977,Valid loss: 0.59125, time : 10.205696821212769 lr : 0.06056466128430856\n",
      "epoch : 279 [5/23] Train loss: 0.28179,Valid loss: 0.63823, time : 10.321154832839966 lr : 0.06056466128430856\n",
      "epoch : 279 [6/23] Train loss: 0.27493,Valid loss: 0.66802, time : 10.394201278686523 lr : 0.06056466128430856\n",
      "epoch : 279 [7/23] Train loss: 0.28251,Valid loss: 0.69970, time : 10.481814861297607 lr : 0.06056466128430856\n",
      "epoch : 279 [8/23] Train loss: 0.27587,Valid loss: 0.64273, time : 9.845295906066895 lr : 0.06056466128430856\n",
      "epoch : 279 [9/23] Train loss: 0.27092,Valid loss: 0.70782, time : 10.175057172775269 lr : 0.06056466128430856\n",
      "epoch : 279 [10/23] Train loss: 0.28643,Valid loss: 0.68981, time : 10.355374097824097 lr : 0.06056466128430856\n",
      "epoch : 279 [11/23] Train loss: 0.27546,Valid loss: 0.71291, time : 10.027704238891602 lr : 0.06056466128430856\n",
      "epoch : 279 [12/23] Train loss: 0.28120,Valid loss: 0.71073, time : 9.995717287063599 lr : 0.06056466128430856\n",
      "epoch : 279 [13/23] Train loss: 0.27614,Valid loss: 0.63724, time : 10.304422616958618 lr : 0.06056466128430856\n",
      "epoch : 279 [14/23] Train loss: 0.27021,Valid loss: 0.62718, time : 10.380209922790527 lr : 0.06056466128430856\n",
      "epoch : 279 [15/23] Train loss: 0.27104,Valid loss: 0.63074, time : 10.453198909759521 lr : 0.06056466128430856\n",
      "epoch : 279 [16/23] Train loss: 0.27446,Valid loss: 0.67800, time : 10.716230630874634 lr : 0.06056466128430856\n",
      "epoch : 279 [17/23] Train loss: 0.27915,Valid loss: 0.67703, time : 10.313135385513306 lr : 0.06056466128430856\n",
      "epoch : 279 [18/23] Train loss: 0.27708,Valid loss: 0.68321, time : 10.272844791412354 lr : 0.06056466128430856\n",
      "epoch : 279 [19/23] Train loss: 0.26813,Valid loss: 0.62024, time : 10.258349657058716 lr : 0.06056466128430856\n",
      "epoch : 279 [20/23] Train loss: 0.27556,Valid loss: 0.67415, time : 10.021401643753052 lr : 0.06056466128430856\n",
      "epoch : 279 [21/23] Train loss: 0.26625,Valid loss: 0.71754, time : 9.64486813545227 lr : 0.06056466128430856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 279 [22/23] Train loss: 0.28502,Valid loss: 0.69330, time : 9.335654973983765 lr : 0.06056466128430856\n",
      "epoch : 280 [0/23] Train loss: 0.27172,Valid loss: 0.71449, time : 10.415850639343262 lr : 0.05995901467146548\n",
      "epoch : 280 [1/23] Train loss: 0.27480,Valid loss: 0.66496, time : 10.28220248222351 lr : 0.05995901467146548\n",
      "epoch : 280 [2/23] Train loss: 0.27414,Valid loss: 0.71166, time : 10.33193063735962 lr : 0.05995901467146548\n",
      "epoch : 280 [3/23] Train loss: 0.28132,Valid loss: 0.62289, time : 10.305082321166992 lr : 0.05995901467146548\n",
      "epoch : 280 [4/23] Train loss: 0.28336,Valid loss: 0.67324, time : 10.386869192123413 lr : 0.05995901467146548\n",
      "epoch : 280 [5/23] Train loss: 0.27218,Valid loss: 0.65585, time : 10.569070816040039 lr : 0.05995901467146548\n",
      "epoch : 280 [6/23] Train loss: 0.26597,Valid loss: 0.61741, time : 10.607264757156372 lr : 0.05995901467146548\n",
      "epoch : 280 [7/23] Train loss: 0.27941,Valid loss: 0.63052, time : 10.531813621520996 lr : 0.05995901467146548\n",
      "epoch : 280 [8/23] Train loss: 0.27511,Valid loss: 0.65444, time : 9.868494510650635 lr : 0.05995901467146548\n",
      "epoch : 280 [9/23] Train loss: 0.28751,Valid loss: 0.67868, time : 10.428484439849854 lr : 0.05995901467146548\n",
      "epoch : 280 [10/23] Train loss: 0.28765,Valid loss: 0.62874, time : 10.310779809951782 lr : 0.05995901467146548\n",
      "epoch : 280 [11/23] Train loss: 0.26944,Valid loss: 0.62680, time : 10.236180782318115 lr : 0.05995901467146548\n",
      "epoch : 280 [12/23] Train loss: 0.27966,Valid loss: 0.65946, time : 9.57744026184082 lr : 0.05995901467146548\n",
      "epoch : 280 [13/23] Train loss: 0.27547,Valid loss: 0.66976, time : 10.077436685562134 lr : 0.05995901467146548\n",
      "epoch : 280 [14/23] Train loss: 0.27832,Valid loss: 0.70334, time : 10.043795585632324 lr : 0.05995901467146548\n",
      "epoch : 280 [15/23] Train loss: 0.27417,Valid loss: 0.62318, time : 10.484240531921387 lr : 0.05995901467146548\n",
      "epoch : 280 [16/23] Train loss: 0.27185,Valid loss: 0.71317, time : 10.152308464050293 lr : 0.05995901467146548\n",
      "epoch : 280 [17/23] Train loss: 0.27547,Valid loss: 0.70629, time : 10.345703125 lr : 0.05995901467146548\n",
      "epoch : 280 [18/23] Train loss: 0.27280,Valid loss: 0.68172, time : 10.314533948898315 lr : 0.05995901467146548\n",
      "epoch : 280 [19/23] Train loss: 0.28523,Valid loss: 0.70893, time : 10.63164234161377 lr : 0.05995901467146548\n",
      "epoch : 280 [20/23] Train loss: 0.28253,Valid loss: 0.71793, time : 10.451042890548706 lr : 0.05995901467146548\n",
      "epoch : 280 [21/23] Train loss: 0.27462,Valid loss: 0.66555, time : 10.800300598144531 lr : 0.05995901467146548\n",
      "epoch : 280 [22/23] Train loss: 0.27617,Valid loss: 0.63502, time : 9.64674162864685 lr : 0.05995901467146548\n",
      "epoch : 281 [0/23] Train loss: 0.26770,Valid loss: 0.64011, time : 10.051097393035889 lr : 0.05935942452475082\n",
      "epoch : 281 [1/23] Train loss: 0.27288,Valid loss: 0.71013, time : 10.141311168670654 lr : 0.05935942452475082\n",
      "epoch : 281 [2/23] Train loss: 0.27422,Valid loss: 0.71631, time : 9.90489935874939 lr : 0.05935942452475082\n",
      "epoch : 281 [3/23] Train loss: 0.27963,Valid loss: 0.64040, time : 9.709984064102173 lr : 0.05935942452475082\n",
      "epoch : 281 [4/23] Train loss: 0.27231,Valid loss: 0.70743, time : 9.996303081512451 lr : 0.05935942452475082\n",
      "epoch : 281 [5/23] Train loss: 0.27517,Valid loss: 0.71671, time : 9.769148826599121 lr : 0.05935942452475082\n",
      "epoch : 281 [6/23] Train loss: 0.27578,Valid loss: 0.68643, time : 10.286848545074463 lr : 0.05935942452475082\n",
      "epoch : 281 [7/23] Train loss: 0.28332,Valid loss: 0.71527, time : 10.383655548095703 lr : 0.05935942452475082\n",
      "epoch : 281 [8/23] Train loss: 0.27897,Valid loss: 0.71557, time : 10.073455810546875 lr : 0.05935942452475082\n",
      "epoch : 281 [9/23] Train loss: 0.28087,Valid loss: 0.65386, time : 10.117044448852539 lr : 0.05935942452475082\n",
      "epoch : 281 [10/23] Train loss: 0.27191,Valid loss: 0.69988, time : 10.208181142807007 lr : 0.05935942452475082\n",
      "epoch : 281 [11/23] Train loss: 0.26883,Valid loss: 0.71958, time : 10.816994190216064 lr : 0.05935942452475082\n",
      "epoch : 281 [12/23] Train loss: 0.26536,Valid loss: 0.66676, time : 10.361146926879883 lr : 0.05935942452475082\n",
      "epoch : 281 [13/23] Train loss: 0.28347,Valid loss: 0.67378, time : 9.992940664291382 lr : 0.05935942452475082\n",
      "epoch : 281 [14/23] Train loss: 0.27003,Valid loss: 0.68961, time : 10.342672348022461 lr : 0.05935942452475082\n",
      "epoch : 281 [15/23] Train loss: 0.27827,Valid loss: 0.66759, time : 10.606149911880493 lr : 0.05935942452475082\n",
      "epoch : 281 [16/23] Train loss: 0.27024,Valid loss: 0.68404, time : 9.886781215667725 lr : 0.05935942452475082\n",
      "epoch : 281 [17/23] Train loss: 0.27858,Valid loss: 0.62457, time : 9.871459245681763 lr : 0.05935942452475082\n",
      "epoch : 281 [18/23] Train loss: 0.28010,Valid loss: 0.71922, time : 10.350392580032349 lr : 0.05935942452475082\n",
      "epoch : 281 [19/23] Train loss: 0.27221,Valid loss: 0.61874, time : 9.94282078742981 lr : 0.05935942452475082\n",
      "epoch : 281 [20/23] Train loss: 0.27844,Valid loss: 0.69732, time : 10.143234968185425 lr : 0.05935942452475082\n",
      "epoch : 281 [21/23] Train loss: 0.27587,Valid loss: 0.71163, time : 9.958680152893066 lr : 0.05935942452475082\n",
      "epoch : 281 [22/23] Train loss: 0.27749,Valid loss: 0.67789, time : 9.518603324890137 lr : 0.05935942452475082\n",
      "epoch : 282 [0/23] Train loss: 0.27644,Valid loss: 0.70999, time : 10.30286693572998 lr : 0.058765830279503314\n",
      "epoch : 282 [1/23] Train loss: 0.27466,Valid loss: 0.67958, time : 10.020435094833374 lr : 0.058765830279503314\n",
      "epoch : 282 [2/23] Train loss: 0.26807,Valid loss: 0.66404, time : 10.117305278778076 lr : 0.058765830279503314\n",
      "epoch : 282 [3/23] Train loss: 0.26969,Valid loss: 0.67225, time : 9.857051610946655 lr : 0.058765830279503314\n",
      "epoch : 282 [4/23] Train loss: 0.27877,Valid loss: 0.67571, time : 10.306904077529907 lr : 0.058765830279503314\n",
      "epoch : 282 [5/23] Train loss: 0.26749,Valid loss: 0.63699, time : 10.308778762817383 lr : 0.058765830279503314\n",
      "epoch : 282 [6/23] Train loss: 0.27694,Valid loss: 0.62365, time : 10.357727289199829 lr : 0.058765830279503314\n",
      "epoch : 282 [7/23] Train loss: 0.27981,Valid loss: 0.60038, time : 9.823089838027954 lr : 0.058765830279503314\n",
      "epoch : 282 [8/23] Train loss: 0.27009,Valid loss: 0.69786, time : 10.216463088989258 lr : 0.058765830279503314\n",
      "epoch : 282 [9/23] Train loss: 0.27716,Valid loss: 0.70328, time : 10.132590770721436 lr : 0.058765830279503314\n",
      "epoch : 282 [10/23] Train loss: 0.27535,Valid loss: 0.61669, time : 10.365222692489624 lr : 0.058765830279503314\n",
      "epoch : 282 [11/23] Train loss: 0.27263,Valid loss: 0.69432, time : 10.242181062698364 lr : 0.058765830279503314\n",
      "epoch : 282 [12/23] Train loss: 0.27985,Valid loss: 0.63415, time : 10.620541334152222 lr : 0.058765830279503314\n",
      "epoch : 282 [13/23] Train loss: 0.27305,Valid loss: 0.62910, time : 10.294734239578247 lr : 0.058765830279503314\n",
      "epoch : 282 [14/23] Train loss: 0.27822,Valid loss: 0.69271, time : 10.31224513053894 lr : 0.058765830279503314\n",
      "epoch : 282 [15/23] Train loss: 0.27729,Valid loss: 0.70128, time : 10.425456762313843 lr : 0.058765830279503314\n",
      "epoch : 282 [16/23] Train loss: 0.27089,Valid loss: 0.71147, time : 10.057332277297974 lr : 0.058765830279503314\n",
      "epoch : 282 [17/23] Train loss: 0.26721,Valid loss: 0.69424, time : 10.160070657730103 lr : 0.058765830279503314\n",
      "epoch : 282 [18/23] Train loss: 0.29356,Valid loss: 0.71502, time : 10.745052576065063 lr : 0.058765830279503314\n",
      "epoch : 282 [19/23] Train loss: 0.26943,Valid loss: 0.69365, time : 10.400785207748413 lr : 0.058765830279503314\n",
      "epoch : 282 [20/23] Train loss: 0.26549,Valid loss: 0.64503, time : 10.5152006149292 lr : 0.058765830279503314\n",
      "epoch : 282 [21/23] Train loss: 0.27743,Valid loss: 0.67555, time : 10.618403434753418 lr : 0.058765830279503314\n",
      "epoch : 282 [22/23] Train loss: 0.26938,Valid loss: 0.69222, time : 9.759251117706299 lr : 0.058765830279503314\n",
      "epoch : 283 [0/23] Train loss: 0.28447,Valid loss: 0.68026, time : 9.982869148254395 lr : 0.05817817197670828\n",
      "epoch : 283 [1/23] Train loss: 0.26472,Valid loss: 0.70469, time : 10.097547054290771 lr : 0.05817817197670828\n",
      "epoch : 283 [2/23] Train loss: 0.27538,Valid loss: 0.59683, time : 9.66315245628357 lr : 0.05817817197670828\n",
      "epoch : 283 [3/23] Train loss: 0.28301,Valid loss: 0.70915, time : 9.866992473602295 lr : 0.05817817197670828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 283 [4/23] Train loss: 0.28284,Valid loss: 0.71008, time : 10.013160228729248 lr : 0.05817817197670828\n",
      "epoch : 283 [5/23] Train loss: 0.27734,Valid loss: 0.67080, time : 10.561294555664062 lr : 0.05817817197670828\n",
      "epoch : 283 [6/23] Train loss: 0.27674,Valid loss: 0.64749, time : 10.174068212509155 lr : 0.05817817197670828\n",
      "epoch : 283 [7/23] Train loss: 0.27013,Valid loss: 0.63365, time : 9.932427406311035 lr : 0.05817817197670828\n",
      "epoch : 283 [8/23] Train loss: 0.28788,Valid loss: 0.68193, time : 10.078747034072876 lr : 0.05817817197670828\n",
      "epoch : 283 [9/23] Train loss: 0.27804,Valid loss: 0.67826, time : 10.39067816734314 lr : 0.05817817197670828\n",
      "epoch : 283 [10/23] Train loss: 0.27186,Valid loss: 0.70812, time : 10.081612825393677 lr : 0.05817817197670828\n",
      "epoch : 283 [11/23] Train loss: 0.26919,Valid loss: 0.62740, time : 10.192925214767456 lr : 0.05817817197670828\n",
      "epoch : 283 [12/23] Train loss: 0.26814,Valid loss: 0.70815, time : 9.762565851211548 lr : 0.05817817197670828\n",
      "epoch : 283 [13/23] Train loss: 0.27067,Valid loss: 0.70935, time : 9.658971309661865 lr : 0.05817817197670828\n",
      "epoch : 283 [14/23] Train loss: 0.27690,Valid loss: 0.67633, time : 10.17290210723877 lr : 0.05817817197670828\n",
      "epoch : 283 [15/23] Train loss: 0.27402,Valid loss: 0.62316, time : 9.656282186508179 lr : 0.05817817197670828\n",
      "epoch : 283 [16/23] Train loss: 0.27421,Valid loss: 0.71786, time : 9.643058061599731 lr : 0.05817817197670828\n",
      "epoch : 283 [17/23] Train loss: 0.26884,Valid loss: 0.68373, time : 9.733257293701172 lr : 0.05817817197670828\n",
      "epoch : 283 [18/23] Train loss: 0.27598,Valid loss: 0.70314, time : 10.273017644882202 lr : 0.05817817197670828\n",
      "epoch : 283 [19/23] Train loss: 0.27103,Valid loss: 0.65370, time : 10.562464714050293 lr : 0.05817817197670828\n",
      "epoch : 283 [20/23] Train loss: 0.27163,Valid loss: 0.70646, time : 9.96062445640564 lr : 0.05817817197670828\n",
      "epoch : 283 [21/23] Train loss: 0.26911,Valid loss: 0.66335, time : 9.857408285140991 lr : 0.05817817197670828\n",
      "epoch : 283 [22/23] Train loss: 0.27262,Valid loss: 0.70250, time : 9.577744245529175 lr : 0.05817817197670828\n",
      "epoch : 284 [0/23] Train loss: 0.28413,Valid loss: 0.61954, time : 9.837326049804688 lr : 0.057596390256941195\n",
      "epoch : 284 [1/23] Train loss: 0.28381,Valid loss: 0.70051, time : 9.99655532836914 lr : 0.057596390256941195\n",
      "epoch : 284 [2/23] Train loss: 0.27886,Valid loss: 0.69671, time : 9.999072313308716 lr : 0.057596390256941195\n",
      "epoch : 284 [3/23] Train loss: 0.27545,Valid loss: 0.66505, time : 10.075172662734985 lr : 0.057596390256941195\n",
      "epoch : 284 [4/23] Train loss: 0.27234,Valid loss: 0.68644, time : 9.79170274734497 lr : 0.057596390256941195\n",
      "epoch : 284 [5/23] Train loss: 0.27638,Valid loss: 0.70242, time : 10.157516717910767 lr : 0.057596390256941195\n",
      "epoch : 284 [6/23] Train loss: 0.27336,Valid loss: 0.67744, time : 9.691352128982544 lr : 0.057596390256941195\n",
      "epoch : 284 [7/23] Train loss: 0.27239,Valid loss: 0.66836, time : 10.422153234481812 lr : 0.057596390256941195\n",
      "epoch : 284 [8/23] Train loss: 0.26685,Valid loss: 0.71088, time : 9.950751781463623 lr : 0.057596390256941195\n",
      "epoch : 284 [9/23] Train loss: 0.26465,Valid loss: 0.70218, time : 9.981693267822266 lr : 0.057596390256941195\n",
      "epoch : 284 [10/23] Train loss: 0.26463,Valid loss: 0.68088, time : 9.958927154541016 lr : 0.057596390256941195\n",
      "epoch : 284 [11/23] Train loss: 0.27967,Valid loss: 0.68140, time : 10.070751905441284 lr : 0.057596390256941195\n",
      "epoch : 284 [12/23] Train loss: 0.27130,Valid loss: 0.66007, time : 9.753161668777466 lr : 0.057596390256941195\n",
      "epoch : 284 [13/23] Train loss: 0.27361,Valid loss: 0.64820, time : 10.090608835220337 lr : 0.057596390256941195\n",
      "epoch : 284 [14/23] Train loss: 0.27323,Valid loss: 0.66889, time : 10.26973581314087 lr : 0.057596390256941195\n",
      "epoch : 284 [15/23] Train loss: 0.27283,Valid loss: 0.62420, time : 10.081800937652588 lr : 0.057596390256941195\n",
      "epoch : 284 [16/23] Train loss: 0.28056,Valid loss: 0.65627, time : 10.308691024780273 lr : 0.057596390256941195\n",
      "epoch : 284 [17/23] Train loss: 0.26628,Valid loss: 0.62217, time : 9.84909725189209 lr : 0.057596390256941195\n",
      "epoch : 284 [18/23] Train loss: 0.27458,Valid loss: 0.66886, time : 10.025484085083008 lr : 0.057596390256941195\n",
      "epoch : 284 [19/23] Train loss: 0.27173,Valid loss: 0.63365, time : 10.301361560821533 lr : 0.057596390256941195\n",
      "epoch : 284 [20/23] Train loss: 0.27261,Valid loss: 0.66330, time : 10.12067437171936 lr : 0.057596390256941195\n",
      "epoch : 284 [21/23] Train loss: 0.27182,Valid loss: 0.72316, time : 9.975217342376709 lr : 0.057596390256941195\n",
      "epoch : 284 [22/23] Train loss: 0.27710,Valid loss: 0.62958, time : 9.299601554870605 lr : 0.057596390256941195\n",
      "epoch : 285 [0/23] Train loss: 0.26683,Valid loss: 0.63457, time : 10.449644565582275 lr : 0.05702042635437178\n",
      "epoch : 285 [1/23] Train loss: 0.27300,Valid loss: 0.62181, time : 10.01116156578064 lr : 0.05702042635437178\n",
      "epoch : 285 [2/23] Train loss: 0.27625,Valid loss: 0.62517, time : 10.004891395568848 lr : 0.05702042635437178\n",
      "epoch : 285 [3/23] Train loss: 0.27152,Valid loss: 0.61927, time : 10.125772953033447 lr : 0.05702042635437178\n",
      "epoch : 285 [4/23] Train loss: 0.26026,Valid loss: 0.66849, time : 9.784512758255005 lr : 0.05702042635437178\n",
      "epoch : 285 [5/23] Train loss: 0.28669,Valid loss: 0.61577, time : 10.016967296600342 lr : 0.05702042635437178\n",
      "epoch : 285 [6/23] Train loss: 0.26592,Valid loss: 0.70823, time : 10.164257764816284 lr : 0.05702042635437178\n",
      "epoch : 285 [7/23] Train loss: 0.26586,Valid loss: 0.62654, time : 9.923772096633911 lr : 0.05702042635437178\n",
      "epoch : 285 [8/23] Train loss: 0.28034,Valid loss: 0.69629, time : 10.267897129058838 lr : 0.05702042635437178\n",
      "epoch : 285 [9/23] Train loss: 0.28558,Valid loss: 0.65383, time : 10.3875732421875 lr : 0.05702042635437178\n",
      "epoch : 285 [10/23] Train loss: 0.27602,Valid loss: 0.67443, time : 10.222018957138062 lr : 0.05702042635437178\n",
      "epoch : 285 [11/23] Train loss: 0.27259,Valid loss: 0.70970, time : 9.816080093383789 lr : 0.05702042635437178\n",
      "epoch : 285 [12/23] Train loss: 0.27938,Valid loss: 0.60799, time : 10.269701957702637 lr : 0.05702042635437178\n",
      "epoch : 285 [13/23] Train loss: 0.28803,Valid loss: 0.61690, time : 9.962498664855957 lr : 0.05702042635437178\n",
      "epoch : 285 [14/23] Train loss: 0.27879,Valid loss: 0.70210, time : 10.561914920806885 lr : 0.05702042635437178\n",
      "epoch : 285 [15/23] Train loss: 0.27236,Valid loss: 0.68303, time : 10.227648973464966 lr : 0.05702042635437178\n",
      "epoch : 285 [16/23] Train loss: 0.26856,Valid loss: 0.71276, time : 10.114028453826904 lr : 0.05702042635437178\n",
      "epoch : 285 [17/23] Train loss: 0.26967,Valid loss: 0.70021, time : 10.280982255935669 lr : 0.05702042635437178\n",
      "epoch : 285 [18/23] Train loss: 0.26700,Valid loss: 0.67629, time : 10.333115816116333 lr : 0.05702042635437178\n",
      "epoch : 285 [19/23] Train loss: 0.28296,Valid loss: 0.68292, time : 10.343256950378418 lr : 0.05702042635437178\n",
      "epoch : 285 [20/23] Train loss: 0.26379,Valid loss: 0.60436, time : 10.343705892562866 lr : 0.05702042635437178\n",
      "epoch : 285 [21/23] Train loss: 0.26363,Valid loss: 0.61367, time : 10.487264156341553 lr : 0.05702042635437178\n",
      "epoch : 285 [22/23] Train loss: 0.27272,Valid loss: 0.60780, time : 9.85357117652893 lr : 0.05702042635437178\n",
      "epoch : 286 [0/23] Train loss: 0.27447,Valid loss: 0.59917, time : 10.651392459869385 lr : 0.05645022209082806\n",
      "epoch : 286 [1/23] Train loss: 0.26799,Valid loss: 0.66072, time : 10.260767698287964 lr : 0.05645022209082806\n",
      "epoch : 286 [2/23] Train loss: 0.27657,Valid loss: 0.60388, time : 10.71059274673462 lr : 0.05645022209082806\n",
      "epoch : 286 [3/23] Train loss: 0.26884,Valid loss: 0.71337, time : 10.196457147598267 lr : 0.05645022209082806\n",
      "epoch : 286 [4/23] Train loss: 0.27221,Valid loss: 0.68694, time : 10.288991451263428 lr : 0.05645022209082806\n",
      "epoch : 286 [5/23] Train loss: 0.27793,Valid loss: 0.63954, time : 10.315914869308472 lr : 0.05645022209082806\n",
      "epoch : 286 [6/23] Train loss: 0.27446,Valid loss: 0.70128, time : 10.52234411239624 lr : 0.05645022209082806\n",
      "epoch : 286 [7/23] Train loss: 0.27391,Valid loss: 0.70085, time : 10.544830560684204 lr : 0.05645022209082806\n",
      "epoch : 286 [8/23] Train loss: 0.27174,Valid loss: 0.66179, time : 10.60800576210022 lr : 0.05645022209082806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 286 [9/23] Train loss: 0.27442,Valid loss: 0.71830, time : 10.355611085891724 lr : 0.05645022209082806\n",
      "epoch : 286 [10/23] Train loss: 0.27684,Valid loss: 0.70360, time : 10.39570927619934 lr : 0.05645022209082806\n",
      "epoch : 286 [11/23] Train loss: 0.27178,Valid loss: 0.73080, time : 10.574519634246826 lr : 0.05645022209082806\n",
      "epoch : 286 [12/23] Train loss: 0.27833,Valid loss: 0.71959, time : 10.179269552230835 lr : 0.05645022209082806\n",
      "epoch : 286 [13/23] Train loss: 0.27218,Valid loss: 0.62424, time : 10.291951417922974 lr : 0.05645022209082806\n",
      "epoch : 286 [14/23] Train loss: 0.27176,Valid loss: 0.71332, time : 10.16816258430481 lr : 0.05645022209082806\n",
      "epoch : 286 [15/23] Train loss: 0.26611,Valid loss: 0.72021, time : 10.230946063995361 lr : 0.05645022209082806\n",
      "epoch : 286 [16/23] Train loss: 0.27372,Valid loss: 0.70495, time : 10.37497067451477 lr : 0.05645022209082806\n",
      "epoch : 286 [17/23] Train loss: 0.26529,Valid loss: 0.66787, time : 10.093690156936646 lr : 0.05645022209082806\n",
      "epoch : 286 [18/23] Train loss: 0.27084,Valid loss: 0.71465, time : 10.122525453567505 lr : 0.05645022209082806\n",
      "epoch : 286 [19/23] Train loss: 0.26823,Valid loss: 0.62829, time : 9.718457460403442 lr : 0.05645022209082806\n",
      "epoch : 286 [20/23] Train loss: 0.27846,Valid loss: 0.66661, time : 10.311829805374146 lr : 0.05645022209082806\n",
      "epoch : 286 [21/23] Train loss: 0.25938,Valid loss: 0.62101, time : 10.285117387771606 lr : 0.05645022209082806\n",
      "epoch : 286 [22/23] Train loss: 0.26892,Valid loss: 0.63029, time : 9.652288436889648 lr : 0.05645022209082806\n",
      "epoch : 287 [0/23] Train loss: 0.26919,Valid loss: 0.62855, time : 10.500890731811523 lr : 0.05588571986991978\n",
      "epoch : 287 [1/23] Train loss: 0.26240,Valid loss: 0.62680, time : 9.870356559753418 lr : 0.05588571986991978\n",
      "epoch : 287 [2/23] Train loss: 0.27715,Valid loss: 0.67022, time : 10.13997220993042 lr : 0.05588571986991978\n",
      "epoch : 287 [3/23] Train loss: 0.27383,Valid loss: 0.62255, time : 10.465340852737427 lr : 0.05588571986991978\n",
      "epoch : 287 [4/23] Train loss: 0.27409,Valid loss: 0.64192, time : 10.606619358062744 lr : 0.05588571986991978\n",
      "epoch : 287 [5/23] Train loss: 0.27318,Valid loss: 0.68042, time : 10.273139476776123 lr : 0.05588571986991978\n",
      "epoch : 287 [6/23] Train loss: 0.27569,Valid loss: 0.63711, time : 10.175672769546509 lr : 0.05588571986991978\n",
      "epoch : 287 [7/23] Train loss: 0.27898,Valid loss: 0.62402, time : 10.183248281478882 lr : 0.05588571986991978\n",
      "epoch : 287 [8/23] Train loss: 0.27777,Valid loss: 0.69943, time : 10.097971200942993 lr : 0.05588571986991978\n",
      "epoch : 287 [9/23] Train loss: 0.27378,Valid loss: 0.67762, time : 10.042922735214233 lr : 0.05588571986991978\n",
      "epoch : 287 [10/23] Train loss: 0.26384,Valid loss: 0.67912, time : 10.277834177017212 lr : 0.05588571986991978\n",
      "epoch : 287 [11/23] Train loss: 0.27201,Valid loss: 0.62941, time : 10.040149450302124 lr : 0.05588571986991978\n",
      "epoch : 287 [12/23] Train loss: 0.26363,Valid loss: 0.67755, time : 9.679195880889893 lr : 0.05588571986991978\n",
      "epoch : 287 [13/23] Train loss: 0.27140,Valid loss: 0.71694, time : 10.158846378326416 lr : 0.05588571986991978\n",
      "epoch : 287 [14/23] Train loss: 0.27746,Valid loss: 0.70449, time : 10.17978811264038 lr : 0.05588571986991978\n",
      "epoch : 287 [15/23] Train loss: 0.27675,Valid loss: 0.72640, time : 9.85374116897583 lr : 0.05588571986991978\n",
      "epoch : 287 [16/23] Train loss: 0.27490,Valid loss: 0.71023, time : 10.143415212631226 lr : 0.05588571986991978\n",
      "epoch : 287 [17/23] Train loss: 0.27685,Valid loss: 0.63748, time : 10.307384014129639 lr : 0.05588571986991978\n",
      "epoch : 287 [18/23] Train loss: 0.25799,Valid loss: 0.70791, time : 10.262584924697876 lr : 0.05588571986991978\n",
      "epoch : 287 [19/23] Train loss: 0.27005,Valid loss: 0.71555, time : 10.745070695877075 lr : 0.05588571986991978\n",
      "epoch : 287 [20/23] Train loss: 0.26545,Valid loss: 0.71862, time : 9.971288919448853 lr : 0.05588571986991978\n",
      "epoch : 287 [21/23] Train loss: 0.27462,Valid loss: 0.71900, time : 10.374475002288818 lr : 0.05588571986991978\n",
      "epoch : 287 [22/23] Train loss: 0.27625,Valid loss: 0.61153, time : 9.385013341903687 lr : 0.05588571986991978\n",
      "epoch : 288 [0/23] Train loss: 0.27514,Valid loss: 0.62851, time : 10.534027576446533 lr : 0.055326862671220584\n",
      "epoch : 288 [1/23] Train loss: 0.28422,Valid loss: 0.62577, time : 10.102896213531494 lr : 0.055326862671220584\n",
      "epoch : 288 [2/23] Train loss: 0.26381,Valid loss: 0.71340, time : 10.139878511428833 lr : 0.055326862671220584\n",
      "epoch : 288 [3/23] Train loss: 0.27073,Valid loss: 0.72833, time : 10.04638147354126 lr : 0.055326862671220584\n",
      "epoch : 288 [4/23] Train loss: 0.27492,Valid loss: 0.71697, time : 10.167277336120605 lr : 0.055326862671220584\n",
      "epoch : 288 [5/23] Train loss: 0.27001,Valid loss: 0.65624, time : 9.937010049819946 lr : 0.055326862671220584\n",
      "epoch : 288 [6/23] Train loss: 0.26467,Valid loss: 0.69484, time : 9.849191427230835 lr : 0.055326862671220584\n",
      "epoch : 288 [7/23] Train loss: 0.26623,Valid loss: 0.69573, time : 10.134510517120361 lr : 0.055326862671220584\n",
      "epoch : 288 [8/23] Train loss: 0.26895,Valid loss: 0.72150, time : 10.301562547683716 lr : 0.055326862671220584\n",
      "epoch : 288 [9/23] Train loss: 0.27091,Valid loss: 0.62529, time : 10.298420429229736 lr : 0.055326862671220584\n",
      "epoch : 288 [10/23] Train loss: 0.26753,Valid loss: 0.70766, time : 10.12162733078003 lr : 0.055326862671220584\n",
      "epoch : 288 [11/23] Train loss: 0.26829,Valid loss: 0.62363, time : 10.237030506134033 lr : 0.055326862671220584\n",
      "epoch : 288 [12/23] Train loss: 0.27258,Valid loss: 0.66937, time : 10.223397016525269 lr : 0.055326862671220584\n",
      "epoch : 288 [13/23] Train loss: 0.27974,Valid loss: 0.71134, time : 10.20424747467041 lr : 0.055326862671220584\n",
      "epoch : 288 [14/23] Train loss: 0.27647,Valid loss: 0.70145, time : 10.207730293273926 lr : 0.055326862671220584\n",
      "epoch : 288 [15/23] Train loss: 0.27968,Valid loss: 0.63190, time : 10.074244499206543 lr : 0.055326862671220584\n",
      "epoch : 288 [16/23] Train loss: 0.27709,Valid loss: 0.62985, time : 9.900493383407593 lr : 0.055326862671220584\n",
      "epoch : 288 [17/23] Train loss: 0.27081,Valid loss: 0.68903, time : 10.072378635406494 lr : 0.055326862671220584\n",
      "epoch : 288 [18/23] Train loss: 0.27711,Valid loss: 0.62808, time : 9.97594928741455 lr : 0.055326862671220584\n",
      "epoch : 288 [19/23] Train loss: 0.26817,Valid loss: 0.71228, time : 10.278697490692139 lr : 0.055326862671220584\n",
      "epoch : 288 [20/23] Train loss: 0.26340,Valid loss: 0.70418, time : 10.180291652679443 lr : 0.055326862671220584\n",
      "epoch : 288 [21/23] Train loss: 0.26050,Valid loss: 0.67601, time : 10.197409868240356 lr : 0.055326862671220584\n",
      "epoch : 288 [22/23] Train loss: 0.27202,Valid loss: 0.62823, time : 9.638469219207764 lr : 0.055326862671220584\n",
      "epoch : 289 [0/23] Train loss: 0.25740,Valid loss: 0.69433, time : 10.462006092071533 lr : 0.05477359404450838\n",
      "epoch : 289 [1/23] Train loss: 0.27355,Valid loss: 0.69510, time : 10.210615158081055 lr : 0.05477359404450838\n",
      "epoch : 289 [2/23] Train loss: 0.26385,Valid loss: 0.71158, time : 9.75028133392334 lr : 0.05477359404450838\n",
      "epoch : 289 [3/23] Train loss: 0.28019,Valid loss: 0.70758, time : 10.113356590270996 lr : 0.05477359404450838\n",
      "epoch : 289 [4/23] Train loss: 0.26810,Valid loss: 0.68364, time : 9.975584030151367 lr : 0.05477359404450838\n",
      "epoch : 289 [5/23] Train loss: 0.26715,Valid loss: 0.66837, time : 10.049894332885742 lr : 0.05477359404450838\n",
      "epoch : 289 [6/23] Train loss: 0.26565,Valid loss: 0.62815, time : 10.205644845962524 lr : 0.05477359404450838\n",
      "epoch : 289 [7/23] Train loss: 0.26310,Valid loss: 0.62788, time : 9.911672592163086 lr : 0.05477359404450838\n",
      "epoch : 289 [8/23] Train loss: 0.27330,Valid loss: 0.64119, time : 9.625086307525635 lr : 0.05477359404450838\n",
      "epoch : 289 [9/23] Train loss: 0.26701,Valid loss: 0.67854, time : 9.98537802696228 lr : 0.05477359404450838\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "from utils import CTCLabelConverter, CTCLabelConverterForBaiduWarpctc, AttnLabelConverter, Averager\n",
    "from c_dataset import custom_Batch_Balanced_Dataset,custom_dataset,AlignCollate\n",
    "from model import Model\n",
    "from test import validation\n",
    "import easydict\n",
    "global opt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "global opt\n",
    "opt = easydict.EasyDict({\n",
    "    \"exp_name\": \"test_01\",\n",
    "    \"train_data\": \"/data/data/STARN/data_lmdb_release/training\",\n",
    "    \"valid_data\":\"/data/data/STARN/data_lmdb_release/validation\",\n",
    "    \"manualSeed\": 1111,\n",
    "    \"workers\": 8,\n",
    "    \"batch_size\":1024,\n",
    "    \"num_iter\":300000,\n",
    "    \"valInterval\":1,\n",
    "    \"saved_model\":'',\n",
    "    \"FT\":False,\n",
    "    \"adam\":False,\n",
    "    \"lr\":1,\n",
    "    \"beta1\":0.9,\n",
    "    \"rho\":0.95,\n",
    "    \"eps\":1e-8,\n",
    "    \"grad_clip\":5,\n",
    "    \"baiduCTC\":False,\n",
    "    \"select_data\":'ST',\n",
    "    \"batch_ratio\":'1',\n",
    "    \"total_data_usage_ratio\":'1.0',\n",
    "    \"batch_max_length\":25,\n",
    "    \"imgW\":100,\n",
    "    \"imgH\":32,\n",
    "    \"rgb\":False,\n",
    "    \"character\":\"0123456789abcdefghijklmnopqrstuvwxyz\",\n",
    "    \"sensitive\":False,\n",
    "    \"PAD\":False,\n",
    "    \"data_filtering_off\":False,\n",
    "    \"Transformation\":\"TPS\",\n",
    "    \"FeatureExtraction\":\"ResNet\",\n",
    "    \"SequenceModeling\":\"BiLSTM\",\n",
    "    \"Prediction\":'Attn',\n",
    "    \"num_fiducial\":20,\n",
    "    \"input_channel\":1,\n",
    "    \"output_channel\":512,\n",
    "    \"hidden_size\":256    \n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def validation(model, criterion, evaluation_loader, converter, opt):\n",
    "    \"\"\" validation or evaluation \"\"\"\n",
    "    n_correct = 0\n",
    "    norm_ED = 0\n",
    "    length_of_data = 0\n",
    "    infer_time = 0\n",
    "    valid_loss_avg = Averager()\n",
    "\n",
    "    for i, (image_tensors, labels) in enumerate(evaluation_loader):\n",
    "        batch_size = image_tensors.size(0)\n",
    "        length_of_data = length_of_data + batch_size\n",
    "        image = image_tensors.to(device)\n",
    "        # For max length prediction\n",
    "        length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)\n",
    "        text_for_pred = torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)\n",
    "\n",
    "        text_for_loss, length_for_loss = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
    "\n",
    "        start_time = time.time()\n",
    "        if 'CTC' in opt.Prediction:\n",
    "            preds = model(image, text_for_pred)\n",
    "            forward_time = time.time() - start_time\n",
    "\n",
    "            # Calculate evaluation loss for CTC deocder.\n",
    "            preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
    "            # permute 'preds' to use CTCloss format\n",
    "            if opt.baiduCTC:\n",
    "                cost = criterion(preds.permute(1, 0, 2), text_for_loss, preds_size, length_for_loss) / batch_size\n",
    "            else:\n",
    "                cost = criterion(preds.log_softmax(2).permute(1, 0, 2), text_for_loss, preds_size, length_for_loss)\n",
    "\n",
    "            # Select max probabilty (greedy decoding) then decode index to character\n",
    "            if opt.baiduCTC:\n",
    "                _, preds_index = preds.max(2)\n",
    "                preds_index = preds_index.view(-1)\n",
    "            else:\n",
    "                _, preds_index = preds.max(2)\n",
    "            preds_str = converter.decode(preds_index.data, preds_size.data)\n",
    "        \n",
    "        else:\n",
    "            preds = model(image, text_for_pred, is_train=False)\n",
    "            forward_time = time.time() - start_time\n",
    "\n",
    "            preds = preds[:, :text_for_loss.shape[1] - 1, :]\n",
    "            target = text_for_loss[:, 1:]  # without [GO] Symbol\n",
    "            cost = criterion(preds.contiguous().view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "\n",
    "            # select max probabilty (greedy decoding) then decode index to character\n",
    "            _, preds_index = preds.max(2)\n",
    "            preds_str = converter.decode(preds_index, length_for_pred)\n",
    "            labels = converter.decode(text_for_loss[:, 1:], length_for_loss)\n",
    "\n",
    "        infer_time += forward_time\n",
    "        valid_loss_avg.add(cost)\n",
    "\n",
    "        # calculate accuracy & confidence score\n",
    "        preds_prob = F.softmax(preds, dim=2)\n",
    "        preds_max_prob, _ = preds_prob.max(dim=2)\n",
    "        confidence_score_list = []\n",
    "        for gt, pred, pred_max_prob in zip(labels, preds_str, preds_max_prob):\n",
    "            if 'Attn' in opt.Prediction:\n",
    "                gt = gt[:gt.find('[s]')]\n",
    "                pred_EOS = pred.find('[s]')\n",
    "                pred = pred[:pred_EOS]  # prune after \"end of sentence\" token ([s])\n",
    "                pred_max_prob = pred_max_prob[:pred_EOS]\n",
    "\n",
    "\n",
    "            if pred == gt:\n",
    "                n_correct += 1\n",
    "\n",
    "            '''\n",
    "            (old version) ICDAR2017 DOST Normalized Edit Distance https://rrc.cvc.uab.es/?ch=7&com=tasks\n",
    "            \"For each word we calculate the normalized edit distance to the length of the ground truth transcription.\"\n",
    "            if len(gt) == 0:\n",
    "                norm_ED += 1\n",
    "            else:\n",
    "                norm_ED += edit_distance(pred, gt) / len(gt)\n",
    "            '''\n",
    "\n",
    "            # ICDAR2019 Normalized Edit Distance\n",
    "            if len(gt) == 0 or len(pred) == 0:\n",
    "                norm_ED += 0\n",
    "            elif len(gt) > len(pred):\n",
    "                norm_ED += 1 - edit_distance(pred, gt) / len(gt)\n",
    "            else:\n",
    "                norm_ED += 1 - edit_distance(pred, gt) / len(pred)\n",
    "\n",
    "            # calculate confidence score (= multiply of pred_max_prob)\n",
    "            try:\n",
    "                confidence_score = pred_max_prob.cumprod(dim=0)[-1]\n",
    "            except:\n",
    "                confidence_score = 0  # for empty pred case, when prune after \"end of sentence\" token ([s])\n",
    "            confidence_score_list.append(confidence_score)\n",
    "            # print(pred, gt, pred==gt, confidence_score)\n",
    "\n",
    "    accuracy = n_correct / float(length_of_data) * 100\n",
    "    norm_ED = norm_ED / float(length_of_data)  # ICDAR2019 Normalized Edit Distance\n",
    "\n",
    "    return valid_loss_avg.val(), accuracy, norm_ED, preds_str, confidence_score_list, labels, infer_time, length_of_data\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \"\"\" Seed and GPU setting \"\"\"\n",
    "    # print(\"Random Seed: \", opt.manualSeed)\n",
    "    random.seed(opt.manualSeed)\n",
    "    np.random.seed(opt.manualSeed)\n",
    "    torch.manual_seed(opt.manualSeed)\n",
    "    torch.cuda.manual_seed(opt.manualSeed)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True\n",
    "    opt.num_gpu = torch.cuda.device_count()\n",
    "    # print('device count', opt.num_gpu)\n",
    "    if opt.num_gpu > 1:\n",
    "        print('------ Use multi-GPU setting ------')\n",
    "        print('if you stuck too long time with multi-GPU setting, try to set --workers 0')\n",
    "        # check multi-GPU issue https://github.com/clovaai/deep-text-recognition-benchmark/issues/1\n",
    "        opt.workers = opt.workers * opt.num_gpu\n",
    "        opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    numclass_path = \"/data/work_dir/img/generate_text_ko/mrjaehong_text_generation/generate_img/ch_range.txt\"\n",
    "    f = open(numclass_path, 'r')\n",
    "    ch_temp = f.read()\n",
    "    f.close()\n",
    "    opt.character = ch_temp\n",
    "\n",
    "    converter = AttnLabelConverter(opt.character)\n",
    "    opt.num_class = len(converter.character)\n",
    "\n",
    "\n",
    "\n",
    "    train_dataset = custom_dataset(\"/data/work_dir/img/generate_text_ko/mrjaehong_text_generation/generate_img/label.csv\")\n",
    "    valid_dataset = custom_dataset(\"/data/work_dir/img/generate_text_ko/mrjaehong_text_generation/generate_img_val/label.csv\")\n",
    "\n",
    "    AlignCollate_valid = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=opt.batch_size,\n",
    "            shuffle=True,  # 'True' to check training progress with validation function.\n",
    "            num_workers=int(opt.workers),\n",
    "            collate_fn=AlignCollate_valid, pin_memory=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=opt.batch_size,\n",
    "            shuffle=True,  # 'True' to check training progress with validation function.\n",
    "            num_workers=int(opt.workers),\n",
    "            collate_fn=AlignCollate_valid, pin_memory=True)\n",
    "\n",
    "\n",
    "    if opt.rgb:\n",
    "        opt.input_channel = 3\n",
    "    model = Model(opt)\n",
    "\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'localization_fc2' in name:\n",
    "            print(f'Skip {name} as it is already initialized')\n",
    "            continue\n",
    "        try:\n",
    "            if 'bias' in name:\n",
    "                init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                init.kaiming_normal_(param)\n",
    "        except Exception as e:  # for batchnorm.\n",
    "            if 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            continue\n",
    "\n",
    "\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "\n",
    "\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "\n",
    "    loss_avg = Averager()\n",
    "\n",
    "\n",
    "    filtered_parameters = []\n",
    "\n",
    "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "        filtered_parameters.append(p)\n",
    "\n",
    "\n",
    "    if opt.adam:\n",
    "#         optimizer = optim.Adam(filtered_parameters, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "        optimizer = optim.Adam(filtered_parameters, lr=opt.lr)\n",
    "    else:\n",
    "        optimizer = optim.Adadelta(filtered_parameters, lr=opt.lr, rho=opt.rho, eps=opt.eps)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "    \n",
    "    nb_epochs = 100000\n",
    "\n",
    "    for epoch in range(nb_epochs + 1):\n",
    "        \n",
    "        for batch_idx, samples in enumerate(train_loader):\n",
    "\n",
    "            log = open(f'./log_val.txt', 'a')\n",
    "            log2= open(f'./log_train.txt', 'a')\n",
    "\n",
    "            start_time = time.time()        \n",
    "            model.train()\n",
    "\n",
    "            image_tensors, labels = samples\n",
    "            image = image_tensors.to(device)\n",
    "            text, length = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            preds = model(image, text[:, :-1])  # align with Attention.forward\n",
    "            target = text[:, 1:]  # without [GO] Symbol\n",
    "            cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "\n",
    "\n",
    "\n",
    "            model.zero_grad()\n",
    "            cost.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip)  # gradient clipping with 5 (Default)\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_avg.add(cost)\n",
    "\n",
    "            for param_group in optimizer.param_groups:\n",
    "                learning_rate_val=param_group['lr']\n",
    "\n",
    "\n",
    "            ## 평가\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_loss, current_accuracy, current_norm_ED, preds, confidence_score, labels, infer_time, length_of_data = validation(\n",
    "                            model, criterion, valid_loader, converter, opt)\n",
    "\n",
    "            end = time.time()\n",
    "            loss_log = f'epoch : {epoch} [{batch_idx}/{len(train_loader)}] Train loss: {loss_avg.val():0.5f},Valid loss: {valid_loss:0.5f}, time : {end-start_time} lr : {learning_rate_val}'        \n",
    "            loss_avg.reset()\n",
    "\n",
    "\n",
    "            print(loss_log)\n",
    "\n",
    "            dashed_line = '-' * 80\n",
    "            head = f'{\"Ground Truth\":25s} | {\"Prediction\":25s} | Confidence Score & T/F'\n",
    "            predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
    "            for gt, pred, confidence in zip(labels[:5], preds[:5], confidence_score[:5]):\n",
    "                if 'Attn' in opt.Prediction:\n",
    "                    gt = gt[:gt.find('[s]')]\n",
    "                    pred = pred[:pred.find('[s]')]\n",
    "\n",
    "                predicted_result_log += f'{gt:25s} | {pred:25s} | {confidence:0.4f}\\t{str(pred == gt)}\\n'\n",
    "            predicted_result_log += f'{dashed_line}'\n",
    "    #         print(predicted_result_log)\n",
    "            \n",
    "            log2.write(loss_log + '\\n')\n",
    "            log.write(loss_log + '\\n')\n",
    "            log.write(predicted_result_log + '\\n')\n",
    "            log.close()\n",
    "            log2.close()\n",
    "            \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensors, labels = train_dataset.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15889c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imzcage,dd = next(iter(valid_loader))\n",
    "print(type(imzcage),type(dd))\n",
    "print(imzcage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70265276",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://wikidocs.net/57165\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
