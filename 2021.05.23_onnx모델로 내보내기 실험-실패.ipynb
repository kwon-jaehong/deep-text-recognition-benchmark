{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c24598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use multi-GPU setting ------\n",
      "if you stuck too long time with multi-GPU setting, try to set --workers 0\n",
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "찍어보기\n",
      "{'exp_name': 'test_01', 'train_data': '/data/data/STARN/data_lmdb_release/training', 'valid_data': '/data/data/STARN/data_lmdb_release/validation', 'manualSeed': 1111, 'workers': 16, 'batch_size': 128, 'num_iter': 300000, 'valInterval': 1, 'saved_model': '', 'FT': False, 'adam': False, 'lr': 1, 'beta1': 0.9, 'rho': 0.95, 'eps': 1e-08, 'grad_clip': 5, 'baiduCTC': False, 'select_data': ['ST'], 'batch_ratio': ['1'], 'total_data_usage_ratio': '0.01', 'batch_max_length': 25, 'imgW': 100, 'imgH': 32, 'rgb': False, 'character': '0123456789abcdefghijklmnopqrstuvwxyz', 'sensitive': False, 'PAD': False, 'data_filtering_off': False, 'Transformation': 'TPS', 'FeatureExtraction': 'ResNet', 'SequenceModeling': 'BiLSTM', 'Prediction': 'Attn', 'num_fiducial': 20, 'input_channel': 1, 'output_channel': 512, 'hidden_size': 256, 'num_gpu': 4} <class 'easydict.EasyDict'>\n",
      "찍어보기 끝\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: /data/data/STARN/data_lmdb_release/training\n",
      "opt.select_data: ['ST']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /data/data/STARN/data_lmdb_release/training\t dataset: ST\n",
      "sub-directory:\t/ST\t num samples: 5522807\n",
      "sub-directory:\t/MJ/MJ_valid\t num samples: 802731\n",
      "sub-directory:\t/MJ/MJ_test\t num samples: 891924\n",
      "sub-directory:\t/MJ/MJ_train\t num samples: 7224586\n",
      "num total samples of ST: 14442048 x 0.01 (total_data_usage_ratio) = 144420\n",
      "num samples of ST per batch: 128 x 1.0 (batch_ratio) = 128\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 128 = 128\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /data/data/STARN/data_lmdb_release/validation\t dataset: /\n",
      "sub-directory:\t/.\t num samples: 6992\n",
      "--------------------------------------------------------------------------------\n",
      "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
      "Model:\n",
      "Model(\n",
      "  (Transformation): TPS_SpatialTransformerNetwork(\n",
      "    (LocalizationNetwork): LocalizationNetwork(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): ReLU(inplace=True)\n",
      "        (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (14): ReLU(inplace=True)\n",
      "        (15): AdaptiveAvgPool2d(output_size=1)\n",
      "      )\n",
      "      (localization_fc1): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
      "    )\n",
      "    (GridGenerator): GridGenerator()\n",
      "  )\n",
      "  (FeatureExtraction): ResNet_FeatureExtractor(\n",
      "    (ConvNet): ResNet(\n",
      "      (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (layer2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "      (layer3): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (layer4): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
      "      (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "      (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "  (SequenceModeling): Sequential(\n",
      "    (0): BidirectionalLSTM(\n",
      "      (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "      (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "    (1): BidirectionalLSTM(\n",
      "      (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "      (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (Prediction): Attention(\n",
      "    (attention_cell): AttentionCell(\n",
      "      (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
      "      (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (score): Linear(in_features=256, out_features=1, bias=False)\n",
      "      (rnn): LSTMCell(294, 256)\n",
      "    )\n",
      "    (generator): Linear(in_features=256, out_features=38, bias=True)\n",
      "  )\n",
      ")\n",
      "Trainable params num :  49555182\n",
      "Optimizer:\n",
      "Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-08\n",
      "    lr: 1\n",
      "    rho: 0.95\n",
      "    weight_decay: 0\n",
      ")\n",
      "------------ Options -------------\n",
      "exp_name: test_01\n",
      "train_data: /data/data/STARN/data_lmdb_release/training\n",
      "valid_data: /data/data/STARN/data_lmdb_release/validation\n",
      "manualSeed: 1111\n",
      "workers: 16\n",
      "batch_size: 128\n",
      "num_iter: 300000\n",
      "valInterval: 1\n",
      "saved_model: \n",
      "FT: False\n",
      "adam: False\n",
      "lr: 1\n",
      "beta1: 0.9\n",
      "rho: 0.95\n",
      "eps: 1e-08\n",
      "grad_clip: 5\n",
      "baiduCTC: False\n",
      "select_data: ['ST']\n",
      "batch_ratio: ['1']\n",
      "total_data_usage_ratio: 0.01\n",
      "batch_max_length: 25\n",
      "imgW: 100\n",
      "imgH: 32\n",
      "rgb: False\n",
      "character: 0123456789abcdefghijklmnopqrstuvwxyz\n",
      "sensitive: False\n",
      "PAD: False\n",
      "data_filtering_off: False\n",
      "Transformation: TPS\n",
      "FeatureExtraction: ResNet\n",
      "SequenceModeling: BiLSTM\n",
      "Prediction: Attn\n",
      "num_fiducial: 20\n",
      "input_channel: 1\n",
      "output_channel: 512\n",
      "hidden_size: 256\n",
      "num_gpu: 4\n",
      "num_class: 38\n",
      "---------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_jit_pass_onnx_set_dynamic_input_shape(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, Dict[int, str]], arg2: List[str]) -> None\n\nInvoked with: graph(%input.1 : Float(128, 1, 32, 100, strides=[3200, 3200, 100, 1], requires_grad=0, device=cuda:0),\n      %1 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.0.weight : Float(64, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.4.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.5.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.5.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.5.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.5.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.5.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.8.weight : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.9.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.9.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.9.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.9.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.9.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.12.weight : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.13.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.13.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.13.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.13.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.13.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.localization_fc1.0.weight : Float(256, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.localization_fc1.0.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.localization_fc2.weight : Float(40, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.localization_fc2.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.GridGenerator.inv_delta_C : Float(23, 23, strides=[23, 1], requires_grad=0, device=cuda:0),\n      %Transformation.GridGenerator.P_hat : Float(3200, 23, strides=[23, 1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv0_1.weight : Float(32, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_1.weight : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_1.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_1.running_mean : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_1.running_var : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv0_2.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_2.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_2.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.conv1.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn1.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn1.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn1.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn1.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.conv2.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn2.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn2.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn2.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn2.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.0.weight : Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.1.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.1.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.1.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.1.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv1.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn1.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn1.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn1.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn1.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.conv1.weight : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn1.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn1.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.conv2.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn2.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn2.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.0.weight : Float(256, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.1.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.1.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.conv1.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn1.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn1.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.conv2.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn2.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn2.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv2.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn2.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn2.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.conv1.weight : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.0.weight : Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv3.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn3.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn3.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn3.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn3.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn3.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv4_1.weight : Float(512, 512, 2, 2, strides=[2048, 4, 2, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv4_2.weight : Float(512, 512, 2, 2, strides=[2048, 4, 2, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %SequenceModeling.0.rnn.weight_ih_l0 : Float(1024, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.weight_hh_l0 : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.bias_ih_l0 : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.bias_hh_l0 : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.weight_ih_l0_reverse : Float(1024, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.weight_hh_l0_reverse : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.bias_ih_l0_reverse : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.bias_hh_l0_reverse : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.linear.weight : Float(256, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.linear.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.weight_ih_l0 : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.weight_hh_l0 : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.bias_ih_l0 : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.bias_hh_l0 : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.weight_ih_l0_reverse : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.weight_hh_l0_reverse : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.bias_ih_l0_reverse : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.bias_hh_l0_reverse : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.linear.weight : Float(256, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.linear.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.i2h.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.h2h.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.h2h.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.score.weight : Float(1, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.rnn.weight_ih : Float(1024, 294, strides=[294, 1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.rnn.weight_hh : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.rnn.bias_ih : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.rnn.bias_hh : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %Prediction.generator.weight : Float(38, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Prediction.generator.bias : Float(38, strides=[1], requires_grad=1, device=cuda:0)):\n  %6444 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %763 : Long(device=cpu) = aten::size(%input.1, %6444) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:80:0\n  %765 : None = prim::Constant()\n  %5301 : int[] = prim::Constant[value=[1, 1]]()\n  %5302 : int[] = prim::Constant[value=[1, 1]]()\n  %5303 : int[] = prim::Constant[value=[1, 1]]()\n  %6445 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5304 : int[] = prim::Constant[value=[0, 0]]()\n  %6446 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6447 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6448 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6449 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6450 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.2 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.1, %Transformation.LocalizationNetwork.conv.0.weight, %765, %5301, %5302, %5303, %6445, %5304, %6446, %6447, %6448, %6449, %6450) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6451 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6452 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6453 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6454 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.3 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.2, %Transformation.LocalizationNetwork.conv.1.weight, %Transformation.LocalizationNetwork.conv.1.bias, %Transformation.LocalizationNetwork.conv.1.running_mean, %Transformation.LocalizationNetwork.conv.1.running_var, %6451, %6452, %6453, %6454) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5078 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.3) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5305 : int[] = prim::Constant[value=[2, 2]]()\n  %5306 : int[] = prim::Constant[value=[2, 2]]()\n  %5307 : int[] = prim::Constant[value=[0, 0]]()\n  %5308 : int[] = prim::Constant[value=[1, 1]]()\n  %6455 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.4 : Float(128, 64, 16, 50, strides=[51200, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5078, %5305, %5306, %5307, %5308, %6455) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %805 : None = prim::Constant()\n  %5309 : int[] = prim::Constant[value=[1, 1]]()\n  %5310 : int[] = prim::Constant[value=[1, 1]]()\n  %5311 : int[] = prim::Constant[value=[1, 1]]()\n  %6456 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5312 : int[] = prim::Constant[value=[0, 0]]()\n  %6457 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6458 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6459 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6460 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6461 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.5 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.4, %Transformation.LocalizationNetwork.conv.4.weight, %805, %5309, %5310, %5311, %6456, %5312, %6457, %6458, %6459, %6460, %6461) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6462 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6463 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6464 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6465 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.6 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.5, %Transformation.LocalizationNetwork.conv.5.weight, %Transformation.LocalizationNetwork.conv.5.bias, %Transformation.LocalizationNetwork.conv.5.running_mean, %Transformation.LocalizationNetwork.conv.5.running_var, %6462, %6463, %6464, %6465) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5079 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.6) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5313 : int[] = prim::Constant[value=[2, 2]]()\n  %5314 : int[] = prim::Constant[value=[2, 2]]()\n  %5315 : int[] = prim::Constant[value=[0, 0]]()\n  %5316 : int[] = prim::Constant[value=[1, 1]]()\n  %6466 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.7 : Float(128, 128, 8, 25, strides=[25600, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5079, %5313, %5314, %5315, %5316, %6466) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %845 : None = prim::Constant()\n  %5317 : int[] = prim::Constant[value=[1, 1]]()\n  %5318 : int[] = prim::Constant[value=[1, 1]]()\n  %5319 : int[] = prim::Constant[value=[1, 1]]()\n  %6467 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5320 : int[] = prim::Constant[value=[0, 0]]()\n  %6468 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6469 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6470 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6471 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6472 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.8 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.7, %Transformation.LocalizationNetwork.conv.8.weight, %845, %5317, %5318, %5319, %6467, %5320, %6468, %6469, %6470, %6471, %6472) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6473 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6474 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6475 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6476 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.9 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.8, %Transformation.LocalizationNetwork.conv.9.weight, %Transformation.LocalizationNetwork.conv.9.bias, %Transformation.LocalizationNetwork.conv.9.running_mean, %Transformation.LocalizationNetwork.conv.9.running_var, %6473, %6474, %6475, %6476) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5080 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.9) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5321 : int[] = prim::Constant[value=[2, 2]]()\n  %5322 : int[] = prim::Constant[value=[2, 2]]()\n  %5323 : int[] = prim::Constant[value=[0, 0]]()\n  %5324 : int[] = prim::Constant[value=[1, 1]]()\n  %6477 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.10 : Float(128, 256, 4, 12, strides=[12288, 48, 12, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5080, %5321, %5322, %5323, %5324, %6477) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %885 : None = prim::Constant()\n  %5325 : int[] = prim::Constant[value=[1, 1]]()\n  %5326 : int[] = prim::Constant[value=[1, 1]]()\n  %5327 : int[] = prim::Constant[value=[1, 1]]()\n  %6478 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5328 : int[] = prim::Constant[value=[0, 0]]()\n  %6479 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6480 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6481 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6482 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6483 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.11 : Float(128, 512, 4, 12, strides=[24576, 48, 12, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.10, %Transformation.LocalizationNetwork.conv.12.weight, %885, %5325, %5326, %5327, %6478, %5328, %6479, %6480, %6481, %6482, %6483) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6484 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6485 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6486 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6487 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.12 : Float(128, 512, 4, 12, strides=[24576, 48, 12, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.11, %Transformation.LocalizationNetwork.conv.13.weight, %Transformation.LocalizationNetwork.conv.13.bias, %Transformation.LocalizationNetwork.conv.13.running_mean, %Transformation.LocalizationNetwork.conv.13.running_var, %6484, %6485, %6486, %6487) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5081 : Float(128, 512, 4, 12, strides=[24576, 48, 12, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.12) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5329 : int[] = prim::Constant[value=[1, 1]]()\n  %926 : Float(128, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = aten::adaptive_avg_pool2d(%5081, %5329) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1037:0\n  %6488 : Long(requires_grad=0, device=cpu) = prim::Constant[value={-1}]()\n  %929 : int[] = prim::ListConstruct(%763, %6488)\n  %input.14 : Float(128, 512, strides=[512, 1], requires_grad=1, device=cuda:0) = aten::view(%926, %929) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:81:0\n  %931 : Float(512, 256, strides=[1, 512], requires_grad=1, device=cuda:0) = aten::t(%Transformation.LocalizationNetwork.localization_fc1.0.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6489 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6490 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.15 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Transformation.LocalizationNetwork.localization_fc1.0.bias, %input.14, %931, %6489, %6490) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %5082 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.15) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %936 : Float(256, 40, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Transformation.LocalizationNetwork.localization_fc2.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6491 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6492 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %939 : Float(128, 40, strides=[40, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Transformation.LocalizationNetwork.localization_fc2.bias, %5082, %936, %6491, %6492) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6493 : Long(requires_grad=0, device=cpu) = prim::Constant[value={20}]()\n  %6494 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %943 : int[] = prim::ListConstruct(%763, %6493, %6494)\n  %batch_C_prime : Float(128, 20, 2, strides=[40, 2, 1], requires_grad=1, device=cuda:0) = aten::view(%939, %943) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:82:0\n  %6495 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %946 : Long(device=cpu) = aten::size(%batch_C_prime, %6495) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:157:0\n  %6496 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6497 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %951 : int[] = prim::ListConstruct(%946, %6496, %6497)\n  %952 : Float(128, 23, 23, strides=[529, 23, 1], requires_grad=0, device=cuda:0) = aten::repeat(%Transformation.GridGenerator.inv_delta_C, %951) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:158:0\n  %6498 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6499 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %956 : int[] = prim::ListConstruct(%946, %6498, %6499)\n  %957 : Float(128, 3200, 23, strides=[73600, 23, 1], requires_grad=0, device=cuda:0) = aten::repeat(%Transformation.GridGenerator.P_hat, %956) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:159:0\n  %6500 : Long(requires_grad=0, device=cpu) = prim::Constant[value={3}]()\n  %6501 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %961 : int[] = prim::ListConstruct(%946, %6500, %6501)\n  %6502 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %963 : None = prim::Constant()\n  %964 : Device = prim::Constant[value=\"cpu\"]() # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %6503 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %966 : Float(128, 3, 2, strides=[6, 2, 1], requires_grad=0, device=cpu) = aten::zeros(%961, %6502, %963, %964, %6503) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %6504 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %6505 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6506 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %970 : None = prim::Constant()\n  %971 : Float(128, 3, 2, strides=[6, 2, 1], requires_grad=0, device=cpu) = aten::to(%966, %6504, %6505, %6506, %970) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %6507 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %6508 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %974 : Device = prim::Constant[value=\"cuda\"]() # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %975 : None = prim::Constant()\n  %6509 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6510 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %978 : None = prim::Constant()\n  %979 : Float(128, 3, 2, strides=[6, 2, 1], requires_grad=0, device=cuda:0) = aten::to(%971, %6507, %6508, %974, %975, %6509, %6510, %978) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %980 : Tensor[] = prim::ListConstruct(%batch_C_prime, %979)\n  %6511 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %982 : Float(128, 23, 2, strides=[46, 2, 1], requires_grad=1, device=cuda:0) = aten::cat(%980, %6511) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %983 : Float(128, 23, 2, strides=[46, 2, 1], requires_grad=1, device=cuda:0) = aten::bmm(%952, %982) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:162:0\n  %984 : Float(128, 3200, 2, strides=[6400, 2, 1], requires_grad=1, device=cuda:0) = aten::bmm(%957, %983) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:163:0\n  %6512 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %986 : Long(device=cpu) = aten::size(%984, %6512) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:32:0\n  %6513 : Long(requires_grad=0, device=cpu) = prim::Constant[value={32}]()\n  %6514 : Long(requires_grad=0, device=cpu) = prim::Constant[value={100}]()\n  %6515 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %992 : int[] = prim::ListConstruct(%986, %6513, %6514, %6515)\n  %build_P_prime_reshape : Float(128, 32, 100, 2, strides=[6400, 200, 2, 1], requires_grad=1, device=cuda:0) = aten::reshape(%984, %992) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:32:0\n  %6516 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6517 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6518 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.17 : Float(128, 1, 32, 100, strides=[3200, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::grid_sampler(%input.1, %build_P_prime_reshape, %6516, %6517, %6518) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3836:0\n  %998 : None = prim::Constant()\n  %5330 : int[] = prim::Constant[value=[1, 1]]()\n  %5331 : int[] = prim::Constant[value=[1, 1]]()\n  %5332 : int[] = prim::Constant[value=[1, 1]]()\n  %6519 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5333 : int[] = prim::Constant[value=[0, 0]]()\n  %6520 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6521 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6522 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6523 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6524 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.18 : Float(128, 32, 32, 100, strides=[102400, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.17, %FeatureExtraction.ConvNet.conv0_1.weight, %998, %5330, %5331, %5332, %6519, %5333, %6520, %6521, %6522, %6523, %6524) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6525 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6526 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6527 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6528 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.19 : Float(128, 32, 32, 100, strides=[102400, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.18, %FeatureExtraction.ConvNet.bn0_1.weight, %FeatureExtraction.ConvNet.bn0_1.bias, %FeatureExtraction.ConvNet.bn0_1.running_mean, %FeatureExtraction.ConvNet.bn0_1.running_var, %6525, %6526, %6527, %6528) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5083 : Float(128, 32, 32, 100, strides=[102400, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.19) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1024 : None = prim::Constant()\n  %5334 : int[] = prim::Constant[value=[1, 1]]()\n  %5335 : int[] = prim::Constant[value=[1, 1]]()\n  %5336 : int[] = prim::Constant[value=[1, 1]]()\n  %6529 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5337 : int[] = prim::Constant[value=[0, 0]]()\n  %6530 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6531 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6532 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6533 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6534 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.21 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5083, %FeatureExtraction.ConvNet.conv0_2.weight, %1024, %5334, %5335, %5336, %6529, %5337, %6530, %6531, %6532, %6533, %6534) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6535 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6536 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6537 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6538 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.22 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.21, %FeatureExtraction.ConvNet.bn0_2.weight, %FeatureExtraction.ConvNet.bn0_2.bias, %FeatureExtraction.ConvNet.bn0_2.running_mean, %FeatureExtraction.ConvNet.bn0_2.running_var, %6535, %6536, %6537, %6538) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5084 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.22) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5338 : int[] = prim::Constant[value=[2, 2]]()\n  %5339 : int[] = prim::Constant[value=[2, 2]]()\n  %5340 : int[] = prim::Constant[value=[0, 0]]()\n  %5341 : int[] = prim::Constant[value=[1, 1]]()\n  %6539 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.23 : Float(128, 64, 16, 50, strides=[51200, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5084, %5338, %5339, %5340, %5341, %6539) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %1064 : None = prim::Constant()\n  %5342 : int[] = prim::Constant[value=[1, 1]]()\n  %5343 : int[] = prim::Constant[value=[1, 1]]()\n  %5344 : int[] = prim::Constant[value=[1, 1]]()\n  %6540 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5345 : int[] = prim::Constant[value=[0, 0]]()\n  %6541 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6542 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6543 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6544 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6545 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.24 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.23, %FeatureExtraction.ConvNet.layer1.0.conv1.weight, %1064, %5342, %5343, %5344, %6540, %5345, %6541, %6542, %6543, %6544, %6545) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6546 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6547 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6548 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6549 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.25 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.24, %FeatureExtraction.ConvNet.layer1.0.bn1.weight, %FeatureExtraction.ConvNet.layer1.0.bn1.bias, %FeatureExtraction.ConvNet.layer1.0.bn1.running_mean, %FeatureExtraction.ConvNet.layer1.0.bn1.running_var, %6546, %6547, %6548, %6549) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5085 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.25) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1090 : None = prim::Constant()\n  %5346 : int[] = prim::Constant[value=[1, 1]]()\n  %5347 : int[] = prim::Constant[value=[1, 1]]()\n  %5348 : int[] = prim::Constant[value=[1, 1]]()\n  %6550 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5349 : int[] = prim::Constant[value=[0, 0]]()\n  %6551 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6552 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6553 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6554 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6555 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.27 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5085, %FeatureExtraction.ConvNet.layer1.0.conv2.weight, %1090, %5346, %5347, %5348, %6550, %5349, %6551, %6552, %6553, %6554, %6555) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6556 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6557 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6558 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6559 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1114 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.27, %FeatureExtraction.ConvNet.layer1.0.bn2.weight, %FeatureExtraction.ConvNet.layer1.0.bn2.bias, %FeatureExtraction.ConvNet.layer1.0.bn2.running_mean, %FeatureExtraction.ConvNet.layer1.0.bn2.running_var, %6556, %6557, %6558, %6559) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %1115 : None = prim::Constant()\n  %5350 : int[] = prim::Constant[value=[1, 1]]()\n  %5351 : int[] = prim::Constant[value=[0, 0]]()\n  %5352 : int[] = prim::Constant[value=[1, 1]]()\n  %6560 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5353 : int[] = prim::Constant[value=[0, 0]]()\n  %6561 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6562 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6563 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6564 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6565 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.28 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.23, %FeatureExtraction.ConvNet.layer1.0.downsample.0.weight, %1115, %5350, %5351, %5352, %6560, %5353, %6561, %6562, %6563, %6564, %6565) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6566 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6567 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6568 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6569 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1139 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.28, %FeatureExtraction.ConvNet.layer1.0.downsample.1.weight, %FeatureExtraction.ConvNet.layer1.0.downsample.1.bias, %FeatureExtraction.ConvNet.layer1.0.downsample.1.running_mean, %FeatureExtraction.ConvNet.layer1.0.downsample.1.running_var, %6566, %6567, %6568, %6569) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6570 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5064 : Tensor = aten::type_as(%1139, %1114)\n  %input.29 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::add_(%1114, %5064, %6570) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.30 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.29) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1143 : None = prim::Constant()\n  %5354 : int[] = prim::Constant[value=[1, 1]]()\n  %5355 : int[] = prim::Constant[value=[1, 1]]()\n  %5356 : int[] = prim::Constant[value=[1, 1]]()\n  %6571 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5357 : int[] = prim::Constant[value=[0, 0]]()\n  %6572 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6573 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6574 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6575 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6576 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.31 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.30, %FeatureExtraction.ConvNet.conv1.weight, %1143, %5354, %5355, %5356, %6571, %5357, %6572, %6573, %6574, %6575, %6576) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6577 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6578 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6579 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6580 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.32 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.31, %FeatureExtraction.ConvNet.bn1.weight, %FeatureExtraction.ConvNet.bn1.bias, %FeatureExtraction.ConvNet.bn1.running_mean, %FeatureExtraction.ConvNet.bn1.running_var, %6577, %6578, %6579, %6580) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5086 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.32) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5358 : int[] = prim::Constant[value=[2, 2]]()\n  %5359 : int[] = prim::Constant[value=[2, 2]]()\n  %5360 : int[] = prim::Constant[value=[0, 0]]()\n  %5361 : int[] = prim::Constant[value=[1, 1]]()\n  %6581 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.33 : Float(128, 128, 8, 25, strides=[25600, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5086, %5358, %5359, %5360, %5361, %6581) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %1183 : None = prim::Constant()\n  %5362 : int[] = prim::Constant[value=[1, 1]]()\n  %5363 : int[] = prim::Constant[value=[1, 1]]()\n  %5364 : int[] = prim::Constant[value=[1, 1]]()\n  %6582 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5365 : int[] = prim::Constant[value=[0, 0]]()\n  %6583 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6584 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6585 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6586 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6587 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.34 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.33, %FeatureExtraction.ConvNet.layer2.0.conv1.weight, %1183, %5362, %5363, %5364, %6582, %5365, %6583, %6584, %6585, %6586, %6587) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6588 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6589 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6590 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6591 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.35 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.34, %FeatureExtraction.ConvNet.layer2.0.bn1.weight, %FeatureExtraction.ConvNet.layer2.0.bn1.bias, %FeatureExtraction.ConvNet.layer2.0.bn1.running_mean, %FeatureExtraction.ConvNet.layer2.0.bn1.running_var, %6588, %6589, %6590, %6591) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5087 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.35) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1209 : None = prim::Constant()\n  %5366 : int[] = prim::Constant[value=[1, 1]]()\n  %5367 : int[] = prim::Constant[value=[1, 1]]()\n  %5368 : int[] = prim::Constant[value=[1, 1]]()\n  %6592 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5369 : int[] = prim::Constant[value=[0, 0]]()\n  %6593 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6594 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6595 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6596 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6597 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.37 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5087, %FeatureExtraction.ConvNet.layer2.0.conv2.weight, %1209, %5366, %5367, %5368, %6592, %5369, %6593, %6594, %6595, %6596, %6597) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6598 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6599 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6600 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6601 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1233 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.37, %FeatureExtraction.ConvNet.layer2.0.bn2.weight, %FeatureExtraction.ConvNet.layer2.0.bn2.bias, %FeatureExtraction.ConvNet.layer2.0.bn2.running_mean, %FeatureExtraction.ConvNet.layer2.0.bn2.running_var, %6598, %6599, %6600, %6601) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %1234 : None = prim::Constant()\n  %5370 : int[] = prim::Constant[value=[1, 1]]()\n  %5371 : int[] = prim::Constant[value=[0, 0]]()\n  %5372 : int[] = prim::Constant[value=[1, 1]]()\n  %6602 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5373 : int[] = prim::Constant[value=[0, 0]]()\n  %6603 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6604 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6605 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6606 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6607 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.38 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.33, %FeatureExtraction.ConvNet.layer2.0.downsample.0.weight, %1234, %5370, %5371, %5372, %6602, %5373, %6603, %6604, %6605, %6606, %6607) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6608 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6609 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6610 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6611 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1258 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.38, %FeatureExtraction.ConvNet.layer2.0.downsample.1.weight, %FeatureExtraction.ConvNet.layer2.0.downsample.1.bias, %FeatureExtraction.ConvNet.layer2.0.downsample.1.running_mean, %FeatureExtraction.ConvNet.layer2.0.downsample.1.running_var, %6608, %6609, %6610, %6611) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6612 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5065 : Tensor = aten::type_as(%1258, %1233)\n  %input.39 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::add_(%1233, %5065, %6612) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.40 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.39) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1262 : None = prim::Constant()\n  %5374 : int[] = prim::Constant[value=[1, 1]]()\n  %5375 : int[] = prim::Constant[value=[1, 1]]()\n  %5376 : int[] = prim::Constant[value=[1, 1]]()\n  %6613 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5377 : int[] = prim::Constant[value=[0, 0]]()\n  %6614 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6615 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6616 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6617 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6618 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.41 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.40, %FeatureExtraction.ConvNet.layer2.1.conv1.weight, %1262, %5374, %5375, %5376, %6613, %5377, %6614, %6615, %6616, %6617, %6618) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6619 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6620 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6621 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6622 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.42 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.41, %FeatureExtraction.ConvNet.layer2.1.bn1.weight, %FeatureExtraction.ConvNet.layer2.1.bn1.bias, %FeatureExtraction.ConvNet.layer2.1.bn1.running_mean, %FeatureExtraction.ConvNet.layer2.1.bn1.running_var, %6619, %6620, %6621, %6622) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5088 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.42) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1288 : None = prim::Constant()\n  %5378 : int[] = prim::Constant[value=[1, 1]]()\n  %5379 : int[] = prim::Constant[value=[1, 1]]()\n  %5380 : int[] = prim::Constant[value=[1, 1]]()\n  %6623 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5381 : int[] = prim::Constant[value=[0, 0]]()\n  %6624 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6625 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6626 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6627 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6628 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.44 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5088, %FeatureExtraction.ConvNet.layer2.1.conv2.weight, %1288, %5378, %5379, %5380, %6623, %5381, %6624, %6625, %6626, %6627, %6628) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6629 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6630 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6631 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6632 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1312 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.44, %FeatureExtraction.ConvNet.layer2.1.bn2.weight, %FeatureExtraction.ConvNet.layer2.1.bn2.bias, %FeatureExtraction.ConvNet.layer2.1.bn2.running_mean, %FeatureExtraction.ConvNet.layer2.1.bn2.running_var, %6629, %6630, %6631, %6632) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6633 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5066 : Tensor = aten::type_as(%input.40, %1312)\n  %input.45 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::add_(%1312, %5066, %6633) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.46 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.45) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1316 : None = prim::Constant()\n  %5382 : int[] = prim::Constant[value=[1, 1]]()\n  %5383 : int[] = prim::Constant[value=[1, 1]]()\n  %5384 : int[] = prim::Constant[value=[1, 1]]()\n  %6634 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5385 : int[] = prim::Constant[value=[0, 0]]()\n  %6635 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6636 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6637 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6638 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6639 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.47 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.46, %FeatureExtraction.ConvNet.conv2.weight, %1316, %5382, %5383, %5384, %6634, %5385, %6635, %6636, %6637, %6638, %6639) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6640 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6641 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6642 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6643 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.48 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.47, %FeatureExtraction.ConvNet.bn2.weight, %FeatureExtraction.ConvNet.bn2.bias, %FeatureExtraction.ConvNet.bn2.running_mean, %FeatureExtraction.ConvNet.bn2.running_var, %6640, %6641, %6642, %6643) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5089 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.48) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5386 : int[] = prim::Constant[value=[2, 2]]()\n  %5387 : int[] = prim::Constant[value=[2, 1]]()\n  %5388 : int[] = prim::Constant[value=[0, 1]]()\n  %5389 : int[] = prim::Constant[value=[1, 1]]()\n  %6644 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.49 : Float(128, 256, 4, 26, strides=[26624, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5089, %5386, %5387, %5388, %5389, %6644) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %1356 : None = prim::Constant()\n  %5390 : int[] = prim::Constant[value=[1, 1]]()\n  %5391 : int[] = prim::Constant[value=[1, 1]]()\n  %5392 : int[] = prim::Constant[value=[1, 1]]()\n  %6645 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5393 : int[] = prim::Constant[value=[0, 0]]()\n  %6646 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6647 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6648 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6649 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6650 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.50 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.49, %FeatureExtraction.ConvNet.layer3.0.conv1.weight, %1356, %5390, %5391, %5392, %6645, %5393, %6646, %6647, %6648, %6649, %6650) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6651 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6652 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6653 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6654 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.51 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.50, %FeatureExtraction.ConvNet.layer3.0.bn1.weight, %FeatureExtraction.ConvNet.layer3.0.bn1.bias, %FeatureExtraction.ConvNet.layer3.0.bn1.running_mean, %FeatureExtraction.ConvNet.layer3.0.bn1.running_var, %6651, %6652, %6653, %6654) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5090 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.51) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1382 : None = prim::Constant()\n  %5394 : int[] = prim::Constant[value=[1, 1]]()\n  %5395 : int[] = prim::Constant[value=[1, 1]]()\n  %5396 : int[] = prim::Constant[value=[1, 1]]()\n  %6655 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5397 : int[] = prim::Constant[value=[0, 0]]()\n  %6656 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6657 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6658 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6659 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6660 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.53 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5090, %FeatureExtraction.ConvNet.layer3.0.conv2.weight, %1382, %5394, %5395, %5396, %6655, %5397, %6656, %6657, %6658, %6659, %6660) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6661 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6662 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6663 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6664 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1406 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.53, %FeatureExtraction.ConvNet.layer3.0.bn2.weight, %FeatureExtraction.ConvNet.layer3.0.bn2.bias, %FeatureExtraction.ConvNet.layer3.0.bn2.running_mean, %FeatureExtraction.ConvNet.layer3.0.bn2.running_var, %6661, %6662, %6663, %6664) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %1407 : None = prim::Constant()\n  %5398 : int[] = prim::Constant[value=[1, 1]]()\n  %5399 : int[] = prim::Constant[value=[0, 0]]()\n  %5400 : int[] = prim::Constant[value=[1, 1]]()\n  %6665 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5401 : int[] = prim::Constant[value=[0, 0]]()\n  %6666 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6667 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6668 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6669 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6670 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.54 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.49, %FeatureExtraction.ConvNet.layer3.0.downsample.0.weight, %1407, %5398, %5399, %5400, %6665, %5401, %6666, %6667, %6668, %6669, %6670) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6671 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6672 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6673 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6674 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1431 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.54, %FeatureExtraction.ConvNet.layer3.0.downsample.1.weight, %FeatureExtraction.ConvNet.layer3.0.downsample.1.bias, %FeatureExtraction.ConvNet.layer3.0.downsample.1.running_mean, %FeatureExtraction.ConvNet.layer3.0.downsample.1.running_var, %6671, %6672, %6673, %6674) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6675 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5067 : Tensor = aten::type_as(%1431, %1406)\n  %input.55 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1406, %5067, %6675) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.56 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.55) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1435 : None = prim::Constant()\n  %5402 : int[] = prim::Constant[value=[1, 1]]()\n  %5403 : int[] = prim::Constant[value=[1, 1]]()\n  %5404 : int[] = prim::Constant[value=[1, 1]]()\n  %6676 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5405 : int[] = prim::Constant[value=[0, 0]]()\n  %6677 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6678 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6679 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6680 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6681 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.57 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.56, %FeatureExtraction.ConvNet.layer3.1.conv1.weight, %1435, %5402, %5403, %5404, %6676, %5405, %6677, %6678, %6679, %6680, %6681) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6682 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6683 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6684 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6685 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.58 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.57, %FeatureExtraction.ConvNet.layer3.1.bn1.weight, %FeatureExtraction.ConvNet.layer3.1.bn1.bias, %FeatureExtraction.ConvNet.layer3.1.bn1.running_mean, %FeatureExtraction.ConvNet.layer3.1.bn1.running_var, %6682, %6683, %6684, %6685) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5091 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.58) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1461 : None = prim::Constant()\n  %5406 : int[] = prim::Constant[value=[1, 1]]()\n  %5407 : int[] = prim::Constant[value=[1, 1]]()\n  %5408 : int[] = prim::Constant[value=[1, 1]]()\n  %6686 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5409 : int[] = prim::Constant[value=[0, 0]]()\n  %6687 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6688 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6689 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6690 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6691 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.60 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5091, %FeatureExtraction.ConvNet.layer3.1.conv2.weight, %1461, %5406, %5407, %5408, %6686, %5409, %6687, %6688, %6689, %6690, %6691) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6692 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6693 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6694 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6695 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1485 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.60, %FeatureExtraction.ConvNet.layer3.1.bn2.weight, %FeatureExtraction.ConvNet.layer3.1.bn2.bias, %FeatureExtraction.ConvNet.layer3.1.bn2.running_mean, %FeatureExtraction.ConvNet.layer3.1.bn2.running_var, %6692, %6693, %6694, %6695) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6696 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5068 : Tensor = aten::type_as(%input.56, %1485)\n  %input.61 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1485, %5068, %6696) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.62 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.61) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1489 : None = prim::Constant()\n  %5410 : int[] = prim::Constant[value=[1, 1]]()\n  %5411 : int[] = prim::Constant[value=[1, 1]]()\n  %5412 : int[] = prim::Constant[value=[1, 1]]()\n  %6697 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5413 : int[] = prim::Constant[value=[0, 0]]()\n  %6698 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6699 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6700 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6701 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6702 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.63 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.62, %FeatureExtraction.ConvNet.layer3.2.conv1.weight, %1489, %5410, %5411, %5412, %6697, %5413, %6698, %6699, %6700, %6701, %6702) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6703 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6704 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6705 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6706 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.64 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.63, %FeatureExtraction.ConvNet.layer3.2.bn1.weight, %FeatureExtraction.ConvNet.layer3.2.bn1.bias, %FeatureExtraction.ConvNet.layer3.2.bn1.running_mean, %FeatureExtraction.ConvNet.layer3.2.bn1.running_var, %6703, %6704, %6705, %6706) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5092 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.64) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1515 : None = prim::Constant()\n  %5414 : int[] = prim::Constant[value=[1, 1]]()\n  %5415 : int[] = prim::Constant[value=[1, 1]]()\n  %5416 : int[] = prim::Constant[value=[1, 1]]()\n  %6707 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5417 : int[] = prim::Constant[value=[0, 0]]()\n  %6708 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6709 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6710 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6711 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6712 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.66 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5092, %FeatureExtraction.ConvNet.layer3.2.conv2.weight, %1515, %5414, %5415, %5416, %6707, %5417, %6708, %6709, %6710, %6711, %6712) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6713 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6714 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6715 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6716 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1539 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.66, %FeatureExtraction.ConvNet.layer3.2.bn2.weight, %FeatureExtraction.ConvNet.layer3.2.bn2.bias, %FeatureExtraction.ConvNet.layer3.2.bn2.running_mean, %FeatureExtraction.ConvNet.layer3.2.bn2.running_var, %6713, %6714, %6715, %6716) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6717 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5069 : Tensor = aten::type_as(%input.62, %1539)\n  %input.67 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1539, %5069, %6717) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.68 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.67) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1543 : None = prim::Constant()\n  %5418 : int[] = prim::Constant[value=[1, 1]]()\n  %5419 : int[] = prim::Constant[value=[1, 1]]()\n  %5420 : int[] = prim::Constant[value=[1, 1]]()\n  %6718 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5421 : int[] = prim::Constant[value=[0, 0]]()\n  %6719 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6720 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6721 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6722 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6723 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.69 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.68, %FeatureExtraction.ConvNet.layer3.3.conv1.weight, %1543, %5418, %5419, %5420, %6718, %5421, %6719, %6720, %6721, %6722, %6723) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6724 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6725 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6726 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6727 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.70 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.69, %FeatureExtraction.ConvNet.layer3.3.bn1.weight, %FeatureExtraction.ConvNet.layer3.3.bn1.bias, %FeatureExtraction.ConvNet.layer3.3.bn1.running_mean, %FeatureExtraction.ConvNet.layer3.3.bn1.running_var, %6724, %6725, %6726, %6727) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5093 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.70) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1569 : None = prim::Constant()\n  %5422 : int[] = prim::Constant[value=[1, 1]]()\n  %5423 : int[] = prim::Constant[value=[1, 1]]()\n  %5424 : int[] = prim::Constant[value=[1, 1]]()\n  %6728 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5425 : int[] = prim::Constant[value=[0, 0]]()\n  %6729 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6730 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6731 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6732 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6733 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.72 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5093, %FeatureExtraction.ConvNet.layer3.3.conv2.weight, %1569, %5422, %5423, %5424, %6728, %5425, %6729, %6730, %6731, %6732, %6733) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6734 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6735 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6736 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6737 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1593 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.72, %FeatureExtraction.ConvNet.layer3.3.bn2.weight, %FeatureExtraction.ConvNet.layer3.3.bn2.bias, %FeatureExtraction.ConvNet.layer3.3.bn2.running_mean, %FeatureExtraction.ConvNet.layer3.3.bn2.running_var, %6734, %6735, %6736, %6737) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6738 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5070 : Tensor = aten::type_as(%input.68, %1593)\n  %input.73 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1593, %5070, %6738) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.74 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.73) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1597 : None = prim::Constant()\n  %5426 : int[] = prim::Constant[value=[1, 1]]()\n  %5427 : int[] = prim::Constant[value=[1, 1]]()\n  %5428 : int[] = prim::Constant[value=[1, 1]]()\n  %6739 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5429 : int[] = prim::Constant[value=[0, 0]]()\n  %6740 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6741 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6742 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6743 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6744 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.75 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.74, %FeatureExtraction.ConvNet.layer3.4.conv1.weight, %1597, %5426, %5427, %5428, %6739, %5429, %6740, %6741, %6742, %6743, %6744) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6745 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6746 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6747 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6748 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.76 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.75, %FeatureExtraction.ConvNet.layer3.4.bn1.weight, %FeatureExtraction.ConvNet.layer3.4.bn1.bias, %FeatureExtraction.ConvNet.layer3.4.bn1.running_mean, %FeatureExtraction.ConvNet.layer3.4.bn1.running_var, %6745, %6746, %6747, %6748) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5094 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.76) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1623 : None = prim::Constant()\n  %5430 : int[] = prim::Constant[value=[1, 1]]()\n  %5431 : int[] = prim::Constant[value=[1, 1]]()\n  %5432 : int[] = prim::Constant[value=[1, 1]]()\n  %6749 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5433 : int[] = prim::Constant[value=[0, 0]]()\n  %6750 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6751 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6752 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6753 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6754 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.78 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5094, %FeatureExtraction.ConvNet.layer3.4.conv2.weight, %1623, %5430, %5431, %5432, %6749, %5433, %6750, %6751, %6752, %6753, %6754) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6755 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6756 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6757 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6758 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1647 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.78, %FeatureExtraction.ConvNet.layer3.4.bn2.weight, %FeatureExtraction.ConvNet.layer3.4.bn2.bias, %FeatureExtraction.ConvNet.layer3.4.bn2.running_mean, %FeatureExtraction.ConvNet.layer3.4.bn2.running_var, %6755, %6756, %6757, %6758) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6759 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5071 : Tensor = aten::type_as(%input.74, %1647)\n  %input.79 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1647, %5071, %6759) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.80 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.79) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1651 : None = prim::Constant()\n  %5434 : int[] = prim::Constant[value=[1, 1]]()\n  %5435 : int[] = prim::Constant[value=[1, 1]]()\n  %5436 : int[] = prim::Constant[value=[1, 1]]()\n  %6760 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5437 : int[] = prim::Constant[value=[0, 0]]()\n  %6761 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6762 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6763 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6764 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6765 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.81 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.80, %FeatureExtraction.ConvNet.conv3.weight, %1651, %5434, %5435, %5436, %6760, %5437, %6761, %6762, %6763, %6764, %6765) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6766 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6767 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6768 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6769 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.82 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.81, %FeatureExtraction.ConvNet.bn3.weight, %FeatureExtraction.ConvNet.bn3.bias, %FeatureExtraction.ConvNet.bn3.running_mean, %FeatureExtraction.ConvNet.bn3.running_var, %6766, %6767, %6768, %6769) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5095 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.82) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1677 : None = prim::Constant()\n  %5438 : int[] = prim::Constant[value=[1, 1]]()\n  %5439 : int[] = prim::Constant[value=[1, 1]]()\n  %5440 : int[] = prim::Constant[value=[1, 1]]()\n  %6770 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5441 : int[] = prim::Constant[value=[0, 0]]()\n  %6771 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6772 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6773 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6774 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6775 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.84 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5095, %FeatureExtraction.ConvNet.layer4.0.conv1.weight, %1677, %5438, %5439, %5440, %6770, %5441, %6771, %6772, %6773, %6774, %6775) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6776 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6777 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6778 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6779 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.85 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.84, %FeatureExtraction.ConvNet.layer4.0.bn1.weight, %FeatureExtraction.ConvNet.layer4.0.bn1.bias, %FeatureExtraction.ConvNet.layer4.0.bn1.running_mean, %FeatureExtraction.ConvNet.layer4.0.bn1.running_var, %6776, %6777, %6778, %6779) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5096 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.85) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1703 : None = prim::Constant()\n  %5442 : int[] = prim::Constant[value=[1, 1]]()\n  %5443 : int[] = prim::Constant[value=[1, 1]]()\n  %5444 : int[] = prim::Constant[value=[1, 1]]()\n  %6780 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5445 : int[] = prim::Constant[value=[0, 0]]()\n  %6781 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6782 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6783 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6784 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6785 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.87 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5096, %FeatureExtraction.ConvNet.layer4.0.conv2.weight, %1703, %5442, %5443, %5444, %6780, %5445, %6781, %6782, %6783, %6784, %6785) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6786 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6787 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6788 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6789 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1727 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.87, %FeatureExtraction.ConvNet.layer4.0.bn2.weight, %FeatureExtraction.ConvNet.layer4.0.bn2.bias, %FeatureExtraction.ConvNet.layer4.0.bn2.running_mean, %FeatureExtraction.ConvNet.layer4.0.bn2.running_var, %6786, %6787, %6788, %6789) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6790 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5072 : Tensor = aten::type_as(%5095, %1727)\n  %input.88 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1727, %5072, %6790) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.89 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.88) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1731 : None = prim::Constant()\n  %5446 : int[] = prim::Constant[value=[1, 1]]()\n  %5447 : int[] = prim::Constant[value=[1, 1]]()\n  %5448 : int[] = prim::Constant[value=[1, 1]]()\n  %6791 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5449 : int[] = prim::Constant[value=[0, 0]]()\n  %6792 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6793 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6794 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6795 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6796 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.90 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.89, %FeatureExtraction.ConvNet.layer4.1.conv1.weight, %1731, %5446, %5447, %5448, %6791, %5449, %6792, %6793, %6794, %6795, %6796) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6797 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6798 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6799 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6800 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.91 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.90, %FeatureExtraction.ConvNet.layer4.1.bn1.weight, %FeatureExtraction.ConvNet.layer4.1.bn1.bias, %FeatureExtraction.ConvNet.layer4.1.bn1.running_mean, %FeatureExtraction.ConvNet.layer4.1.bn1.running_var, %6797, %6798, %6799, %6800) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5097 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.91) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1757 : None = prim::Constant()\n  %5450 : int[] = prim::Constant[value=[1, 1]]()\n  %5451 : int[] = prim::Constant[value=[1, 1]]()\n  %5452 : int[] = prim::Constant[value=[1, 1]]()\n  %6801 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5453 : int[] = prim::Constant[value=[0, 0]]()\n  %6802 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6803 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6804 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6805 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6806 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.93 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5097, %FeatureExtraction.ConvNet.layer4.1.conv2.weight, %1757, %5450, %5451, %5452, %6801, %5453, %6802, %6803, %6804, %6805, %6806) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6807 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6808 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6809 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6810 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1781 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.93, %FeatureExtraction.ConvNet.layer4.1.bn2.weight, %FeatureExtraction.ConvNet.layer4.1.bn2.bias, %FeatureExtraction.ConvNet.layer4.1.bn2.running_mean, %FeatureExtraction.ConvNet.layer4.1.bn2.running_var, %6807, %6808, %6809, %6810) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6811 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5073 : Tensor = aten::type_as(%input.89, %1781)\n  %input.94 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1781, %5073, %6811) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.95 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.94) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1785 : None = prim::Constant()\n  %5454 : int[] = prim::Constant[value=[1, 1]]()\n  %5455 : int[] = prim::Constant[value=[1, 1]]()\n  %5456 : int[] = prim::Constant[value=[1, 1]]()\n  %6812 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5457 : int[] = prim::Constant[value=[0, 0]]()\n  %6813 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6814 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6815 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6816 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6817 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.96 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.95, %FeatureExtraction.ConvNet.layer4.2.conv1.weight, %1785, %5454, %5455, %5456, %6812, %5457, %6813, %6814, %6815, %6816, %6817) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6818 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6819 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6820 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6821 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.97 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.96, %FeatureExtraction.ConvNet.layer4.2.bn1.weight, %FeatureExtraction.ConvNet.layer4.2.bn1.bias, %FeatureExtraction.ConvNet.layer4.2.bn1.running_mean, %FeatureExtraction.ConvNet.layer4.2.bn1.running_var, %6818, %6819, %6820, %6821) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5098 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.97) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1811 : None = prim::Constant()\n  %5458 : int[] = prim::Constant[value=[1, 1]]()\n  %5459 : int[] = prim::Constant[value=[1, 1]]()\n  %5460 : int[] = prim::Constant[value=[1, 1]]()\n  %6822 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5461 : int[] = prim::Constant[value=[0, 0]]()\n  %6823 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6824 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6825 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6826 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6827 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.99 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5098, %FeatureExtraction.ConvNet.layer4.2.conv2.weight, %1811, %5458, %5459, %5460, %6822, %5461, %6823, %6824, %6825, %6826, %6827) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6828 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6829 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6830 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6831 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1835 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.99, %FeatureExtraction.ConvNet.layer4.2.bn2.weight, %FeatureExtraction.ConvNet.layer4.2.bn2.bias, %FeatureExtraction.ConvNet.layer4.2.bn2.running_mean, %FeatureExtraction.ConvNet.layer4.2.bn2.running_var, %6828, %6829, %6830, %6831) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6832 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5074 : Tensor = aten::type_as(%input.95, %1835)\n  %input.100 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1835, %5074, %6832) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.101 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.100) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1839 : None = prim::Constant()\n  %5462 : int[] = prim::Constant[value=[2, 1]]()\n  %5463 : int[] = prim::Constant[value=[0, 1]]()\n  %5464 : int[] = prim::Constant[value=[1, 1]]()\n  %6833 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5465 : int[] = prim::Constant[value=[0, 0]]()\n  %6834 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6835 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6836 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6837 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6838 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.102 : Float(128, 512, 2, 27, strides=[27648, 54, 27, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.101, %FeatureExtraction.ConvNet.conv4_1.weight, %1839, %5462, %5463, %5464, %6833, %5465, %6834, %6835, %6836, %6837, %6838) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6839 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6840 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6841 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6842 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.103 : Float(128, 512, 2, 27, strides=[27648, 54, 27, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.102, %FeatureExtraction.ConvNet.bn4_1.weight, %FeatureExtraction.ConvNet.bn4_1.bias, %FeatureExtraction.ConvNet.bn4_1.running_mean, %FeatureExtraction.ConvNet.bn4_1.running_var, %6839, %6840, %6841, %6842) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5099 : Float(128, 512, 2, 27, strides=[27648, 54, 27, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.103) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1865 : None = prim::Constant()\n  %5466 : int[] = prim::Constant[value=[1, 1]]()\n  %5467 : int[] = prim::Constant[value=[0, 0]]()\n  %5468 : int[] = prim::Constant[value=[1, 1]]()\n  %6843 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5469 : int[] = prim::Constant[value=[0, 0]]()\n  %6844 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6845 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6846 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6847 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6848 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.105 : Float(128, 512, 1, 26, strides=[13312, 26, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5099, %FeatureExtraction.ConvNet.conv4_2.weight, %1865, %5466, %5467, %5468, %6843, %5469, %6844, %6845, %6846, %6847, %6848) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6849 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6850 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6851 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6852 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.106 : Float(128, 512, 1, 26, strides=[13312, 26, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.105, %FeatureExtraction.ConvNet.bn4_2.weight, %FeatureExtraction.ConvNet.bn4_2.bias, %FeatureExtraction.ConvNet.bn4_2.running_mean, %FeatureExtraction.ConvNet.bn4_2.running_var, %6849, %6850, %6851, %6852) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5100 : Float(128, 512, 1, 26, strides=[13312, 26, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.106) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5470 : int[] = prim::Constant[value=[0, 3, 1, 2]]()\n  %input.107 : Float(128, 26, 512, 1, strides=[13312, 1, 26, 26], requires_grad=1, device=cuda:0) = aten::permute(%5100, %5470) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/model.py:77:0\n  %6853 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %1904 : Long(device=cpu) = aten::size(%input.107, %6853) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1036:0\n  %6854 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1911 : int[] = prim::ListConstruct(%1904, %6854)\n  %1912 : Float(128, 26, 512, 1, strides=[13312, 1, 26, 26], requires_grad=1, device=cuda:0) = aten::adaptive_avg_pool2d(%input.107, %1911) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1037:0\n  %6855 : Long(requires_grad=0, device=cpu) = prim::Constant[value={3}]()\n  %input.108 : Float(128, 26, 512, strides=[13312, 1, 26], requires_grad=1, device=cuda:0) = aten::squeeze(%1912, %6855) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/model.py:78:0\n  %6856 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %1926 : Long(device=cpu) = aten::size(%input.108, %6856) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:640:0\n  %6857 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6858 : Long(requires_grad=0, device=cpu) = prim::Constant[value={256}]()\n  %1931 : int[] = prim::ListConstruct(%6857, %1926, %6858)\n  %6859 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %1933 : None = prim::Constant()\n  %1934 : Device = prim::Constant[value=\"cuda:0\"]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:649:0\n  %6860 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %1936 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = aten::zeros(%1931, %6859, %1933, %1934, %6860) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:649:0\n  %6861 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6862 : Long(requires_grad=0, device=cpu) = prim::Constant[value={256}]()\n  %1940 : int[] = prim::ListConstruct(%6861, %1926, %6862)\n  %6863 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %1942 : None = prim::Constant()\n  %1943 : Device = prim::Constant[value=\"cuda:0\"]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:652:0\n  %6864 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %1945 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = aten::zeros(%1940, %6863, %1942, %1943, %6864) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:652:0\n  %1985 : Tensor[] = prim::ListConstruct(%1936, %1945)\n  %1986 : Tensor[] = prim::ListConstruct(%SequenceModeling.0.rnn.weight_ih_l0, %SequenceModeling.0.rnn.weight_hh_l0, %SequenceModeling.0.rnn.bias_ih_l0, %SequenceModeling.0.rnn.bias_hh_l0, %SequenceModeling.0.rnn.weight_ih_l0_reverse, %SequenceModeling.0.rnn.weight_hh_l0_reverse, %SequenceModeling.0.rnn.bias_ih_l0_reverse, %SequenceModeling.0.rnn.bias_hh_l0_reverse)\n  %6865 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6866 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6867 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6868 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6869 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6870 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.109 : Float(128, 26, 512, strides=[512, 65536, 1], requires_grad=1, device=cuda:0), %1994 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cuda:0), %1995 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cuda:0) = aten::lstm(%input.108, %1985, %1986, %6865, %6866, %6867, %6868, %6869, %6870) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:662:0\n  %1996 : Float(512, 256, strides=[1, 512], requires_grad=1, device=cuda:0) = aten::t(%SequenceModeling.0.linear.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %1997 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.109, %1996) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6871 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5075 : Tensor = aten::type_as(%SequenceModeling.0.linear.bias, %1997)\n  %input.110 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add_(%1997, %5075, %6871) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6872 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2011 : Long(device=cpu) = aten::size(%input.110, %6872) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:640:0\n  %6873 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6874 : Long(requires_grad=0, device=cpu) = prim::Constant[value={256}]()\n  %2016 : int[] = prim::ListConstruct(%6873, %2011, %6874)\n  %6875 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %2018 : None = prim::Constant()\n  %2019 : Device = prim::Constant[value=\"cuda:0\"]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:649:0\n  %6876 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2021 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = aten::zeros(%2016, %6875, %2018, %2019, %6876) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:649:0\n  %6877 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6878 : Long(requires_grad=0, device=cpu) = prim::Constant[value={256}]()\n  %2025 : int[] = prim::ListConstruct(%6877, %2011, %6878)\n  %6879 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %2027 : None = prim::Constant()\n  %2028 : Device = prim::Constant[value=\"cuda:0\"]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:652:0\n  %6880 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2030 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = aten::zeros(%2025, %6879, %2027, %2028, %6880) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:652:0\n  %2070 : Tensor[] = prim::ListConstruct(%2021, %2030)\n  %2071 : Tensor[] = prim::ListConstruct(%SequenceModeling.1.rnn.weight_ih_l0, %SequenceModeling.1.rnn.weight_hh_l0, %SequenceModeling.1.rnn.bias_ih_l0, %SequenceModeling.1.rnn.bias_hh_l0, %SequenceModeling.1.rnn.weight_ih_l0_reverse, %SequenceModeling.1.rnn.weight_hh_l0_reverse, %SequenceModeling.1.rnn.bias_ih_l0_reverse, %SequenceModeling.1.rnn.bias_hh_l0_reverse)\n  %6881 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6882 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6883 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6884 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6885 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6886 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.111 : Float(128, 26, 512, strides=[512, 65536, 1], requires_grad=1, device=cuda:0), %2079 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cuda:0), %2080 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cuda:0) = aten::lstm(%input.110, %2070, %2071, %6881, %6882, %6883, %6884, %6885, %6886) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:662:0\n  %2081 : Float(512, 256, strides=[1, 512], requires_grad=1, device=cuda:0) = aten::t(%SequenceModeling.1.linear.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2082 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.111, %2081) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6887 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5076 : Tensor = aten::type_as(%SequenceModeling.1.linear.bias, %2082)\n  %2084 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add_(%2082, %5076, %6887) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6888 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.112 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::contiguous(%2084, %6888) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/model.py:90:0\n  %5473 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()\n  %6889 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %6890 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2104 : Device = prim::Constant[value=\"cuda\"]() # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:33:0\n  %2105 : None = prim::Constant()\n  %6891 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6892 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2108 : None = prim::Constant()\n  %input : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=0, device=cuda:0) = aten::to(%5473, %6889, %6890, %2104, %2105, %6891, %6892, %2108) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:33:0\n  %5477 : Float(128, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5481 : Float(128, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %6893 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6894 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6895 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6896 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2152 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %6893, %6894, %6895, %6896) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6897 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6898 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2155 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2152, %6897, %6898) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6899 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2157 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2155, %6899) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %6900 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6901 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5485 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5125 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5485, %6900, %2157, %6901) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2182 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2183 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2182) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2184 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6902 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6903 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2187 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %5477, %2184, %6902, %6903) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6904 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2189 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2187, %6904) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %6905 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2191 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2183, %2189, %6905) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.114 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2191) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2193 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.1 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.114, %2193) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6906 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2196 : None = prim::Constant()\n  %2197 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.1, %6906, %2196) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5486 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2202 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2197, %5486) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2203 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2202, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %6907 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2205 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2203, %6907) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2206 : Tensor[] = prim::ListConstruct(%2205, %5125)\n  %6908 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.115 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2206, %6908) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2238 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2239 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.115, %2238) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2240 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2241 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%5477, %2240) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.191 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2243 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2244 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2239, %2241, %5481, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %6909 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6910 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6911 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6912 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2249 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=0, device=cuda:0) = aten::slice(%input, %6909, %6910, %6911, %6912) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6913 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6914 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2252 : Float(128, 256, strides=[6656, 1], requires_grad=0, device=cuda:0) = aten::select(%2249, %6913, %6914) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6915 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6916 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6917 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6918 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2257 : Float(128, 256, strides=[6656, 1], requires_grad=0, device=cuda:0) = aten::slice(%2252, %6915, %6916, %6917, %6918) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6919 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.116 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.191, %2257) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6920 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5616 : Long(device=cpu) = aten::size(%input, %6920)\n  %6921 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5618 : None = prim::Constant()\n  %5619 : None = prim::Constant()\n  %5620 : None = prim::Constant()\n  %5621 : Tensor = aten::arange(%5616, %6921, %5618, %5619, %5620)\n  %6922 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5623 : Tensor = aten::slice(%5621, %6922, %6910, %6911, %6912)\n  %6923 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5626 : Tensor = aten::unsqueeze(%6914, %6923)\n  %6924 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5628 : Long(device=cpu) = aten::size(%input, %6924)\n  %6925 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5630 : None = prim::Constant()\n  %5631 : None = prim::Constant()\n  %5632 : None = prim::Constant()\n  %5633 : Tensor = aten::arange(%5628, %6925, %5630, %5631, %5632)\n  %6926 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5635 : Tensor = aten::slice(%5633, %6926, %6916, %6917, %6918)\n  %5636 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5637 : Tensor = aten::view(%5623, %5636)\n  %5638 : int[] = prim::Constant[value=[-1, 1]]()\n  %5639 : Tensor = aten::view(%5626, %5638)\n  %5640 : int[] = prim::Constant[value=[-1]]()\n  %5641 : Tensor = aten::view(%5635, %5640)\n  %5642 : Tensor?[] = prim::ListConstruct(%5637, %5639, %5641)\n  %5643 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%input, %5642, %input.116, %6919)\n  %6927 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6928 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6929 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6930 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2264 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %6927, %6928, %6929, %6930) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6931 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6932 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2267 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2264, %6931, %6932) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6933 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2269 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2267, %6933) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %6934 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6935 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5490 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5132 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5490, %6934, %2269, %6935) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2294 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2295 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2294) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2296 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6936 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6937 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2299 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.191, %2296, %6936, %6937) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6938 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2301 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2299, %6938) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %6939 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2303 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2295, %2301, %6939) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.117 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2303) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2305 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.2 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.117, %2305) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6940 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2308 : None = prim::Constant()\n  %2309 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.2, %6940, %2308) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5491 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2314 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2309, %5491) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2315 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2314, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %6941 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2317 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2315, %6941) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2318 : Tensor[] = prim::ListConstruct(%2317, %5132)\n  %6942 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.118 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2318, %6942) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2350 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2351 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.118, %2350) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2352 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2353 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.191, %2352) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.192 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2355 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2356 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2351, %2353, %2243, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %6943 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6944 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6945 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6946 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2361 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5643, %6943, %6944, %6945, %6946) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6947 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6948 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2364 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2361, %6947, %6948) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6949 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6950 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6951 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6952 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2369 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2364, %6949, %6950, %6951, %6952) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6953 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.119 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.192, %2369) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6954 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5648 : Long(device=cpu) = aten::size(%5643, %6954)\n  %6955 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5650 : None = prim::Constant()\n  %5651 : None = prim::Constant()\n  %5652 : None = prim::Constant()\n  %5653 : Tensor = aten::arange(%5648, %6955, %5650, %5651, %5652)\n  %6956 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5655 : Tensor = aten::slice(%5653, %6956, %6944, %6945, %6946)\n  %6957 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5658 : Tensor = aten::unsqueeze(%6948, %6957)\n  %6958 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5660 : Long(device=cpu) = aten::size(%5643, %6958)\n  %6959 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5662 : None = prim::Constant()\n  %5663 : None = prim::Constant()\n  %5664 : None = prim::Constant()\n  %5665 : Tensor = aten::arange(%5660, %6959, %5662, %5663, %5664)\n  %6960 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5667 : Tensor = aten::slice(%5665, %6960, %6950, %6951, %6952)\n  %5668 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5669 : Tensor = aten::view(%5655, %5668)\n  %5670 : int[] = prim::Constant[value=[-1, 1]]()\n  %5671 : Tensor = aten::view(%5658, %5670)\n  %5672 : int[] = prim::Constant[value=[-1]]()\n  %5673 : Tensor = aten::view(%5667, %5672)\n  %5674 : Tensor?[] = prim::ListConstruct(%5669, %5671, %5673)\n  %5675 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5643, %5674, %input.119, %6953)\n  %6961 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6962 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6963 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6964 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2376 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %6961, %6962, %6963, %6964) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6965 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6966 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %2379 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2376, %6965, %6966) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6967 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2381 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2379, %6967) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %6968 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6969 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5495 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5139 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5495, %6968, %2381, %6969) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2406 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2407 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2406) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2408 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6970 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6971 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2411 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.192, %2408, %6970, %6971) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6972 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2413 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2411, %6972) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %6973 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2415 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2407, %2413, %6973) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.120 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2415) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2417 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.3 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.120, %2417) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6974 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2420 : None = prim::Constant()\n  %2421 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.3, %6974, %2420) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5496 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2426 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2421, %5496) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2427 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2426, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %6975 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2429 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2427, %6975) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2430 : Tensor[] = prim::ListConstruct(%2429, %5139)\n  %6976 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.121 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2430, %6976) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2462 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2463 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.121, %2462) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2464 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2465 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.192, %2464) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.193 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2467 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2468 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2463, %2465, %2355, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %6977 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6978 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6979 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6980 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2473 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5675, %6977, %6978, %6979, %6980) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6981 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6982 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %2476 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2473, %6981, %6982) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6983 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6984 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6985 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6986 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2481 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2476, %6983, %6984, %6985, %6986) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6987 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.122 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.193, %2481) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6988 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5680 : Long(device=cpu) = aten::size(%5675, %6988)\n  %6989 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5682 : None = prim::Constant()\n  %5683 : None = prim::Constant()\n  %5684 : None = prim::Constant()\n  %5685 : Tensor = aten::arange(%5680, %6989, %5682, %5683, %5684)\n  %6990 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5687 : Tensor = aten::slice(%5685, %6990, %6978, %6979, %6980)\n  %6991 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5690 : Tensor = aten::unsqueeze(%6982, %6991)\n  %6992 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5692 : Long(device=cpu) = aten::size(%5675, %6992)\n  %6993 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5694 : None = prim::Constant()\n  %5695 : None = prim::Constant()\n  %5696 : None = prim::Constant()\n  %5697 : Tensor = aten::arange(%5692, %6993, %5694, %5695, %5696)\n  %6994 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5699 : Tensor = aten::slice(%5697, %6994, %6984, %6985, %6986)\n  %5700 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5701 : Tensor = aten::view(%5687, %5700)\n  %5702 : int[] = prim::Constant[value=[-1, 1]]()\n  %5703 : Tensor = aten::view(%5690, %5702)\n  %5704 : int[] = prim::Constant[value=[-1]]()\n  %5705 : Tensor = aten::view(%5699, %5704)\n  %5706 : Tensor?[] = prim::ListConstruct(%5701, %5703, %5705)\n  %5707 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5675, %5706, %input.122, %6987)\n  %6995 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6996 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6997 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6998 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2488 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %6995, %6996, %6997, %6998) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6999 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7000 : Long(requires_grad=0, device=cpu) = prim::Constant[value={3}]()\n  %2491 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2488, %6999, %7000) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7001 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2493 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2491, %7001) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7002 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7003 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5500 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5146 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5500, %7002, %2493, %7003) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2518 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2519 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2518) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2520 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7004 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7005 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2523 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.193, %2520, %7004, %7005) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7006 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2525 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2523, %7006) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7007 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2527 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2519, %2525, %7007) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.123 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2527) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2529 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.4 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.123, %2529) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7008 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2532 : None = prim::Constant()\n  %2533 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.4, %7008, %2532) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5501 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2538 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2533, %5501) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2539 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2538, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7009 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2541 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2539, %7009) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2542 : Tensor[] = prim::ListConstruct(%2541, %5146)\n  %7010 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.124 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2542, %7010) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2574 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2575 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.124, %2574) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2576 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2577 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.193, %2576) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.194 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2579 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2580 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2575, %2577, %2467, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7011 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7012 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7013 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7014 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2585 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5707, %7011, %7012, %7013, %7014) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7015 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7016 : Long(requires_grad=0, device=cpu) = prim::Constant[value={3}]()\n  %2588 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2585, %7015, %7016) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7017 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7018 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7019 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7020 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2593 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2588, %7017, %7018, %7019, %7020) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7021 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.125 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.194, %2593) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7022 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5712 : Long(device=cpu) = aten::size(%5707, %7022)\n  %7023 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5714 : None = prim::Constant()\n  %5715 : None = prim::Constant()\n  %5716 : None = prim::Constant()\n  %5717 : Tensor = aten::arange(%5712, %7023, %5714, %5715, %5716)\n  %7024 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5719 : Tensor = aten::slice(%5717, %7024, %7012, %7013, %7014)\n  %7025 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5722 : Tensor = aten::unsqueeze(%7016, %7025)\n  %7026 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5724 : Long(device=cpu) = aten::size(%5707, %7026)\n  %7027 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5726 : None = prim::Constant()\n  %5727 : None = prim::Constant()\n  %5728 : None = prim::Constant()\n  %5729 : Tensor = aten::arange(%5724, %7027, %5726, %5727, %5728)\n  %7028 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5731 : Tensor = aten::slice(%5729, %7028, %7018, %7019, %7020)\n  %5732 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5733 : Tensor = aten::view(%5719, %5732)\n  %5734 : int[] = prim::Constant[value=[-1, 1]]()\n  %5735 : Tensor = aten::view(%5722, %5734)\n  %5736 : int[] = prim::Constant[value=[-1]]()\n  %5737 : Tensor = aten::view(%5731, %5736)\n  %5738 : Tensor?[] = prim::ListConstruct(%5733, %5735, %5737)\n  %5739 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5707, %5738, %input.125, %7021)\n  %7029 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7030 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7031 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7032 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2600 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7029, %7030, %7031, %7032) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7033 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7034 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %2603 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2600, %7033, %7034) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7035 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2605 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2603, %7035) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7036 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7037 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5505 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5153 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5505, %7036, %2605, %7037) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2630 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2631 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2630) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2632 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7038 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7039 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2635 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.194, %2632, %7038, %7039) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7040 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2637 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2635, %7040) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7041 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2639 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2631, %2637, %7041) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.126 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2639) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2641 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.5 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.126, %2641) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7042 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2644 : None = prim::Constant()\n  %2645 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.5, %7042, %2644) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5506 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2650 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2645, %5506) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2651 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2650, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7043 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2653 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2651, %7043) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2654 : Tensor[] = prim::ListConstruct(%2653, %5153)\n  %7044 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.127 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2654, %7044) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2686 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2687 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.127, %2686) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2688 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2689 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.194, %2688) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.195 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2691 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2692 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2687, %2689, %2579, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7045 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7046 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7047 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7048 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2697 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5739, %7045, %7046, %7047, %7048) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7049 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7050 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %2700 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2697, %7049, %7050) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7051 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7052 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7053 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7054 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2705 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2700, %7051, %7052, %7053, %7054) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7055 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.128 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.195, %2705) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7056 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5744 : Long(device=cpu) = aten::size(%5739, %7056)\n  %7057 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5746 : None = prim::Constant()\n  %5747 : None = prim::Constant()\n  %5748 : None = prim::Constant()\n  %5749 : Tensor = aten::arange(%5744, %7057, %5746, %5747, %5748)\n  %7058 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5751 : Tensor = aten::slice(%5749, %7058, %7046, %7047, %7048)\n  %7059 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5754 : Tensor = aten::unsqueeze(%7050, %7059)\n  %7060 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5756 : Long(device=cpu) = aten::size(%5739, %7060)\n  %7061 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5758 : None = prim::Constant()\n  %5759 : None = prim::Constant()\n  %5760 : None = prim::Constant()\n  %5761 : Tensor = aten::arange(%5756, %7061, %5758, %5759, %5760)\n  %7062 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5763 : Tensor = aten::slice(%5761, %7062, %7052, %7053, %7054)\n  %5764 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5765 : Tensor = aten::view(%5751, %5764)\n  %5766 : int[] = prim::Constant[value=[-1, 1]]()\n  %5767 : Tensor = aten::view(%5754, %5766)\n  %5768 : int[] = prim::Constant[value=[-1]]()\n  %5769 : Tensor = aten::view(%5763, %5768)\n  %5770 : Tensor?[] = prim::ListConstruct(%5765, %5767, %5769)\n  %5771 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5739, %5770, %input.128, %7055)\n  %7063 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7064 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7065 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7066 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2712 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7063, %7064, %7065, %7066) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7067 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7068 : Long(requires_grad=0, device=cpu) = prim::Constant[value={5}]()\n  %2715 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2712, %7067, %7068) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7069 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2717 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2715, %7069) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7070 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7071 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5510 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5160 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5510, %7070, %2717, %7071) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2742 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2743 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2742) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2744 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7072 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7073 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2747 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.195, %2744, %7072, %7073) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7074 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2749 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2747, %7074) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7075 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2751 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2743, %2749, %7075) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.129 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2751) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2753 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.6 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.129, %2753) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7076 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2756 : None = prim::Constant()\n  %2757 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.6, %7076, %2756) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5511 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2762 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2757, %5511) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2763 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2762, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7077 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2765 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2763, %7077) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2766 : Tensor[] = prim::ListConstruct(%2765, %5160)\n  %7078 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.130 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2766, %7078) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2798 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2799 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.130, %2798) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2800 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2801 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.195, %2800) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.196 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2803 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2804 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2799, %2801, %2691, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7079 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7080 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7081 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7082 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2809 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5771, %7079, %7080, %7081, %7082) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7083 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7084 : Long(requires_grad=0, device=cpu) = prim::Constant[value={5}]()\n  %2812 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2809, %7083, %7084) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7085 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7086 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7087 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7088 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2817 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2812, %7085, %7086, %7087, %7088) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7089 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.131 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.196, %2817) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7090 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5776 : Long(device=cpu) = aten::size(%5771, %7090)\n  %7091 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5778 : None = prim::Constant()\n  %5779 : None = prim::Constant()\n  %5780 : None = prim::Constant()\n  %5781 : Tensor = aten::arange(%5776, %7091, %5778, %5779, %5780)\n  %7092 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5783 : Tensor = aten::slice(%5781, %7092, %7080, %7081, %7082)\n  %7093 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5786 : Tensor = aten::unsqueeze(%7084, %7093)\n  %7094 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5788 : Long(device=cpu) = aten::size(%5771, %7094)\n  %7095 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5790 : None = prim::Constant()\n  %5791 : None = prim::Constant()\n  %5792 : None = prim::Constant()\n  %5793 : Tensor = aten::arange(%5788, %7095, %5790, %5791, %5792)\n  %7096 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5795 : Tensor = aten::slice(%5793, %7096, %7086, %7087, %7088)\n  %5796 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5797 : Tensor = aten::view(%5783, %5796)\n  %5798 : int[] = prim::Constant[value=[-1, 1]]()\n  %5799 : Tensor = aten::view(%5786, %5798)\n  %5800 : int[] = prim::Constant[value=[-1]]()\n  %5801 : Tensor = aten::view(%5795, %5800)\n  %5802 : Tensor?[] = prim::ListConstruct(%5797, %5799, %5801)\n  %5803 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5771, %5802, %input.131, %7089)\n  %7097 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7098 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7099 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7100 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2824 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7097, %7098, %7099, %7100) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7101 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7102 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %2827 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2824, %7101, %7102) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7103 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2829 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2827, %7103) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7104 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7105 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5515 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5167 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5515, %7104, %2829, %7105) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2854 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2855 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2854) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2856 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7106 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7107 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2859 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.196, %2856, %7106, %7107) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7108 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2861 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2859, %7108) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7109 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2863 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2855, %2861, %7109) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.132 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2863) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2865 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.7 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.132, %2865) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7110 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2868 : None = prim::Constant()\n  %2869 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.7, %7110, %2868) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5516 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2874 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2869, %5516) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2875 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2874, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7111 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2877 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2875, %7111) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2878 : Tensor[] = prim::ListConstruct(%2877, %5167)\n  %7112 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.133 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2878, %7112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2910 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2911 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.133, %2910) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2912 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2913 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.196, %2912) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.197 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2915 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2916 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2911, %2913, %2803, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7113 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7114 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7115 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7116 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2921 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5803, %7113, %7114, %7115, %7116) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7117 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7118 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %2924 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2921, %7117, %7118) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7119 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7120 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7121 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7122 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2929 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2924, %7119, %7120, %7121, %7122) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7123 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.134 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.197, %2929) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7124 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5808 : Long(device=cpu) = aten::size(%5803, %7124)\n  %7125 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5810 : None = prim::Constant()\n  %5811 : None = prim::Constant()\n  %5812 : None = prim::Constant()\n  %5813 : Tensor = aten::arange(%5808, %7125, %5810, %5811, %5812)\n  %7126 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5815 : Tensor = aten::slice(%5813, %7126, %7114, %7115, %7116)\n  %7127 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5818 : Tensor = aten::unsqueeze(%7118, %7127)\n  %7128 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5820 : Long(device=cpu) = aten::size(%5803, %7128)\n  %7129 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5822 : None = prim::Constant()\n  %5823 : None = prim::Constant()\n  %5824 : None = prim::Constant()\n  %5825 : Tensor = aten::arange(%5820, %7129, %5822, %5823, %5824)\n  %7130 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5827 : Tensor = aten::slice(%5825, %7130, %7120, %7121, %7122)\n  %5828 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5829 : Tensor = aten::view(%5815, %5828)\n  %5830 : int[] = prim::Constant[value=[-1, 1]]()\n  %5831 : Tensor = aten::view(%5818, %5830)\n  %5832 : int[] = prim::Constant[value=[-1]]()\n  %5833 : Tensor = aten::view(%5827, %5832)\n  %5834 : Tensor?[] = prim::ListConstruct(%5829, %5831, %5833)\n  %5835 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5803, %5834, %input.134, %7123)\n  %7131 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7132 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7133 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7134 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2936 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7131, %7132, %7133, %7134) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7135 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7136 : Long(requires_grad=0, device=cpu) = prim::Constant[value={7}]()\n  %2939 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2936, %7135, %7136) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7137 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2941 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2939, %7137) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7138 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7139 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5520 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5174 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5520, %7138, %2941, %7139) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2966 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2967 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2966) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2968 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7140 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7141 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2971 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.197, %2968, %7140, %7141) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7142 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2973 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2971, %7142) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7143 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2975 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2967, %2973, %7143) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.135 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2975) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2977 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.8 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.135, %2977) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7144 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2980 : None = prim::Constant()\n  %2981 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.8, %7144, %2980) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5521 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2986 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2981, %5521) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2987 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2986, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7145 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2989 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2987, %7145) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2990 : Tensor[] = prim::ListConstruct(%2989, %5174)\n  %7146 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.136 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2990, %7146) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3022 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3023 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.136, %3022) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3024 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3025 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.197, %3024) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.198 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3027 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3028 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3023, %3025, %2915, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7147 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7148 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7149 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7150 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3033 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5835, %7147, %7148, %7149, %7150) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7151 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7152 : Long(requires_grad=0, device=cpu) = prim::Constant[value={7}]()\n  %3036 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3033, %7151, %7152) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7153 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7154 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7155 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7156 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3041 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3036, %7153, %7154, %7155, %7156) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7157 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.137 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.198, %3041) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7158 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5840 : Long(device=cpu) = aten::size(%5835, %7158)\n  %7159 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5842 : None = prim::Constant()\n  %5843 : None = prim::Constant()\n  %5844 : None = prim::Constant()\n  %5845 : Tensor = aten::arange(%5840, %7159, %5842, %5843, %5844)\n  %7160 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5847 : Tensor = aten::slice(%5845, %7160, %7148, %7149, %7150)\n  %7161 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5850 : Tensor = aten::unsqueeze(%7152, %7161)\n  %7162 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5852 : Long(device=cpu) = aten::size(%5835, %7162)\n  %7163 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5854 : None = prim::Constant()\n  %5855 : None = prim::Constant()\n  %5856 : None = prim::Constant()\n  %5857 : Tensor = aten::arange(%5852, %7163, %5854, %5855, %5856)\n  %7164 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5859 : Tensor = aten::slice(%5857, %7164, %7154, %7155, %7156)\n  %5860 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5861 : Tensor = aten::view(%5847, %5860)\n  %5862 : int[] = prim::Constant[value=[-1, 1]]()\n  %5863 : Tensor = aten::view(%5850, %5862)\n  %5864 : int[] = prim::Constant[value=[-1]]()\n  %5865 : Tensor = aten::view(%5859, %5864)\n  %5866 : Tensor?[] = prim::ListConstruct(%5861, %5863, %5865)\n  %5867 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5835, %5866, %input.137, %7157)\n  %7165 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7166 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7167 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7168 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3048 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7165, %7166, %7167, %7168) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7169 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7170 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}]()\n  %3051 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3048, %7169, %7170) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7171 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3053 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3051, %7171) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7172 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7173 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5525 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5181 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5525, %7172, %3053, %7173) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3078 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3079 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3078) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3080 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7174 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7175 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3083 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.198, %3080, %7174, %7175) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7176 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3085 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3083, %7176) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7177 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3087 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3079, %3085, %7177) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.138 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3087) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3089 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.9 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.138, %3089) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7178 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3092 : None = prim::Constant()\n  %3093 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.9, %7178, %3092) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5526 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3098 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3093, %5526) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3099 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3098, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7179 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3101 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3099, %7179) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3102 : Tensor[] = prim::ListConstruct(%3101, %5181)\n  %7180 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.139 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3102, %7180) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3134 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3135 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.139, %3134) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3136 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3137 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.198, %3136) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.199 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3139 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3140 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3135, %3137, %3027, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7181 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7182 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7183 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7184 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3145 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5867, %7181, %7182, %7183, %7184) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7185 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7186 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}]()\n  %3148 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3145, %7185, %7186) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7187 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7188 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7189 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7190 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3153 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3148, %7187, %7188, %7189, %7190) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7191 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.140 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.199, %3153) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7192 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5872 : Long(device=cpu) = aten::size(%5867, %7192)\n  %7193 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5874 : None = prim::Constant()\n  %5875 : None = prim::Constant()\n  %5876 : None = prim::Constant()\n  %5877 : Tensor = aten::arange(%5872, %7193, %5874, %5875, %5876)\n  %7194 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5879 : Tensor = aten::slice(%5877, %7194, %7182, %7183, %7184)\n  %7195 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5882 : Tensor = aten::unsqueeze(%7186, %7195)\n  %7196 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5884 : Long(device=cpu) = aten::size(%5867, %7196)\n  %7197 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5886 : None = prim::Constant()\n  %5887 : None = prim::Constant()\n  %5888 : None = prim::Constant()\n  %5889 : Tensor = aten::arange(%5884, %7197, %5886, %5887, %5888)\n  %7198 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5891 : Tensor = aten::slice(%5889, %7198, %7188, %7189, %7190)\n  %5892 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5893 : Tensor = aten::view(%5879, %5892)\n  %5894 : int[] = prim::Constant[value=[-1, 1]]()\n  %5895 : Tensor = aten::view(%5882, %5894)\n  %5896 : int[] = prim::Constant[value=[-1]]()\n  %5897 : Tensor = aten::view(%5891, %5896)\n  %5898 : Tensor?[] = prim::ListConstruct(%5893, %5895, %5897)\n  %5899 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5867, %5898, %input.140, %7191)\n  %7199 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7200 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7201 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7202 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3160 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7199, %7200, %7201, %7202) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7203 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7204 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9}]()\n  %3163 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3160, %7203, %7204) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7205 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3165 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3163, %7205) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7206 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7207 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5530 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5188 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5530, %7206, %3165, %7207) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3190 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3191 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3190) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3192 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7208 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7209 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3195 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.199, %3192, %7208, %7209) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7210 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3197 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3195, %7210) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7211 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3199 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3191, %3197, %7211) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.141 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3199) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3201 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.10 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.141, %3201) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7212 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3204 : None = prim::Constant()\n  %3205 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.10, %7212, %3204) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5531 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3210 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3205, %5531) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3211 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3210, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7213 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3213 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3211, %7213) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3214 : Tensor[] = prim::ListConstruct(%3213, %5188)\n  %7214 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.142 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3214, %7214) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3246 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3247 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.142, %3246) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3248 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3249 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.199, %3248) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.200 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3251 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3252 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3247, %3249, %3139, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7215 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7216 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7217 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7218 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3257 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5899, %7215, %7216, %7217, %7218) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7219 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7220 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9}]()\n  %3260 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3257, %7219, %7220) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7221 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7222 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7223 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7224 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3265 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3260, %7221, %7222, %7223, %7224) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7225 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.143 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.200, %3265) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7226 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5904 : Long(device=cpu) = aten::size(%5899, %7226)\n  %7227 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5906 : None = prim::Constant()\n  %5907 : None = prim::Constant()\n  %5908 : None = prim::Constant()\n  %5909 : Tensor = aten::arange(%5904, %7227, %5906, %5907, %5908)\n  %7228 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5911 : Tensor = aten::slice(%5909, %7228, %7216, %7217, %7218)\n  %7229 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5914 : Tensor = aten::unsqueeze(%7220, %7229)\n  %7230 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5916 : Long(device=cpu) = aten::size(%5899, %7230)\n  %7231 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5918 : None = prim::Constant()\n  %5919 : None = prim::Constant()\n  %5920 : None = prim::Constant()\n  %5921 : Tensor = aten::arange(%5916, %7231, %5918, %5919, %5920)\n  %7232 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5923 : Tensor = aten::slice(%5921, %7232, %7222, %7223, %7224)\n  %5924 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5925 : Tensor = aten::view(%5911, %5924)\n  %5926 : int[] = prim::Constant[value=[-1, 1]]()\n  %5927 : Tensor = aten::view(%5914, %5926)\n  %5928 : int[] = prim::Constant[value=[-1]]()\n  %5929 : Tensor = aten::view(%5923, %5928)\n  %5930 : Tensor?[] = prim::ListConstruct(%5925, %5927, %5929)\n  %5931 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5899, %5930, %input.143, %7225)\n  %7233 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7234 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7235 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7236 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3272 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7233, %7234, %7235, %7236) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7237 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7238 : Long(requires_grad=0, device=cpu) = prim::Constant[value={10}]()\n  %3275 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3272, %7237, %7238) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7239 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3277 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3275, %7239) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7240 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7241 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5535 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5195 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5535, %7240, %3277, %7241) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3302 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3303 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3302) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3304 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7242 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7243 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3307 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.200, %3304, %7242, %7243) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7244 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3309 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3307, %7244) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7245 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3311 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3303, %3309, %7245) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.144 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3311) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3313 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.11 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.144, %3313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7246 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3316 : None = prim::Constant()\n  %3317 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.11, %7246, %3316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5536 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3322 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3317, %5536) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3323 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3322, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7247 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3325 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3323, %7247) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3326 : Tensor[] = prim::ListConstruct(%3325, %5195)\n  %7248 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.145 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3326, %7248) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3358 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3359 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.145, %3358) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3360 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3361 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.200, %3360) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.201 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3363 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3364 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3359, %3361, %3251, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7249 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7250 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7251 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7252 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3369 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5931, %7249, %7250, %7251, %7252) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7253 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7254 : Long(requires_grad=0, device=cpu) = prim::Constant[value={10}]()\n  %3372 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3369, %7253, %7254) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7255 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7256 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7257 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7258 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3377 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3372, %7255, %7256, %7257, %7258) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7259 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.146 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.201, %3377) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7260 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5936 : Long(device=cpu) = aten::size(%5931, %7260)\n  %7261 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5938 : None = prim::Constant()\n  %5939 : None = prim::Constant()\n  %5940 : None = prim::Constant()\n  %5941 : Tensor = aten::arange(%5936, %7261, %5938, %5939, %5940)\n  %7262 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5943 : Tensor = aten::slice(%5941, %7262, %7250, %7251, %7252)\n  %7263 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5946 : Tensor = aten::unsqueeze(%7254, %7263)\n  %7264 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5948 : Long(device=cpu) = aten::size(%5931, %7264)\n  %7265 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5950 : None = prim::Constant()\n  %5951 : None = prim::Constant()\n  %5952 : None = prim::Constant()\n  %5953 : Tensor = aten::arange(%5948, %7265, %5950, %5951, %5952)\n  %7266 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5955 : Tensor = aten::slice(%5953, %7266, %7256, %7257, %7258)\n  %5956 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5957 : Tensor = aten::view(%5943, %5956)\n  %5958 : int[] = prim::Constant[value=[-1, 1]]()\n  %5959 : Tensor = aten::view(%5946, %5958)\n  %5960 : int[] = prim::Constant[value=[-1]]()\n  %5961 : Tensor = aten::view(%5955, %5960)\n  %5962 : Tensor?[] = prim::ListConstruct(%5957, %5959, %5961)\n  %5963 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5931, %5962, %input.146, %7259)\n  %7267 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7268 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7269 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7270 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3384 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7267, %7268, %7269, %7270) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7271 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7272 : Long(requires_grad=0, device=cpu) = prim::Constant[value={11}]()\n  %3387 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3384, %7271, %7272) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7273 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3389 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3387, %7273) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7274 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7275 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5540 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5202 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5540, %7274, %3389, %7275) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3414 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3415 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3414) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3416 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7276 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7277 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3419 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.201, %3416, %7276, %7277) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7278 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3421 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3419, %7278) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7279 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3423 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3415, %3421, %7279) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.147 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3423) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3425 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.12 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.147, %3425) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7280 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3428 : None = prim::Constant()\n  %3429 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.12, %7280, %3428) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5541 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3434 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3429, %5541) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3435 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3434, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7281 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3437 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3435, %7281) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3438 : Tensor[] = prim::ListConstruct(%3437, %5202)\n  %7282 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.148 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3438, %7282) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3470 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3471 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.148, %3470) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3472 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3473 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.201, %3472) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.202 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3475 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3476 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3471, %3473, %3363, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7283 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7284 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7285 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7286 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3481 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5963, %7283, %7284, %7285, %7286) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7287 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7288 : Long(requires_grad=0, device=cpu) = prim::Constant[value={11}]()\n  %3484 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3481, %7287, %7288) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7289 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7290 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7291 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7292 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3489 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3484, %7289, %7290, %7291, %7292) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7293 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.149 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.202, %3489) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7294 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5968 : Long(device=cpu) = aten::size(%5963, %7294)\n  %7295 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5970 : None = prim::Constant()\n  %5971 : None = prim::Constant()\n  %5972 : None = prim::Constant()\n  %5973 : Tensor = aten::arange(%5968, %7295, %5970, %5971, %5972)\n  %7296 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5975 : Tensor = aten::slice(%5973, %7296, %7284, %7285, %7286)\n  %7297 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5978 : Tensor = aten::unsqueeze(%7288, %7297)\n  %7298 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5980 : Long(device=cpu) = aten::size(%5963, %7298)\n  %7299 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5982 : None = prim::Constant()\n  %5983 : None = prim::Constant()\n  %5984 : None = prim::Constant()\n  %5985 : Tensor = aten::arange(%5980, %7299, %5982, %5983, %5984)\n  %7300 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5987 : Tensor = aten::slice(%5985, %7300, %7290, %7291, %7292)\n  %5988 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5989 : Tensor = aten::view(%5975, %5988)\n  %5990 : int[] = prim::Constant[value=[-1, 1]]()\n  %5991 : Tensor = aten::view(%5978, %5990)\n  %5992 : int[] = prim::Constant[value=[-1]]()\n  %5993 : Tensor = aten::view(%5987, %5992)\n  %5994 : Tensor?[] = prim::ListConstruct(%5989, %5991, %5993)\n  %5995 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5963, %5994, %input.149, %7293)\n  %7301 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7302 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7303 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7304 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3496 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7301, %7302, %7303, %7304) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7305 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7306 : Long(requires_grad=0, device=cpu) = prim::Constant[value={12}]()\n  %3499 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3496, %7305, %7306) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7307 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3501 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3499, %7307) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7308 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7309 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5545 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5209 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5545, %7308, %3501, %7309) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3526 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3527 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3526) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3528 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7310 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7311 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3531 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.202, %3528, %7310, %7311) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7312 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3533 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3531, %7312) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7313 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3535 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3527, %3533, %7313) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.150 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3535) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3537 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.13 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.150, %3537) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7314 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3540 : None = prim::Constant()\n  %3541 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.13, %7314, %3540) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5546 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3546 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3541, %5546) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3547 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3546, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7315 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3549 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3547, %7315) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3550 : Tensor[] = prim::ListConstruct(%3549, %5209)\n  %7316 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.151 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3550, %7316) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3582 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3583 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.151, %3582) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3584 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3585 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.202, %3584) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.203 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3587 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3588 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3583, %3585, %3475, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7317 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7318 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7319 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7320 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3593 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5995, %7317, %7318, %7319, %7320) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7321 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7322 : Long(requires_grad=0, device=cpu) = prim::Constant[value={12}]()\n  %3596 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3593, %7321, %7322) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7323 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7324 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7325 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7326 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3601 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3596, %7323, %7324, %7325, %7326) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7327 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.152 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.203, %3601) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7328 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6000 : Long(device=cpu) = aten::size(%5995, %7328)\n  %7329 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6002 : None = prim::Constant()\n  %6003 : None = prim::Constant()\n  %6004 : None = prim::Constant()\n  %6005 : Tensor = aten::arange(%6000, %7329, %6002, %6003, %6004)\n  %7330 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6007 : Tensor = aten::slice(%6005, %7330, %7318, %7319, %7320)\n  %7331 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6010 : Tensor = aten::unsqueeze(%7322, %7331)\n  %7332 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6012 : Long(device=cpu) = aten::size(%5995, %7332)\n  %7333 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6014 : None = prim::Constant()\n  %6015 : None = prim::Constant()\n  %6016 : None = prim::Constant()\n  %6017 : Tensor = aten::arange(%6012, %7333, %6014, %6015, %6016)\n  %7334 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6019 : Tensor = aten::slice(%6017, %7334, %7324, %7325, %7326)\n  %6020 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6021 : Tensor = aten::view(%6007, %6020)\n  %6022 : int[] = prim::Constant[value=[-1, 1]]()\n  %6023 : Tensor = aten::view(%6010, %6022)\n  %6024 : int[] = prim::Constant[value=[-1]]()\n  %6025 : Tensor = aten::view(%6019, %6024)\n  %6026 : Tensor?[] = prim::ListConstruct(%6021, %6023, %6025)\n  %6027 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5995, %6026, %input.152, %7327)\n  %7335 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7336 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7337 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7338 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3608 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7335, %7336, %7337, %7338) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7339 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7340 : Long(requires_grad=0, device=cpu) = prim::Constant[value={13}]()\n  %3611 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3608, %7339, %7340) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7341 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3613 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3611, %7341) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7342 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7343 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5550 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5216 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5550, %7342, %3613, %7343) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3638 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3639 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3638) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3640 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7344 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7345 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3643 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.203, %3640, %7344, %7345) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7346 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3645 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3643, %7346) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7347 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3647 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3639, %3645, %7347) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.153 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3647) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3649 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.14 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.153, %3649) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7348 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3652 : None = prim::Constant()\n  %3653 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.14, %7348, %3652) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5551 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3658 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3653, %5551) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3659 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3658, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7349 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3661 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3659, %7349) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3662 : Tensor[] = prim::ListConstruct(%3661, %5216)\n  %7350 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.154 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3662, %7350) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3694 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3695 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.154, %3694) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3696 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3697 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.203, %3696) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.204 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3699 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3700 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3695, %3697, %3587, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7351 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7352 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7353 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7354 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3705 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6027, %7351, %7352, %7353, %7354) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7355 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7356 : Long(requires_grad=0, device=cpu) = prim::Constant[value={13}]()\n  %3708 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3705, %7355, %7356) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7357 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7358 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7359 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7360 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3713 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3708, %7357, %7358, %7359, %7360) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7361 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.155 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.204, %3713) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7362 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6032 : Long(device=cpu) = aten::size(%6027, %7362)\n  %7363 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6034 : None = prim::Constant()\n  %6035 : None = prim::Constant()\n  %6036 : None = prim::Constant()\n  %6037 : Tensor = aten::arange(%6032, %7363, %6034, %6035, %6036)\n  %7364 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6039 : Tensor = aten::slice(%6037, %7364, %7352, %7353, %7354)\n  %7365 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6042 : Tensor = aten::unsqueeze(%7356, %7365)\n  %7366 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6044 : Long(device=cpu) = aten::size(%6027, %7366)\n  %7367 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6046 : None = prim::Constant()\n  %6047 : None = prim::Constant()\n  %6048 : None = prim::Constant()\n  %6049 : Tensor = aten::arange(%6044, %7367, %6046, %6047, %6048)\n  %7368 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6051 : Tensor = aten::slice(%6049, %7368, %7358, %7359, %7360)\n  %6052 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6053 : Tensor = aten::view(%6039, %6052)\n  %6054 : int[] = prim::Constant[value=[-1, 1]]()\n  %6055 : Tensor = aten::view(%6042, %6054)\n  %6056 : int[] = prim::Constant[value=[-1]]()\n  %6057 : Tensor = aten::view(%6051, %6056)\n  %6058 : Tensor?[] = prim::ListConstruct(%6053, %6055, %6057)\n  %6059 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6027, %6058, %input.155, %7361)\n  %7369 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7370 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7371 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7372 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3720 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7369, %7370, %7371, %7372) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7373 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7374 : Long(requires_grad=0, device=cpu) = prim::Constant[value={14}]()\n  %3723 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3720, %7373, %7374) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7375 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3725 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3723, %7375) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7376 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7377 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5555 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5223 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5555, %7376, %3725, %7377) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3750 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3751 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3750) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3752 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7378 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7379 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3755 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.204, %3752, %7378, %7379) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7380 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3757 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3755, %7380) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7381 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3759 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3751, %3757, %7381) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.156 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3759) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3761 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.15 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.156, %3761) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7382 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3764 : None = prim::Constant()\n  %3765 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.15, %7382, %3764) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5556 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3770 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3765, %5556) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3771 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3770, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7383 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3773 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3771, %7383) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3774 : Tensor[] = prim::ListConstruct(%3773, %5223)\n  %7384 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.157 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3774, %7384) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3806 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3807 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.157, %3806) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3808 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3809 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.204, %3808) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.205 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3811 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3812 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3807, %3809, %3699, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7385 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7386 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7387 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7388 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3817 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6059, %7385, %7386, %7387, %7388) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7389 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7390 : Long(requires_grad=0, device=cpu) = prim::Constant[value={14}]()\n  %3820 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3817, %7389, %7390) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7391 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7392 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7393 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7394 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3825 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3820, %7391, %7392, %7393, %7394) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7395 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.158 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.205, %3825) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7396 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6064 : Long(device=cpu) = aten::size(%6059, %7396)\n  %7397 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6066 : None = prim::Constant()\n  %6067 : None = prim::Constant()\n  %6068 : None = prim::Constant()\n  %6069 : Tensor = aten::arange(%6064, %7397, %6066, %6067, %6068)\n  %7398 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6071 : Tensor = aten::slice(%6069, %7398, %7386, %7387, %7388)\n  %7399 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6074 : Tensor = aten::unsqueeze(%7390, %7399)\n  %7400 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6076 : Long(device=cpu) = aten::size(%6059, %7400)\n  %7401 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6078 : None = prim::Constant()\n  %6079 : None = prim::Constant()\n  %6080 : None = prim::Constant()\n  %6081 : Tensor = aten::arange(%6076, %7401, %6078, %6079, %6080)\n  %7402 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6083 : Tensor = aten::slice(%6081, %7402, %7392, %7393, %7394)\n  %6084 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6085 : Tensor = aten::view(%6071, %6084)\n  %6086 : int[] = prim::Constant[value=[-1, 1]]()\n  %6087 : Tensor = aten::view(%6074, %6086)\n  %6088 : int[] = prim::Constant[value=[-1]]()\n  %6089 : Tensor = aten::view(%6083, %6088)\n  %6090 : Tensor?[] = prim::ListConstruct(%6085, %6087, %6089)\n  %6091 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6059, %6090, %input.158, %7395)\n  %7403 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7404 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7405 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7406 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3832 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7403, %7404, %7405, %7406) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7407 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7408 : Long(requires_grad=0, device=cpu) = prim::Constant[value={15}]()\n  %3835 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3832, %7407, %7408) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7409 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3837 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3835, %7409) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7410 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7411 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5560 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5230 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5560, %7410, %3837, %7411) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3862 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3863 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3862) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3864 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7412 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7413 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3867 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.205, %3864, %7412, %7413) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7414 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3869 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3867, %7414) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7415 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3871 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3863, %3869, %7415) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.159 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3871) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3873 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.16 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.159, %3873) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7416 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3876 : None = prim::Constant()\n  %3877 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.16, %7416, %3876) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5561 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3882 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3877, %5561) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3883 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3882, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7417 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3885 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3883, %7417) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3886 : Tensor[] = prim::ListConstruct(%3885, %5230)\n  %7418 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.160 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3886, %7418) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3918 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3919 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.160, %3918) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3920 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3921 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.205, %3920) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.206 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3923 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3924 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3919, %3921, %3811, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7419 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7420 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7421 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7422 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3929 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6091, %7419, %7420, %7421, %7422) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7423 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7424 : Long(requires_grad=0, device=cpu) = prim::Constant[value={15}]()\n  %3932 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3929, %7423, %7424) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7425 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7426 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7427 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7428 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3937 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3932, %7425, %7426, %7427, %7428) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7429 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.161 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.206, %3937) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7430 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6096 : Long(device=cpu) = aten::size(%6091, %7430)\n  %7431 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6098 : None = prim::Constant()\n  %6099 : None = prim::Constant()\n  %6100 : None = prim::Constant()\n  %6101 : Tensor = aten::arange(%6096, %7431, %6098, %6099, %6100)\n  %7432 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6103 : Tensor = aten::slice(%6101, %7432, %7420, %7421, %7422)\n  %7433 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6106 : Tensor = aten::unsqueeze(%7424, %7433)\n  %7434 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6108 : Long(device=cpu) = aten::size(%6091, %7434)\n  %7435 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6110 : None = prim::Constant()\n  %6111 : None = prim::Constant()\n  %6112 : None = prim::Constant()\n  %6113 : Tensor = aten::arange(%6108, %7435, %6110, %6111, %6112)\n  %7436 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6115 : Tensor = aten::slice(%6113, %7436, %7426, %7427, %7428)\n  %6116 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6117 : Tensor = aten::view(%6103, %6116)\n  %6118 : int[] = prim::Constant[value=[-1, 1]]()\n  %6119 : Tensor = aten::view(%6106, %6118)\n  %6120 : int[] = prim::Constant[value=[-1]]()\n  %6121 : Tensor = aten::view(%6115, %6120)\n  %6122 : Tensor?[] = prim::ListConstruct(%6117, %6119, %6121)\n  %6123 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6091, %6122, %input.161, %7429)\n  %7437 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7438 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7439 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7440 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3944 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7437, %7438, %7439, %7440) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7441 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7442 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]()\n  %3947 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3944, %7441, %7442) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7443 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3949 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3947, %7443) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7444 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7445 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5565 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5237 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5565, %7444, %3949, %7445) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3974 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3975 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3974) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3976 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7446 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7447 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3979 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.206, %3976, %7446, %7447) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7448 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3981 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3979, %7448) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7449 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3983 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3975, %3981, %7449) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.162 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3983) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3985 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.17 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.162, %3985) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7450 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3988 : None = prim::Constant()\n  %3989 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.17, %7450, %3988) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5566 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3994 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3989, %5566) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3995 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3994, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7451 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3997 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3995, %7451) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3998 : Tensor[] = prim::ListConstruct(%3997, %5237)\n  %7452 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.163 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3998, %7452) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4030 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4031 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.163, %4030) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4032 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4033 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.206, %4032) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.207 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4035 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4036 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4031, %4033, %3923, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7453 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7454 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7455 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7456 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4041 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6123, %7453, %7454, %7455, %7456) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7457 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7458 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]()\n  %4044 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4041, %7457, %7458) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7459 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7460 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7461 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7462 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4049 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4044, %7459, %7460, %7461, %7462) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7463 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.164 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.207, %4049) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7464 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6128 : Long(device=cpu) = aten::size(%6123, %7464)\n  %7465 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6130 : None = prim::Constant()\n  %6131 : None = prim::Constant()\n  %6132 : None = prim::Constant()\n  %6133 : Tensor = aten::arange(%6128, %7465, %6130, %6131, %6132)\n  %7466 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6135 : Tensor = aten::slice(%6133, %7466, %7454, %7455, %7456)\n  %7467 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6138 : Tensor = aten::unsqueeze(%7458, %7467)\n  %7468 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6140 : Long(device=cpu) = aten::size(%6123, %7468)\n  %7469 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6142 : None = prim::Constant()\n  %6143 : None = prim::Constant()\n  %6144 : None = prim::Constant()\n  %6145 : Tensor = aten::arange(%6140, %7469, %6142, %6143, %6144)\n  %7470 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6147 : Tensor = aten::slice(%6145, %7470, %7460, %7461, %7462)\n  %6148 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6149 : Tensor = aten::view(%6135, %6148)\n  %6150 : int[] = prim::Constant[value=[-1, 1]]()\n  %6151 : Tensor = aten::view(%6138, %6150)\n  %6152 : int[] = prim::Constant[value=[-1]]()\n  %6153 : Tensor = aten::view(%6147, %6152)\n  %6154 : Tensor?[] = prim::ListConstruct(%6149, %6151, %6153)\n  %6155 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6123, %6154, %input.164, %7463)\n  %7471 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7472 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7473 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7474 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4056 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7471, %7472, %7473, %7474) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7475 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7476 : Long(requires_grad=0, device=cpu) = prim::Constant[value={17}]()\n  %4059 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4056, %7475, %7476) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7477 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4061 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4059, %7477) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7478 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7479 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5570 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5244 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5570, %7478, %4061, %7479) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4086 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4087 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4086) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4088 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7480 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7481 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4091 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.207, %4088, %7480, %7481) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7482 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4093 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4091, %7482) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7483 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4095 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4087, %4093, %7483) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.165 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4095) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4097 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.18 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.165, %4097) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7484 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4100 : None = prim::Constant()\n  %4101 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.18, %7484, %4100) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5571 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4106 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4101, %5571) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4107 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4106, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7485 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4109 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4107, %7485) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4110 : Tensor[] = prim::ListConstruct(%4109, %5244)\n  %7486 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.166 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4110, %7486) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4142 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4143 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.166, %4142) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4144 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4145 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.207, %4144) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.208 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4147 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4148 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4143, %4145, %4035, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7487 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7488 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7489 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7490 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4153 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6155, %7487, %7488, %7489, %7490) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7491 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7492 : Long(requires_grad=0, device=cpu) = prim::Constant[value={17}]()\n  %4156 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4153, %7491, %7492) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7493 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7494 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7495 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7496 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4161 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4156, %7493, %7494, %7495, %7496) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7497 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.167 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.208, %4161) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7498 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6160 : Long(device=cpu) = aten::size(%6155, %7498)\n  %7499 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6162 : None = prim::Constant()\n  %6163 : None = prim::Constant()\n  %6164 : None = prim::Constant()\n  %6165 : Tensor = aten::arange(%6160, %7499, %6162, %6163, %6164)\n  %7500 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6167 : Tensor = aten::slice(%6165, %7500, %7488, %7489, %7490)\n  %7501 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6170 : Tensor = aten::unsqueeze(%7492, %7501)\n  %7502 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6172 : Long(device=cpu) = aten::size(%6155, %7502)\n  %7503 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6174 : None = prim::Constant()\n  %6175 : None = prim::Constant()\n  %6176 : None = prim::Constant()\n  %6177 : Tensor = aten::arange(%6172, %7503, %6174, %6175, %6176)\n  %7504 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6179 : Tensor = aten::slice(%6177, %7504, %7494, %7495, %7496)\n  %6180 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6181 : Tensor = aten::view(%6167, %6180)\n  %6182 : int[] = prim::Constant[value=[-1, 1]]()\n  %6183 : Tensor = aten::view(%6170, %6182)\n  %6184 : int[] = prim::Constant[value=[-1]]()\n  %6185 : Tensor = aten::view(%6179, %6184)\n  %6186 : Tensor?[] = prim::ListConstruct(%6181, %6183, %6185)\n  %6187 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6155, %6186, %input.167, %7497)\n  %7505 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7506 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7507 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7508 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4168 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7505, %7506, %7507, %7508) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7509 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7510 : Long(requires_grad=0, device=cpu) = prim::Constant[value={18}]()\n  %4171 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4168, %7509, %7510) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7511 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4173 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4171, %7511) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7512 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7513 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5575 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5251 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5575, %7512, %4173, %7513) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4198 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4199 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4198) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4200 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7514 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7515 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4203 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.208, %4200, %7514, %7515) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7516 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4205 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4203, %7516) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7517 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4207 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4199, %4205, %7517) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.168 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4207) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4209 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.19 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.168, %4209) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7518 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4212 : None = prim::Constant()\n  %4213 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.19, %7518, %4212) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5576 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4218 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4213, %5576) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4219 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4218, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7519 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4221 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4219, %7519) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4222 : Tensor[] = prim::ListConstruct(%4221, %5251)\n  %7520 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.169 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4222, %7520) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4254 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4255 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.169, %4254) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4256 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4257 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.208, %4256) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.209 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4259 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4260 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4255, %4257, %4147, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7521 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7522 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7523 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7524 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4265 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6187, %7521, %7522, %7523, %7524) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7525 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7526 : Long(requires_grad=0, device=cpu) = prim::Constant[value={18}]()\n  %4268 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4265, %7525, %7526) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7527 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7528 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7529 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7530 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4273 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4268, %7527, %7528, %7529, %7530) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7531 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.170 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.209, %4273) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7532 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6192 : Long(device=cpu) = aten::size(%6187, %7532)\n  %7533 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6194 : None = prim::Constant()\n  %6195 : None = prim::Constant()\n  %6196 : None = prim::Constant()\n  %6197 : Tensor = aten::arange(%6192, %7533, %6194, %6195, %6196)\n  %7534 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6199 : Tensor = aten::slice(%6197, %7534, %7522, %7523, %7524)\n  %7535 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6202 : Tensor = aten::unsqueeze(%7526, %7535)\n  %7536 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6204 : Long(device=cpu) = aten::size(%6187, %7536)\n  %7537 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6206 : None = prim::Constant()\n  %6207 : None = prim::Constant()\n  %6208 : None = prim::Constant()\n  %6209 : Tensor = aten::arange(%6204, %7537, %6206, %6207, %6208)\n  %7538 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6211 : Tensor = aten::slice(%6209, %7538, %7528, %7529, %7530)\n  %6212 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6213 : Tensor = aten::view(%6199, %6212)\n  %6214 : int[] = prim::Constant[value=[-1, 1]]()\n  %6215 : Tensor = aten::view(%6202, %6214)\n  %6216 : int[] = prim::Constant[value=[-1]]()\n  %6217 : Tensor = aten::view(%6211, %6216)\n  %6218 : Tensor?[] = prim::ListConstruct(%6213, %6215, %6217)\n  %6219 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6187, %6218, %input.170, %7531)\n  %7539 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7540 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7541 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7542 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4280 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7539, %7540, %7541, %7542) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7543 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7544 : Long(requires_grad=0, device=cpu) = prim::Constant[value={19}]()\n  %4283 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4280, %7543, %7544) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7545 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4285 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4283, %7545) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7546 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7547 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5580 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5258 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5580, %7546, %4285, %7547) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4310 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4311 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4310) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4312 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7548 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7549 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4315 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.209, %4312, %7548, %7549) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7550 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4317 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4315, %7550) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7551 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4319 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4311, %4317, %7551) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.171 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4319) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4321 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.20 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.171, %4321) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7552 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4324 : None = prim::Constant()\n  %4325 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.20, %7552, %4324) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5581 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4330 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4325, %5581) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4331 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4330, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7553 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4333 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4331, %7553) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4334 : Tensor[] = prim::ListConstruct(%4333, %5258)\n  %7554 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.172 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4334, %7554) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4366 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4367 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.172, %4366) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4368 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4369 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.209, %4368) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.210 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4371 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4372 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4367, %4369, %4259, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7555 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7556 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7557 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7558 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4377 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6219, %7555, %7556, %7557, %7558) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7559 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7560 : Long(requires_grad=0, device=cpu) = prim::Constant[value={19}]()\n  %4380 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4377, %7559, %7560) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7561 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7562 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7563 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7564 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4385 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4380, %7561, %7562, %7563, %7564) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7565 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.173 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.210, %4385) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7566 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6224 : Long(device=cpu) = aten::size(%6219, %7566)\n  %7567 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6226 : None = prim::Constant()\n  %6227 : None = prim::Constant()\n  %6228 : None = prim::Constant()\n  %6229 : Tensor = aten::arange(%6224, %7567, %6226, %6227, %6228)\n  %7568 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6231 : Tensor = aten::slice(%6229, %7568, %7556, %7557, %7558)\n  %7569 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6234 : Tensor = aten::unsqueeze(%7560, %7569)\n  %7570 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6236 : Long(device=cpu) = aten::size(%6219, %7570)\n  %7571 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6238 : None = prim::Constant()\n  %6239 : None = prim::Constant()\n  %6240 : None = prim::Constant()\n  %6241 : Tensor = aten::arange(%6236, %7571, %6238, %6239, %6240)\n  %7572 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6243 : Tensor = aten::slice(%6241, %7572, %7562, %7563, %7564)\n  %6244 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6245 : Tensor = aten::view(%6231, %6244)\n  %6246 : int[] = prim::Constant[value=[-1, 1]]()\n  %6247 : Tensor = aten::view(%6234, %6246)\n  %6248 : int[] = prim::Constant[value=[-1]]()\n  %6249 : Tensor = aten::view(%6243, %6248)\n  %6250 : Tensor?[] = prim::ListConstruct(%6245, %6247, %6249)\n  %6251 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6219, %6250, %input.173, %7565)\n  %7573 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7574 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7575 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7576 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4392 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7573, %7574, %7575, %7576) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7577 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7578 : Long(requires_grad=0, device=cpu) = prim::Constant[value={20}]()\n  %4395 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4392, %7577, %7578) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7579 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4397 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4395, %7579) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7580 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7581 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5585 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5265 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5585, %7580, %4397, %7581) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4422 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4423 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4422) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4424 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7582 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7583 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4427 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.210, %4424, %7582, %7583) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7584 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4429 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4427, %7584) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7585 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4431 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4423, %4429, %7585) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.174 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4431) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4433 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.21 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.174, %4433) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7586 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4436 : None = prim::Constant()\n  %4437 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.21, %7586, %4436) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5586 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4442 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4437, %5586) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4443 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4442, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7587 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4445 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4443, %7587) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4446 : Tensor[] = prim::ListConstruct(%4445, %5265)\n  %7588 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.175 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4446, %7588) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4478 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4479 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.175, %4478) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4480 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4481 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.210, %4480) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.211 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4483 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4484 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4479, %4481, %4371, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7589 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7590 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7591 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7592 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4489 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6251, %7589, %7590, %7591, %7592) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7593 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7594 : Long(requires_grad=0, device=cpu) = prim::Constant[value={20}]()\n  %4492 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4489, %7593, %7594) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7595 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7596 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7597 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7598 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4497 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4492, %7595, %7596, %7597, %7598) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7599 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.176 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.211, %4497) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7600 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6256 : Long(device=cpu) = aten::size(%6251, %7600)\n  %7601 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6258 : None = prim::Constant()\n  %6259 : None = prim::Constant()\n  %6260 : None = prim::Constant()\n  %6261 : Tensor = aten::arange(%6256, %7601, %6258, %6259, %6260)\n  %7602 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6263 : Tensor = aten::slice(%6261, %7602, %7590, %7591, %7592)\n  %7603 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6266 : Tensor = aten::unsqueeze(%7594, %7603)\n  %7604 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6268 : Long(device=cpu) = aten::size(%6251, %7604)\n  %7605 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6270 : None = prim::Constant()\n  %6271 : None = prim::Constant()\n  %6272 : None = prim::Constant()\n  %6273 : Tensor = aten::arange(%6268, %7605, %6270, %6271, %6272)\n  %7606 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6275 : Tensor = aten::slice(%6273, %7606, %7596, %7597, %7598)\n  %6276 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6277 : Tensor = aten::view(%6263, %6276)\n  %6278 : int[] = prim::Constant[value=[-1, 1]]()\n  %6279 : Tensor = aten::view(%6266, %6278)\n  %6280 : int[] = prim::Constant[value=[-1]]()\n  %6281 : Tensor = aten::view(%6275, %6280)\n  %6282 : Tensor?[] = prim::ListConstruct(%6277, %6279, %6281)\n  %6283 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6251, %6282, %input.176, %7599)\n  %7607 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7608 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7609 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7610 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4504 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7607, %7608, %7609, %7610) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7611 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7612 : Long(requires_grad=0, device=cpu) = prim::Constant[value={21}]()\n  %4507 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4504, %7611, %7612) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7613 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4509 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4507, %7613) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7614 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7615 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5590 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5272 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5590, %7614, %4509, %7615) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4534 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4535 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4534) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4536 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7616 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7617 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4539 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.211, %4536, %7616, %7617) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7618 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4541 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4539, %7618) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7619 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4543 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4535, %4541, %7619) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.177 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4543) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4545 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.22 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.177, %4545) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7620 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4548 : None = prim::Constant()\n  %4549 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.22, %7620, %4548) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5591 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4554 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4549, %5591) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4555 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4554, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7621 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4557 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4555, %7621) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4558 : Tensor[] = prim::ListConstruct(%4557, %5272)\n  %7622 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.178 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4558, %7622) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4590 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4591 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.178, %4590) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4592 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4593 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.211, %4592) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.212 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4595 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4596 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4591, %4593, %4483, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7623 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7624 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7625 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7626 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4601 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6283, %7623, %7624, %7625, %7626) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7627 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7628 : Long(requires_grad=0, device=cpu) = prim::Constant[value={21}]()\n  %4604 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4601, %7627, %7628) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7629 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7630 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7631 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7632 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4609 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4604, %7629, %7630, %7631, %7632) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7633 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.179 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.212, %4609) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7634 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6288 : Long(device=cpu) = aten::size(%6283, %7634)\n  %7635 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6290 : None = prim::Constant()\n  %6291 : None = prim::Constant()\n  %6292 : None = prim::Constant()\n  %6293 : Tensor = aten::arange(%6288, %7635, %6290, %6291, %6292)\n  %7636 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6295 : Tensor = aten::slice(%6293, %7636, %7624, %7625, %7626)\n  %7637 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6298 : Tensor = aten::unsqueeze(%7628, %7637)\n  %7638 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6300 : Long(device=cpu) = aten::size(%6283, %7638)\n  %7639 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6302 : None = prim::Constant()\n  %6303 : None = prim::Constant()\n  %6304 : None = prim::Constant()\n  %6305 : Tensor = aten::arange(%6300, %7639, %6302, %6303, %6304)\n  %7640 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6307 : Tensor = aten::slice(%6305, %7640, %7630, %7631, %7632)\n  %6308 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6309 : Tensor = aten::view(%6295, %6308)\n  %6310 : int[] = prim::Constant[value=[-1, 1]]()\n  %6311 : Tensor = aten::view(%6298, %6310)\n  %6312 : int[] = prim::Constant[value=[-1]]()\n  %6313 : Tensor = aten::view(%6307, %6312)\n  %6314 : Tensor?[] = prim::ListConstruct(%6309, %6311, %6313)\n  %6315 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6283, %6314, %input.179, %7633)\n  %7641 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7642 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7643 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7644 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4616 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7641, %7642, %7643, %7644) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7645 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7646 : Long(requires_grad=0, device=cpu) = prim::Constant[value={22}]()\n  %4619 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4616, %7645, %7646) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7647 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4621 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4619, %7647) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7648 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7649 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5595 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5279 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5595, %7648, %4621, %7649) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4646 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4647 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4646) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4648 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7650 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7651 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4651 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.212, %4648, %7650, %7651) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7652 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4653 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4651, %7652) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7653 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4655 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4647, %4653, %7653) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.180 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4655) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4657 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.23 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.180, %4657) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7654 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4660 : None = prim::Constant()\n  %4661 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.23, %7654, %4660) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5596 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4666 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4661, %5596) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4667 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4666, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7655 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4669 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4667, %7655) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4670 : Tensor[] = prim::ListConstruct(%4669, %5279)\n  %7656 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.181 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4670, %7656) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4702 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4703 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.181, %4702) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4704 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4705 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.212, %4704) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.213 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4707 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4708 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4703, %4705, %4595, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7657 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7658 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7659 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7660 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4713 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6315, %7657, %7658, %7659, %7660) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7661 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7662 : Long(requires_grad=0, device=cpu) = prim::Constant[value={22}]()\n  %4716 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4713, %7661, %7662) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7663 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7664 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7665 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7666 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4721 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4716, %7663, %7664, %7665, %7666) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7667 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.182 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.213, %4721) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7668 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6320 : Long(device=cpu) = aten::size(%6315, %7668)\n  %7669 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6322 : None = prim::Constant()\n  %6323 : None = prim::Constant()\n  %6324 : None = prim::Constant()\n  %6325 : Tensor = aten::arange(%6320, %7669, %6322, %6323, %6324)\n  %7670 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6327 : Tensor = aten::slice(%6325, %7670, %7658, %7659, %7660)\n  %7671 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6330 : Tensor = aten::unsqueeze(%7662, %7671)\n  %7672 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6332 : Long(device=cpu) = aten::size(%6315, %7672)\n  %7673 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6334 : None = prim::Constant()\n  %6335 : None = prim::Constant()\n  %6336 : None = prim::Constant()\n  %6337 : Tensor = aten::arange(%6332, %7673, %6334, %6335, %6336)\n  %7674 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6339 : Tensor = aten::slice(%6337, %7674, %7664, %7665, %7666)\n  %6340 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6341 : Tensor = aten::view(%6327, %6340)\n  %6342 : int[] = prim::Constant[value=[-1, 1]]()\n  %6343 : Tensor = aten::view(%6330, %6342)\n  %6344 : int[] = prim::Constant[value=[-1]]()\n  %6345 : Tensor = aten::view(%6339, %6344)\n  %6346 : Tensor?[] = prim::ListConstruct(%6341, %6343, %6345)\n  %6347 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6315, %6346, %input.182, %7667)\n  %7675 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7676 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7677 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7678 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4728 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7675, %7676, %7677, %7678) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7679 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7680 : Long(requires_grad=0, device=cpu) = prim::Constant[value={23}]()\n  %4731 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4728, %7679, %7680) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7681 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4733 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4731, %7681) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7682 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7683 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5600 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5286 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5600, %7682, %4733, %7683) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4758 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4759 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4758) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4760 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7684 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7685 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4763 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.213, %4760, %7684, %7685) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7686 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4765 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4763, %7686) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7687 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4767 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4759, %4765, %7687) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.183 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4767) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4769 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.24 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.183, %4769) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7688 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4772 : None = prim::Constant()\n  %4773 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.24, %7688, %4772) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5601 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4778 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4773, %5601) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4779 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4778, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7689 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4781 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4779, %7689) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4782 : Tensor[] = prim::ListConstruct(%4781, %5286)\n  %7690 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.184 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4782, %7690) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4814 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4815 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.184, %4814) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4816 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4817 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.213, %4816) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.214 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4819 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4820 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4815, %4817, %4707, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7691 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7692 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7693 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7694 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4825 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6347, %7691, %7692, %7693, %7694) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7695 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7696 : Long(requires_grad=0, device=cpu) = prim::Constant[value={23}]()\n  %4828 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4825, %7695, %7696) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7697 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7698 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7699 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7700 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4833 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4828, %7697, %7698, %7699, %7700) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7701 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.185 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.214, %4833) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7702 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6352 : Long(device=cpu) = aten::size(%6347, %7702)\n  %7703 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6354 : None = prim::Constant()\n  %6355 : None = prim::Constant()\n  %6356 : None = prim::Constant()\n  %6357 : Tensor = aten::arange(%6352, %7703, %6354, %6355, %6356)\n  %7704 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6359 : Tensor = aten::slice(%6357, %7704, %7692, %7693, %7694)\n  %7705 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6362 : Tensor = aten::unsqueeze(%7696, %7705)\n  %7706 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6364 : Long(device=cpu) = aten::size(%6347, %7706)\n  %7707 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6366 : None = prim::Constant()\n  %6367 : None = prim::Constant()\n  %6368 : None = prim::Constant()\n  %6369 : Tensor = aten::arange(%6364, %7707, %6366, %6367, %6368)\n  %7708 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6371 : Tensor = aten::slice(%6369, %7708, %7698, %7699, %7700)\n  %6372 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6373 : Tensor = aten::view(%6359, %6372)\n  %6374 : int[] = prim::Constant[value=[-1, 1]]()\n  %6375 : Tensor = aten::view(%6362, %6374)\n  %6376 : int[] = prim::Constant[value=[-1]]()\n  %6377 : Tensor = aten::view(%6371, %6376)\n  %6378 : Tensor?[] = prim::ListConstruct(%6373, %6375, %6377)\n  %6379 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6347, %6378, %input.185, %7701)\n  %7709 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7710 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7711 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7712 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4840 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7709, %7710, %7711, %7712) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7713 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7714 : Long(requires_grad=0, device=cpu) = prim::Constant[value={24}]()\n  %4843 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4840, %7713, %7714) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7715 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4845 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4843, %7715) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7716 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7717 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5605 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5293 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5605, %7716, %4845, %7717) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4870 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4871 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4870) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4872 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7718 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7719 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4875 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.214, %4872, %7718, %7719) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7720 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4877 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4875, %7720) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7721 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4879 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4871, %4877, %7721) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.186 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4879) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4881 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.25 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.186, %4881) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7722 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4884 : None = prim::Constant()\n  %4885 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.25, %7722, %4884) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5606 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4890 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4885, %5606) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4891 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4890, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7723 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4893 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4891, %7723) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4894 : Tensor[] = prim::ListConstruct(%4893, %5293)\n  %7724 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.187 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4894, %7724) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4926 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4927 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.187, %4926) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4928 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4929 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.214, %4928) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.215 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4931 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4932 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4927, %4929, %4819, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7725 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7726 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7727 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7728 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4937 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6379, %7725, %7726, %7727, %7728) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7729 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7730 : Long(requires_grad=0, device=cpu) = prim::Constant[value={24}]()\n  %4940 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4937, %7729, %7730) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7731 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7732 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7733 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7734 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4945 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4940, %7731, %7732, %7733, %7734) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7735 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.188 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.215, %4945) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7736 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6384 : Long(device=cpu) = aten::size(%6379, %7736)\n  %7737 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6386 : None = prim::Constant()\n  %6387 : None = prim::Constant()\n  %6388 : None = prim::Constant()\n  %6389 : Tensor = aten::arange(%6384, %7737, %6386, %6387, %6388)\n  %7738 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6391 : Tensor = aten::slice(%6389, %7738, %7726, %7727, %7728)\n  %7739 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6394 : Tensor = aten::unsqueeze(%7730, %7739)\n  %7740 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6396 : Long(device=cpu) = aten::size(%6379, %7740)\n  %7741 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6398 : None = prim::Constant()\n  %6399 : None = prim::Constant()\n  %6400 : None = prim::Constant()\n  %6401 : Tensor = aten::arange(%6396, %7741, %6398, %6399, %6400)\n  %7742 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6403 : Tensor = aten::slice(%6401, %7742, %7732, %7733, %7734)\n  %6404 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6405 : Tensor = aten::view(%6391, %6404)\n  %6406 : int[] = prim::Constant[value=[-1, 1]]()\n  %6407 : Tensor = aten::view(%6394, %6406)\n  %6408 : int[] = prim::Constant[value=[-1]]()\n  %6409 : Tensor = aten::view(%6403, %6408)\n  %6410 : Tensor?[] = prim::ListConstruct(%6405, %6407, %6409)\n  %6411 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6379, %6410, %input.188, %7735)\n  %7743 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7744 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7745 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7746 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4952 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7743, %7744, %7745, %7746) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7747 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7748 : Long(requires_grad=0, device=cpu) = prim::Constant[value={25}]()\n  %4955 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4952, %7747, %7748) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7749 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4957 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4955, %7749) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7750 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7751 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5610 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5300 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5610, %7750, %4957, %7751) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4982 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4983 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4982) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4984 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7752 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7753 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4987 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.215, %4984, %7752, %7753) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7754 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4989 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4987, %7754) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7755 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4991 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4983, %4989, %7755) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.189 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4991) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4993 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.189, %4993) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7756 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4996 : None = prim::Constant()\n  %4997 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e, %7756, %4996) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5611 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %5002 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4997, %5611) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %5003 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%5002, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7757 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5005 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%5003, %7757) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %5006 : Tensor[] = prim::ListConstruct(%5005, %5300)\n  %7758 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.190 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%5006, %7758) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %5038 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %5039 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.190, %5038) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %5040 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %5041 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.215, %5040) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %5042 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %5043 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %5044 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%5039, %5041, %4931, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7759 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7760 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7761 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7762 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5049 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6411, %7759, %7760, %7761, %7762) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7763 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7764 : Long(requires_grad=0, device=cpu) = prim::Constant[value={25}]()\n  %5052 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%5049, %7763, %7764) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7765 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7766 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7767 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7768 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5057 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%5052, %7765, %7766, %7767, %7768) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7769 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6413 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%5042, %5057) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7770 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6416 : Long(device=cpu) = aten::size(%6411, %7770)\n  %7771 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6418 : None = prim::Constant()\n  %6419 : None = prim::Constant()\n  %6420 : None = prim::Constant()\n  %6421 : Tensor = aten::arange(%6416, %7771, %6418, %6419, %6420)\n  %7772 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6423 : Tensor = aten::slice(%6421, %7772, %7760, %7761, %7762)\n  %7773 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6426 : Tensor = aten::unsqueeze(%7764, %7773)\n  %7774 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6428 : Long(device=cpu) = aten::size(%6411, %7774)\n  %7775 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6430 : None = prim::Constant()\n  %6431 : None = prim::Constant()\n  %6432 : None = prim::Constant()\n  %6433 : Tensor = aten::arange(%6428, %7775, %6430, %6431, %6432)\n  %7776 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6435 : Tensor = aten::slice(%6433, %7776, %7766, %7767, %7768)\n  %6436 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6437 : Tensor = aten::view(%6423, %6436)\n  %6438 : int[] = prim::Constant[value=[-1, 1]]()\n  %6439 : Tensor = aten::view(%6426, %6438)\n  %6440 : int[] = prim::Constant[value=[-1]]()\n  %6441 : Tensor = aten::view(%6435, %6440)\n  %6442 : Tensor?[] = prim::ListConstruct(%6437, %6439, %6441)\n  %6443 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6411, %6442, %6413, %7769)\n  %5060 : Float(256, 38, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.generator.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %5061 : Float(128, 26, 38, strides=[988, 38, 1], requires_grad=1, device=cuda:0) = aten::matmul(%6443, %5060) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7777 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5077 : Tensor = aten::type_as(%Prediction.generator.bias, %5061)\n  %5063 : Float(128, 26, 38, strides=[988, 38, 1], requires_grad=1, device=cuda:0) = aten::add_(%5061, %5077, %7777) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  return (%5063)\n, {}, 'input_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a912b98dc48b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \"\"\"\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-a912b98dc48b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# align with Attention.forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m## 한번 찍어보기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./ttt.onnx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input_names\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output_names\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"저장끝\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# without [GO] Symbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    274\u001b[0m                         \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                         custom_opsets, enable_onnx_checker, use_external_data_format)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mcustom_opsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_opsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_onnx_checker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_onnx_checker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             use_external_data_format=use_external_data_format)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format, onnx_shape_inference, use_new_jit_passes)\u001b[0m\n\u001b[1;32m    699\u001b[0m                                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                                 \u001b[0muse_new_jit_passes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_new_jit_passes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m                                 dynamic_axes=dynamic_axes)\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, use_new_jit_passes, dynamic_axes)\u001b[0m\n\u001b[1;32m    466\u001b[0m                             \u001b[0muse_new_jit_passes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_new_jit_passes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m                             \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                             module=module)\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_onnx_shape_inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScriptFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, use_new_jit_passes, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0minput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mdynamic_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdynamic_axes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx_set_dynamic_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _jit_pass_onnx_set_dynamic_input_shape(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, Dict[int, str]], arg2: List[str]) -> None\n\nInvoked with: graph(%input.1 : Float(128, 1, 32, 100, strides=[3200, 3200, 100, 1], requires_grad=0, device=cuda:0),\n      %1 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.0.weight : Float(64, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.1.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.1.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.1.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.1.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.4.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.5.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.5.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.5.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.5.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.5.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.8.weight : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.9.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.9.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.9.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.9.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.9.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.12.weight : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.13.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.13.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.13.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.13.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.conv.13.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %Transformation.LocalizationNetwork.localization_fc1.0.weight : Float(256, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.localization_fc1.0.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.localization_fc2.weight : Float(40, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Transformation.LocalizationNetwork.localization_fc2.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n      %Transformation.GridGenerator.inv_delta_C : Float(23, 23, strides=[23, 1], requires_grad=0, device=cuda:0),\n      %Transformation.GridGenerator.P_hat : Float(3200, 23, strides=[23, 1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv0_1.weight : Float(32, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_1.weight : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_1.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_1.running_mean : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_1.running_var : Float(32, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv0_2.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_2.weight : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_2.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_2.running_mean : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_2.running_var : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn0_2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.conv1.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn1.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn1.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn1.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn1.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.conv2.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn2.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn2.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn2.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn2.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.0.weight : Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.1.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.1.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.1.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.1.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer1.0.downsample.1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv1.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn1.weight : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn1.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn1.running_mean : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn1.running_var : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.conv1.weight : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn1.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn1.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.conv2.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn2.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn2.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.0.weight : Float(256, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.1.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.1.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.0.downsample.1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.conv1.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn1.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn1.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn1.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn1.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.conv2.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn2.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn2.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer2.1.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv2.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn2.weight : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn2.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn2.running_mean : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn2.running_var : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.conv1.weight : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.0.weight : Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.0.downsample.1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.1.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.2.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.3.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer3.4.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv3.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn3.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn3.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn3.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn3.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn3.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.0.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.1.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.conv1.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.conv2.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.layer4.2.bn2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv4_1.weight : Float(512, 512, 2, 2, strides=[2048, 4, 2, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_1.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_1.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_1.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_1.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_1.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.conv4_2.weight : Float(512, 512, 2, 2, strides=[2048, 4, 2, 1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_2.weight : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_2.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_2.running_mean : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_2.running_var : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n      %FeatureExtraction.ConvNet.bn4_2.num_batches_tracked : Long(requires_grad=0, device=cuda:0),\n      %SequenceModeling.0.rnn.weight_ih_l0 : Float(1024, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.weight_hh_l0 : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.bias_ih_l0 : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.bias_hh_l0 : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.weight_ih_l0_reverse : Float(1024, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.weight_hh_l0_reverse : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.bias_ih_l0_reverse : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.rnn.bias_hh_l0_reverse : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.linear.weight : Float(256, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.0.linear.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.weight_ih_l0 : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.weight_hh_l0 : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.bias_ih_l0 : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.bias_hh_l0 : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.weight_ih_l0_reverse : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.weight_hh_l0_reverse : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.bias_ih_l0_reverse : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.rnn.bias_hh_l0_reverse : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.linear.weight : Float(256, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n      %SequenceModeling.1.linear.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.i2h.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.h2h.weight : Float(256, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.h2h.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.score.weight : Float(1, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.rnn.weight_ih : Float(1024, 294, strides=[294, 1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.rnn.weight_hh : Float(1024, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.rnn.bias_ih : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %Prediction.attention_cell.rnn.bias_hh : Float(1024, strides=[1], requires_grad=1, device=cuda:0),\n      %Prediction.generator.weight : Float(38, 256, strides=[256, 1], requires_grad=1, device=cuda:0),\n      %Prediction.generator.bias : Float(38, strides=[1], requires_grad=1, device=cuda:0)):\n  %6444 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %763 : Long(device=cpu) = aten::size(%input.1, %6444) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:80:0\n  %765 : None = prim::Constant()\n  %5301 : int[] = prim::Constant[value=[1, 1]]()\n  %5302 : int[] = prim::Constant[value=[1, 1]]()\n  %5303 : int[] = prim::Constant[value=[1, 1]]()\n  %6445 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5304 : int[] = prim::Constant[value=[0, 0]]()\n  %6446 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6447 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6448 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6449 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6450 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.2 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.1, %Transformation.LocalizationNetwork.conv.0.weight, %765, %5301, %5302, %5303, %6445, %5304, %6446, %6447, %6448, %6449, %6450) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6451 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6452 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6453 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6454 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.3 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.2, %Transformation.LocalizationNetwork.conv.1.weight, %Transformation.LocalizationNetwork.conv.1.bias, %Transformation.LocalizationNetwork.conv.1.running_mean, %Transformation.LocalizationNetwork.conv.1.running_var, %6451, %6452, %6453, %6454) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5078 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.3) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5305 : int[] = prim::Constant[value=[2, 2]]()\n  %5306 : int[] = prim::Constant[value=[2, 2]]()\n  %5307 : int[] = prim::Constant[value=[0, 0]]()\n  %5308 : int[] = prim::Constant[value=[1, 1]]()\n  %6455 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.4 : Float(128, 64, 16, 50, strides=[51200, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5078, %5305, %5306, %5307, %5308, %6455) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %805 : None = prim::Constant()\n  %5309 : int[] = prim::Constant[value=[1, 1]]()\n  %5310 : int[] = prim::Constant[value=[1, 1]]()\n  %5311 : int[] = prim::Constant[value=[1, 1]]()\n  %6456 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5312 : int[] = prim::Constant[value=[0, 0]]()\n  %6457 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6458 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6459 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6460 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6461 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.5 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.4, %Transformation.LocalizationNetwork.conv.4.weight, %805, %5309, %5310, %5311, %6456, %5312, %6457, %6458, %6459, %6460, %6461) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6462 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6463 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6464 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6465 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.6 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.5, %Transformation.LocalizationNetwork.conv.5.weight, %Transformation.LocalizationNetwork.conv.5.bias, %Transformation.LocalizationNetwork.conv.5.running_mean, %Transformation.LocalizationNetwork.conv.5.running_var, %6462, %6463, %6464, %6465) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5079 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.6) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5313 : int[] = prim::Constant[value=[2, 2]]()\n  %5314 : int[] = prim::Constant[value=[2, 2]]()\n  %5315 : int[] = prim::Constant[value=[0, 0]]()\n  %5316 : int[] = prim::Constant[value=[1, 1]]()\n  %6466 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.7 : Float(128, 128, 8, 25, strides=[25600, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5079, %5313, %5314, %5315, %5316, %6466) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %845 : None = prim::Constant()\n  %5317 : int[] = prim::Constant[value=[1, 1]]()\n  %5318 : int[] = prim::Constant[value=[1, 1]]()\n  %5319 : int[] = prim::Constant[value=[1, 1]]()\n  %6467 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5320 : int[] = prim::Constant[value=[0, 0]]()\n  %6468 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6469 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6470 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6471 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6472 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.8 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.7, %Transformation.LocalizationNetwork.conv.8.weight, %845, %5317, %5318, %5319, %6467, %5320, %6468, %6469, %6470, %6471, %6472) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6473 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6474 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6475 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6476 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.9 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.8, %Transformation.LocalizationNetwork.conv.9.weight, %Transformation.LocalizationNetwork.conv.9.bias, %Transformation.LocalizationNetwork.conv.9.running_mean, %Transformation.LocalizationNetwork.conv.9.running_var, %6473, %6474, %6475, %6476) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5080 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.9) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5321 : int[] = prim::Constant[value=[2, 2]]()\n  %5322 : int[] = prim::Constant[value=[2, 2]]()\n  %5323 : int[] = prim::Constant[value=[0, 0]]()\n  %5324 : int[] = prim::Constant[value=[1, 1]]()\n  %6477 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.10 : Float(128, 256, 4, 12, strides=[12288, 48, 12, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5080, %5321, %5322, %5323, %5324, %6477) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %885 : None = prim::Constant()\n  %5325 : int[] = prim::Constant[value=[1, 1]]()\n  %5326 : int[] = prim::Constant[value=[1, 1]]()\n  %5327 : int[] = prim::Constant[value=[1, 1]]()\n  %6478 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5328 : int[] = prim::Constant[value=[0, 0]]()\n  %6479 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6480 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6481 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6482 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6483 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.11 : Float(128, 512, 4, 12, strides=[24576, 48, 12, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.10, %Transformation.LocalizationNetwork.conv.12.weight, %885, %5325, %5326, %5327, %6478, %5328, %6479, %6480, %6481, %6482, %6483) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6484 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6485 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6486 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6487 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.12 : Float(128, 512, 4, 12, strides=[24576, 48, 12, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.11, %Transformation.LocalizationNetwork.conv.13.weight, %Transformation.LocalizationNetwork.conv.13.bias, %Transformation.LocalizationNetwork.conv.13.running_mean, %Transformation.LocalizationNetwork.conv.13.running_var, %6484, %6485, %6486, %6487) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5081 : Float(128, 512, 4, 12, strides=[24576, 48, 12, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.12) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5329 : int[] = prim::Constant[value=[1, 1]]()\n  %926 : Float(128, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = aten::adaptive_avg_pool2d(%5081, %5329) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1037:0\n  %6488 : Long(requires_grad=0, device=cpu) = prim::Constant[value={-1}]()\n  %929 : int[] = prim::ListConstruct(%763, %6488)\n  %input.14 : Float(128, 512, strides=[512, 1], requires_grad=1, device=cuda:0) = aten::view(%926, %929) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:81:0\n  %931 : Float(512, 256, strides=[1, 512], requires_grad=1, device=cuda:0) = aten::t(%Transformation.LocalizationNetwork.localization_fc1.0.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6489 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6490 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.15 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Transformation.LocalizationNetwork.localization_fc1.0.bias, %input.14, %931, %6489, %6490) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %5082 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.15) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %936 : Float(256, 40, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Transformation.LocalizationNetwork.localization_fc2.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6491 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6492 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %939 : Float(128, 40, strides=[40, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Transformation.LocalizationNetwork.localization_fc2.bias, %5082, %936, %6491, %6492) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6493 : Long(requires_grad=0, device=cpu) = prim::Constant[value={20}]()\n  %6494 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %943 : int[] = prim::ListConstruct(%763, %6493, %6494)\n  %batch_C_prime : Float(128, 20, 2, strides=[40, 2, 1], requires_grad=1, device=cuda:0) = aten::view(%939, %943) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:82:0\n  %6495 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %946 : Long(device=cpu) = aten::size(%batch_C_prime, %6495) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:157:0\n  %6496 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6497 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %951 : int[] = prim::ListConstruct(%946, %6496, %6497)\n  %952 : Float(128, 23, 23, strides=[529, 23, 1], requires_grad=0, device=cuda:0) = aten::repeat(%Transformation.GridGenerator.inv_delta_C, %951) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:158:0\n  %6498 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6499 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %956 : int[] = prim::ListConstruct(%946, %6498, %6499)\n  %957 : Float(128, 3200, 23, strides=[73600, 23, 1], requires_grad=0, device=cuda:0) = aten::repeat(%Transformation.GridGenerator.P_hat, %956) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:159:0\n  %6500 : Long(requires_grad=0, device=cpu) = prim::Constant[value={3}]()\n  %6501 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %961 : int[] = prim::ListConstruct(%946, %6500, %6501)\n  %6502 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %963 : None = prim::Constant()\n  %964 : Device = prim::Constant[value=\"cpu\"]() # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %6503 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %966 : Float(128, 3, 2, strides=[6, 2, 1], requires_grad=0, device=cpu) = aten::zeros(%961, %6502, %963, %964, %6503) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %6504 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %6505 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6506 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %970 : None = prim::Constant()\n  %971 : Float(128, 3, 2, strides=[6, 2, 1], requires_grad=0, device=cpu) = aten::to(%966, %6504, %6505, %6506, %970) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %6507 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %6508 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %974 : Device = prim::Constant[value=\"cuda\"]() # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %975 : None = prim::Constant()\n  %6509 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6510 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %978 : None = prim::Constant()\n  %979 : Float(128, 3, 2, strides=[6, 2, 1], requires_grad=0, device=cuda:0) = aten::to(%971, %6507, %6508, %974, %975, %6509, %6510, %978) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %980 : Tensor[] = prim::ListConstruct(%batch_C_prime, %979)\n  %6511 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %982 : Float(128, 23, 2, strides=[46, 2, 1], requires_grad=1, device=cuda:0) = aten::cat(%980, %6511) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:161:0\n  %983 : Float(128, 23, 2, strides=[46, 2, 1], requires_grad=1, device=cuda:0) = aten::bmm(%952, %982) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:162:0\n  %984 : Float(128, 3200, 2, strides=[6400, 2, 1], requires_grad=1, device=cuda:0) = aten::bmm(%957, %983) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:163:0\n  %6512 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %986 : Long(device=cpu) = aten::size(%984, %6512) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:32:0\n  %6513 : Long(requires_grad=0, device=cpu) = prim::Constant[value={32}]()\n  %6514 : Long(requires_grad=0, device=cpu) = prim::Constant[value={100}]()\n  %6515 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %992 : int[] = prim::ListConstruct(%986, %6513, %6514, %6515)\n  %build_P_prime_reshape : Float(128, 32, 100, 2, strides=[6400, 200, 2, 1], requires_grad=1, device=cuda:0) = aten::reshape(%984, %992) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/transformation.py:32:0\n  %6516 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6517 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6518 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.17 : Float(128, 1, 32, 100, strides=[3200, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::grid_sampler(%input.1, %build_P_prime_reshape, %6516, %6517, %6518) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3836:0\n  %998 : None = prim::Constant()\n  %5330 : int[] = prim::Constant[value=[1, 1]]()\n  %5331 : int[] = prim::Constant[value=[1, 1]]()\n  %5332 : int[] = prim::Constant[value=[1, 1]]()\n  %6519 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5333 : int[] = prim::Constant[value=[0, 0]]()\n  %6520 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6521 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6522 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6523 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6524 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.18 : Float(128, 32, 32, 100, strides=[102400, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.17, %FeatureExtraction.ConvNet.conv0_1.weight, %998, %5330, %5331, %5332, %6519, %5333, %6520, %6521, %6522, %6523, %6524) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6525 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6526 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6527 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6528 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.19 : Float(128, 32, 32, 100, strides=[102400, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.18, %FeatureExtraction.ConvNet.bn0_1.weight, %FeatureExtraction.ConvNet.bn0_1.bias, %FeatureExtraction.ConvNet.bn0_1.running_mean, %FeatureExtraction.ConvNet.bn0_1.running_var, %6525, %6526, %6527, %6528) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5083 : Float(128, 32, 32, 100, strides=[102400, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.19) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1024 : None = prim::Constant()\n  %5334 : int[] = prim::Constant[value=[1, 1]]()\n  %5335 : int[] = prim::Constant[value=[1, 1]]()\n  %5336 : int[] = prim::Constant[value=[1, 1]]()\n  %6529 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5337 : int[] = prim::Constant[value=[0, 0]]()\n  %6530 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6531 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6532 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6533 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6534 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.21 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5083, %FeatureExtraction.ConvNet.conv0_2.weight, %1024, %5334, %5335, %5336, %6529, %5337, %6530, %6531, %6532, %6533, %6534) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6535 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6536 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6537 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6538 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.22 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.21, %FeatureExtraction.ConvNet.bn0_2.weight, %FeatureExtraction.ConvNet.bn0_2.bias, %FeatureExtraction.ConvNet.bn0_2.running_mean, %FeatureExtraction.ConvNet.bn0_2.running_var, %6535, %6536, %6537, %6538) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5084 : Float(128, 64, 32, 100, strides=[204800, 3200, 100, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.22) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5338 : int[] = prim::Constant[value=[2, 2]]()\n  %5339 : int[] = prim::Constant[value=[2, 2]]()\n  %5340 : int[] = prim::Constant[value=[0, 0]]()\n  %5341 : int[] = prim::Constant[value=[1, 1]]()\n  %6539 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.23 : Float(128, 64, 16, 50, strides=[51200, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5084, %5338, %5339, %5340, %5341, %6539) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %1064 : None = prim::Constant()\n  %5342 : int[] = prim::Constant[value=[1, 1]]()\n  %5343 : int[] = prim::Constant[value=[1, 1]]()\n  %5344 : int[] = prim::Constant[value=[1, 1]]()\n  %6540 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5345 : int[] = prim::Constant[value=[0, 0]]()\n  %6541 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6542 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6543 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6544 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6545 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.24 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.23, %FeatureExtraction.ConvNet.layer1.0.conv1.weight, %1064, %5342, %5343, %5344, %6540, %5345, %6541, %6542, %6543, %6544, %6545) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6546 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6547 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6548 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6549 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.25 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.24, %FeatureExtraction.ConvNet.layer1.0.bn1.weight, %FeatureExtraction.ConvNet.layer1.0.bn1.bias, %FeatureExtraction.ConvNet.layer1.0.bn1.running_mean, %FeatureExtraction.ConvNet.layer1.0.bn1.running_var, %6546, %6547, %6548, %6549) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5085 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.25) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1090 : None = prim::Constant()\n  %5346 : int[] = prim::Constant[value=[1, 1]]()\n  %5347 : int[] = prim::Constant[value=[1, 1]]()\n  %5348 : int[] = prim::Constant[value=[1, 1]]()\n  %6550 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5349 : int[] = prim::Constant[value=[0, 0]]()\n  %6551 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6552 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6553 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6554 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6555 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.27 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5085, %FeatureExtraction.ConvNet.layer1.0.conv2.weight, %1090, %5346, %5347, %5348, %6550, %5349, %6551, %6552, %6553, %6554, %6555) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6556 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6557 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6558 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6559 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1114 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.27, %FeatureExtraction.ConvNet.layer1.0.bn2.weight, %FeatureExtraction.ConvNet.layer1.0.bn2.bias, %FeatureExtraction.ConvNet.layer1.0.bn2.running_mean, %FeatureExtraction.ConvNet.layer1.0.bn2.running_var, %6556, %6557, %6558, %6559) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %1115 : None = prim::Constant()\n  %5350 : int[] = prim::Constant[value=[1, 1]]()\n  %5351 : int[] = prim::Constant[value=[0, 0]]()\n  %5352 : int[] = prim::Constant[value=[1, 1]]()\n  %6560 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5353 : int[] = prim::Constant[value=[0, 0]]()\n  %6561 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6562 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6563 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6564 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6565 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.28 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.23, %FeatureExtraction.ConvNet.layer1.0.downsample.0.weight, %1115, %5350, %5351, %5352, %6560, %5353, %6561, %6562, %6563, %6564, %6565) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6566 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6567 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6568 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6569 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1139 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.28, %FeatureExtraction.ConvNet.layer1.0.downsample.1.weight, %FeatureExtraction.ConvNet.layer1.0.downsample.1.bias, %FeatureExtraction.ConvNet.layer1.0.downsample.1.running_mean, %FeatureExtraction.ConvNet.layer1.0.downsample.1.running_var, %6566, %6567, %6568, %6569) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6570 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5064 : Tensor = aten::type_as(%1139, %1114)\n  %input.29 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::add_(%1114, %5064, %6570) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.30 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.29) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1143 : None = prim::Constant()\n  %5354 : int[] = prim::Constant[value=[1, 1]]()\n  %5355 : int[] = prim::Constant[value=[1, 1]]()\n  %5356 : int[] = prim::Constant[value=[1, 1]]()\n  %6571 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5357 : int[] = prim::Constant[value=[0, 0]]()\n  %6572 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6573 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6574 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6575 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6576 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.31 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.30, %FeatureExtraction.ConvNet.conv1.weight, %1143, %5354, %5355, %5356, %6571, %5357, %6572, %6573, %6574, %6575, %6576) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6577 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6578 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6579 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6580 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.32 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.31, %FeatureExtraction.ConvNet.bn1.weight, %FeatureExtraction.ConvNet.bn1.bias, %FeatureExtraction.ConvNet.bn1.running_mean, %FeatureExtraction.ConvNet.bn1.running_var, %6577, %6578, %6579, %6580) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5086 : Float(128, 128, 16, 50, strides=[102400, 800, 50, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.32) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5358 : int[] = prim::Constant[value=[2, 2]]()\n  %5359 : int[] = prim::Constant[value=[2, 2]]()\n  %5360 : int[] = prim::Constant[value=[0, 0]]()\n  %5361 : int[] = prim::Constant[value=[1, 1]]()\n  %6581 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.33 : Float(128, 128, 8, 25, strides=[25600, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5086, %5358, %5359, %5360, %5361, %6581) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %1183 : None = prim::Constant()\n  %5362 : int[] = prim::Constant[value=[1, 1]]()\n  %5363 : int[] = prim::Constant[value=[1, 1]]()\n  %5364 : int[] = prim::Constant[value=[1, 1]]()\n  %6582 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5365 : int[] = prim::Constant[value=[0, 0]]()\n  %6583 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6584 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6585 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6586 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6587 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.34 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.33, %FeatureExtraction.ConvNet.layer2.0.conv1.weight, %1183, %5362, %5363, %5364, %6582, %5365, %6583, %6584, %6585, %6586, %6587) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6588 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6589 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6590 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6591 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.35 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.34, %FeatureExtraction.ConvNet.layer2.0.bn1.weight, %FeatureExtraction.ConvNet.layer2.0.bn1.bias, %FeatureExtraction.ConvNet.layer2.0.bn1.running_mean, %FeatureExtraction.ConvNet.layer2.0.bn1.running_var, %6588, %6589, %6590, %6591) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5087 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.35) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1209 : None = prim::Constant()\n  %5366 : int[] = prim::Constant[value=[1, 1]]()\n  %5367 : int[] = prim::Constant[value=[1, 1]]()\n  %5368 : int[] = prim::Constant[value=[1, 1]]()\n  %6592 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5369 : int[] = prim::Constant[value=[0, 0]]()\n  %6593 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6594 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6595 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6596 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6597 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.37 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5087, %FeatureExtraction.ConvNet.layer2.0.conv2.weight, %1209, %5366, %5367, %5368, %6592, %5369, %6593, %6594, %6595, %6596, %6597) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6598 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6599 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6600 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6601 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1233 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.37, %FeatureExtraction.ConvNet.layer2.0.bn2.weight, %FeatureExtraction.ConvNet.layer2.0.bn2.bias, %FeatureExtraction.ConvNet.layer2.0.bn2.running_mean, %FeatureExtraction.ConvNet.layer2.0.bn2.running_var, %6598, %6599, %6600, %6601) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %1234 : None = prim::Constant()\n  %5370 : int[] = prim::Constant[value=[1, 1]]()\n  %5371 : int[] = prim::Constant[value=[0, 0]]()\n  %5372 : int[] = prim::Constant[value=[1, 1]]()\n  %6602 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5373 : int[] = prim::Constant[value=[0, 0]]()\n  %6603 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6604 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6605 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6606 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6607 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.38 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.33, %FeatureExtraction.ConvNet.layer2.0.downsample.0.weight, %1234, %5370, %5371, %5372, %6602, %5373, %6603, %6604, %6605, %6606, %6607) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6608 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6609 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6610 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6611 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1258 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.38, %FeatureExtraction.ConvNet.layer2.0.downsample.1.weight, %FeatureExtraction.ConvNet.layer2.0.downsample.1.bias, %FeatureExtraction.ConvNet.layer2.0.downsample.1.running_mean, %FeatureExtraction.ConvNet.layer2.0.downsample.1.running_var, %6608, %6609, %6610, %6611) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6612 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5065 : Tensor = aten::type_as(%1258, %1233)\n  %input.39 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::add_(%1233, %5065, %6612) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.40 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.39) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1262 : None = prim::Constant()\n  %5374 : int[] = prim::Constant[value=[1, 1]]()\n  %5375 : int[] = prim::Constant[value=[1, 1]]()\n  %5376 : int[] = prim::Constant[value=[1, 1]]()\n  %6613 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5377 : int[] = prim::Constant[value=[0, 0]]()\n  %6614 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6615 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6616 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6617 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6618 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.41 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.40, %FeatureExtraction.ConvNet.layer2.1.conv1.weight, %1262, %5374, %5375, %5376, %6613, %5377, %6614, %6615, %6616, %6617, %6618) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6619 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6620 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6621 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6622 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.42 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.41, %FeatureExtraction.ConvNet.layer2.1.bn1.weight, %FeatureExtraction.ConvNet.layer2.1.bn1.bias, %FeatureExtraction.ConvNet.layer2.1.bn1.running_mean, %FeatureExtraction.ConvNet.layer2.1.bn1.running_var, %6619, %6620, %6621, %6622) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5088 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.42) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1288 : None = prim::Constant()\n  %5378 : int[] = prim::Constant[value=[1, 1]]()\n  %5379 : int[] = prim::Constant[value=[1, 1]]()\n  %5380 : int[] = prim::Constant[value=[1, 1]]()\n  %6623 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5381 : int[] = prim::Constant[value=[0, 0]]()\n  %6624 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6625 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6626 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6627 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6628 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.44 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5088, %FeatureExtraction.ConvNet.layer2.1.conv2.weight, %1288, %5378, %5379, %5380, %6623, %5381, %6624, %6625, %6626, %6627, %6628) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6629 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6630 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6631 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6632 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1312 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.44, %FeatureExtraction.ConvNet.layer2.1.bn2.weight, %FeatureExtraction.ConvNet.layer2.1.bn2.bias, %FeatureExtraction.ConvNet.layer2.1.bn2.running_mean, %FeatureExtraction.ConvNet.layer2.1.bn2.running_var, %6629, %6630, %6631, %6632) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6633 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5066 : Tensor = aten::type_as(%input.40, %1312)\n  %input.45 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::add_(%1312, %5066, %6633) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.46 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.45) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1316 : None = prim::Constant()\n  %5382 : int[] = prim::Constant[value=[1, 1]]()\n  %5383 : int[] = prim::Constant[value=[1, 1]]()\n  %5384 : int[] = prim::Constant[value=[1, 1]]()\n  %6634 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5385 : int[] = prim::Constant[value=[0, 0]]()\n  %6635 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6636 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6637 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6638 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6639 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.47 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.46, %FeatureExtraction.ConvNet.conv2.weight, %1316, %5382, %5383, %5384, %6634, %5385, %6635, %6636, %6637, %6638, %6639) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6640 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6641 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6642 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6643 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.48 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.47, %FeatureExtraction.ConvNet.bn2.weight, %FeatureExtraction.ConvNet.bn2.bias, %FeatureExtraction.ConvNet.bn2.running_mean, %FeatureExtraction.ConvNet.bn2.running_var, %6640, %6641, %6642, %6643) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5089 : Float(128, 256, 8, 25, strides=[51200, 200, 25, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.48) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5386 : int[] = prim::Constant[value=[2, 2]]()\n  %5387 : int[] = prim::Constant[value=[2, 1]]()\n  %5388 : int[] = prim::Constant[value=[0, 1]]()\n  %5389 : int[] = prim::Constant[value=[1, 1]]()\n  %6644 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.49 : Float(128, 256, 4, 26, strides=[26624, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::max_pool2d(%5089, %5386, %5387, %5388, %5389, %6644) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:659:0\n  %1356 : None = prim::Constant()\n  %5390 : int[] = prim::Constant[value=[1, 1]]()\n  %5391 : int[] = prim::Constant[value=[1, 1]]()\n  %5392 : int[] = prim::Constant[value=[1, 1]]()\n  %6645 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5393 : int[] = prim::Constant[value=[0, 0]]()\n  %6646 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6647 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6648 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6649 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6650 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.50 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.49, %FeatureExtraction.ConvNet.layer3.0.conv1.weight, %1356, %5390, %5391, %5392, %6645, %5393, %6646, %6647, %6648, %6649, %6650) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6651 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6652 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6653 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6654 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.51 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.50, %FeatureExtraction.ConvNet.layer3.0.bn1.weight, %FeatureExtraction.ConvNet.layer3.0.bn1.bias, %FeatureExtraction.ConvNet.layer3.0.bn1.running_mean, %FeatureExtraction.ConvNet.layer3.0.bn1.running_var, %6651, %6652, %6653, %6654) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5090 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.51) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1382 : None = prim::Constant()\n  %5394 : int[] = prim::Constant[value=[1, 1]]()\n  %5395 : int[] = prim::Constant[value=[1, 1]]()\n  %5396 : int[] = prim::Constant[value=[1, 1]]()\n  %6655 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5397 : int[] = prim::Constant[value=[0, 0]]()\n  %6656 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6657 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6658 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6659 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6660 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.53 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5090, %FeatureExtraction.ConvNet.layer3.0.conv2.weight, %1382, %5394, %5395, %5396, %6655, %5397, %6656, %6657, %6658, %6659, %6660) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6661 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6662 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6663 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6664 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1406 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.53, %FeatureExtraction.ConvNet.layer3.0.bn2.weight, %FeatureExtraction.ConvNet.layer3.0.bn2.bias, %FeatureExtraction.ConvNet.layer3.0.bn2.running_mean, %FeatureExtraction.ConvNet.layer3.0.bn2.running_var, %6661, %6662, %6663, %6664) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %1407 : None = prim::Constant()\n  %5398 : int[] = prim::Constant[value=[1, 1]]()\n  %5399 : int[] = prim::Constant[value=[0, 0]]()\n  %5400 : int[] = prim::Constant[value=[1, 1]]()\n  %6665 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5401 : int[] = prim::Constant[value=[0, 0]]()\n  %6666 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6667 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6668 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6669 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6670 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.54 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.49, %FeatureExtraction.ConvNet.layer3.0.downsample.0.weight, %1407, %5398, %5399, %5400, %6665, %5401, %6666, %6667, %6668, %6669, %6670) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6671 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6672 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6673 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6674 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1431 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.54, %FeatureExtraction.ConvNet.layer3.0.downsample.1.weight, %FeatureExtraction.ConvNet.layer3.0.downsample.1.bias, %FeatureExtraction.ConvNet.layer3.0.downsample.1.running_mean, %FeatureExtraction.ConvNet.layer3.0.downsample.1.running_var, %6671, %6672, %6673, %6674) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6675 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5067 : Tensor = aten::type_as(%1431, %1406)\n  %input.55 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1406, %5067, %6675) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.56 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.55) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1435 : None = prim::Constant()\n  %5402 : int[] = prim::Constant[value=[1, 1]]()\n  %5403 : int[] = prim::Constant[value=[1, 1]]()\n  %5404 : int[] = prim::Constant[value=[1, 1]]()\n  %6676 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5405 : int[] = prim::Constant[value=[0, 0]]()\n  %6677 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6678 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6679 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6680 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6681 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.57 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.56, %FeatureExtraction.ConvNet.layer3.1.conv1.weight, %1435, %5402, %5403, %5404, %6676, %5405, %6677, %6678, %6679, %6680, %6681) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6682 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6683 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6684 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6685 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.58 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.57, %FeatureExtraction.ConvNet.layer3.1.bn1.weight, %FeatureExtraction.ConvNet.layer3.1.bn1.bias, %FeatureExtraction.ConvNet.layer3.1.bn1.running_mean, %FeatureExtraction.ConvNet.layer3.1.bn1.running_var, %6682, %6683, %6684, %6685) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5091 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.58) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1461 : None = prim::Constant()\n  %5406 : int[] = prim::Constant[value=[1, 1]]()\n  %5407 : int[] = prim::Constant[value=[1, 1]]()\n  %5408 : int[] = prim::Constant[value=[1, 1]]()\n  %6686 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5409 : int[] = prim::Constant[value=[0, 0]]()\n  %6687 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6688 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6689 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6690 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6691 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.60 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5091, %FeatureExtraction.ConvNet.layer3.1.conv2.weight, %1461, %5406, %5407, %5408, %6686, %5409, %6687, %6688, %6689, %6690, %6691) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6692 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6693 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6694 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6695 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1485 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.60, %FeatureExtraction.ConvNet.layer3.1.bn2.weight, %FeatureExtraction.ConvNet.layer3.1.bn2.bias, %FeatureExtraction.ConvNet.layer3.1.bn2.running_mean, %FeatureExtraction.ConvNet.layer3.1.bn2.running_var, %6692, %6693, %6694, %6695) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6696 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5068 : Tensor = aten::type_as(%input.56, %1485)\n  %input.61 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1485, %5068, %6696) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.62 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.61) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1489 : None = prim::Constant()\n  %5410 : int[] = prim::Constant[value=[1, 1]]()\n  %5411 : int[] = prim::Constant[value=[1, 1]]()\n  %5412 : int[] = prim::Constant[value=[1, 1]]()\n  %6697 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5413 : int[] = prim::Constant[value=[0, 0]]()\n  %6698 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6699 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6700 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6701 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6702 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.63 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.62, %FeatureExtraction.ConvNet.layer3.2.conv1.weight, %1489, %5410, %5411, %5412, %6697, %5413, %6698, %6699, %6700, %6701, %6702) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6703 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6704 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6705 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6706 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.64 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.63, %FeatureExtraction.ConvNet.layer3.2.bn1.weight, %FeatureExtraction.ConvNet.layer3.2.bn1.bias, %FeatureExtraction.ConvNet.layer3.2.bn1.running_mean, %FeatureExtraction.ConvNet.layer3.2.bn1.running_var, %6703, %6704, %6705, %6706) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5092 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.64) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1515 : None = prim::Constant()\n  %5414 : int[] = prim::Constant[value=[1, 1]]()\n  %5415 : int[] = prim::Constant[value=[1, 1]]()\n  %5416 : int[] = prim::Constant[value=[1, 1]]()\n  %6707 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5417 : int[] = prim::Constant[value=[0, 0]]()\n  %6708 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6709 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6710 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6711 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6712 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.66 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5092, %FeatureExtraction.ConvNet.layer3.2.conv2.weight, %1515, %5414, %5415, %5416, %6707, %5417, %6708, %6709, %6710, %6711, %6712) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6713 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6714 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6715 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6716 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1539 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.66, %FeatureExtraction.ConvNet.layer3.2.bn2.weight, %FeatureExtraction.ConvNet.layer3.2.bn2.bias, %FeatureExtraction.ConvNet.layer3.2.bn2.running_mean, %FeatureExtraction.ConvNet.layer3.2.bn2.running_var, %6713, %6714, %6715, %6716) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6717 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5069 : Tensor = aten::type_as(%input.62, %1539)\n  %input.67 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1539, %5069, %6717) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.68 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.67) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1543 : None = prim::Constant()\n  %5418 : int[] = prim::Constant[value=[1, 1]]()\n  %5419 : int[] = prim::Constant[value=[1, 1]]()\n  %5420 : int[] = prim::Constant[value=[1, 1]]()\n  %6718 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5421 : int[] = prim::Constant[value=[0, 0]]()\n  %6719 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6720 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6721 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6722 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6723 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.69 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.68, %FeatureExtraction.ConvNet.layer3.3.conv1.weight, %1543, %5418, %5419, %5420, %6718, %5421, %6719, %6720, %6721, %6722, %6723) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6724 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6725 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6726 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6727 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.70 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.69, %FeatureExtraction.ConvNet.layer3.3.bn1.weight, %FeatureExtraction.ConvNet.layer3.3.bn1.bias, %FeatureExtraction.ConvNet.layer3.3.bn1.running_mean, %FeatureExtraction.ConvNet.layer3.3.bn1.running_var, %6724, %6725, %6726, %6727) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5093 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.70) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1569 : None = prim::Constant()\n  %5422 : int[] = prim::Constant[value=[1, 1]]()\n  %5423 : int[] = prim::Constant[value=[1, 1]]()\n  %5424 : int[] = prim::Constant[value=[1, 1]]()\n  %6728 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5425 : int[] = prim::Constant[value=[0, 0]]()\n  %6729 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6730 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6731 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6732 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6733 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.72 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5093, %FeatureExtraction.ConvNet.layer3.3.conv2.weight, %1569, %5422, %5423, %5424, %6728, %5425, %6729, %6730, %6731, %6732, %6733) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6734 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6735 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6736 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6737 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1593 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.72, %FeatureExtraction.ConvNet.layer3.3.bn2.weight, %FeatureExtraction.ConvNet.layer3.3.bn2.bias, %FeatureExtraction.ConvNet.layer3.3.bn2.running_mean, %FeatureExtraction.ConvNet.layer3.3.bn2.running_var, %6734, %6735, %6736, %6737) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6738 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5070 : Tensor = aten::type_as(%input.68, %1593)\n  %input.73 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1593, %5070, %6738) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.74 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.73) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1597 : None = prim::Constant()\n  %5426 : int[] = prim::Constant[value=[1, 1]]()\n  %5427 : int[] = prim::Constant[value=[1, 1]]()\n  %5428 : int[] = prim::Constant[value=[1, 1]]()\n  %6739 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5429 : int[] = prim::Constant[value=[0, 0]]()\n  %6740 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6741 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6742 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6743 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6744 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.75 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.74, %FeatureExtraction.ConvNet.layer3.4.conv1.weight, %1597, %5426, %5427, %5428, %6739, %5429, %6740, %6741, %6742, %6743, %6744) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6745 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6746 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6747 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6748 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.76 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.75, %FeatureExtraction.ConvNet.layer3.4.bn1.weight, %FeatureExtraction.ConvNet.layer3.4.bn1.bias, %FeatureExtraction.ConvNet.layer3.4.bn1.running_mean, %FeatureExtraction.ConvNet.layer3.4.bn1.running_var, %6745, %6746, %6747, %6748) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5094 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.76) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1623 : None = prim::Constant()\n  %5430 : int[] = prim::Constant[value=[1, 1]]()\n  %5431 : int[] = prim::Constant[value=[1, 1]]()\n  %5432 : int[] = prim::Constant[value=[1, 1]]()\n  %6749 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5433 : int[] = prim::Constant[value=[0, 0]]()\n  %6750 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6751 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6752 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6753 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6754 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.78 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5094, %FeatureExtraction.ConvNet.layer3.4.conv2.weight, %1623, %5430, %5431, %5432, %6749, %5433, %6750, %6751, %6752, %6753, %6754) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6755 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6756 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6757 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6758 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1647 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.78, %FeatureExtraction.ConvNet.layer3.4.bn2.weight, %FeatureExtraction.ConvNet.layer3.4.bn2.bias, %FeatureExtraction.ConvNet.layer3.4.bn2.running_mean, %FeatureExtraction.ConvNet.layer3.4.bn2.running_var, %6755, %6756, %6757, %6758) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6759 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5071 : Tensor = aten::type_as(%input.74, %1647)\n  %input.79 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1647, %5071, %6759) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.80 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.79) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1651 : None = prim::Constant()\n  %5434 : int[] = prim::Constant[value=[1, 1]]()\n  %5435 : int[] = prim::Constant[value=[1, 1]]()\n  %5436 : int[] = prim::Constant[value=[1, 1]]()\n  %6760 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5437 : int[] = prim::Constant[value=[0, 0]]()\n  %6761 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6762 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6763 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6764 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6765 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.81 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.80, %FeatureExtraction.ConvNet.conv3.weight, %1651, %5434, %5435, %5436, %6760, %5437, %6761, %6762, %6763, %6764, %6765) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6766 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6767 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6768 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6769 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.82 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.81, %FeatureExtraction.ConvNet.bn3.weight, %FeatureExtraction.ConvNet.bn3.bias, %FeatureExtraction.ConvNet.bn3.running_mean, %FeatureExtraction.ConvNet.bn3.running_var, %6766, %6767, %6768, %6769) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5095 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.82) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1677 : None = prim::Constant()\n  %5438 : int[] = prim::Constant[value=[1, 1]]()\n  %5439 : int[] = prim::Constant[value=[1, 1]]()\n  %5440 : int[] = prim::Constant[value=[1, 1]]()\n  %6770 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5441 : int[] = prim::Constant[value=[0, 0]]()\n  %6771 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6772 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6773 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6774 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6775 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.84 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5095, %FeatureExtraction.ConvNet.layer4.0.conv1.weight, %1677, %5438, %5439, %5440, %6770, %5441, %6771, %6772, %6773, %6774, %6775) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6776 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6777 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6778 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6779 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.85 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.84, %FeatureExtraction.ConvNet.layer4.0.bn1.weight, %FeatureExtraction.ConvNet.layer4.0.bn1.bias, %FeatureExtraction.ConvNet.layer4.0.bn1.running_mean, %FeatureExtraction.ConvNet.layer4.0.bn1.running_var, %6776, %6777, %6778, %6779) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5096 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.85) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1703 : None = prim::Constant()\n  %5442 : int[] = prim::Constant[value=[1, 1]]()\n  %5443 : int[] = prim::Constant[value=[1, 1]]()\n  %5444 : int[] = prim::Constant[value=[1, 1]]()\n  %6780 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5445 : int[] = prim::Constant[value=[0, 0]]()\n  %6781 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6782 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6783 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6784 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6785 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.87 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5096, %FeatureExtraction.ConvNet.layer4.0.conv2.weight, %1703, %5442, %5443, %5444, %6780, %5445, %6781, %6782, %6783, %6784, %6785) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6786 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6787 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6788 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6789 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1727 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.87, %FeatureExtraction.ConvNet.layer4.0.bn2.weight, %FeatureExtraction.ConvNet.layer4.0.bn2.bias, %FeatureExtraction.ConvNet.layer4.0.bn2.running_mean, %FeatureExtraction.ConvNet.layer4.0.bn2.running_var, %6786, %6787, %6788, %6789) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6790 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5072 : Tensor = aten::type_as(%5095, %1727)\n  %input.88 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1727, %5072, %6790) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.89 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.88) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1731 : None = prim::Constant()\n  %5446 : int[] = prim::Constant[value=[1, 1]]()\n  %5447 : int[] = prim::Constant[value=[1, 1]]()\n  %5448 : int[] = prim::Constant[value=[1, 1]]()\n  %6791 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5449 : int[] = prim::Constant[value=[0, 0]]()\n  %6792 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6793 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6794 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6795 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6796 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.90 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.89, %FeatureExtraction.ConvNet.layer4.1.conv1.weight, %1731, %5446, %5447, %5448, %6791, %5449, %6792, %6793, %6794, %6795, %6796) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6797 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6798 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6799 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6800 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.91 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.90, %FeatureExtraction.ConvNet.layer4.1.bn1.weight, %FeatureExtraction.ConvNet.layer4.1.bn1.bias, %FeatureExtraction.ConvNet.layer4.1.bn1.running_mean, %FeatureExtraction.ConvNet.layer4.1.bn1.running_var, %6797, %6798, %6799, %6800) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5097 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.91) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1757 : None = prim::Constant()\n  %5450 : int[] = prim::Constant[value=[1, 1]]()\n  %5451 : int[] = prim::Constant[value=[1, 1]]()\n  %5452 : int[] = prim::Constant[value=[1, 1]]()\n  %6801 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5453 : int[] = prim::Constant[value=[0, 0]]()\n  %6802 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6803 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6804 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6805 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6806 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.93 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5097, %FeatureExtraction.ConvNet.layer4.1.conv2.weight, %1757, %5450, %5451, %5452, %6801, %5453, %6802, %6803, %6804, %6805, %6806) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6807 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6808 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6809 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6810 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1781 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.93, %FeatureExtraction.ConvNet.layer4.1.bn2.weight, %FeatureExtraction.ConvNet.layer4.1.bn2.bias, %FeatureExtraction.ConvNet.layer4.1.bn2.running_mean, %FeatureExtraction.ConvNet.layer4.1.bn2.running_var, %6807, %6808, %6809, %6810) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6811 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5073 : Tensor = aten::type_as(%input.89, %1781)\n  %input.94 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1781, %5073, %6811) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.95 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.94) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1785 : None = prim::Constant()\n  %5454 : int[] = prim::Constant[value=[1, 1]]()\n  %5455 : int[] = prim::Constant[value=[1, 1]]()\n  %5456 : int[] = prim::Constant[value=[1, 1]]()\n  %6812 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5457 : int[] = prim::Constant[value=[0, 0]]()\n  %6813 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6814 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6815 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6816 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6817 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.96 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.95, %FeatureExtraction.ConvNet.layer4.2.conv1.weight, %1785, %5454, %5455, %5456, %6812, %5457, %6813, %6814, %6815, %6816, %6817) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6818 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6819 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6820 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6821 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.97 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.96, %FeatureExtraction.ConvNet.layer4.2.bn1.weight, %FeatureExtraction.ConvNet.layer4.2.bn1.bias, %FeatureExtraction.ConvNet.layer4.2.bn1.running_mean, %FeatureExtraction.ConvNet.layer4.2.bn1.running_var, %6818, %6819, %6820, %6821) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5098 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.97) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1811 : None = prim::Constant()\n  %5458 : int[] = prim::Constant[value=[1, 1]]()\n  %5459 : int[] = prim::Constant[value=[1, 1]]()\n  %5460 : int[] = prim::Constant[value=[1, 1]]()\n  %6822 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5461 : int[] = prim::Constant[value=[0, 0]]()\n  %6823 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6824 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6825 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6826 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6827 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.99 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5098, %FeatureExtraction.ConvNet.layer4.2.conv2.weight, %1811, %5458, %5459, %5460, %6822, %5461, %6823, %6824, %6825, %6826, %6827) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6828 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6829 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6830 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6831 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1835 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.99, %FeatureExtraction.ConvNet.layer4.2.bn2.weight, %FeatureExtraction.ConvNet.layer4.2.bn2.bias, %FeatureExtraction.ConvNet.layer4.2.bn2.running_mean, %FeatureExtraction.ConvNet.layer4.2.bn2.running_var, %6828, %6829, %6830, %6831) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %6832 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5074 : Tensor = aten::type_as(%input.95, %1835)\n  %input.100 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::add_(%1835, %5074, %6832) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/feature_extraction.py:147:0\n  %input.101 : Float(128, 512, 4, 26, strides=[53248, 104, 26, 1], requires_grad=1, device=cuda:0) = aten::relu_(%input.100) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1839 : None = prim::Constant()\n  %5462 : int[] = prim::Constant[value=[2, 1]]()\n  %5463 : int[] = prim::Constant[value=[0, 1]]()\n  %5464 : int[] = prim::Constant[value=[1, 1]]()\n  %6833 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5465 : int[] = prim::Constant[value=[0, 0]]()\n  %6834 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6835 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6836 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6837 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6838 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.102 : Float(128, 512, 2, 27, strides=[27648, 54, 27, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%input.101, %FeatureExtraction.ConvNet.conv4_1.weight, %1839, %5462, %5463, %5464, %6833, %5465, %6834, %6835, %6836, %6837, %6838) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6839 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6840 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6841 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6842 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.103 : Float(128, 512, 2, 27, strides=[27648, 54, 27, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.102, %FeatureExtraction.ConvNet.bn4_1.weight, %FeatureExtraction.ConvNet.bn4_1.bias, %FeatureExtraction.ConvNet.bn4_1.running_mean, %FeatureExtraction.ConvNet.bn4_1.running_var, %6839, %6840, %6841, %6842) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5099 : Float(128, 512, 2, 27, strides=[27648, 54, 27, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.103) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %1865 : None = prim::Constant()\n  %5466 : int[] = prim::Constant[value=[1, 1]]()\n  %5467 : int[] = prim::Constant[value=[0, 0]]()\n  %5468 : int[] = prim::Constant[value=[1, 1]]()\n  %6843 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5469 : int[] = prim::Constant[value=[0, 0]]()\n  %6844 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6845 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6846 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6847 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6848 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.105 : Float(128, 512, 1, 26, strides=[13312, 26, 26, 1], requires_grad=1, device=cuda:0) = aten::_convolution(%5099, %FeatureExtraction.ConvNet.conv4_2.weight, %1865, %5466, %5467, %5468, %6843, %5469, %6844, %6845, %6846, %6847, %6848) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:396:0\n  %6849 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6850 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0.1}]()\n  %6851 : Double(requires_grad=0, device=cpu) = prim::Constant[value={1e-05}]()\n  %6852 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.106 : Float(128, 512, 1, 26, strides=[13312, 26, 26, 1], requires_grad=1, device=cuda:0) = aten::batch_norm(%input.105, %FeatureExtraction.ConvNet.bn4_2.weight, %FeatureExtraction.ConvNet.bn4_2.bias, %FeatureExtraction.ConvNet.bn4_2.running_mean, %FeatureExtraction.ConvNet.bn4_2.running_var, %6849, %6850, %6851, %6852) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2150:0\n  %5100 : Float(128, 512, 1, 26, strides=[13312, 26, 26, 1], requires_grad=1, device=cuda:0) = aten::relu(%input.106) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1204:0\n  %5470 : int[] = prim::Constant[value=[0, 3, 1, 2]]()\n  %input.107 : Float(128, 26, 512, 1, strides=[13312, 1, 26, 26], requires_grad=1, device=cuda:0) = aten::permute(%5100, %5470) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/model.py:77:0\n  %6853 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %1904 : Long(device=cpu) = aten::size(%input.107, %6853) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1036:0\n  %6854 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %1911 : int[] = prim::ListConstruct(%1904, %6854)\n  %1912 : Float(128, 26, 512, 1, strides=[13312, 1, 26, 26], requires_grad=1, device=cuda:0) = aten::adaptive_avg_pool2d(%input.107, %1911) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1037:0\n  %6855 : Long(requires_grad=0, device=cpu) = prim::Constant[value={3}]()\n  %input.108 : Float(128, 26, 512, strides=[13312, 1, 26], requires_grad=1, device=cuda:0) = aten::squeeze(%1912, %6855) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/model.py:78:0\n  %6856 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %1926 : Long(device=cpu) = aten::size(%input.108, %6856) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:640:0\n  %6857 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6858 : Long(requires_grad=0, device=cpu) = prim::Constant[value={256}]()\n  %1931 : int[] = prim::ListConstruct(%6857, %1926, %6858)\n  %6859 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %1933 : None = prim::Constant()\n  %1934 : Device = prim::Constant[value=\"cuda:0\"]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:649:0\n  %6860 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %1936 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = aten::zeros(%1931, %6859, %1933, %1934, %6860) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:649:0\n  %6861 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6862 : Long(requires_grad=0, device=cpu) = prim::Constant[value={256}]()\n  %1940 : int[] = prim::ListConstruct(%6861, %1926, %6862)\n  %6863 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %1942 : None = prim::Constant()\n  %1943 : Device = prim::Constant[value=\"cuda:0\"]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:652:0\n  %6864 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %1945 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = aten::zeros(%1940, %6863, %1942, %1943, %6864) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:652:0\n  %1985 : Tensor[] = prim::ListConstruct(%1936, %1945)\n  %1986 : Tensor[] = prim::ListConstruct(%SequenceModeling.0.rnn.weight_ih_l0, %SequenceModeling.0.rnn.weight_hh_l0, %SequenceModeling.0.rnn.bias_ih_l0, %SequenceModeling.0.rnn.bias_hh_l0, %SequenceModeling.0.rnn.weight_ih_l0_reverse, %SequenceModeling.0.rnn.weight_hh_l0_reverse, %SequenceModeling.0.rnn.bias_ih_l0_reverse, %SequenceModeling.0.rnn.bias_hh_l0_reverse)\n  %6865 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6866 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6867 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6868 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6869 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6870 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.109 : Float(128, 26, 512, strides=[512, 65536, 1], requires_grad=1, device=cuda:0), %1994 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cuda:0), %1995 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cuda:0) = aten::lstm(%input.108, %1985, %1986, %6865, %6866, %6867, %6868, %6869, %6870) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:662:0\n  %1996 : Float(512, 256, strides=[1, 512], requires_grad=1, device=cuda:0) = aten::t(%SequenceModeling.0.linear.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %1997 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.109, %1996) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6871 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5075 : Tensor = aten::type_as(%SequenceModeling.0.linear.bias, %1997)\n  %input.110 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add_(%1997, %5075, %6871) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6872 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2011 : Long(device=cpu) = aten::size(%input.110, %6872) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:640:0\n  %6873 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6874 : Long(requires_grad=0, device=cpu) = prim::Constant[value={256}]()\n  %2016 : int[] = prim::ListConstruct(%6873, %2011, %6874)\n  %6875 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %2018 : None = prim::Constant()\n  %2019 : Device = prim::Constant[value=\"cuda:0\"]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:649:0\n  %6876 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2021 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = aten::zeros(%2016, %6875, %2018, %2019, %6876) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:649:0\n  %6877 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6878 : Long(requires_grad=0, device=cpu) = prim::Constant[value={256}]()\n  %2025 : int[] = prim::ListConstruct(%6877, %2011, %6878)\n  %6879 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %2027 : None = prim::Constant()\n  %2028 : Device = prim::Constant[value=\"cuda:0\"]() # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:652:0\n  %6880 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2030 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=0, device=cuda:0) = aten::zeros(%2025, %6879, %2027, %2028, %6880) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:652:0\n  %2070 : Tensor[] = prim::ListConstruct(%2021, %2030)\n  %2071 : Tensor[] = prim::ListConstruct(%SequenceModeling.1.rnn.weight_ih_l0, %SequenceModeling.1.rnn.weight_hh_l0, %SequenceModeling.1.rnn.bias_ih_l0, %SequenceModeling.1.rnn.bias_hh_l0, %SequenceModeling.1.rnn.weight_ih_l0_reverse, %SequenceModeling.1.rnn.weight_hh_l0_reverse, %SequenceModeling.1.rnn.bias_ih_l0_reverse, %SequenceModeling.1.rnn.bias_hh_l0_reverse)\n  %6881 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6882 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6883 : Double(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6884 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6885 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6886 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.111 : Float(128, 26, 512, strides=[512, 65536, 1], requires_grad=1, device=cuda:0), %2079 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cuda:0), %2080 : Float(2, 128, 256, strides=[32768, 256, 1], requires_grad=1, device=cuda:0) = aten::lstm(%input.110, %2070, %2071, %6881, %6882, %6883, %6884, %6885, %6886) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:662:0\n  %2081 : Float(512, 256, strides=[1, 512], requires_grad=1, device=cuda:0) = aten::t(%SequenceModeling.1.linear.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2082 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.111, %2081) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6887 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5076 : Tensor = aten::type_as(%SequenceModeling.1.linear.bias, %2082)\n  %2084 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add_(%2082, %5076, %6887) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6888 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.112 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::contiguous(%2084, %6888) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/model.py:90:0\n  %5473 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=0, device=cpu) = prim::Constant[value=<Tensor>]()\n  %6889 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %6890 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2104 : Device = prim::Constant[value=\"cuda\"]() # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:33:0\n  %2105 : None = prim::Constant()\n  %6891 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6892 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2108 : None = prim::Constant()\n  %input : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=0, device=cuda:0) = aten::to(%5473, %6889, %6890, %2104, %2105, %6891, %6892, %2108) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:33:0\n  %5477 : Float(128, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5481 : Float(128, 256, strides=[256, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %6893 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6894 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6895 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6896 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2152 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %6893, %6894, %6895, %6896) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6897 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6898 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2155 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2152, %6897, %6898) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6899 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2157 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2155, %6899) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %6900 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6901 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5485 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5125 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5485, %6900, %2157, %6901) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2182 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2183 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2182) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2184 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6902 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6903 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2187 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %5477, %2184, %6902, %6903) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6904 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2189 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2187, %6904) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %6905 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2191 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2183, %2189, %6905) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.114 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2191) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2193 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.1 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.114, %2193) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6906 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2196 : None = prim::Constant()\n  %2197 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.1, %6906, %2196) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5486 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2202 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2197, %5486) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2203 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2202, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %6907 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2205 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2203, %6907) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2206 : Tensor[] = prim::ListConstruct(%2205, %5125)\n  %6908 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.115 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2206, %6908) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2238 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2239 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.115, %2238) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2240 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2241 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%5477, %2240) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.191 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2243 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2244 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2239, %2241, %5481, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %6909 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6910 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6911 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6912 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2249 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=0, device=cuda:0) = aten::slice(%input, %6909, %6910, %6911, %6912) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6913 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6914 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %2252 : Float(128, 256, strides=[6656, 1], requires_grad=0, device=cuda:0) = aten::select(%2249, %6913, %6914) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6915 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6916 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6917 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6918 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2257 : Float(128, 256, strides=[6656, 1], requires_grad=0, device=cuda:0) = aten::slice(%2252, %6915, %6916, %6917, %6918) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6919 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.116 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.191, %2257) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6920 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5616 : Long(device=cpu) = aten::size(%input, %6920)\n  %6921 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5618 : None = prim::Constant()\n  %5619 : None = prim::Constant()\n  %5620 : None = prim::Constant()\n  %5621 : Tensor = aten::arange(%5616, %6921, %5618, %5619, %5620)\n  %6922 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5623 : Tensor = aten::slice(%5621, %6922, %6910, %6911, %6912)\n  %6923 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5626 : Tensor = aten::unsqueeze(%6914, %6923)\n  %6924 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5628 : Long(device=cpu) = aten::size(%input, %6924)\n  %6925 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5630 : None = prim::Constant()\n  %5631 : None = prim::Constant()\n  %5632 : None = prim::Constant()\n  %5633 : Tensor = aten::arange(%5628, %6925, %5630, %5631, %5632)\n  %6926 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5635 : Tensor = aten::slice(%5633, %6926, %6916, %6917, %6918)\n  %5636 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5637 : Tensor = aten::view(%5623, %5636)\n  %5638 : int[] = prim::Constant[value=[-1, 1]]()\n  %5639 : Tensor = aten::view(%5626, %5638)\n  %5640 : int[] = prim::Constant[value=[-1]]()\n  %5641 : Tensor = aten::view(%5635, %5640)\n  %5642 : Tensor?[] = prim::ListConstruct(%5637, %5639, %5641)\n  %5643 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%input, %5642, %input.116, %6919)\n  %6927 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6928 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6929 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6930 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2264 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %6927, %6928, %6929, %6930) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6931 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6932 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2267 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2264, %6931, %6932) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6933 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2269 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2267, %6933) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %6934 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6935 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5490 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5132 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5490, %6934, %2269, %6935) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2294 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2295 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2294) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2296 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6936 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6937 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2299 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.191, %2296, %6936, %6937) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6938 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2301 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2299, %6938) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %6939 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2303 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2295, %2301, %6939) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.117 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2303) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2305 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.2 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.117, %2305) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6940 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2308 : None = prim::Constant()\n  %2309 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.2, %6940, %2308) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5491 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2314 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2309, %5491) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2315 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2314, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %6941 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2317 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2315, %6941) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2318 : Tensor[] = prim::ListConstruct(%2317, %5132)\n  %6942 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.118 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2318, %6942) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2350 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2351 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.118, %2350) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2352 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2353 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.191, %2352) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.192 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2355 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2356 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2351, %2353, %2243, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %6943 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6944 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6945 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6946 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2361 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5643, %6943, %6944, %6945, %6946) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6947 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6948 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2364 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2361, %6947, %6948) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6949 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6950 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6951 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6952 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2369 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2364, %6949, %6950, %6951, %6952) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6953 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.119 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.192, %2369) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6954 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5648 : Long(device=cpu) = aten::size(%5643, %6954)\n  %6955 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5650 : None = prim::Constant()\n  %5651 : None = prim::Constant()\n  %5652 : None = prim::Constant()\n  %5653 : Tensor = aten::arange(%5648, %6955, %5650, %5651, %5652)\n  %6956 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5655 : Tensor = aten::slice(%5653, %6956, %6944, %6945, %6946)\n  %6957 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5658 : Tensor = aten::unsqueeze(%6948, %6957)\n  %6958 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5660 : Long(device=cpu) = aten::size(%5643, %6958)\n  %6959 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5662 : None = prim::Constant()\n  %5663 : None = prim::Constant()\n  %5664 : None = prim::Constant()\n  %5665 : Tensor = aten::arange(%5660, %6959, %5662, %5663, %5664)\n  %6960 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5667 : Tensor = aten::slice(%5665, %6960, %6950, %6951, %6952)\n  %5668 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5669 : Tensor = aten::view(%5655, %5668)\n  %5670 : int[] = prim::Constant[value=[-1, 1]]()\n  %5671 : Tensor = aten::view(%5658, %5670)\n  %5672 : int[] = prim::Constant[value=[-1]]()\n  %5673 : Tensor = aten::view(%5667, %5672)\n  %5674 : Tensor?[] = prim::ListConstruct(%5669, %5671, %5673)\n  %5675 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5643, %5674, %input.119, %6953)\n  %6961 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6962 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6963 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6964 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2376 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %6961, %6962, %6963, %6964) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6965 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6966 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %2379 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2376, %6965, %6966) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6967 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2381 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2379, %6967) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %6968 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6969 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5495 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5139 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5495, %6968, %2381, %6969) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2406 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2407 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2406) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2408 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6970 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6971 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2411 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.192, %2408, %6970, %6971) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6972 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2413 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2411, %6972) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %6973 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2415 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2407, %2413, %6973) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.120 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2415) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2417 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.3 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.120, %2417) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %6974 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2420 : None = prim::Constant()\n  %2421 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.3, %6974, %2420) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5496 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2426 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2421, %5496) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2427 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2426, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %6975 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2429 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2427, %6975) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2430 : Tensor[] = prim::ListConstruct(%2429, %5139)\n  %6976 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.121 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2430, %6976) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2462 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2463 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.121, %2462) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2464 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2465 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.192, %2464) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.193 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2467 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2468 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2463, %2465, %2355, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %6977 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6978 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6979 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6980 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2473 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5675, %6977, %6978, %6979, %6980) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6981 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6982 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %2476 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2473, %6981, %6982) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6983 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %6984 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6985 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6986 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2481 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2476, %6983, %6984, %6985, %6986) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6987 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.122 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.193, %2481) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %6988 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5680 : Long(device=cpu) = aten::size(%5675, %6988)\n  %6989 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5682 : None = prim::Constant()\n  %5683 : None = prim::Constant()\n  %5684 : None = prim::Constant()\n  %5685 : Tensor = aten::arange(%5680, %6989, %5682, %5683, %5684)\n  %6990 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5687 : Tensor = aten::slice(%5685, %6990, %6978, %6979, %6980)\n  %6991 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5690 : Tensor = aten::unsqueeze(%6982, %6991)\n  %6992 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5692 : Long(device=cpu) = aten::size(%5675, %6992)\n  %6993 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5694 : None = prim::Constant()\n  %5695 : None = prim::Constant()\n  %5696 : None = prim::Constant()\n  %5697 : Tensor = aten::arange(%5692, %6993, %5694, %5695, %5696)\n  %6994 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5699 : Tensor = aten::slice(%5697, %6994, %6984, %6985, %6986)\n  %5700 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5701 : Tensor = aten::view(%5687, %5700)\n  %5702 : int[] = prim::Constant[value=[-1, 1]]()\n  %5703 : Tensor = aten::view(%5690, %5702)\n  %5704 : int[] = prim::Constant[value=[-1]]()\n  %5705 : Tensor = aten::view(%5699, %5704)\n  %5706 : Tensor?[] = prim::ListConstruct(%5701, %5703, %5705)\n  %5707 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5675, %5706, %input.122, %6987)\n  %6995 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6996 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6997 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %6998 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2488 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %6995, %6996, %6997, %6998) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %6999 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7000 : Long(requires_grad=0, device=cpu) = prim::Constant[value={3}]()\n  %2491 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2488, %6999, %7000) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7001 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2493 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2491, %7001) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7002 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7003 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5500 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5146 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5500, %7002, %2493, %7003) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2518 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2519 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2518) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2520 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7004 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7005 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2523 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.193, %2520, %7004, %7005) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7006 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2525 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2523, %7006) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7007 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2527 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2519, %2525, %7007) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.123 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2527) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2529 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.4 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.123, %2529) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7008 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2532 : None = prim::Constant()\n  %2533 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.4, %7008, %2532) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5501 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2538 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2533, %5501) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2539 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2538, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7009 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2541 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2539, %7009) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2542 : Tensor[] = prim::ListConstruct(%2541, %5146)\n  %7010 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.124 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2542, %7010) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2574 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2575 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.124, %2574) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2576 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2577 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.193, %2576) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.194 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2579 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2580 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2575, %2577, %2467, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7011 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7012 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7013 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7014 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2585 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5707, %7011, %7012, %7013, %7014) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7015 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7016 : Long(requires_grad=0, device=cpu) = prim::Constant[value={3}]()\n  %2588 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2585, %7015, %7016) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7017 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7018 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7019 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7020 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2593 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2588, %7017, %7018, %7019, %7020) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7021 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.125 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.194, %2593) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7022 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5712 : Long(device=cpu) = aten::size(%5707, %7022)\n  %7023 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5714 : None = prim::Constant()\n  %5715 : None = prim::Constant()\n  %5716 : None = prim::Constant()\n  %5717 : Tensor = aten::arange(%5712, %7023, %5714, %5715, %5716)\n  %7024 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5719 : Tensor = aten::slice(%5717, %7024, %7012, %7013, %7014)\n  %7025 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5722 : Tensor = aten::unsqueeze(%7016, %7025)\n  %7026 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5724 : Long(device=cpu) = aten::size(%5707, %7026)\n  %7027 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5726 : None = prim::Constant()\n  %5727 : None = prim::Constant()\n  %5728 : None = prim::Constant()\n  %5729 : Tensor = aten::arange(%5724, %7027, %5726, %5727, %5728)\n  %7028 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5731 : Tensor = aten::slice(%5729, %7028, %7018, %7019, %7020)\n  %5732 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5733 : Tensor = aten::view(%5719, %5732)\n  %5734 : int[] = prim::Constant[value=[-1, 1]]()\n  %5735 : Tensor = aten::view(%5722, %5734)\n  %5736 : int[] = prim::Constant[value=[-1]]()\n  %5737 : Tensor = aten::view(%5731, %5736)\n  %5738 : Tensor?[] = prim::ListConstruct(%5733, %5735, %5737)\n  %5739 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5707, %5738, %input.125, %7021)\n  %7029 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7030 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7031 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7032 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2600 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7029, %7030, %7031, %7032) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7033 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7034 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %2603 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2600, %7033, %7034) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7035 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2605 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2603, %7035) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7036 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7037 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5505 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5153 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5505, %7036, %2605, %7037) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2630 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2631 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2630) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2632 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7038 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7039 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2635 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.194, %2632, %7038, %7039) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7040 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2637 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2635, %7040) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7041 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2639 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2631, %2637, %7041) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.126 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2639) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2641 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.5 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.126, %2641) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7042 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2644 : None = prim::Constant()\n  %2645 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.5, %7042, %2644) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5506 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2650 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2645, %5506) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2651 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2650, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7043 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2653 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2651, %7043) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2654 : Tensor[] = prim::ListConstruct(%2653, %5153)\n  %7044 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.127 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2654, %7044) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2686 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2687 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.127, %2686) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2688 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2689 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.194, %2688) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.195 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2691 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2692 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2687, %2689, %2579, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7045 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7046 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7047 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7048 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2697 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5739, %7045, %7046, %7047, %7048) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7049 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7050 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %2700 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2697, %7049, %7050) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7051 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7052 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7053 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7054 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2705 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2700, %7051, %7052, %7053, %7054) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7055 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.128 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.195, %2705) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7056 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5744 : Long(device=cpu) = aten::size(%5739, %7056)\n  %7057 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5746 : None = prim::Constant()\n  %5747 : None = prim::Constant()\n  %5748 : None = prim::Constant()\n  %5749 : Tensor = aten::arange(%5744, %7057, %5746, %5747, %5748)\n  %7058 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5751 : Tensor = aten::slice(%5749, %7058, %7046, %7047, %7048)\n  %7059 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5754 : Tensor = aten::unsqueeze(%7050, %7059)\n  %7060 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5756 : Long(device=cpu) = aten::size(%5739, %7060)\n  %7061 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5758 : None = prim::Constant()\n  %5759 : None = prim::Constant()\n  %5760 : None = prim::Constant()\n  %5761 : Tensor = aten::arange(%5756, %7061, %5758, %5759, %5760)\n  %7062 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5763 : Tensor = aten::slice(%5761, %7062, %7052, %7053, %7054)\n  %5764 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5765 : Tensor = aten::view(%5751, %5764)\n  %5766 : int[] = prim::Constant[value=[-1, 1]]()\n  %5767 : Tensor = aten::view(%5754, %5766)\n  %5768 : int[] = prim::Constant[value=[-1]]()\n  %5769 : Tensor = aten::view(%5763, %5768)\n  %5770 : Tensor?[] = prim::ListConstruct(%5765, %5767, %5769)\n  %5771 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5739, %5770, %input.128, %7055)\n  %7063 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7064 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7065 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7066 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2712 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7063, %7064, %7065, %7066) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7067 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7068 : Long(requires_grad=0, device=cpu) = prim::Constant[value={5}]()\n  %2715 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2712, %7067, %7068) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7069 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2717 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2715, %7069) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7070 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7071 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5510 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5160 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5510, %7070, %2717, %7071) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2742 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2743 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2742) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2744 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7072 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7073 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2747 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.195, %2744, %7072, %7073) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7074 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2749 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2747, %7074) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7075 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2751 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2743, %2749, %7075) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.129 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2751) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2753 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.6 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.129, %2753) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7076 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2756 : None = prim::Constant()\n  %2757 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.6, %7076, %2756) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5511 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2762 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2757, %5511) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2763 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2762, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7077 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2765 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2763, %7077) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2766 : Tensor[] = prim::ListConstruct(%2765, %5160)\n  %7078 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.130 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2766, %7078) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2798 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2799 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.130, %2798) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2800 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2801 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.195, %2800) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.196 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2803 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2804 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2799, %2801, %2691, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7079 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7080 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7081 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7082 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2809 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5771, %7079, %7080, %7081, %7082) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7083 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7084 : Long(requires_grad=0, device=cpu) = prim::Constant[value={5}]()\n  %2812 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2809, %7083, %7084) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7085 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7086 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7087 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7088 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2817 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2812, %7085, %7086, %7087, %7088) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7089 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.131 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.196, %2817) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7090 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5776 : Long(device=cpu) = aten::size(%5771, %7090)\n  %7091 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5778 : None = prim::Constant()\n  %5779 : None = prim::Constant()\n  %5780 : None = prim::Constant()\n  %5781 : Tensor = aten::arange(%5776, %7091, %5778, %5779, %5780)\n  %7092 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5783 : Tensor = aten::slice(%5781, %7092, %7080, %7081, %7082)\n  %7093 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5786 : Tensor = aten::unsqueeze(%7084, %7093)\n  %7094 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5788 : Long(device=cpu) = aten::size(%5771, %7094)\n  %7095 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5790 : None = prim::Constant()\n  %5791 : None = prim::Constant()\n  %5792 : None = prim::Constant()\n  %5793 : Tensor = aten::arange(%5788, %7095, %5790, %5791, %5792)\n  %7096 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5795 : Tensor = aten::slice(%5793, %7096, %7086, %7087, %7088)\n  %5796 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5797 : Tensor = aten::view(%5783, %5796)\n  %5798 : int[] = prim::Constant[value=[-1, 1]]()\n  %5799 : Tensor = aten::view(%5786, %5798)\n  %5800 : int[] = prim::Constant[value=[-1]]()\n  %5801 : Tensor = aten::view(%5795, %5800)\n  %5802 : Tensor?[] = prim::ListConstruct(%5797, %5799, %5801)\n  %5803 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5771, %5802, %input.131, %7089)\n  %7097 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7098 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7099 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7100 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2824 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7097, %7098, %7099, %7100) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7101 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7102 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %2827 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2824, %7101, %7102) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7103 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2829 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2827, %7103) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7104 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7105 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5515 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5167 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5515, %7104, %2829, %7105) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2854 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2855 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2854) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2856 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7106 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7107 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2859 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.196, %2856, %7106, %7107) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7108 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2861 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2859, %7108) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7109 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2863 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2855, %2861, %7109) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.132 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2863) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2865 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.7 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.132, %2865) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7110 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2868 : None = prim::Constant()\n  %2869 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.7, %7110, %2868) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5516 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2874 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2869, %5516) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2875 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2874, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7111 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2877 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2875, %7111) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2878 : Tensor[] = prim::ListConstruct(%2877, %5167)\n  %7112 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.133 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2878, %7112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %2910 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2911 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.133, %2910) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2912 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %2913 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.196, %2912) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.197 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2915 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %2916 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%2911, %2913, %2803, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7113 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7114 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7115 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7116 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2921 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5803, %7113, %7114, %7115, %7116) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7117 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7118 : Long(requires_grad=0, device=cpu) = prim::Constant[value={6}]()\n  %2924 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%2921, %7117, %7118) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7119 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7120 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7121 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7122 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2929 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%2924, %7119, %7120, %7121, %7122) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7123 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.134 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.197, %2929) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7124 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5808 : Long(device=cpu) = aten::size(%5803, %7124)\n  %7125 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5810 : None = prim::Constant()\n  %5811 : None = prim::Constant()\n  %5812 : None = prim::Constant()\n  %5813 : Tensor = aten::arange(%5808, %7125, %5810, %5811, %5812)\n  %7126 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5815 : Tensor = aten::slice(%5813, %7126, %7114, %7115, %7116)\n  %7127 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5818 : Tensor = aten::unsqueeze(%7118, %7127)\n  %7128 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5820 : Long(device=cpu) = aten::size(%5803, %7128)\n  %7129 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5822 : None = prim::Constant()\n  %5823 : None = prim::Constant()\n  %5824 : None = prim::Constant()\n  %5825 : Tensor = aten::arange(%5820, %7129, %5822, %5823, %5824)\n  %7130 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5827 : Tensor = aten::slice(%5825, %7130, %7120, %7121, %7122)\n  %5828 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5829 : Tensor = aten::view(%5815, %5828)\n  %5830 : int[] = prim::Constant[value=[-1, 1]]()\n  %5831 : Tensor = aten::view(%5818, %5830)\n  %5832 : int[] = prim::Constant[value=[-1]]()\n  %5833 : Tensor = aten::view(%5827, %5832)\n  %5834 : Tensor?[] = prim::ListConstruct(%5829, %5831, %5833)\n  %5835 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5803, %5834, %input.134, %7123)\n  %7131 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7132 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7133 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7134 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2936 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7131, %7132, %7133, %7134) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7135 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7136 : Long(requires_grad=0, device=cpu) = prim::Constant[value={7}]()\n  %2939 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%2936, %7135, %7136) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7137 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2941 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%2939, %7137) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7138 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7139 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5520 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5174 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5520, %7138, %2941, %7139) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %2966 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2967 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %2966) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %2968 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7140 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7141 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2971 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.197, %2968, %7140, %7141) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7142 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2973 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%2971, %7142) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7143 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2975 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%2967, %2973, %7143) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.135 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%2975) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %2977 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.8 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.135, %2977) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7144 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2980 : None = prim::Constant()\n  %2981 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.8, %7144, %2980) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5521 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %2986 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%2981, %5521) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2987 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%2986, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7145 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %2989 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%2987, %7145) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %2990 : Tensor[] = prim::ListConstruct(%2989, %5174)\n  %7146 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.136 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%2990, %7146) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3022 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3023 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.136, %3022) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3024 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3025 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.197, %3024) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.198 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3027 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3028 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3023, %3025, %2915, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7147 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7148 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7149 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7150 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3033 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5835, %7147, %7148, %7149, %7150) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7151 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7152 : Long(requires_grad=0, device=cpu) = prim::Constant[value={7}]()\n  %3036 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3033, %7151, %7152) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7153 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7154 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7155 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7156 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3041 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3036, %7153, %7154, %7155, %7156) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7157 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.137 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.198, %3041) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7158 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5840 : Long(device=cpu) = aten::size(%5835, %7158)\n  %7159 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5842 : None = prim::Constant()\n  %5843 : None = prim::Constant()\n  %5844 : None = prim::Constant()\n  %5845 : Tensor = aten::arange(%5840, %7159, %5842, %5843, %5844)\n  %7160 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5847 : Tensor = aten::slice(%5845, %7160, %7148, %7149, %7150)\n  %7161 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5850 : Tensor = aten::unsqueeze(%7152, %7161)\n  %7162 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5852 : Long(device=cpu) = aten::size(%5835, %7162)\n  %7163 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5854 : None = prim::Constant()\n  %5855 : None = prim::Constant()\n  %5856 : None = prim::Constant()\n  %5857 : Tensor = aten::arange(%5852, %7163, %5854, %5855, %5856)\n  %7164 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5859 : Tensor = aten::slice(%5857, %7164, %7154, %7155, %7156)\n  %5860 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5861 : Tensor = aten::view(%5847, %5860)\n  %5862 : int[] = prim::Constant[value=[-1, 1]]()\n  %5863 : Tensor = aten::view(%5850, %5862)\n  %5864 : int[] = prim::Constant[value=[-1]]()\n  %5865 : Tensor = aten::view(%5859, %5864)\n  %5866 : Tensor?[] = prim::ListConstruct(%5861, %5863, %5865)\n  %5867 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5835, %5866, %input.137, %7157)\n  %7165 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7166 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7167 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7168 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3048 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7165, %7166, %7167, %7168) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7169 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7170 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}]()\n  %3051 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3048, %7169, %7170) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7171 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3053 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3051, %7171) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7172 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7173 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5525 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5181 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5525, %7172, %3053, %7173) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3078 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3079 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3078) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3080 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7174 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7175 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3083 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.198, %3080, %7174, %7175) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7176 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3085 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3083, %7176) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7177 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3087 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3079, %3085, %7177) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.138 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3087) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3089 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.9 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.138, %3089) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7178 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3092 : None = prim::Constant()\n  %3093 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.9, %7178, %3092) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5526 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3098 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3093, %5526) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3099 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3098, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7179 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3101 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3099, %7179) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3102 : Tensor[] = prim::ListConstruct(%3101, %5181)\n  %7180 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.139 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3102, %7180) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3134 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3135 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.139, %3134) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3136 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3137 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.198, %3136) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.199 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3139 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3140 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3135, %3137, %3027, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7181 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7182 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7183 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7184 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3145 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5867, %7181, %7182, %7183, %7184) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7185 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7186 : Long(requires_grad=0, device=cpu) = prim::Constant[value={8}]()\n  %3148 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3145, %7185, %7186) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7187 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7188 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7189 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7190 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3153 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3148, %7187, %7188, %7189, %7190) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7191 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.140 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.199, %3153) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7192 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5872 : Long(device=cpu) = aten::size(%5867, %7192)\n  %7193 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5874 : None = prim::Constant()\n  %5875 : None = prim::Constant()\n  %5876 : None = prim::Constant()\n  %5877 : Tensor = aten::arange(%5872, %7193, %5874, %5875, %5876)\n  %7194 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5879 : Tensor = aten::slice(%5877, %7194, %7182, %7183, %7184)\n  %7195 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5882 : Tensor = aten::unsqueeze(%7186, %7195)\n  %7196 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5884 : Long(device=cpu) = aten::size(%5867, %7196)\n  %7197 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5886 : None = prim::Constant()\n  %5887 : None = prim::Constant()\n  %5888 : None = prim::Constant()\n  %5889 : Tensor = aten::arange(%5884, %7197, %5886, %5887, %5888)\n  %7198 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5891 : Tensor = aten::slice(%5889, %7198, %7188, %7189, %7190)\n  %5892 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5893 : Tensor = aten::view(%5879, %5892)\n  %5894 : int[] = prim::Constant[value=[-1, 1]]()\n  %5895 : Tensor = aten::view(%5882, %5894)\n  %5896 : int[] = prim::Constant[value=[-1]]()\n  %5897 : Tensor = aten::view(%5891, %5896)\n  %5898 : Tensor?[] = prim::ListConstruct(%5893, %5895, %5897)\n  %5899 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5867, %5898, %input.140, %7191)\n  %7199 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7200 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7201 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7202 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3160 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7199, %7200, %7201, %7202) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7203 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7204 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9}]()\n  %3163 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3160, %7203, %7204) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7205 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3165 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3163, %7205) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7206 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7207 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5530 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5188 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5530, %7206, %3165, %7207) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3190 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3191 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3190) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3192 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7208 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7209 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3195 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.199, %3192, %7208, %7209) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7210 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3197 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3195, %7210) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7211 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3199 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3191, %3197, %7211) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.141 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3199) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3201 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.10 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.141, %3201) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7212 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3204 : None = prim::Constant()\n  %3205 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.10, %7212, %3204) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5531 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3210 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3205, %5531) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3211 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3210, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7213 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3213 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3211, %7213) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3214 : Tensor[] = prim::ListConstruct(%3213, %5188)\n  %7214 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.142 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3214, %7214) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3246 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3247 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.142, %3246) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3248 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3249 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.199, %3248) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.200 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3251 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3252 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3247, %3249, %3139, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7215 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7216 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7217 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7218 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3257 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5899, %7215, %7216, %7217, %7218) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7219 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7220 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9}]()\n  %3260 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3257, %7219, %7220) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7221 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7222 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7223 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7224 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3265 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3260, %7221, %7222, %7223, %7224) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7225 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.143 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.200, %3265) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7226 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5904 : Long(device=cpu) = aten::size(%5899, %7226)\n  %7227 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5906 : None = prim::Constant()\n  %5907 : None = prim::Constant()\n  %5908 : None = prim::Constant()\n  %5909 : Tensor = aten::arange(%5904, %7227, %5906, %5907, %5908)\n  %7228 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5911 : Tensor = aten::slice(%5909, %7228, %7216, %7217, %7218)\n  %7229 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5914 : Tensor = aten::unsqueeze(%7220, %7229)\n  %7230 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5916 : Long(device=cpu) = aten::size(%5899, %7230)\n  %7231 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5918 : None = prim::Constant()\n  %5919 : None = prim::Constant()\n  %5920 : None = prim::Constant()\n  %5921 : Tensor = aten::arange(%5916, %7231, %5918, %5919, %5920)\n  %7232 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5923 : Tensor = aten::slice(%5921, %7232, %7222, %7223, %7224)\n  %5924 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5925 : Tensor = aten::view(%5911, %5924)\n  %5926 : int[] = prim::Constant[value=[-1, 1]]()\n  %5927 : Tensor = aten::view(%5914, %5926)\n  %5928 : int[] = prim::Constant[value=[-1]]()\n  %5929 : Tensor = aten::view(%5923, %5928)\n  %5930 : Tensor?[] = prim::ListConstruct(%5925, %5927, %5929)\n  %5931 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5899, %5930, %input.143, %7225)\n  %7233 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7234 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7235 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7236 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3272 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7233, %7234, %7235, %7236) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7237 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7238 : Long(requires_grad=0, device=cpu) = prim::Constant[value={10}]()\n  %3275 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3272, %7237, %7238) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7239 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3277 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3275, %7239) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7240 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7241 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5535 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5195 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5535, %7240, %3277, %7241) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3302 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3303 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3302) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3304 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7242 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7243 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3307 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.200, %3304, %7242, %7243) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7244 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3309 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3307, %7244) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7245 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3311 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3303, %3309, %7245) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.144 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3311) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3313 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.11 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.144, %3313) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7246 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3316 : None = prim::Constant()\n  %3317 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.11, %7246, %3316) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5536 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3322 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3317, %5536) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3323 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3322, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7247 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3325 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3323, %7247) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3326 : Tensor[] = prim::ListConstruct(%3325, %5195)\n  %7248 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.145 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3326, %7248) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3358 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3359 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.145, %3358) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3360 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3361 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.200, %3360) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.201 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3363 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3364 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3359, %3361, %3251, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7249 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7250 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7251 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7252 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3369 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5931, %7249, %7250, %7251, %7252) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7253 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7254 : Long(requires_grad=0, device=cpu) = prim::Constant[value={10}]()\n  %3372 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3369, %7253, %7254) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7255 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7256 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7257 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7258 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3377 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3372, %7255, %7256, %7257, %7258) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7259 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.146 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.201, %3377) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7260 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5936 : Long(device=cpu) = aten::size(%5931, %7260)\n  %7261 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5938 : None = prim::Constant()\n  %5939 : None = prim::Constant()\n  %5940 : None = prim::Constant()\n  %5941 : Tensor = aten::arange(%5936, %7261, %5938, %5939, %5940)\n  %7262 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5943 : Tensor = aten::slice(%5941, %7262, %7250, %7251, %7252)\n  %7263 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5946 : Tensor = aten::unsqueeze(%7254, %7263)\n  %7264 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5948 : Long(device=cpu) = aten::size(%5931, %7264)\n  %7265 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5950 : None = prim::Constant()\n  %5951 : None = prim::Constant()\n  %5952 : None = prim::Constant()\n  %5953 : Tensor = aten::arange(%5948, %7265, %5950, %5951, %5952)\n  %7266 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5955 : Tensor = aten::slice(%5953, %7266, %7256, %7257, %7258)\n  %5956 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5957 : Tensor = aten::view(%5943, %5956)\n  %5958 : int[] = prim::Constant[value=[-1, 1]]()\n  %5959 : Tensor = aten::view(%5946, %5958)\n  %5960 : int[] = prim::Constant[value=[-1]]()\n  %5961 : Tensor = aten::view(%5955, %5960)\n  %5962 : Tensor?[] = prim::ListConstruct(%5957, %5959, %5961)\n  %5963 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5931, %5962, %input.146, %7259)\n  %7267 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7268 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7269 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7270 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3384 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7267, %7268, %7269, %7270) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7271 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7272 : Long(requires_grad=0, device=cpu) = prim::Constant[value={11}]()\n  %3387 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3384, %7271, %7272) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7273 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3389 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3387, %7273) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7274 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7275 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5540 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5202 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5540, %7274, %3389, %7275) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3414 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3415 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3414) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3416 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7276 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7277 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3419 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.201, %3416, %7276, %7277) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7278 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3421 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3419, %7278) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7279 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3423 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3415, %3421, %7279) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.147 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3423) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3425 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.12 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.147, %3425) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7280 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3428 : None = prim::Constant()\n  %3429 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.12, %7280, %3428) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5541 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3434 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3429, %5541) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3435 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3434, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7281 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3437 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3435, %7281) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3438 : Tensor[] = prim::ListConstruct(%3437, %5202)\n  %7282 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.148 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3438, %7282) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3470 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3471 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.148, %3470) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3472 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3473 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.201, %3472) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.202 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3475 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3476 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3471, %3473, %3363, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7283 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7284 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7285 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7286 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3481 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5963, %7283, %7284, %7285, %7286) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7287 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7288 : Long(requires_grad=0, device=cpu) = prim::Constant[value={11}]()\n  %3484 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3481, %7287, %7288) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7289 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7290 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7291 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7292 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3489 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3484, %7289, %7290, %7291, %7292) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7293 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.149 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.202, %3489) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7294 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5968 : Long(device=cpu) = aten::size(%5963, %7294)\n  %7295 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5970 : None = prim::Constant()\n  %5971 : None = prim::Constant()\n  %5972 : None = prim::Constant()\n  %5973 : Tensor = aten::arange(%5968, %7295, %5970, %5971, %5972)\n  %7296 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5975 : Tensor = aten::slice(%5973, %7296, %7284, %7285, %7286)\n  %7297 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5978 : Tensor = aten::unsqueeze(%7288, %7297)\n  %7298 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %5980 : Long(device=cpu) = aten::size(%5963, %7298)\n  %7299 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %5982 : None = prim::Constant()\n  %5983 : None = prim::Constant()\n  %5984 : None = prim::Constant()\n  %5985 : Tensor = aten::arange(%5980, %7299, %5982, %5983, %5984)\n  %7300 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %5987 : Tensor = aten::slice(%5985, %7300, %7290, %7291, %7292)\n  %5988 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %5989 : Tensor = aten::view(%5975, %5988)\n  %5990 : int[] = prim::Constant[value=[-1, 1]]()\n  %5991 : Tensor = aten::view(%5978, %5990)\n  %5992 : int[] = prim::Constant[value=[-1]]()\n  %5993 : Tensor = aten::view(%5987, %5992)\n  %5994 : Tensor?[] = prim::ListConstruct(%5989, %5991, %5993)\n  %5995 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5963, %5994, %input.149, %7293)\n  %7301 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7302 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7303 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7304 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3496 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7301, %7302, %7303, %7304) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7305 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7306 : Long(requires_grad=0, device=cpu) = prim::Constant[value={12}]()\n  %3499 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3496, %7305, %7306) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7307 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3501 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3499, %7307) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7308 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7309 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5545 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5209 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5545, %7308, %3501, %7309) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3526 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3527 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3526) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3528 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7310 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7311 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3531 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.202, %3528, %7310, %7311) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7312 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3533 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3531, %7312) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7313 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3535 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3527, %3533, %7313) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.150 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3535) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3537 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.13 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.150, %3537) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7314 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3540 : None = prim::Constant()\n  %3541 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.13, %7314, %3540) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5546 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3546 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3541, %5546) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3547 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3546, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7315 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3549 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3547, %7315) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3550 : Tensor[] = prim::ListConstruct(%3549, %5209)\n  %7316 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.151 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3550, %7316) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3582 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3583 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.151, %3582) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3584 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3585 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.202, %3584) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.203 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3587 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3588 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3583, %3585, %3475, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7317 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7318 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7319 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7320 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3593 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%5995, %7317, %7318, %7319, %7320) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7321 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7322 : Long(requires_grad=0, device=cpu) = prim::Constant[value={12}]()\n  %3596 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3593, %7321, %7322) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7323 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7324 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7325 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7326 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3601 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3596, %7323, %7324, %7325, %7326) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7327 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.152 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.203, %3601) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7328 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6000 : Long(device=cpu) = aten::size(%5995, %7328)\n  %7329 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6002 : None = prim::Constant()\n  %6003 : None = prim::Constant()\n  %6004 : None = prim::Constant()\n  %6005 : Tensor = aten::arange(%6000, %7329, %6002, %6003, %6004)\n  %7330 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6007 : Tensor = aten::slice(%6005, %7330, %7318, %7319, %7320)\n  %7331 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6010 : Tensor = aten::unsqueeze(%7322, %7331)\n  %7332 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6012 : Long(device=cpu) = aten::size(%5995, %7332)\n  %7333 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6014 : None = prim::Constant()\n  %6015 : None = prim::Constant()\n  %6016 : None = prim::Constant()\n  %6017 : Tensor = aten::arange(%6012, %7333, %6014, %6015, %6016)\n  %7334 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6019 : Tensor = aten::slice(%6017, %7334, %7324, %7325, %7326)\n  %6020 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6021 : Tensor = aten::view(%6007, %6020)\n  %6022 : int[] = prim::Constant[value=[-1, 1]]()\n  %6023 : Tensor = aten::view(%6010, %6022)\n  %6024 : int[] = prim::Constant[value=[-1]]()\n  %6025 : Tensor = aten::view(%6019, %6024)\n  %6026 : Tensor?[] = prim::ListConstruct(%6021, %6023, %6025)\n  %6027 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%5995, %6026, %input.152, %7327)\n  %7335 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7336 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7337 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7338 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3608 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7335, %7336, %7337, %7338) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7339 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7340 : Long(requires_grad=0, device=cpu) = prim::Constant[value={13}]()\n  %3611 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3608, %7339, %7340) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7341 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3613 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3611, %7341) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7342 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7343 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5550 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5216 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5550, %7342, %3613, %7343) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3638 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3639 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3638) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3640 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7344 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7345 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3643 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.203, %3640, %7344, %7345) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7346 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3645 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3643, %7346) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7347 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3647 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3639, %3645, %7347) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.153 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3647) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3649 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.14 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.153, %3649) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7348 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3652 : None = prim::Constant()\n  %3653 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.14, %7348, %3652) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5551 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3658 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3653, %5551) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3659 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3658, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7349 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3661 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3659, %7349) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3662 : Tensor[] = prim::ListConstruct(%3661, %5216)\n  %7350 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.154 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3662, %7350) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3694 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3695 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.154, %3694) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3696 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3697 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.203, %3696) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.204 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3699 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3700 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3695, %3697, %3587, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7351 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7352 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7353 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7354 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3705 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6027, %7351, %7352, %7353, %7354) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7355 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7356 : Long(requires_grad=0, device=cpu) = prim::Constant[value={13}]()\n  %3708 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3705, %7355, %7356) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7357 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7358 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7359 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7360 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3713 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3708, %7357, %7358, %7359, %7360) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7361 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.155 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.204, %3713) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7362 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6032 : Long(device=cpu) = aten::size(%6027, %7362)\n  %7363 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6034 : None = prim::Constant()\n  %6035 : None = prim::Constant()\n  %6036 : None = prim::Constant()\n  %6037 : Tensor = aten::arange(%6032, %7363, %6034, %6035, %6036)\n  %7364 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6039 : Tensor = aten::slice(%6037, %7364, %7352, %7353, %7354)\n  %7365 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6042 : Tensor = aten::unsqueeze(%7356, %7365)\n  %7366 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6044 : Long(device=cpu) = aten::size(%6027, %7366)\n  %7367 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6046 : None = prim::Constant()\n  %6047 : None = prim::Constant()\n  %6048 : None = prim::Constant()\n  %6049 : Tensor = aten::arange(%6044, %7367, %6046, %6047, %6048)\n  %7368 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6051 : Tensor = aten::slice(%6049, %7368, %7358, %7359, %7360)\n  %6052 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6053 : Tensor = aten::view(%6039, %6052)\n  %6054 : int[] = prim::Constant[value=[-1, 1]]()\n  %6055 : Tensor = aten::view(%6042, %6054)\n  %6056 : int[] = prim::Constant[value=[-1]]()\n  %6057 : Tensor = aten::view(%6051, %6056)\n  %6058 : Tensor?[] = prim::ListConstruct(%6053, %6055, %6057)\n  %6059 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6027, %6058, %input.155, %7361)\n  %7369 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7370 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7371 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7372 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3720 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7369, %7370, %7371, %7372) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7373 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7374 : Long(requires_grad=0, device=cpu) = prim::Constant[value={14}]()\n  %3723 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3720, %7373, %7374) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7375 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3725 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3723, %7375) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7376 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7377 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5555 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5223 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5555, %7376, %3725, %7377) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3750 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3751 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3750) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3752 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7378 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7379 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3755 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.204, %3752, %7378, %7379) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7380 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3757 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3755, %7380) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7381 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3759 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3751, %3757, %7381) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.156 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3759) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3761 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.15 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.156, %3761) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7382 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3764 : None = prim::Constant()\n  %3765 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.15, %7382, %3764) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5556 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3770 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3765, %5556) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3771 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3770, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7383 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3773 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3771, %7383) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3774 : Tensor[] = prim::ListConstruct(%3773, %5223)\n  %7384 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.157 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3774, %7384) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3806 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3807 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.157, %3806) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3808 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3809 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.204, %3808) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.205 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3811 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3812 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3807, %3809, %3699, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7385 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7386 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7387 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7388 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3817 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6059, %7385, %7386, %7387, %7388) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7389 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7390 : Long(requires_grad=0, device=cpu) = prim::Constant[value={14}]()\n  %3820 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3817, %7389, %7390) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7391 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7392 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7393 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7394 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3825 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3820, %7391, %7392, %7393, %7394) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7395 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.158 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.205, %3825) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7396 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6064 : Long(device=cpu) = aten::size(%6059, %7396)\n  %7397 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6066 : None = prim::Constant()\n  %6067 : None = prim::Constant()\n  %6068 : None = prim::Constant()\n  %6069 : Tensor = aten::arange(%6064, %7397, %6066, %6067, %6068)\n  %7398 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6071 : Tensor = aten::slice(%6069, %7398, %7386, %7387, %7388)\n  %7399 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6074 : Tensor = aten::unsqueeze(%7390, %7399)\n  %7400 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6076 : Long(device=cpu) = aten::size(%6059, %7400)\n  %7401 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6078 : None = prim::Constant()\n  %6079 : None = prim::Constant()\n  %6080 : None = prim::Constant()\n  %6081 : Tensor = aten::arange(%6076, %7401, %6078, %6079, %6080)\n  %7402 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6083 : Tensor = aten::slice(%6081, %7402, %7392, %7393, %7394)\n  %6084 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6085 : Tensor = aten::view(%6071, %6084)\n  %6086 : int[] = prim::Constant[value=[-1, 1]]()\n  %6087 : Tensor = aten::view(%6074, %6086)\n  %6088 : int[] = prim::Constant[value=[-1]]()\n  %6089 : Tensor = aten::view(%6083, %6088)\n  %6090 : Tensor?[] = prim::ListConstruct(%6085, %6087, %6089)\n  %6091 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6059, %6090, %input.158, %7395)\n  %7403 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7404 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7405 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7406 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3832 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7403, %7404, %7405, %7406) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7407 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7408 : Long(requires_grad=0, device=cpu) = prim::Constant[value={15}]()\n  %3835 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3832, %7407, %7408) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7409 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3837 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3835, %7409) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7410 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7411 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5560 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5230 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5560, %7410, %3837, %7411) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3862 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3863 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3862) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3864 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7412 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7413 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3867 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.205, %3864, %7412, %7413) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7414 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3869 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3867, %7414) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7415 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3871 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3863, %3869, %7415) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.159 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3871) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3873 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.16 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.159, %3873) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7416 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3876 : None = prim::Constant()\n  %3877 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.16, %7416, %3876) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5561 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3882 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3877, %5561) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3883 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3882, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7417 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3885 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3883, %7417) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3886 : Tensor[] = prim::ListConstruct(%3885, %5230)\n  %7418 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.160 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3886, %7418) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %3918 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3919 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.160, %3918) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3920 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %3921 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.205, %3920) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.206 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3923 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %3924 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%3919, %3921, %3811, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7419 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7420 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7421 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7422 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3929 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6091, %7419, %7420, %7421, %7422) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7423 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7424 : Long(requires_grad=0, device=cpu) = prim::Constant[value={15}]()\n  %3932 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%3929, %7423, %7424) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7425 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7426 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7427 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7428 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3937 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%3932, %7425, %7426, %7427, %7428) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7429 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.161 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.206, %3937) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7430 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6096 : Long(device=cpu) = aten::size(%6091, %7430)\n  %7431 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6098 : None = prim::Constant()\n  %6099 : None = prim::Constant()\n  %6100 : None = prim::Constant()\n  %6101 : Tensor = aten::arange(%6096, %7431, %6098, %6099, %6100)\n  %7432 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6103 : Tensor = aten::slice(%6101, %7432, %7420, %7421, %7422)\n  %7433 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6106 : Tensor = aten::unsqueeze(%7424, %7433)\n  %7434 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6108 : Long(device=cpu) = aten::size(%6091, %7434)\n  %7435 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6110 : None = prim::Constant()\n  %6111 : None = prim::Constant()\n  %6112 : None = prim::Constant()\n  %6113 : Tensor = aten::arange(%6108, %7435, %6110, %6111, %6112)\n  %7436 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6115 : Tensor = aten::slice(%6113, %7436, %7426, %7427, %7428)\n  %6116 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6117 : Tensor = aten::view(%6103, %6116)\n  %6118 : int[] = prim::Constant[value=[-1, 1]]()\n  %6119 : Tensor = aten::view(%6106, %6118)\n  %6120 : int[] = prim::Constant[value=[-1]]()\n  %6121 : Tensor = aten::view(%6115, %6120)\n  %6122 : Tensor?[] = prim::ListConstruct(%6117, %6119, %6121)\n  %6123 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6091, %6122, %input.161, %7429)\n  %7437 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7438 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7439 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7440 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3944 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7437, %7438, %7439, %7440) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7441 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7442 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]()\n  %3947 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%3944, %7441, %7442) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7443 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3949 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%3947, %7443) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7444 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7445 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5565 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5237 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5565, %7444, %3949, %7445) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %3974 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3975 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %3974) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %3976 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7446 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7447 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3979 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.206, %3976, %7446, %7447) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7448 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3981 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%3979, %7448) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7449 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3983 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%3975, %3981, %7449) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.162 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%3983) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %3985 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.17 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.162, %3985) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7450 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3988 : None = prim::Constant()\n  %3989 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.17, %7450, %3988) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5566 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %3994 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%3989, %5566) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3995 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%3994, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7451 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %3997 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%3995, %7451) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %3998 : Tensor[] = prim::ListConstruct(%3997, %5237)\n  %7452 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.163 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%3998, %7452) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4030 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4031 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.163, %4030) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4032 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4033 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.206, %4032) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.207 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4035 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4036 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4031, %4033, %3923, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7453 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7454 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7455 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7456 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4041 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6123, %7453, %7454, %7455, %7456) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7457 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7458 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}]()\n  %4044 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4041, %7457, %7458) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7459 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7460 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7461 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7462 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4049 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4044, %7459, %7460, %7461, %7462) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7463 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.164 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.207, %4049) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7464 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6128 : Long(device=cpu) = aten::size(%6123, %7464)\n  %7465 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6130 : None = prim::Constant()\n  %6131 : None = prim::Constant()\n  %6132 : None = prim::Constant()\n  %6133 : Tensor = aten::arange(%6128, %7465, %6130, %6131, %6132)\n  %7466 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6135 : Tensor = aten::slice(%6133, %7466, %7454, %7455, %7456)\n  %7467 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6138 : Tensor = aten::unsqueeze(%7458, %7467)\n  %7468 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6140 : Long(device=cpu) = aten::size(%6123, %7468)\n  %7469 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6142 : None = prim::Constant()\n  %6143 : None = prim::Constant()\n  %6144 : None = prim::Constant()\n  %6145 : Tensor = aten::arange(%6140, %7469, %6142, %6143, %6144)\n  %7470 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6147 : Tensor = aten::slice(%6145, %7470, %7460, %7461, %7462)\n  %6148 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6149 : Tensor = aten::view(%6135, %6148)\n  %6150 : int[] = prim::Constant[value=[-1, 1]]()\n  %6151 : Tensor = aten::view(%6138, %6150)\n  %6152 : int[] = prim::Constant[value=[-1]]()\n  %6153 : Tensor = aten::view(%6147, %6152)\n  %6154 : Tensor?[] = prim::ListConstruct(%6149, %6151, %6153)\n  %6155 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6123, %6154, %input.164, %7463)\n  %7471 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7472 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7473 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7474 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4056 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7471, %7472, %7473, %7474) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7475 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7476 : Long(requires_grad=0, device=cpu) = prim::Constant[value={17}]()\n  %4059 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4056, %7475, %7476) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7477 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4061 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4059, %7477) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7478 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7479 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5570 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5244 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5570, %7478, %4061, %7479) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4086 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4087 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4086) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4088 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7480 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7481 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4091 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.207, %4088, %7480, %7481) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7482 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4093 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4091, %7482) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7483 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4095 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4087, %4093, %7483) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.165 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4095) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4097 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.18 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.165, %4097) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7484 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4100 : None = prim::Constant()\n  %4101 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.18, %7484, %4100) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5571 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4106 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4101, %5571) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4107 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4106, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7485 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4109 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4107, %7485) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4110 : Tensor[] = prim::ListConstruct(%4109, %5244)\n  %7486 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.166 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4110, %7486) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4142 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4143 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.166, %4142) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4144 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4145 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.207, %4144) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.208 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4147 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4148 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4143, %4145, %4035, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7487 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7488 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7489 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7490 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4153 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6155, %7487, %7488, %7489, %7490) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7491 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7492 : Long(requires_grad=0, device=cpu) = prim::Constant[value={17}]()\n  %4156 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4153, %7491, %7492) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7493 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7494 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7495 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7496 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4161 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4156, %7493, %7494, %7495, %7496) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7497 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.167 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.208, %4161) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7498 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6160 : Long(device=cpu) = aten::size(%6155, %7498)\n  %7499 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6162 : None = prim::Constant()\n  %6163 : None = prim::Constant()\n  %6164 : None = prim::Constant()\n  %6165 : Tensor = aten::arange(%6160, %7499, %6162, %6163, %6164)\n  %7500 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6167 : Tensor = aten::slice(%6165, %7500, %7488, %7489, %7490)\n  %7501 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6170 : Tensor = aten::unsqueeze(%7492, %7501)\n  %7502 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6172 : Long(device=cpu) = aten::size(%6155, %7502)\n  %7503 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6174 : None = prim::Constant()\n  %6175 : None = prim::Constant()\n  %6176 : None = prim::Constant()\n  %6177 : Tensor = aten::arange(%6172, %7503, %6174, %6175, %6176)\n  %7504 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6179 : Tensor = aten::slice(%6177, %7504, %7494, %7495, %7496)\n  %6180 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6181 : Tensor = aten::view(%6167, %6180)\n  %6182 : int[] = prim::Constant[value=[-1, 1]]()\n  %6183 : Tensor = aten::view(%6170, %6182)\n  %6184 : int[] = prim::Constant[value=[-1]]()\n  %6185 : Tensor = aten::view(%6179, %6184)\n  %6186 : Tensor?[] = prim::ListConstruct(%6181, %6183, %6185)\n  %6187 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6155, %6186, %input.167, %7497)\n  %7505 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7506 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7507 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7508 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4168 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7505, %7506, %7507, %7508) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7509 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7510 : Long(requires_grad=0, device=cpu) = prim::Constant[value={18}]()\n  %4171 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4168, %7509, %7510) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7511 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4173 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4171, %7511) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7512 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7513 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5575 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5251 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5575, %7512, %4173, %7513) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4198 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4199 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4198) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4200 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7514 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7515 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4203 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.208, %4200, %7514, %7515) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7516 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4205 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4203, %7516) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7517 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4207 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4199, %4205, %7517) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.168 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4207) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4209 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.19 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.168, %4209) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7518 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4212 : None = prim::Constant()\n  %4213 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.19, %7518, %4212) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5576 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4218 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4213, %5576) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4219 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4218, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7519 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4221 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4219, %7519) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4222 : Tensor[] = prim::ListConstruct(%4221, %5251)\n  %7520 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.169 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4222, %7520) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4254 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4255 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.169, %4254) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4256 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4257 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.208, %4256) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.209 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4259 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4260 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4255, %4257, %4147, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7521 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7522 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7523 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7524 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4265 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6187, %7521, %7522, %7523, %7524) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7525 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7526 : Long(requires_grad=0, device=cpu) = prim::Constant[value={18}]()\n  %4268 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4265, %7525, %7526) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7527 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7528 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7529 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7530 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4273 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4268, %7527, %7528, %7529, %7530) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7531 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.170 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.209, %4273) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7532 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6192 : Long(device=cpu) = aten::size(%6187, %7532)\n  %7533 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6194 : None = prim::Constant()\n  %6195 : None = prim::Constant()\n  %6196 : None = prim::Constant()\n  %6197 : Tensor = aten::arange(%6192, %7533, %6194, %6195, %6196)\n  %7534 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6199 : Tensor = aten::slice(%6197, %7534, %7522, %7523, %7524)\n  %7535 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6202 : Tensor = aten::unsqueeze(%7526, %7535)\n  %7536 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6204 : Long(device=cpu) = aten::size(%6187, %7536)\n  %7537 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6206 : None = prim::Constant()\n  %6207 : None = prim::Constant()\n  %6208 : None = prim::Constant()\n  %6209 : Tensor = aten::arange(%6204, %7537, %6206, %6207, %6208)\n  %7538 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6211 : Tensor = aten::slice(%6209, %7538, %7528, %7529, %7530)\n  %6212 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6213 : Tensor = aten::view(%6199, %6212)\n  %6214 : int[] = prim::Constant[value=[-1, 1]]()\n  %6215 : Tensor = aten::view(%6202, %6214)\n  %6216 : int[] = prim::Constant[value=[-1]]()\n  %6217 : Tensor = aten::view(%6211, %6216)\n  %6218 : Tensor?[] = prim::ListConstruct(%6213, %6215, %6217)\n  %6219 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6187, %6218, %input.170, %7531)\n  %7539 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7540 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7541 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7542 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4280 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7539, %7540, %7541, %7542) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7543 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7544 : Long(requires_grad=0, device=cpu) = prim::Constant[value={19}]()\n  %4283 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4280, %7543, %7544) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7545 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4285 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4283, %7545) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7546 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7547 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5580 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5258 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5580, %7546, %4285, %7547) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4310 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4311 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4310) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4312 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7548 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7549 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4315 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.209, %4312, %7548, %7549) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7550 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4317 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4315, %7550) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7551 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4319 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4311, %4317, %7551) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.171 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4319) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4321 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.20 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.171, %4321) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7552 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4324 : None = prim::Constant()\n  %4325 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.20, %7552, %4324) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5581 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4330 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4325, %5581) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4331 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4330, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7553 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4333 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4331, %7553) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4334 : Tensor[] = prim::ListConstruct(%4333, %5258)\n  %7554 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.172 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4334, %7554) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4366 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4367 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.172, %4366) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4368 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4369 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.209, %4368) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.210 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4371 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4372 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4367, %4369, %4259, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7555 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7556 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7557 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7558 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4377 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6219, %7555, %7556, %7557, %7558) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7559 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7560 : Long(requires_grad=0, device=cpu) = prim::Constant[value={19}]()\n  %4380 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4377, %7559, %7560) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7561 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7562 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7563 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7564 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4385 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4380, %7561, %7562, %7563, %7564) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7565 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.173 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.210, %4385) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7566 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6224 : Long(device=cpu) = aten::size(%6219, %7566)\n  %7567 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6226 : None = prim::Constant()\n  %6227 : None = prim::Constant()\n  %6228 : None = prim::Constant()\n  %6229 : Tensor = aten::arange(%6224, %7567, %6226, %6227, %6228)\n  %7568 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6231 : Tensor = aten::slice(%6229, %7568, %7556, %7557, %7558)\n  %7569 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6234 : Tensor = aten::unsqueeze(%7560, %7569)\n  %7570 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6236 : Long(device=cpu) = aten::size(%6219, %7570)\n  %7571 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6238 : None = prim::Constant()\n  %6239 : None = prim::Constant()\n  %6240 : None = prim::Constant()\n  %6241 : Tensor = aten::arange(%6236, %7571, %6238, %6239, %6240)\n  %7572 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6243 : Tensor = aten::slice(%6241, %7572, %7562, %7563, %7564)\n  %6244 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6245 : Tensor = aten::view(%6231, %6244)\n  %6246 : int[] = prim::Constant[value=[-1, 1]]()\n  %6247 : Tensor = aten::view(%6234, %6246)\n  %6248 : int[] = prim::Constant[value=[-1]]()\n  %6249 : Tensor = aten::view(%6243, %6248)\n  %6250 : Tensor?[] = prim::ListConstruct(%6245, %6247, %6249)\n  %6251 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6219, %6250, %input.173, %7565)\n  %7573 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7574 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7575 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7576 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4392 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7573, %7574, %7575, %7576) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7577 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7578 : Long(requires_grad=0, device=cpu) = prim::Constant[value={20}]()\n  %4395 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4392, %7577, %7578) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7579 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4397 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4395, %7579) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7580 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7581 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5585 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5265 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5585, %7580, %4397, %7581) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4422 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4423 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4422) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4424 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7582 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7583 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4427 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.210, %4424, %7582, %7583) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7584 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4429 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4427, %7584) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7585 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4431 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4423, %4429, %7585) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.174 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4431) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4433 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.21 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.174, %4433) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7586 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4436 : None = prim::Constant()\n  %4437 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.21, %7586, %4436) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5586 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4442 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4437, %5586) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4443 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4442, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7587 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4445 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4443, %7587) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4446 : Tensor[] = prim::ListConstruct(%4445, %5265)\n  %7588 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.175 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4446, %7588) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4478 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4479 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.175, %4478) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4480 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4481 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.210, %4480) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.211 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4483 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4484 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4479, %4481, %4371, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7589 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7590 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7591 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7592 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4489 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6251, %7589, %7590, %7591, %7592) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7593 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7594 : Long(requires_grad=0, device=cpu) = prim::Constant[value={20}]()\n  %4492 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4489, %7593, %7594) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7595 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7596 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7597 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7598 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4497 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4492, %7595, %7596, %7597, %7598) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7599 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.176 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.211, %4497) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7600 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6256 : Long(device=cpu) = aten::size(%6251, %7600)\n  %7601 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6258 : None = prim::Constant()\n  %6259 : None = prim::Constant()\n  %6260 : None = prim::Constant()\n  %6261 : Tensor = aten::arange(%6256, %7601, %6258, %6259, %6260)\n  %7602 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6263 : Tensor = aten::slice(%6261, %7602, %7590, %7591, %7592)\n  %7603 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6266 : Tensor = aten::unsqueeze(%7594, %7603)\n  %7604 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6268 : Long(device=cpu) = aten::size(%6251, %7604)\n  %7605 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6270 : None = prim::Constant()\n  %6271 : None = prim::Constant()\n  %6272 : None = prim::Constant()\n  %6273 : Tensor = aten::arange(%6268, %7605, %6270, %6271, %6272)\n  %7606 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6275 : Tensor = aten::slice(%6273, %7606, %7596, %7597, %7598)\n  %6276 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6277 : Tensor = aten::view(%6263, %6276)\n  %6278 : int[] = prim::Constant[value=[-1, 1]]()\n  %6279 : Tensor = aten::view(%6266, %6278)\n  %6280 : int[] = prim::Constant[value=[-1]]()\n  %6281 : Tensor = aten::view(%6275, %6280)\n  %6282 : Tensor?[] = prim::ListConstruct(%6277, %6279, %6281)\n  %6283 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6251, %6282, %input.176, %7599)\n  %7607 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7608 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7609 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7610 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4504 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7607, %7608, %7609, %7610) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7611 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7612 : Long(requires_grad=0, device=cpu) = prim::Constant[value={21}]()\n  %4507 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4504, %7611, %7612) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7613 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4509 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4507, %7613) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7614 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7615 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5590 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5272 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5590, %7614, %4509, %7615) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4534 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4535 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4534) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4536 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7616 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7617 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4539 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.211, %4536, %7616, %7617) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7618 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4541 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4539, %7618) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7619 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4543 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4535, %4541, %7619) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.177 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4543) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4545 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.22 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.177, %4545) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7620 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4548 : None = prim::Constant()\n  %4549 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.22, %7620, %4548) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5591 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4554 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4549, %5591) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4555 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4554, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7621 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4557 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4555, %7621) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4558 : Tensor[] = prim::ListConstruct(%4557, %5272)\n  %7622 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.178 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4558, %7622) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4590 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4591 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.178, %4590) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4592 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4593 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.211, %4592) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.212 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4595 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4596 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4591, %4593, %4483, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7623 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7624 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7625 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7626 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4601 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6283, %7623, %7624, %7625, %7626) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7627 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7628 : Long(requires_grad=0, device=cpu) = prim::Constant[value={21}]()\n  %4604 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4601, %7627, %7628) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7629 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7630 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7631 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7632 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4609 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4604, %7629, %7630, %7631, %7632) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7633 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.179 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.212, %4609) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7634 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6288 : Long(device=cpu) = aten::size(%6283, %7634)\n  %7635 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6290 : None = prim::Constant()\n  %6291 : None = prim::Constant()\n  %6292 : None = prim::Constant()\n  %6293 : Tensor = aten::arange(%6288, %7635, %6290, %6291, %6292)\n  %7636 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6295 : Tensor = aten::slice(%6293, %7636, %7624, %7625, %7626)\n  %7637 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6298 : Tensor = aten::unsqueeze(%7628, %7637)\n  %7638 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6300 : Long(device=cpu) = aten::size(%6283, %7638)\n  %7639 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6302 : None = prim::Constant()\n  %6303 : None = prim::Constant()\n  %6304 : None = prim::Constant()\n  %6305 : Tensor = aten::arange(%6300, %7639, %6302, %6303, %6304)\n  %7640 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6307 : Tensor = aten::slice(%6305, %7640, %7630, %7631, %7632)\n  %6308 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6309 : Tensor = aten::view(%6295, %6308)\n  %6310 : int[] = prim::Constant[value=[-1, 1]]()\n  %6311 : Tensor = aten::view(%6298, %6310)\n  %6312 : int[] = prim::Constant[value=[-1]]()\n  %6313 : Tensor = aten::view(%6307, %6312)\n  %6314 : Tensor?[] = prim::ListConstruct(%6309, %6311, %6313)\n  %6315 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6283, %6314, %input.179, %7633)\n  %7641 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7642 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7643 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7644 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4616 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7641, %7642, %7643, %7644) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7645 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7646 : Long(requires_grad=0, device=cpu) = prim::Constant[value={22}]()\n  %4619 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4616, %7645, %7646) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7647 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4621 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4619, %7647) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7648 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7649 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5595 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5279 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5595, %7648, %4621, %7649) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4646 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4647 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4646) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4648 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7650 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7651 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4651 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.212, %4648, %7650, %7651) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7652 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4653 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4651, %7652) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7653 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4655 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4647, %4653, %7653) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.180 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4655) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4657 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.23 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.180, %4657) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7654 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4660 : None = prim::Constant()\n  %4661 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.23, %7654, %4660) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5596 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4666 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4661, %5596) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4667 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4666, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7655 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4669 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4667, %7655) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4670 : Tensor[] = prim::ListConstruct(%4669, %5279)\n  %7656 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.181 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4670, %7656) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4702 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4703 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.181, %4702) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4704 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4705 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.212, %4704) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.213 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4707 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4708 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4703, %4705, %4595, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7657 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7658 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7659 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7660 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4713 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6315, %7657, %7658, %7659, %7660) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7661 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7662 : Long(requires_grad=0, device=cpu) = prim::Constant[value={22}]()\n  %4716 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4713, %7661, %7662) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7663 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7664 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7665 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7666 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4721 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4716, %7663, %7664, %7665, %7666) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7667 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.182 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.213, %4721) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7668 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6320 : Long(device=cpu) = aten::size(%6315, %7668)\n  %7669 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6322 : None = prim::Constant()\n  %6323 : None = prim::Constant()\n  %6324 : None = prim::Constant()\n  %6325 : Tensor = aten::arange(%6320, %7669, %6322, %6323, %6324)\n  %7670 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6327 : Tensor = aten::slice(%6325, %7670, %7658, %7659, %7660)\n  %7671 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6330 : Tensor = aten::unsqueeze(%7662, %7671)\n  %7672 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6332 : Long(device=cpu) = aten::size(%6315, %7672)\n  %7673 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6334 : None = prim::Constant()\n  %6335 : None = prim::Constant()\n  %6336 : None = prim::Constant()\n  %6337 : Tensor = aten::arange(%6332, %7673, %6334, %6335, %6336)\n  %7674 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6339 : Tensor = aten::slice(%6337, %7674, %7664, %7665, %7666)\n  %6340 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6341 : Tensor = aten::view(%6327, %6340)\n  %6342 : int[] = prim::Constant[value=[-1, 1]]()\n  %6343 : Tensor = aten::view(%6330, %6342)\n  %6344 : int[] = prim::Constant[value=[-1]]()\n  %6345 : Tensor = aten::view(%6339, %6344)\n  %6346 : Tensor?[] = prim::ListConstruct(%6341, %6343, %6345)\n  %6347 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6315, %6346, %input.182, %7667)\n  %7675 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7676 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7677 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7678 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4728 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7675, %7676, %7677, %7678) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7679 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7680 : Long(requires_grad=0, device=cpu) = prim::Constant[value={23}]()\n  %4731 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4728, %7679, %7680) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7681 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4733 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4731, %7681) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7682 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7683 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5600 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5286 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5600, %7682, %4733, %7683) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4758 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4759 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4758) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4760 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7684 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7685 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4763 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.213, %4760, %7684, %7685) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7686 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4765 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4763, %7686) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7687 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4767 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4759, %4765, %7687) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.183 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4767) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4769 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.24 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.183, %4769) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7688 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4772 : None = prim::Constant()\n  %4773 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.24, %7688, %4772) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5601 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4778 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4773, %5601) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4779 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4778, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7689 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4781 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4779, %7689) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4782 : Tensor[] = prim::ListConstruct(%4781, %5286)\n  %7690 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.184 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4782, %7690) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4814 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4815 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.184, %4814) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4816 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4817 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.213, %4816) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.214 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4819 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4820 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4815, %4817, %4707, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7691 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7692 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7693 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7694 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4825 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6347, %7691, %7692, %7693, %7694) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7695 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7696 : Long(requires_grad=0, device=cpu) = prim::Constant[value={23}]()\n  %4828 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4825, %7695, %7696) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7697 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7698 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7699 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7700 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4833 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4828, %7697, %7698, %7699, %7700) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7701 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.185 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.214, %4833) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7702 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6352 : Long(device=cpu) = aten::size(%6347, %7702)\n  %7703 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6354 : None = prim::Constant()\n  %6355 : None = prim::Constant()\n  %6356 : None = prim::Constant()\n  %6357 : Tensor = aten::arange(%6352, %7703, %6354, %6355, %6356)\n  %7704 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6359 : Tensor = aten::slice(%6357, %7704, %7692, %7693, %7694)\n  %7705 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6362 : Tensor = aten::unsqueeze(%7696, %7705)\n  %7706 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6364 : Long(device=cpu) = aten::size(%6347, %7706)\n  %7707 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6366 : None = prim::Constant()\n  %6367 : None = prim::Constant()\n  %6368 : None = prim::Constant()\n  %6369 : Tensor = aten::arange(%6364, %7707, %6366, %6367, %6368)\n  %7708 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6371 : Tensor = aten::slice(%6369, %7708, %7698, %7699, %7700)\n  %6372 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6373 : Tensor = aten::view(%6359, %6372)\n  %6374 : int[] = prim::Constant[value=[-1, 1]]()\n  %6375 : Tensor = aten::view(%6362, %6374)\n  %6376 : int[] = prim::Constant[value=[-1]]()\n  %6377 : Tensor = aten::view(%6371, %6376)\n  %6378 : Tensor?[] = prim::ListConstruct(%6373, %6375, %6377)\n  %6379 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6347, %6378, %input.185, %7701)\n  %7709 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7710 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7711 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7712 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4840 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7709, %7710, %7711, %7712) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7713 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7714 : Long(requires_grad=0, device=cpu) = prim::Constant[value={24}]()\n  %4843 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4840, %7713, %7714) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7715 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4845 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4843, %7715) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7716 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7717 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5605 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5293 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5605, %7716, %4845, %7717) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4870 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4871 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4870) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4872 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7718 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7719 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4875 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.214, %4872, %7718, %7719) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7720 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4877 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4875, %7720) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7721 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4879 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4871, %4877, %7721) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.186 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4879) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4881 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e.25 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.186, %4881) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7722 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4884 : None = prim::Constant()\n  %4885 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e.25, %7722, %4884) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5606 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %4890 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4885, %5606) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4891 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%4890, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7723 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4893 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%4891, %7723) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %4894 : Tensor[] = prim::ListConstruct(%4893, %5293)\n  %7724 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.187 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%4894, %7724) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %4926 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4927 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.187, %4926) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4928 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %4929 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.214, %4928) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %input.215 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4931 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %4932 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%4927, %4929, %4819, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7725 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7726 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7727 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7728 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4937 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6379, %7725, %7726, %7727, %7728) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7729 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7730 : Long(requires_grad=0, device=cpu) = prim::Constant[value={24}]()\n  %4940 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%4937, %7729, %7730) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7731 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7732 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7733 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7734 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4945 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%4940, %7731, %7732, %7733, %7734) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7735 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %input.188 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%input.215, %4945) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7736 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6384 : Long(device=cpu) = aten::size(%6379, %7736)\n  %7737 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6386 : None = prim::Constant()\n  %6387 : None = prim::Constant()\n  %6388 : None = prim::Constant()\n  %6389 : Tensor = aten::arange(%6384, %7737, %6386, %6387, %6388)\n  %7738 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6391 : Tensor = aten::slice(%6389, %7738, %7726, %7727, %7728)\n  %7739 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6394 : Tensor = aten::unsqueeze(%7730, %7739)\n  %7740 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6396 : Long(device=cpu) = aten::size(%6379, %7740)\n  %7741 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6398 : None = prim::Constant()\n  %6399 : None = prim::Constant()\n  %6400 : None = prim::Constant()\n  %6401 : Tensor = aten::arange(%6396, %7741, %6398, %6399, %6400)\n  %7742 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6403 : Tensor = aten::slice(%6401, %7742, %7732, %7733, %7734)\n  %6404 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6405 : Tensor = aten::view(%6391, %6404)\n  %6406 : int[] = prim::Constant[value=[-1, 1]]()\n  %6407 : Tensor = aten::view(%6394, %6406)\n  %6408 : int[] = prim::Constant[value=[-1]]()\n  %6409 : Tensor = aten::view(%6403, %6408)\n  %6410 : Tensor?[] = prim::ListConstruct(%6405, %6407, %6409)\n  %6411 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6379, %6410, %input.188, %7735)\n  %7743 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7744 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7745 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7746 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4952 : Long(128, 27, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::slice(%1, %7743, %7744, %7745, %7746) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7747 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7748 : Long(requires_grad=0, device=cpu) = prim::Constant[value={25}]()\n  %4955 : Long(128, strides=[27], requires_grad=0, device=cuda:0) = aten::select(%4952, %7747, %7748) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:40:0\n  %7749 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4957 : Long(128, 1, strides=[27, 1], requires_grad=0, device=cuda:0) = aten::unsqueeze(%4955, %7749) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:17:0\n  %7750 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7751 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5610 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = prim::Constant[value=<Tensor>]()\n  %5300 : Float(128, 38, strides=[38, 1], requires_grad=0, device=cuda:0) = aten::scatter(%5610, %7750, %4957, %7751) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:20:0\n  %4982 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.i2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4983 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.112, %4982) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %4984 : Float(256, 256, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.h2h.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7752 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7753 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4987 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::addmm(%Prediction.attention_cell.h2h.bias, %input.215, %4984, %7752, %7753) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7754 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4989 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::unsqueeze(%4987, %7754) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:74:0\n  %7755 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4991 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::add(%4983, %4989, %7755) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %input.189 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::tanh(%4991) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:75:0\n  %4993 : Float(256, 1, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.score.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %e : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.189, %4993) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7756 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %4996 : None = prim::Constant()\n  %4997 : Float(128, 26, 1, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::softmax(%e, %7756, %4996) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1583:0\n  %5611 : int[] = prim::Constant[value=[0, 2, 1]]()\n  %5002 : Float(128, 1, 26, strides=[26, 1, 1], requires_grad=1, device=cuda:0) = aten::permute(%4997, %5611) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %5003 : Float(128, 1, 256, strides=[256, 256, 1], requires_grad=1, device=cuda:0) = aten::bmm(%5002, %input.112) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %7757 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5005 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::squeeze(%5003, %7757) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:78:0\n  %5006 : Tensor[] = prim::ListConstruct(%5005, %5300)\n  %7758 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %input.190 : Float(128, 294, strides=[294, 1], requires_grad=1, device=cuda:0) = aten::cat(%5006, %7758) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:79:0\n  %5038 : Float(294, 1024, strides=[1, 294], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_ih) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %5039 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.190, %5038) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %5040 : Float(256, 1024, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.attention_cell.rnn.weight_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %5041 : Float(128, 1024, strides=[1024, 1], requires_grad=1, device=cuda:0) = aten::matmul(%input.215, %5040) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %5042 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %5043 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0), %5044 : Float(128, 1024, strides=[1024, 1], requires_grad=0, device=cuda:0) = aten::_thnn_fused_lstm_cell(%5039, %5041, %4931, %Prediction.attention_cell.rnn.bias_ih, %Prediction.attention_cell.rnn.bias_hh) # /usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:1057:0\n  %7759 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7760 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7761 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7762 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5049 : Float(128, 26, 256, strides=[6656, 256, 1], requires_grad=1, device=cuda:0) = aten::slice(%6411, %7759, %7760, %7761, %7762) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7763 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7764 : Long(requires_grad=0, device=cpu) = prim::Constant[value={25}]()\n  %5052 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::select(%5049, %7763, %7764) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7765 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %7766 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %7767 : Long(requires_grad=0, device=cpu) = prim::Constant[value={9223372036854775807}]()\n  %7768 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5057 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::slice(%5052, %7765, %7766, %7767, %7768) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7769 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6413 : Float(128, 256, strides=[256, 1], requires_grad=1, device=cuda:0) = aten::expand_as(%5042, %5057) # /data/work_dir/img/text_recognition/deep-text-recognition-benchmark/modules/prediction.py:43:0\n  %7770 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6416 : Long(device=cpu) = aten::size(%6411, %7770)\n  %7771 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6418 : None = prim::Constant()\n  %6419 : None = prim::Constant()\n  %6420 : None = prim::Constant()\n  %6421 : Tensor = aten::arange(%6416, %7771, %6418, %6419, %6420)\n  %7772 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6423 : Tensor = aten::slice(%6421, %7772, %7760, %7761, %7762)\n  %7773 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6426 : Tensor = aten::unsqueeze(%7764, %7773)\n  %7774 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]()\n  %6428 : Long(device=cpu) = aten::size(%6411, %7774)\n  %7775 : Long(requires_grad=0, device=cpu) = prim::Constant[value={4}]()\n  %6430 : None = prim::Constant()\n  %6431 : None = prim::Constant()\n  %6432 : None = prim::Constant()\n  %6433 : Tensor = aten::arange(%6428, %7775, %6430, %6431, %6432)\n  %7776 : Long(requires_grad=0, device=cpu) = prim::Constant[value={0}]()\n  %6435 : Tensor = aten::slice(%6433, %7776, %7766, %7767, %7768)\n  %6436 : int[] = prim::Constant[value=[-1, 1, 1]]()\n  %6437 : Tensor = aten::view(%6423, %6436)\n  %6438 : int[] = prim::Constant[value=[-1, 1]]()\n  %6439 : Tensor = aten::view(%6426, %6438)\n  %6440 : int[] = prim::Constant[value=[-1]]()\n  %6441 : Tensor = aten::view(%6435, %6440)\n  %6442 : Tensor?[] = prim::ListConstruct(%6437, %6439, %6441)\n  %6443 : Float(128, 256, strides=[6656, 1], requires_grad=1, device=cuda:0) = aten::index_put(%6411, %6442, %6413, %7769)\n  %5060 : Float(256, 38, strides=[1, 256], requires_grad=1, device=cuda:0) = aten::t(%Prediction.generator.weight) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %5061 : Float(128, 26, 38, strides=[988, 38, 1], requires_grad=1, device=cuda:0) = aten::matmul(%6443, %5060) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  %7777 : Long(requires_grad=0, device=cpu) = prim::Constant[value={1}]()\n  %5077 : Tensor = aten::type_as(%Prediction.generator.bias, %5061)\n  %5063 : Float(128, 26, 38, strides=[988, 38, 1], requires_grad=1, device=cuda:0) = aten::add_(%5061, %5077, %7777) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n  return (%5063)\n, {}, 'input_names'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "import easydict\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "from utils import CTCLabelConverter, CTCLabelConverterForBaiduWarpctc, AttnLabelConverter, Averager\n",
    "from dataset import hierarchical_dataset, AlignCollate, Batch_Balanced_Dataset\n",
    "from model import Model\n",
    "from test import validation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import easydict\n",
    "global opt\n",
    "\n",
    "\n",
    "\n",
    "opt = easydict.EasyDict({\n",
    "    \"exp_name\": \"test_01\",\n",
    "    \"train_data\": \"/data/data/STARN/data_lmdb_release/training\",\n",
    "    \"valid_data\":\"/data/data/STARN/data_lmdb_release/validation\",\n",
    "    \"manualSeed\": 1111,\n",
    "    \"workers\": 4,\n",
    "    \"batch_size\":32,\n",
    "    \"num_iter\":300000,\n",
    "    \"valInterval\":1,\n",
    "    \"saved_model\":'',\n",
    "    \"FT\":False,\n",
    "    \"adam\":False,\n",
    "    \"lr\":1,\n",
    "    \"beta1\":0.9,\n",
    "    \"rho\":0.95,\n",
    "    \"eps\":1e-8,\n",
    "    \"grad_clip\":5,\n",
    "    \"baiduCTC\":False,\n",
    "    \"select_data\":'ST',\n",
    "    \"batch_ratio\":'1',\n",
    "    \"total_data_usage_ratio\":'0.01',\n",
    "    \"batch_max_length\":25,\n",
    "    \"imgW\":100,\n",
    "    \"imgH\":32,\n",
    "    \"rgb\":False,\n",
    "    \"character\":\"0123456789abcdefghijklmnopqrstuvwxyz\",\n",
    "    \"sensitive\":False,\n",
    "    \"PAD\":False,\n",
    "    \"data_filtering_off\":False,\n",
    "    \"Transformation\":\"TPS\",\n",
    "    \"FeatureExtraction\":\"ResNet\",\n",
    "    \"SequenceModeling\":\"BiLSTM\",\n",
    "    \"Prediction\":'Attn',\n",
    "    \"num_fiducial\":20,\n",
    "    \"input_channel\":1,\n",
    "    \"output_channel\":512,\n",
    "    \"hidden_size\":256    \n",
    "})\n",
    "\n",
    "\n",
    "def train(opt):\n",
    "    \"\"\" dataset preparation \"\"\"\n",
    "    if not opt.data_filtering_off:\n",
    "        print('Filtering the images containing characters which are not in opt.character')\n",
    "        print('Filtering the images whose label is longer than opt.batch_max_length')\n",
    "        # see https://github.com/clovaai/deep-text-recognition-benchmark/blob/6593928855fb7abb999a99f428b3e4477d4ae356/dataset.py#L130\n",
    "\n",
    "    opt.select_data = opt.select_data.split('-')\n",
    "    opt.batch_ratio = opt.batch_ratio.split('-')\n",
    "    print(\"찍어보기\")\n",
    "    print(opt,type(opt))\n",
    "    print(\"찍어보기 끝\")\n",
    "\n",
    "    train_dataset = Batch_Balanced_Dataset(opt)\n",
    "\n",
    "    log = open(f'./saved_models/{opt.exp_name}/log_dataset.txt', 'a')\n",
    "    AlignCollate_valid = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)\n",
    "    valid_dataset, valid_dataset_log = hierarchical_dataset(root=opt.valid_data, opt=opt)\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=opt.batch_size,\n",
    "        shuffle=True,  # 'True' to check training progress with validation function.\n",
    "        num_workers=int(opt.workers),\n",
    "        collate_fn=AlignCollate_valid, pin_memory=True)\n",
    "    log.write(valid_dataset_log)\n",
    "    print('-' * 80)\n",
    "    log.write('-' * 80 + '\\n')\n",
    "    log.close()\n",
    "    \n",
    "    \"\"\" model configuration \"\"\"\n",
    "    if 'CTC' in opt.Prediction:\n",
    "        if opt.baiduCTC:\n",
    "            converter = CTCLabelConverterForBaiduWarpctc(opt.character)\n",
    "        else:\n",
    "            converter = CTCLabelConverter(opt.character)\n",
    "    else:\n",
    "        converter = AttnLabelConverter(opt.character)\n",
    "    opt.num_class = len(converter.character)\n",
    "\n",
    "    if opt.rgb:\n",
    "        opt.input_channel = 3\n",
    "    model = Model(opt)\n",
    "    print('model input parameters', opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel,\n",
    "          opt.hidden_size, opt.num_class, opt.batch_max_length, opt.Transformation, opt.FeatureExtraction,\n",
    "          opt.SequenceModeling, opt.Prediction)\n",
    "\n",
    "    # weight initialization\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'localization_fc2' in name:\n",
    "            print(f'Skip {name} as it is already initialized')\n",
    "            continue\n",
    "        try:\n",
    "            if 'bias' in name:\n",
    "                init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                init.kaiming_normal_(param)\n",
    "        except Exception as e:  # for batchnorm.\n",
    "            if 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            continue\n",
    "\n",
    "    # data parallel for multi-GPU\n",
    "    model.train()\n",
    "    if opt.saved_model != '':\n",
    "        print(f'loading pretrained model from {opt.saved_model}')\n",
    "        if opt.FT:\n",
    "            model.load_state_dict(torch.load(opt.saved_model), strict=False)\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(opt.saved_model))\n",
    "    print(\"Model:\")\n",
    "    print(model)\n",
    "\n",
    "    \"\"\" setup loss \"\"\"\n",
    "    if 'CTC' in opt.Prediction:\n",
    "        if opt.baiduCTC:\n",
    "            # need to install warpctc. see our guideline.\n",
    "            from warpctc_pytorch import CTCLoss \n",
    "            criterion = CTCLoss()\n",
    "        else:\n",
    "            criterion = torch.nn.CTCLoss(zero_infinity=True).to(device)\n",
    "    else:\n",
    "        criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)  # ignore [GO] token = ignore index 0\n",
    "    # loss averager\n",
    "    loss_avg = Averager()\n",
    "\n",
    "    # filter that only require gradient decent\n",
    "    filtered_parameters = []\n",
    "    params_num = []\n",
    "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "        filtered_parameters.append(p)\n",
    "        params_num.append(np.prod(p.size()))\n",
    "    print('Trainable params num : ', sum(params_num))\n",
    "    # [print(name, p.numel()) for name, p in filter(lambda p: p[1].requires_grad, model.named_parameters())]\n",
    "\n",
    "    # setup optimizer\n",
    "    if opt.adam:\n",
    "        optimizer = optim.Adam(filtered_parameters, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "    else:\n",
    "        optimizer = optim.Adadelta(filtered_parameters, lr=opt.lr, rho=opt.rho, eps=opt.eps)\n",
    "    print(\"Optimizer:\")\n",
    "    print(optimizer)\n",
    "\n",
    "    \"\"\" final options \"\"\"\n",
    "    # print(opt)\n",
    "    with open(f'./saved_models/{opt.exp_name}/opt.txt', 'a') as opt_file:\n",
    "        opt_log = '------------ Options -------------\\n'\n",
    "        args = vars(opt)\n",
    "        for k, v in args.items():\n",
    "            opt_log += f'{str(k)}: {str(v)}\\n'\n",
    "        opt_log += '---------------------------------------\\n'\n",
    "        print(opt_log)\n",
    "        opt_file.write(opt_log)\n",
    "\n",
    "    \"\"\" start training \"\"\"\n",
    "    start_iter = 0\n",
    "    if opt.saved_model != '':\n",
    "        try:\n",
    "            start_iter = int(opt.saved_model.split('_')[-1].split('.')[0])\n",
    "            print(f'continue to train, start_iter: {start_iter}')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    model = model.to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    best_accuracy = -1\n",
    "    best_norm_ED = -1\n",
    "    iteration = start_iter\n",
    "\n",
    "    while(True):\n",
    "        # train part\n",
    "        image_tensors, labels = train_dataset.get_batch()\n",
    "        image = image_tensors.to(device)\n",
    "        text, length = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
    "        batch_size = image.size(0)\n",
    "\n",
    "        if 'CTC' in opt.Prediction:\n",
    "            preds = model(image, text)\n",
    "            preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
    "            if opt.baiduCTC:\n",
    "                preds = preds.permute(1, 0, 2)  # to use CTCLoss format\n",
    "                cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "            else:\n",
    "                preds = preds.log_softmax(2).permute(1, 0, 2)\n",
    "                cost = criterion(preds, text, preds_size, length)\n",
    "\n",
    "        else:\n",
    "            preds = model(image, text[:, :-1])  # align with Attention.forward\n",
    "            ## 한번 찍어보기\n",
    "            torch.onnx.export(model,(image, text), './ttt.onnx', input_names=\"input_names\", output_names=\"output_names\")\n",
    "            print(\"저장끝\")\n",
    "            target = text[:, 1:]  # without [GO] Symbol\n",
    "            cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "\n",
    "        model.zero_grad()\n",
    "        cost.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip)  # gradient clipping with 5 (Default)\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_avg.add(cost)\n",
    "\n",
    "        # validation part\n",
    "        if (iteration + 1) % opt.valInterval == 0 or iteration == 0: # To see training progress, we also conduct validation when 'iteration == 0' \n",
    "            elapsed_time = time.time() - start_time\n",
    "            # for log\n",
    "            with open(f'./saved_models/{opt.exp_name}/log_train.txt', 'a') as log:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    valid_loss, current_accuracy, current_norm_ED, preds, confidence_score, labels, infer_time, length_of_data = validation(\n",
    "                        model, criterion, valid_loader, converter, opt)\n",
    "                model.train()\n",
    "\n",
    "                # training loss and validation loss\n",
    "                loss_log = f'[{iteration+1}/{opt.num_iter}] Train loss: {loss_avg.val():0.5f}, Valid loss: {valid_loss:0.5f}, Elapsed_time: {elapsed_time:0.5f}'\n",
    "                loss_avg.reset()\n",
    "\n",
    "                current_model_log = f'{\"Current_accuracy\":17s}: {current_accuracy:0.3f}, {\"Current_norm_ED\":17s}: {current_norm_ED:0.2f}'\n",
    "\n",
    "                # keep best accuracy model (on valid dataset)\n",
    "                if current_accuracy > best_accuracy:\n",
    "                    best_accuracy = current_accuracy\n",
    "                    torch.save(model.state_dict(), f'./saved_models/{opt.exp_name}/best_accuracy.pth')\n",
    "                if current_norm_ED > best_norm_ED:\n",
    "                    best_norm_ED = current_norm_ED\n",
    "                    torch.save(model.state_dict(), f'./saved_models/{opt.exp_name}/best_norm_ED.pth')\n",
    "                best_model_log = f'{\"Best_accuracy\":17s}: {best_accuracy:0.3f}, {\"Best_norm_ED\":17s}: {best_norm_ED:0.2f}'\n",
    "\n",
    "                loss_model_log = f'{loss_log}\\n{current_model_log}\\n{best_model_log}'\n",
    "                print(loss_model_log)\n",
    "                log.write(loss_model_log + '\\n')\n",
    "\n",
    "                # show some predicted results\n",
    "                dashed_line = '-' * 80\n",
    "                head = f'{\"Ground Truth\":25s} | {\"Prediction\":25s} | Confidence Score & T/F'\n",
    "                predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
    "                for gt, pred, confidence in zip(labels[:5], preds[:5], confidence_score[:5]):\n",
    "                    if 'Attn' in opt.Prediction:\n",
    "                        gt = gt[:gt.find('[s]')]\n",
    "                        pred = pred[:pred.find('[s]')]\n",
    "\n",
    "                    predicted_result_log += f'{gt:25s} | {pred:25s} | {confidence:0.4f}\\t{str(pred == gt)}\\n'\n",
    "                predicted_result_log += f'{dashed_line}'\n",
    "                print(predicted_result_log)\n",
    "                log.write(predicted_result_log + '\\n')\n",
    "\n",
    "        # save model per 1e+5 iter.\n",
    "        if (iteration + 1) % 1e+5 == 0:\n",
    "            torch.save(\n",
    "                model.state_dict(), f'./saved_models/{opt.exp_name}/iter_{iteration+1}.pth')\n",
    "\n",
    "        if (iteration + 1) == opt.num_iter:\n",
    "            print('end the training')\n",
    "            sys.exit()\n",
    "        iteration += 1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    if not opt.exp_name:\n",
    "        opt.exp_name = f'{opt.Transformation}-{opt.FeatureExtraction}-{opt.SequenceModeling}-{opt.Prediction}'\n",
    "        opt.exp_name += f'-Seed{opt.manualSeed}'\n",
    "        # print(opt.exp_name)\n",
    "\n",
    "    os.makedirs(f'./saved_models/{opt.exp_name}', exist_ok=True)\n",
    "\n",
    "    \"\"\" vocab / character number configuration \"\"\"\n",
    "    if opt.sensitive:\n",
    "        # opt.character += 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "        opt.character = string.printable[:-6]  # same with ASTER setting (use 94 char).\n",
    "\n",
    "    \"\"\" Seed and GPU setting \"\"\"\n",
    "    # print(\"Random Seed: \", opt.manualSeed)\n",
    "    random.seed(opt.manualSeed)\n",
    "    np.random.seed(opt.manualSeed)\n",
    "    torch.manual_seed(opt.manualSeed)\n",
    "    torch.cuda.manual_seed(opt.manualSeed)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True\n",
    "    opt.num_gpu = torch.cuda.device_count()\n",
    "    # print('device count', opt.num_gpu)\n",
    "    if opt.num_gpu > 1:\n",
    "        print('------ Use multi-GPU setting ------')\n",
    "        print('if you stuck too long time with multi-GPU setting, try to set --workers 0')\n",
    "        # check multi-GPU issue https://github.com/clovaai/deep-text-recognition-benchmark/issues/1\n",
    "        opt.workers = opt.workers * opt.num_gpu\n",
    "        opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "\n",
    "        \"\"\" previous version\n",
    "        print('To equlize batch stats to 1-GPU setting, the batch_size is multiplied with num_gpu and multiplied batch_size is ', opt.batch_size)\n",
    "        opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "        print('To equalize the number of epochs to 1-GPU setting, num_iter is divided with num_gpu by default.')\n",
    "        If you dont care about it, just commnet out these line.)\n",
    "        opt.num_iter = int(opt.num_iter / opt.num_gpu)\n",
    "        \"\"\"\n",
    "\n",
    "    train(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfc8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchsummary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
