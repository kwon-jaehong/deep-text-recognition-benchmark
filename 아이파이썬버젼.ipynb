{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e4c5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use multi-GPU setting ------\n",
      "if you stuck too long time with multi-GPU setting, try to set --workers 0\n",
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "찍어보기\n",
      "{'exp_name': 'test_01', 'train_data': '/data/data/STARN/data_lmdb_release/training', 'valid_data': '/data/data/STARN/data_lmdb_release/validation', 'manualSeed': 1111, 'workers': 64, 'batch_size': 3072, 'num_iter': 300000, 'valInterval': 1, 'saved_model': '', 'FT': False, 'adam': False, 'lr': 1, 'beta1': 0.9, 'rho': 0.95, 'eps': 1e-08, 'grad_clip': 5, 'baiduCTC': False, 'select_data': ['ST'], 'batch_ratio': ['1'], 'total_data_usage_ratio': '0.01', 'batch_max_length': 25, 'imgW': 100, 'imgH': 32, 'rgb': False, 'character': '0123456789abcdefghijklmnopqrstuvwxyz', 'sensitive': False, 'PAD': False, 'data_filtering_off': False, 'Transformation': 'TPS', 'FeatureExtraction': 'ResNet', 'SequenceModeling': 'BiLSTM', 'Prediction': 'Attn', 'num_fiducial': 20, 'input_channel': 1, 'output_channel': 512, 'hidden_size': 256, 'num_gpu': 4} <class 'easydict.EasyDict'>\n",
      "찍어보기 끝\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: /data/data/STARN/data_lmdb_release/training\n",
      "opt.select_data: ['ST']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /data/data/STARN/data_lmdb_release/training\t dataset: ST\n",
      "sub-directory:\t/ST\t num samples: 5522807\n",
      "sub-directory:\t/MJ/MJ_valid\t num samples: 802731\n",
      "sub-directory:\t/MJ/MJ_test\t num samples: 891924\n",
      "sub-directory:\t/MJ/MJ_train\t num samples: 7224586\n",
      "num total samples of ST: 14442048 x 0.01 (total_data_usage_ratio) = 144420\n",
      "num samples of ST per batch: 3072 x 1.0 (batch_ratio) = 3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 3072 = 3072\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    /data/data/STARN/data_lmdb_release/validation\t dataset: /\n",
      "sub-directory:\t/.\t num samples: 6992\n",
      "--------------------------------------------------------------------------------\n",
      "model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n",
      "Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (Transformation): TPS_SpatialTransformerNetwork(\n",
      "      (LocalizationNetwork): LocalizationNetwork(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (6): ReLU(inplace=True)\n",
      "          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (10): ReLU(inplace=True)\n",
      "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (14): ReLU(inplace=True)\n",
      "          (15): AdaptiveAvgPool2d(output_size=1)\n",
      "        )\n",
      "        (localization_fc1): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "        )\n",
      "        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n",
      "      )\n",
      "      (GridGenerator): GridGenerator()\n",
      "    )\n",
      "    (FeatureExtraction): ResNet_FeatureExtractor(\n",
      "      (ConvNet): ResNet(\n",
      "        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (layer2): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
      "        (layer3): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (layer4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n",
      "        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      "        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): Attention(\n",
      "      (attention_cell): AttentionCell(\n",
      "        (i2h): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (h2h): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (score): Linear(in_features=256, out_features=1, bias=False)\n",
      "        (rnn): LSTMCell(294, 256)\n",
      "      )\n",
      "      (generator): Linear(in_features=256, out_features=38, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Trainable params num :  49555182\n",
      "Optimizer:\n",
      "Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-08\n",
      "    lr: 1\n",
      "    rho: 0.95\n",
      "    weight_decay: 0\n",
      ")\n",
      "------------ Options -------------\n",
      "exp_name: test_01\n",
      "train_data: /data/data/STARN/data_lmdb_release/training\n",
      "valid_data: /data/data/STARN/data_lmdb_release/validation\n",
      "manualSeed: 1111\n",
      "workers: 64\n",
      "batch_size: 3072\n",
      "num_iter: 300000\n",
      "valInterval: 1\n",
      "saved_model: \n",
      "FT: False\n",
      "adam: False\n",
      "lr: 1\n",
      "beta1: 0.9\n",
      "rho: 0.95\n",
      "eps: 1e-08\n",
      "grad_clip: 5\n",
      "baiduCTC: False\n",
      "select_data: ['ST']\n",
      "batch_ratio: ['1']\n",
      "total_data_usage_ratio: 0.01\n",
      "batch_max_length: 25\n",
      "imgW: 100\n",
      "imgH: 32\n",
      "rgb: False\n",
      "character: 0123456789abcdefghijklmnopqrstuvwxyz\n",
      "sensitive: False\n",
      "PAD: False\n",
      "data_filtering_off: False\n",
      "Transformation: TPS\n",
      "FeatureExtraction: ResNet\n",
      "SequenceModeling: BiLSTM\n",
      "Prediction: Attn\n",
      "num_fiducial: 20\n",
      "input_channel: 1\n",
      "output_channel: 512\n",
      "hidden_size: 256\n",
      "num_gpu: 4\n",
      "num_class: 38\n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "\n",
    "import easydict\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "from utils import CTCLabelConverter, CTCLabelConverterForBaiduWarpctc, AttnLabelConverter, Averager\n",
    "from dataset import hierarchical_dataset, AlignCollate, Batch_Balanced_Dataset\n",
    "from model import Model\n",
    "from test import validation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import easydict\n",
    "global opt\n",
    "opt = easydict.EasyDict({\n",
    "    \"exp_name\": \"test_01\",\n",
    "    \"train_data\": \"/data/data/STARN/data_lmdb_release/training\",\n",
    "    \"valid_data\":\"/data/data/STARN/data_lmdb_release/validation\",\n",
    "    \"manualSeed\": 1111,\n",
    "    \"workers\": 16,\n",
    "    \"batch_size\":768,\n",
    "    \"num_iter\":300000,\n",
    "    \"valInterval\":1,\n",
    "    \"saved_model\":'',\n",
    "    \"FT\":False,\n",
    "    \"adam\":False,\n",
    "    \"lr\":1,\n",
    "    \"beta1\":0.9,\n",
    "    \"rho\":0.95,\n",
    "    \"eps\":1e-8,\n",
    "    \"grad_clip\":5,\n",
    "    \"baiduCTC\":False,\n",
    "    \"select_data\":'ST',\n",
    "    \"batch_ratio\":'1',\n",
    "    \"total_data_usage_ratio\":'0.01',\n",
    "    \"batch_max_length\":25,\n",
    "    \"imgW\":100,\n",
    "    \"imgH\":32,\n",
    "    \"rgb\":False,\n",
    "    \"character\":\"0123456789abcdefghijklmnopqrstuvwxyz\",\n",
    "    \"sensitive\":False,\n",
    "    \"PAD\":False,\n",
    "    \"data_filtering_off\":False,\n",
    "    \"Transformation\":\"TPS\",\n",
    "    \"FeatureExtraction\":\"ResNet\",\n",
    "    \"SequenceModeling\":\"BiLSTM\",\n",
    "    \"Prediction\":'Attn',\n",
    "    \"num_fiducial\":20,\n",
    "    \"input_channel\":1,\n",
    "    \"output_channel\":512,\n",
    "    \"hidden_size\":256    \n",
    "})\n",
    "\n",
    "\n",
    "def train(opt):\n",
    "    \"\"\" dataset preparation \"\"\"\n",
    "    if not opt.data_filtering_off:\n",
    "        print('Filtering the images containing characters which are not in opt.character')\n",
    "        print('Filtering the images whose label is longer than opt.batch_max_length')\n",
    "        # see https://github.com/clovaai/deep-text-recognition-benchmark/blob/6593928855fb7abb999a99f428b3e4477d4ae356/dataset.py#L130\n",
    "\n",
    "    opt.select_data = opt.select_data.split('-')\n",
    "    opt.batch_ratio = opt.batch_ratio.split('-')\n",
    "    print(\"찍어보기\")\n",
    "    print(opt,type(opt))\n",
    "    print(\"찍어보기 끝\")\n",
    "\n",
    "    train_dataset = Batch_Balanced_Dataset(opt)\n",
    "\n",
    "    log = open(f'./saved_models/{opt.exp_name}/log_dataset.txt', 'a')\n",
    "    AlignCollate_valid = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)\n",
    "    valid_dataset, valid_dataset_log = hierarchical_dataset(root=opt.valid_data, opt=opt)\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=opt.batch_size,\n",
    "        shuffle=True,  # 'True' to check training progress with validation function.\n",
    "        num_workers=int(opt.workers),\n",
    "        collate_fn=AlignCollate_valid, pin_memory=True)\n",
    "    log.write(valid_dataset_log)\n",
    "    print('-' * 80)\n",
    "    log.write('-' * 80 + '\\n')\n",
    "    log.close()\n",
    "    \n",
    "    \"\"\" model configuration \"\"\"\n",
    "    if 'CTC' in opt.Prediction:\n",
    "        if opt.baiduCTC:\n",
    "            converter = CTCLabelConverterForBaiduWarpctc(opt.character)\n",
    "        else:\n",
    "            converter = CTCLabelConverter(opt.character)\n",
    "    else:\n",
    "        converter = AttnLabelConverter(opt.character)\n",
    "    opt.num_class = len(converter.character)\n",
    "\n",
    "    if opt.rgb:\n",
    "        opt.input_channel = 3\n",
    "    model = Model(opt)\n",
    "    print('model input parameters', opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel,\n",
    "          opt.hidden_size, opt.num_class, opt.batch_max_length, opt.Transformation, opt.FeatureExtraction,\n",
    "          opt.SequenceModeling, opt.Prediction)\n",
    "\n",
    "    # weight initialization\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'localization_fc2' in name:\n",
    "            print(f'Skip {name} as it is already initialized')\n",
    "            continue\n",
    "        try:\n",
    "            if 'bias' in name:\n",
    "                init.constant_(param, 0.0)\n",
    "            elif 'weight' in name:\n",
    "                init.kaiming_normal_(param)\n",
    "        except Exception as e:  # for batchnorm.\n",
    "            if 'weight' in name:\n",
    "                param.data.fill_(1)\n",
    "            continue\n",
    "\n",
    "    # data parallel for multi-GPU\n",
    "    model = torch.nn.DataParallel(model).to(device)\n",
    "    model.train()\n",
    "    if opt.saved_model != '':\n",
    "        print(f'loading pretrained model from {opt.saved_model}')\n",
    "        if opt.FT:\n",
    "            model.load_state_dict(torch.load(opt.saved_model), strict=False)\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(opt.saved_model))\n",
    "    print(\"Model:\")\n",
    "    print(model)\n",
    "\n",
    "    \"\"\" setup loss \"\"\"\n",
    "    if 'CTC' in opt.Prediction:\n",
    "        if opt.baiduCTC:\n",
    "            # need to install warpctc. see our guideline.\n",
    "            from warpctc_pytorch import CTCLoss \n",
    "            criterion = CTCLoss()\n",
    "        else:\n",
    "            criterion = torch.nn.CTCLoss(zero_infinity=True).to(device)\n",
    "    else:\n",
    "        criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)  # ignore [GO] token = ignore index 0\n",
    "    # loss averager\n",
    "    loss_avg = Averager()\n",
    "\n",
    "    # filter that only require gradient decent\n",
    "    filtered_parameters = []\n",
    "    params_num = []\n",
    "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "        filtered_parameters.append(p)\n",
    "        params_num.append(np.prod(p.size()))\n",
    "    print('Trainable params num : ', sum(params_num))\n",
    "    # [print(name, p.numel()) for name, p in filter(lambda p: p[1].requires_grad, model.named_parameters())]\n",
    "\n",
    "    # setup optimizer\n",
    "    if opt.adam:\n",
    "        optimizer = optim.Adam(filtered_parameters, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "    else:\n",
    "        optimizer = optim.Adadelta(filtered_parameters, lr=opt.lr, rho=opt.rho, eps=opt.eps)\n",
    "    print(\"Optimizer:\")\n",
    "    print(optimizer)\n",
    "\n",
    "    \"\"\" final options \"\"\"\n",
    "    # print(opt)\n",
    "    with open(f'./saved_models/{opt.exp_name}/opt.txt', 'a') as opt_file:\n",
    "        opt_log = '------------ Options -------------\\n'\n",
    "        args = vars(opt)\n",
    "        for k, v in args.items():\n",
    "            opt_log += f'{str(k)}: {str(v)}\\n'\n",
    "        opt_log += '---------------------------------------\\n'\n",
    "        print(opt_log)\n",
    "        opt_file.write(opt_log)\n",
    "\n",
    "    \"\"\" start training \"\"\"\n",
    "    start_iter = 0\n",
    "    if opt.saved_model != '':\n",
    "        try:\n",
    "            start_iter = int(opt.saved_model.split('_')[-1].split('.')[0])\n",
    "            print(f'continue to train, start_iter: {start_iter}')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    start_time = time.time()\n",
    "    best_accuracy = -1\n",
    "    best_norm_ED = -1\n",
    "    iteration = start_iter\n",
    "\n",
    "    while(True):\n",
    "        # train part\n",
    "        image_tensors, labels = train_dataset.get_batch()\n",
    "        image = image_tensors.to(device)\n",
    "        text, length = converter.encode(labels, batch_max_length=opt.batch_max_length)\n",
    "        batch_size = image.size(0)\n",
    "\n",
    "        if 'CTC' in opt.Prediction:\n",
    "            preds = model(image, text)\n",
    "            preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
    "            if opt.baiduCTC:\n",
    "                preds = preds.permute(1, 0, 2)  # to use CTCLoss format\n",
    "                cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "            else:\n",
    "                preds = preds.log_softmax(2).permute(1, 0, 2)\n",
    "                cost = criterion(preds, text, preds_size, length)\n",
    "\n",
    "        else:\n",
    "            preds = model(image, text[:, :-1])  # align with Attention.forward\n",
    "            target = text[:, 1:]  # without [GO] Symbol\n",
    "            cost = criterion(preds.view(-1, preds.shape[-1]), target.contiguous().view(-1))\n",
    "\n",
    "        model.zero_grad()\n",
    "        cost.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), opt.grad_clip)  # gradient clipping with 5 (Default)\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_avg.add(cost)\n",
    "\n",
    "        # validation part\n",
    "        if (iteration + 1) % opt.valInterval == 0 or iteration == 0: # To see training progress, we also conduct validation when 'iteration == 0' \n",
    "            elapsed_time = time.time() - start_time\n",
    "            # for log\n",
    "            with open(f'./saved_models/{opt.exp_name}/log_train.txt', 'a') as log:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    valid_loss, current_accuracy, current_norm_ED, preds, confidence_score, labels, infer_time, length_of_data = validation(\n",
    "                        model, criterion, valid_loader, converter, opt)\n",
    "                model.train()\n",
    "\n",
    "                # training loss and validation loss\n",
    "                loss_log = f'[{iteration+1}/{opt.num_iter}] Train loss: {loss_avg.val():0.5f}, Valid loss: {valid_loss:0.5f}, Elapsed_time: {elapsed_time:0.5f}'\n",
    "                loss_avg.reset()\n",
    "\n",
    "                current_model_log = f'{\"Current_accuracy\":17s}: {current_accuracy:0.3f}, {\"Current_norm_ED\":17s}: {current_norm_ED:0.2f}'\n",
    "\n",
    "                # keep best accuracy model (on valid dataset)\n",
    "                if current_accuracy > best_accuracy:\n",
    "                    best_accuracy = current_accuracy\n",
    "                    torch.save(model.state_dict(), f'./saved_models/{opt.exp_name}/best_accuracy.pth')\n",
    "                if current_norm_ED > best_norm_ED:\n",
    "                    best_norm_ED = current_norm_ED\n",
    "                    torch.save(model.state_dict(), f'./saved_models/{opt.exp_name}/best_norm_ED.pth')\n",
    "                best_model_log = f'{\"Best_accuracy\":17s}: {best_accuracy:0.3f}, {\"Best_norm_ED\":17s}: {best_norm_ED:0.2f}'\n",
    "\n",
    "                loss_model_log = f'{loss_log}\\n{current_model_log}\\n{best_model_log}'\n",
    "                print(loss_model_log)\n",
    "                log.write(loss_model_log + '\\n')\n",
    "\n",
    "                # show some predicted results\n",
    "                dashed_line = '-' * 80\n",
    "                head = f'{\"Ground Truth\":25s} | {\"Prediction\":25s} | Confidence Score & T/F'\n",
    "                predicted_result_log = f'{dashed_line}\\n{head}\\n{dashed_line}\\n'\n",
    "                for gt, pred, confidence in zip(labels[:5], preds[:5], confidence_score[:5]):\n",
    "                    if 'Attn' in opt.Prediction:\n",
    "                        gt = gt[:gt.find('[s]')]\n",
    "                        pred = pred[:pred.find('[s]')]\n",
    "\n",
    "                    predicted_result_log += f'{gt:25s} | {pred:25s} | {confidence:0.4f}\\t{str(pred == gt)}\\n'\n",
    "                predicted_result_log += f'{dashed_line}'\n",
    "                print(predicted_result_log)\n",
    "                log.write(predicted_result_log + '\\n')\n",
    "\n",
    "        # save model per 1e+5 iter.\n",
    "        if (iteration + 1) % 1e+5 == 0:\n",
    "            torch.save(\n",
    "                model.state_dict(), f'./saved_models/{opt.exp_name}/iter_{iteration+1}.pth')\n",
    "\n",
    "        if (iteration + 1) == opt.num_iter:\n",
    "            print('end the training')\n",
    "            sys.exit()\n",
    "        iteration += 1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    if not opt.exp_name:\n",
    "        opt.exp_name = f'{opt.Transformation}-{opt.FeatureExtraction}-{opt.SequenceModeling}-{opt.Prediction}'\n",
    "        opt.exp_name += f'-Seed{opt.manualSeed}'\n",
    "        # print(opt.exp_name)\n",
    "\n",
    "    os.makedirs(f'./saved_models/{opt.exp_name}', exist_ok=True)\n",
    "\n",
    "    \"\"\" vocab / character number configuration \"\"\"\n",
    "    if opt.sensitive:\n",
    "        # opt.character += 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "        opt.character = string.printable[:-6]  # same with ASTER setting (use 94 char).\n",
    "\n",
    "    \"\"\" Seed and GPU setting \"\"\"\n",
    "    # print(\"Random Seed: \", opt.manualSeed)\n",
    "    random.seed(opt.manualSeed)\n",
    "    np.random.seed(opt.manualSeed)\n",
    "    torch.manual_seed(opt.manualSeed)\n",
    "    torch.cuda.manual_seed(opt.manualSeed)\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True\n",
    "    opt.num_gpu = torch.cuda.device_count()\n",
    "    # print('device count', opt.num_gpu)\n",
    "    if opt.num_gpu > 1:\n",
    "        print('------ Use multi-GPU setting ------')\n",
    "        print('if you stuck too long time with multi-GPU setting, try to set --workers 0')\n",
    "        # check multi-GPU issue https://github.com/clovaai/deep-text-recognition-benchmark/issues/1\n",
    "        opt.workers = opt.workers * opt.num_gpu\n",
    "        opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "\n",
    "        \"\"\" previous version\n",
    "        print('To equlize batch stats to 1-GPU setting, the batch_size is multiplied with num_gpu and multiplied batch_size is ', opt.batch_size)\n",
    "        opt.batch_size = opt.batch_size * opt.num_gpu\n",
    "        print('To equalize the number of epochs to 1-GPU setting, num_iter is divided with num_gpu by default.')\n",
    "        If you dont care about it, just commnet out these line.)\n",
    "        opt.num_iter = int(opt.num_iter / opt.num_gpu)\n",
    "        \"\"\"\n",
    "\n",
    "    train(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf583acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
